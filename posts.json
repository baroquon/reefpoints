{"tags":[{"name":"Announcement","id":"announcement"},{"name":"Mobile","id":"mobile"},{"name":"Mobile Web","id":"mobile-web"},{"name":"Opinion","id":"opinion"},{"name":"JavaScript","id":"javascript"},{"name":"Office","id":"office"},{"name":"Ruby on Rails","id":"rails"},{"name":"Gems","id":"gems"},{"name":"Design Patterns","id":"design-patterns"},{"name":"Testing","id":"testing"},{"name":"Code Guidelines","id":"code-guidelines"},{"name":"Linux","id":"linux"},{"name":"Workflow","id":"workflow"},{"name":"Backbone.js","id":"backbone"},{"name":"jQuery","id":"jquery"},{"name":"PostgreSQL","id":"postgres"},{"name":"Community","id":"community"},{"name":"Business","id":"business"},{"name":"Consulting","id":"consulting"},{"name":"Ember Libraries","id":"ember-libraries"},{"name":"Products","id":"products"},{"name":"Design","id":"design"},{"name":"Ember.js","id":"ember"},{"name":"Job","id":"job"},{"name":"Training","id":"training"},{"name":"Intern","id":"intern"},{"name":"Ruby","id":"ruby"},{"name":"Context Validation","id":"context-validation"},{"name":"Postgres_ext","id":"postgres_ext"},{"name":"Vim","id":"vim"},{"name":"Illustration","id":"illustration"},{"name":"Art","id":"art"},{"name":"Postgis","id":"postgis"},{"name":"Postgres_ext-postgis","id":"postgres_ext-postgis"},{"name":"ES6","id":"es6"},{"name":"Design Process","id":"design-process"},{"name":"Inspiration","id":"inspiration"},{"name":"Best Practices","id":"best-practices"},{"name":"Design Thinking","id":"design-thinking"},{"name":"User Experience","id":"user-experience"},{"name":"Process","id":"process"},{"name":"Agile","id":"agile"},{"name":"Swift","id":"swift"},{"name":"Conferences","id":"conferences"},{"name":"Prototyping","id":"prototyping"},{"name":"Ember-cli","id":"ember-cli"},{"name":"Experiments","id":"experiments"},{"name":"Project Management","id":"project-management"},{"name":"Planning","id":"planning"},{"name":"Engineering","id":"engineering"},{"name":"Html","id":"html"},{"name":"Css","id":"css"},{"name":"Observations","id":"observations"},{"name":"Storytelling","id":"storytelling"},{"name":"Information Graphics","id":"information-graphics"},{"name":"Quality","id":"quality"},{"name":"Ux East","id":"ux-east"},{"name":"Tools","id":"tools"},{"name":"Marketing","id":"marketing"},{"name":"Ux Camp","id":"ux-camp"},{"name":"Htmlbars","id":"htmlbars"},{"name":"Elixir","id":"elixir"},{"name":"Privacy","id":"privacy"},{"name":"Culture","id":"culture"},{"name":"Team","id":"team"},{"name":"Interaction","id":"interaction"},{"name":"Native Web","id":"native-web"},{"name":"Broccoli","id":"broccoli"},{"name":"Ux Design","id":"ux-design"},{"name":"Research","id":"research"},{"name":"Discovery","id":"discovery"},{"name":"Automation","id":"automation"},{"name":"Lean","id":"lean"},{"name":"Addon","id":"addon"},{"name":"Benchmarking","id":"benchmarking"},{"name":"Phoenix","id":"phoenix"},{"name":"Components","id":"components"},{"name":"Color","id":"color"},{"name":"Pattern","id":"pattern"},{"name":"Repeat Pattern","id":"repeat-pattern"},{"name":"Creativity","id":"creativity"},{"name":"Design Sprints","id":"design-sprints"},{"name":"Design Strategy","id":"design-strategy"},{"name":"New Hire","id":"new-hire"},{"name":"Data Visualization","id":"data-visualization"},{"name":"Conference","id":"conference"},{"name":"Ecto","id":"ecto"},{"name":"Continuous Integration","id":"continuous-integration"},{"name":"Travis Ci","id":"travis-ci"},{"name":"Deployment","id":"deployment"},{"name":"Postcss","id":"postcss"},{"name":"Til","id":"til"},{"name":"Product Management","id":"product-management"},{"name":"Development","id":"development"},{"name":"Presence","id":"presence"},{"name":"Fastboot","id":"fastboot"},{"name":"Security","id":"security"},{"name":"Services","id":"services"},{"name":"Single Page Applications","id":"single-page-applications"},{"name":"Alumni","id":"alumni"},{"name":"Announcements","id":"announcements"},{"name":"Git","id":"git"},{"name":"Channels","id":"channels"},{"name":"Action Cable","id":"action-cable"},{"name":"Open Source","id":"open-source"},{"name":"Pwa","id":"pwa"},{"name":"Press-release","id":"press-release"},{"name":"Ets","id":"ets"},{"name":"Progressive Web Apps","id":"progressive-web-apps"},{"name":"Authorization","id":"authorization"},{"name":"Ux","id":"ux"}],"posts":[{"title":"DockYard is launched!","tags":["announcement"],"summary":null,"legacy":false,"illustration_alt":"Hoo-ray!","illustration":"https://i.imgur.com/oRUq9T6.jpg","id":"2011/08/24/launch","employee":"Brian Cardarella","date":"2011-08-24T00:00:00","body":"\n\nDockYard has officially launched!\n\nHoo-ray!\n\n![Hoo-ray!](https://i.imgur.com/oRUq9T6.jpg)\n"},{"title":"Mobile Web Apps Still Have Some Major Hurdles","tags":["mobile","mobile web"],"summary":"Brian summarizes DockYard's experience thus far with mobile web apps and some of the existing challenges to compete with native","legacy":false,"id":"2011/11/10/mobile-web-apps","employee":"Brian Cardarella","date":"2011-11-10T00:00:00","body":"\n\nOver the past 24 hours I've seen several articles ([1](http://venturebeat.com/2011/11/09/mobile-web/),[2](http://www.guardian.co.uk/technology/blog/2011/nov/03/will-html5-replace-native-apps)) on [Hacker News](http://news.ycombinator.com)\npredicting that in the near future mobile web apps are going to\nreplace their native counterparts. Here at DockYard we really hope this\nhappens. We believe in the mobile web and have decided forego regular\nweb application development in favor of focusing on mobile web\napplication development. However, experience has told us the future is not as nigh as we\nall hope.\n\nNative applications (iOS, Android, etc.) still have and will continue\nto have some significant advantages over mobile web apps. Let's start\nwith the obvious...\n\n### Native functionality ###\n\nHaving access to mobile hardware such as the camera, microphone, and\nstorage (file system, internal datbases, etc...) is important. There is also the issue\nof running the application in the background. None of this is currently\npossible in a mobile web application. Immediately the scope of a mobile\nweb application is much smaller.\n\nThe [W3C has a working draft of what a media capture API should\nbe](http://www.w3.org/TR/html-media-capture/). It may be a\nmatter of time until we see mobile browsers begin to provide access to\nthis native functionality. Personally, I would like to see this API\ndeveloped further. In its current form it is simply a delegator API to\nthe camera and microphone applications. We hand off application control and wait for a\ncallback that has the list of media just captured. This is not good\nenough. How can a mobile web application compete with the many\ndifferent native camera applications that exist with custom camera\nfunctionality if there is no way to\ncustomize the camera experience? Simple: it can't. Augmented reality\nmobile web application? Nope. What about something as simple as skinning\nthe camera? Not with the current working draft of the MediaCapture API.\n\nMost mobile web browsers implement the HTML canvas element. So mobile\nweb gaming is possible. But what we really want is hardware accelerated\nWebGL. It's not here yet. We're still waiting for the desktop\ncanvas apps to close the gap between their native desktop counterparts.\nMobile web gaming will not be competing with native mobile gaming\nanytime soon.\n\n### Performance ###\n\nNative is the clear winner here but with each new generation of phone\nhardware the lead is becoming less noticeable. In fact, I'm going to\npredict that in the 2nd half of 2012 (iPhone5, assuming Apple goes back\nto the previous iPhone release cycle) for everything\nexcept gaming, the difference will be negligible.\n\nWe're getting closer and closer to the point of convergence. Hardware is\ngetting faster, JavaScript VMs are getting faster. Native and mobile web\napps will never be equally as fast, native will **always** be faster.\nWith each generation of mobile hardware we will care less because the gap will continue to get asymptotically\nsmaller.\n\nThis current performance gap can be felt most with [jQuery\nMobile](http://jquerymobile.com). We use jQuery Mobile, we believe in\nit. On the latest iPhone 4S there is still a noticeable lag when\ndoing page trasitions, even on mobile web applications that have very few\npages of low complexity. The page enhancement algorithm does **a lot** of\nDOM manipulation and hoop jumping. Elements are pulled out of the DOM,\nwrapped, reinserted. In the end it allows us to\nprovide very little markup and get some beautiful results.\n\nAs of this writing jQuery Mobile is in 1.0 Release Candidate 2. On the bucket\nlist for 1.0 Gold is a [performance boost for page enhancement](https://github.com/jquery/jquery-mobile/issues/2853).\n[Most likely this will only have an effect upon very complex pages](https://twitter.com/#!/jquerymobile/status/133670336318291969).\nClosing the performance gap on jQuery Mobile is going to be a watershed\nmoment for mobile web application development.\n\n### Distribution ###\n\nNothing beats the web as a distribution platform. Every time I use a web\napp I am on the latest version of that app. If there are any business\ncritical updates they are immediately available for everybody. Native\nmobile applications are at a clear disadvantage here. We're comparing a\npassive opt-in system to an active apt-in system.\n\nOne disadvantage (for now) that mobile web applications have is\naccessibility after distribution. Native apps default to installing on\nyour phone, mobile web applications do not. Yes, you can save links to\nthe mobile web app and make it appear you have it installed. But what\nabout off-line mode?\n\n### Discovery ###\n\nI'm going to argue that native applications win here. Finding a native\nmobile application is easier than finding a mobile web application.\nGoogle has made a large dent for the web with Chrome's Omnibar. (btw,\nwhy hasn't everybody copied the omnibar? This should be the default for mobile\nweb browsers, screen real estate is already at a premium.)\n\nThat being said, discovery for native is not great. We've\nall see the studies where the Top 10 apps have a significantly skewed\ndownload rate compared to the below Top 10. This is be expected. I don't\nunderstand why the mobile app stores have not put more effort into\nperfecting discovery. I'm more likely to purchase an application that I\nlike if I can find it easily.\n\n### PhoneGap (Apache Callback) ###\n\nIf you've made it this far you've probably been yelling at your screen\n\"**PhoneGap!**\" to several of the points I've made above. Yes, PhoneGap solves many of these problems. But how do\nwe define a PhoneGap application? The technology stack I'm using is that\nof a mobile web application: HTML, CSS, JavaScript. However, the\ndistribution and discovery systems I am using are that of a native\napplication. PhoneGap application straddle the fence between the two\nworlds.\n\nFor those that don't know, PhoneGap extends a WebUI. It will add certain\nfunctionality to the JavaScript API. Access to the camera, microphone,\nfile system [as well as many other wonderful features](http://docs.phonegap.com/en/1.2.0/index.html).\nThe PhoneGap developers were smart, they saw the W3C's proposed API for\nsome of this and modeled the PhoneGap API after it. In fact, PhoneGap\nshould acts as a polyfill if certain functionality already exists.\n\nFrom a developer's point of view, PhoneGap in most cases should be a no\nbrainer. I am most likely developing a web site alongside the mobile\napplication. The website is likely going to be sharing the\nfunctionality of the mobile application. It makes sense if my\nmobile application can share a technology stack with my web application.\nI don't have to employ a separate team to develop the mobile\napplication, and if you want to target more than one mobile platform\nyou'll most likely have to employ more than one team.\n\nFrom our perspective PhoneGap gives us a\nhuge advantage. Why pay two teams to develop the same application when you\npay us once? Then when we hand off the team maintaining and developing\nyour website can also maintain and develop the mobile application. It's\na no-brainer. In most cases.\n\nThere are some serious issues with the PhoneGap project. The first of\nwhich is the difficulty in reporting errors. This will hopefully change\nnow that the project is under Apache (as [Apache Callback](http://wiki.phonegap.com/w/page/46311152/apache-callback-proposal))\nbut the project has been split into different Github repos for each\nplatform. So there is one for [iOS](https://github.com/phonegap/phonegap-iphone), [Android](https://github.com/phonegap/phonegap-android), [Windows Phone 7](https://github.com/phonegap/phonegap-wp7), [BlackBerry](https://github.com/phonegap/phonegap-blackberry-webworks), [WebOS](https://github.com/phonegap/phonegap-webos), etc... they are all under separate development with very dedicated teams. If I find a common problem that affects all platforms (for example, [a suggestion I proposed on how PhoneGap currently implements its File API](https://github.com/phonegap/phonegap-iphone/issues/280)) I have to report this issue individually on each platform. This is a very inefficient process.\n\nThe second is the same issue stated above with the camera. While PhoneGap does give us the access to the camera we are still stuck\nwith the same experience we will have with the W3C MediaCapture API: no\ncamera customization, this is just a delegation with a callback. You can\nhack together the camera experience you want if decide to write some\nnative code.\n\nThe third is lack of any background processing. When I throw my PhoneGap\napp into the background it does nothing. It would be nice if we could\nget a callback in the PhoneGap API that allowed us to kick off function\nif the app is sent to the background. When it is up front again give us\nanother callback to halt the previous function.\n\n[Check out the \"Limitations\" section on the PhoneGap wiki for some\nothers](http://wiki.phonegap.com/w/page/36752779/PhoneGap%20Plugins).\n\nPhoneGap is fantastic (despite some of the criticism I've stated). We have\nhigh hopes for the project now that it is accepted into Apache.\n\n## Conclusion ##\n\nPerhaps [Adobe's announcement that they are abandoning Flash in\nfavor of HTML5 for mobile](http://techland.time.com/2011/11/09/mobile-flash-abandoned-for-html5-adobe-surrenders-apple-wins/?iid=tl-main-lede) will be seen as the turning point when\nmobile web application development begins to be a serious contender to\nnative. Or maybe it is just a coincidence that this buzz is happening\nall at once. Either way, we're happy\npeople are talking about this. Discussions, arguments, and all of the\nattention in between are the best way to push this technology into the\nfuture we all know is just a matter of time.\n\nAs my friend [Pascal Rettig](http://twitter.com/cykod) says: It is a great time to be a web developer.\n"},{"title":"GitHub Is One Commit Away From Being The Ultimate Blog Engine","tags":["opinion"],"summary":null,"legacy":false,"id":"2011/11/14/github-is-one-commit-away-from-being-the-ultimate-blog-engine","employee":"Brian Cardarella","date":"2011-11-14T00:00:00","body":"\n\nThis past August [GitHub released file editing using the Ace code\neditor](https://github.com/blog/905-edit-like-an-ace). It's pretty damn\nawesome if you haven't tried it. Basically, you get\n[TextMate](http://macromates.com) in your\nbrowser. Here at [DockYard](https://dockyard.com) we've been using\n[GitHub Pages](http://pages.github.com/) to host this blog. The posts\nare written in [Jekyll](https://github.com/mojombo/jekyll). So we're\ndoing all of our post creation and editing locally.\n\n## The Dream ##\n\nIt would be great if GitHub allowed us to create new [blobs](http://book.git-scm.com/1_the_git_object_model.html) from the web interface.\nAt that point GitHub would be a full-service blog engine. Think about it, they already do the\nhosting, version tracking, and editing of files through the web\ninterface. If file creation was added that's pretty much all I would\nwant. ([Jekyll has a way to track drafts by setting the `published`\nflag](https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter))\n\nSo if anybody at GitHub is reading, can we please have this feature?\n"},{"title":"I Don't Give A Shit About Your Pitch","tags":[],"summary":null,"legacy":false,"illustration_alt":"Spock Pitch","illustration":"/images/spockpitch.png","id":"2011/11/14/i-dont-give-a-shit-about-your-pitch","employee":"Brian Cardarella","date":"2011-11-14T00:00:00","body":"\n\n![Spock Pitch](/images/spockpitch.png)\n\nI like going to Boston Technology Social events for three reasons:\n\n1. I live in Boston\n2. I like talking about technology\n3. I'm a social person and I enjoy meeting new people\n\nLately, there has been a growing trend. I can see it coming from a mile\naway. The shoulders go back, the stance widens, the pupils dialate. **Oh\nfuck, I'm about to get pitched to.** I come away feeling violated, I want\nto take shower. But I know it's just going to happen again and again.\n\nThis is not a Boston problem, but I suspect it is a tech problem. I\ncannot go to a tech event any more and expect to have actual\nconversations with people. It's true that when you're making new\nconnections sometimes the conversation is just small talk, but it seems\nthe (self appointed) entrepreneures have decided that any opportunity to\npractice their pitch is a good one.\n\n![Fight Club](/images/fightclub.png)\n\nI blame the incubators for this. Last year I went to [TechStars For A\nDay](http://www.techstars.com/techstars-for-a-day/). It was terrible. Terrible enough to get me to pull my submission. (in retrospect it didn't have a chance) \nPeople lined up to speak to the mentors, pitch, move to the next person.\nThe experience was dehumanizing. But I can see how people come out of it\nthinking they need to perfect their pitch. Mostly because that message\nis drilled into your head. The only thing between you and millions of dollars is **the perfect pitch**.\n\nI want to talk to people, not to a robot, not to a walking\nadvertisement. Nailing that pitch is not going to \n"},{"title":"Where Are The Killer Mobile Apps?","tags":[],"summary":null,"legacy":false,"id":"2011/11/14/where-are-the-killer-mobile-apps","employee":"Brian Cardarella","date":"2011-11-14T00:00:00","body":"\n\nEvery platform should have the [Killer App](http://en.wikipedia.org/wiki/Killer_application) The [AppleII](http://en.wikipedia.org/wiki/Apple_II) had [VisiCalc](http://en.wikipedia.org/wiki/VisiCalc), 3D accelerated hardware had [Quake](http://en.wikipedia.org/wiki/Quake_(video_game)), and the [XBox](http://en.wikipedia.org/wiki/Xbox) had [Halo](http://en.wikipedia.org/wiki/Halo_(series)) (just some examples of killer apps). Are we to believe that games such as [Angry Birds](http://en.wikipedia.org/wiki/Angry_Birds) and [Fruit Ninja](http://en.wikipedia.org/wiki/Fruit_Ninja) are the **true** Killer Apps for mobile?\n\n## I don't think so ##\n\nIMO a killer app must provide a reason for you to purchase the hardware.\nThe software is so good, something that you cannot obtain on any other\nplatform that you will shell out a few hundred dollars to purchase the\nentire system. Even though I see many people playing these games on\ntheir mobile phone I find it hard to believe they bought their mobile\nphones for the purpose of any one of these games.\n\n## The platform of the future ##\n\nIn a [recent Fast Company interview, Bill Nguyen spoke about the \"post-PC\nworld\"](http://www.fastcompany.com/magazine/160/bill-nguyen-startups).\nIn summary:\n\n> When Steve [Jobs] describes the post-PC world, all the things that were written in the PC world are almost doomed to fail. Everything that Facebook built as a technology was based on old technology. It was all around this premise that you'll sit in front of this machine that has no idea who you are, so you have to tell it--who you are and what you like.\n\n> IBM didn't survive the PC, none of the PC guys survived the web, and I don't think any of the web guys will survive the post-PC world\n\nNow, if you ignore some of the bullshit Bill is spouting (as the article\npoints out, IBM is a $100-billion-a-year company) I think there is\nactually some substance here. Each technology company developers\nproducts in the age they are in. Then they get big and it becomes\ndifficult for them to adapt. In some cases, they don't want to adapt as\nthat implies risk. For a company making billions of dollars, why would\nthey want to take on any risk? It doesn't make sense. So when the\nstate-of-the-art moves forward there becomes opportunity for disruption.\nWe're currently in the beginning of this \"Post-PC world\".\n\n## If there is no killer app then why do I have a phone? ##\n\nThat's a good question. When I think about what defines my experience as\na mobile user I come up with: email, Twitter, maps, and phone calls. In\nthat order. I'm sure it is different for many people but these are my\nreasons. To be perfectly honest, maps is the only item that is not better on my\nPC.\n\nEmail and Twitter I can lump together, typing on my keyboard vs typing\non my iPhone is no-contest. However, with the recent release of Siri it\nmight be heading back in the other direction. Dictating emails is\nactually pretty good. I would really like to be able to tell Siri:\n\n> Tweet at somebody: How is it going?\n\nConsidering that Twitter is integrated into iOS 5 I do not understand\nwhy this was not added.\n\nMaking phone calls on my phone is actually not very good. AT&T still\ndrops calls, and the voice quality is terrible. I usually just VoIP all\nimportant calls from my gMail account.\n\nGeolocating myself with maps and getting directions is great. Of course\nhis is better than the PC.\n\n## And that's the point ##\n\nMaps are a better experience on my phone because they make use of\nseveral technologies that my PC does have: GPS and compass.\n\nWhatever the killer for mobile ends up being it is going to make use of\nthe unique technology available. I suspect most developers are just now\nstarting to get their head out of the box of the stationary apps.\n"},{"title":"Convert Ruby Regexp to JavaScript RegExp","tags":["javascript"],"summary":"A simple extraction from ClientSideValidations","legacy":false,"id":"2011/11/18/convert-ruby-regexp-to-javascript-regex","employee":"Brian Cardarella","date":"2011-11-18T00:00:00","body":"\n\nThis has a very limited use case, but I needed it for\n[ClientSideValidations](http://github.com/bcardarella/client_side_validations). It took a while\nto track down some of the possible conversion issues, I figure someone\nelse might find this useful.\n\n```ruby\nclass Regexp\n  def to_javascript\n    Regexp.new(inspect.sub('\\\\A','^').sub('\\\\Z','$').sub('\\\\z','$').sub(/^\\//,'').sub(/\\/[a-z]*$/,'').gsub(/\\(\\?#.+\\)/, '').gsub(/\\(\\?-\\w+:/,'('), self.options).inspect\n  end\nend\n```\n\nWhen you render it to the client simply instantiate a new `RegExp`\nobject with the resulting string:\n\n```javascript\nnew RegExp(regexpStringFromRuby);\n```\n\nIf there are any edge-cases that won't convert cleanly please report\nthem in the comments.\n\nSee how it is being used in `ClientSideValidations` [to_json](https://github.com/bcardarella/client_side_validations/blob/master/lib/client_side_validations/core_ext/regexp.rb)\n[tests cases](https://github.com/bcardarella/client_side_validations/blob/master/test/core_ext/cases/test_core_ext.rb)\n"},{"title":"It's Not A Vacation","tags":["office"],"summary":null,"legacy":false,"illustration_alt":"Ocean State","illustration":"https://i.imgur.com/j46sVqU.jpg","id":"2011/12/04/its-not-a-vacation","employee":"Brian Cardarella","date":"2011-12-04T00:00:00","body":"\n\n### DockYard is invading The Ocean State! ###\n\n![Ocean State](https://i.imgur.com/j46sVqU.jpg)\n\nThere is one annoying issue working with a remote team:\nEverybody is remote. There is something lost when you don't get to see the people you're working with.\nApps like Skype have made a difference how remote work is done. We're\nnot any less productive, but it's difficult to grab drinks with co-workers\nwhen they're 2 hours away.\n\nTo that end we've decided to work from a city for a week once every\nfew months. We'll pack up, grab a hotel, and lock ourselves in a coffee\nshop to get a crazy amount of work done. Our girlfriends and wives\nmight disagree but we're calling this: **It's Not A Vacation**\n\nWe're very serious about this, the entire week is a dedicated work week.\nWe've set some ambitious goals for our client applications and we're\nall pretty fired up to get going. There is something interesting that\nhappens to productivity with you shake things up.\n\nThis is of course all experimental so I'll write a follow up at the end\nof the week on how things went.\n"},{"title":"It's Not A Vacation Follow Up","tags":["office"],"summary":null,"legacy":false,"illustration_alt":"Dan Pickett & Russ Jones","illustration":"https://i.imgur.com/4oG6ECL.jpg","id":"2012/01/04/its-not-a-vacation-follow-up","employee":"Brian Cardarella","date":"2012-01-04T00:00:00","body":"\n\nWe have been pretty busy here at DockYard and I haven't had a chance to\nfollow up on the [previous post](/2011/12/04/its-not-a-vacation.html)\n\nTo recap: DockYard is a distributed team, we decided to switch it up for\na week and go to the same city and work our asses off.\n\nResult: We kicked ass.\n\n![Dan Pickett & Russ Jones](https://i.imgur.com/4oG6ECL.jpg)\n\nThe city we chose to work from for the week is Providence, RI. It was\nclose enough most of the team to not be expensive to travel to yet far\nenough away to necessitate not going home each night. On top of that,\nProvidence is a very affordable city and it has a tech scene that is\nstarting to take off.\n\n![Tazza Cafe](https://i.imgur.com/nBZMrGO.jpg)\n\nFor the week we worked from [Tazza Cafe](http://tazzacaffe.com) and I\nhave only the highest praise for the atmosphere, the food, and the\nstaff. Free wi-fi, never too crowded, amazing food selection, and some\nof the friendliest wait staff I've ever seen at anywhere. If you in the\narea, or just passing through, I highly recommend stopping in.\n\nThe progress we made during the week was pretty amazing. This type of\nwork is only possible with a great team. We were\nfortuante enough to be joined by [Dan\nPickett](http://enlightsolutions.com) along with the DockYard regulars\nof [Angelo Simeoni](http://cssboy.com), [Russ\nJones](http://codeofficer.com), and myself.\n\n![Downtown Providence](https://i.imgur.com/eGkHJxu.jpg)\n\nDuring the week we got to meet many from the local tech scene. Monday\nnight we crashed a [Betaspring](http://betaspring) event and Thursday we\nhosted our own Providence Pub Crawl hitting [AS220](http://as220.org/),\n[Trinity Brewhouse](http://www.trinitybrewhouse.com), Union Station\nBrewery, [Rira](http://www.trinitybrewhouse.com), and ending up at\nTazza. It was a great way to end a great week. We'll be doing this again\nin the future.\n"},{"title":"ClientSideValidations goes modular","tags":["rails","gems"],"summary":"Brian summarizes the changes to come in ClientSideValidations 3.2.0","legacy":false,"id":"2012/01/22/client-side-validations-goes-modular","employee":"Brian Cardarella","date":"2012-01-22T00:00:00","body":"\n\n[ClientSideValidations](https://github.com/bcardarella/client_side_validations) has been gaining popularity over the past few\nmonths as it is nearing 1000 watchers on Github. With the release of\nRails 3.2.0 I've decided to start extracting out all of the non-Rails\ncomponents, such as SimpleForm support and Mongoid support, into their\nown gems. I want to disucss my reasons for doing this as I believe this\npath of modularity is going to mean better gem maintenance, more frequent\nreleases, and the opportunity for the community to really get involved.\n\nLast night I released ClientSideValidations-3.2.0.beta.1 and I have extracted the following into their own gems:\n\n##### ORMs #####\n\n* [ClientSideValidations-Mongoid](https://github.com/dockyard/client_side_validations-mongoid)\n* [ClientSideValidations-MongoMapper](https://github.com/dockyard/client_side_validations-mongo_mapper)\n\n##### FormBuilders #####\n\n* [ClientSideValidations-Formtastic](https://github.com/dockyard/client_side_validations-formtastic)\n* [ClientSideValidations-SimpleForm](https://github.com/dockyard/client_side_validations-simple_form)\n\n\n## Going Modular ##\n\nThe problem with keeping support for the many different ORMs and\nFormBuilders in the ClientSideValidations gem is that there are just too\nmany dependencies doing different things. A great example is with\nMongoid and [ClientSideValidations Issue #253](https://github.com/bcardarella/client_side_validations/issues/253).\nMongoid `2.4.0` added a [PresenceValidator](https://github.com/mongoid/mongoid/blob/2.4.0-stable/lib/mongoid/validations/presence.rb) instead of using\nthe ActiveModel version. This caused translations to fail as they were\nbeing served up directly from Mongoid instead of ActiveModel. I could\nhave fixed this easily in ClientSideValidations but now this means all\nfuture releases would require anyone using a version of Mongoid previous\nto this change to upgrade. There are many reason why you may not want to\nupgrade Mongoid, none of which are my business.\n\nPulling the Mongoid code out into its own plugin allows this bug to be\nfixed there and I can continue to do bug fixes/feature development in\nClientSideValidations that everyone can benefit from.\n\n## More than just SemVer ##\n\nThe versions of the plugins now matter. I've decided to\nmatch the library they are supporting's Major and Minor version. For\nexample, with Mongoid the current version is `2.4.x` so the current\nversion of [ClientSideValidations-Mongoid](https://github.com/dockyard/client_side_validations-mongoid)\nis `2.4.0`. All bug fixes for this version will only bump the patch\nversion. We can then go back and add a `2.3.0` version that does not\nexpect a Mongoid PresenceValidator and you won't need to change the\nversion of ClientSideValidations. Simple enough stuff, but it gives the\nlibrary a lot of flexibility.\n\n## Community Support ##\n\nI won't go back and cover every single Major/Minor\nrelease of the different gems. I'm starting with the current versions\nand going to look to the community to send pull-requests to fill in the\ngaps.\n\nWith these ORM and FormBuilder gems the community should have a good\nstarting point for writing their own ClientSideValidations plugins.\n\nIf someone is looking for a good starting point to build a gem you can\nstart with NestedForm as this is a gem that I did not extract and its\nsupport was dropped.\n\nIn addition, I'm looking for help. It would be nice to get some\nmaintainers on the plugins but I'm also looking for someone to lend a\nhand with ClientSideValidations.\n\n## When will it be released? ##\n\nI've got a bunch of [issues in\nClientSideValidations](https://github.com/bcardarella/client_side_validations/issues) I want to fix, I'm\nguessing maybe a week or two to get through all of these. I'll go\nthrough a few `beta` gems then a release candidate or two. I am always open to community contributions. If you want to help, please do!\n\nYou can start using this today with the beta version. All of the plugins\nrequire the beta version of ClientSideValidations 3.2.0.\n\n## The Future ##\n\nRails `3.2.0` will be the last `3.x` version of Rails, and so this will\nalso be the last `3.x` version of ClientSideValidations. Work is already\nunderway on the `4.x` version. One of the biggest changes is going to\nhappen on the JavaScript side. Client-side model validations will be the\ngoal. As well as compostite views for the error rendering. Ideally I\nwould like ClientSideValidations to be able to hook into the popular\nJavaScript MVC frameworks.\n"},{"title":"Angelo Simeoni is a DockYarder!","tags":["office"],"summary":"DockYard welcomes Angelo Simeoni as a partner","legacy":false,"illustration_alt":"Angelo Simeoni","illustration":"https://i.imgur.com/DUKUM7V.png","id":"2012/02/10/angelo-simeoni-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-02-10T00:00:00","body":"\n\n![Angelo Simeoni](https://i.imgur.com/DUKUM7V.png)\n\nI first met Angelo when we both worked at [zendesk](http://zendesk.com) two years ago. I had heard about him before this as he had done some redesigns for [The Boston Ruby Group](http://bostonrb.org) website. Over the few months that zendesk was in Boston we got to be friends, and when we both left zendesk I knew this was someone I wanted to work with again in the future. That opportunity came when I moved back to Boston in the summer of 2010. For the past year Angelo and I have been collaborating on several projects and I'm happy to announce that he has agreed to come on as a partner for DockYard.\n\nAngelo has been working in Rails for a few years now, and is a master of\nall things CSS. His love for typefaces has influenced me quite a bit in\nhow I approach web design.\n\nYou can view a lot of Angelo's work over at his personal site:\n[CSSBoy](http://cssboy.com).\n\n[Follow Angelo on Twitter](http://twitter.com/cssboy)\n"},{"title":"Russ Jones is a DockYarder!","tags":["office"],"summary":"DockYard welcomes Russ Jones as a partner","legacy":false,"illustration_alt":"Russ Jones","illustration":"https://i.imgur.com/9AZ94dd.png","id":"2012/02/10/russ-jones-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-02-10T00:00:00","body":"\n\n![Russ Jones](https://i.imgur.com/9AZ94dd.png)\n\nRuss and I met during the first [Rails Camp New\nEngland](http://railscamps.com). Over the past few years we've gotten to know one another and have been looking to collaborate as developers. Last March Russ, myself, and a few others, got together to talk about the possibility of starting our own consultancy. Since getting a bunch of freelancers on the same schedule is difficult, it wasn't until 8 months later that I was finally able to bring Russ in on a project.\n\nRuss has been developing in Rails since 2006, but has been focusing most of his recent development efforts on the client. When we joined up he immediately took ownership of a mobile web application, bringing some sanity to a combination of Phonegap, jQueryMobile and Backbone. He's already released a few open source projects for DockYard: [jquery-backbone](https://github.com/dockyard/jquerymobile-backbone) and [ember-jasmine-standalone](https://github.com/dockyard/ember-jasmine-standalone).\n\nI'm very happy to announce that Russ has agreed to come on board as a\npartner.\n\nNow I just have to get him to write some blog posts...\n\n[Follow Russ on Twitter](http://twitter.com/codeofficer)\n"},{"title":"Authenticating multiple models with a strategy","tags":["rails","design patterns"],"summary":"Using the Strategy Pattern to clean up multiple login paths","legacy":false,"id":"2012/02/13/authenticating-multiple-models-with-a-strategy","employee":"Brian Cardarella","date":"2012-02-13T00:00:00","body":"\n\nA current project requires that there be multiple models that can sign\nin and each one must use the same sign in form. The original\n`SessionsController#create` action looked like the following:\n\n```ruby\ndef create\n  if user = (Owner.authenticate(params[:user]) || Employee.authenticate(params[:user]))\n    session[:user_id]    = user.id\n    session[:user_class] = user.class\n    redirect_to dashboard_path\n  else\n    render :action => :new\n  end\nend\n```\n\nWe're using `has_secure_password` and rolling our own authentication.\nConsidering that, the above was good enough. But... looking down\nthe line for this app it is likely we will have to support authentication\nfor more than just two models on the same form. I also don't like having\nlogic in my controllers. So I decided to break this logic out and I\nchose the [Strategy Pattern](http://en.wikipedia.org/wiki/Strategy_pattern) to help.\n\nI like putting all of my strategies into\n`app/strategies`. This required me to add this directory to the Rails\n`autoload_paths`. Simply open up `config/application.rb`\n(not necessary in Rails 3.1+, thanks Artur Roszczyk)\n\n```ruby\nconfig.autoload_paths += %W(#{config.root}/app/strategies)\n```\n\nNext I wrote up a simple spec, thankfully I already had the logic from\nthe controller so there wasn't much work to be done here. This went into\n`spec/strategies/authentication_strategy_spec.rb`\n\n```ruby\nrequire 'spec_helper'\n\ndescribe AuthenticationStrategy do\n  context 'authenticating an owner' do\n    let(:owner) { mock('Owner') }\n    before do\n      owner.stubs(:authenticate).returns(owner)\n      Owner.stubs(:where).returns([owner])\n    end\n    it 'returns an owner' do\n      AuthenticationStrategy.run(:email => 'owner@example.com', :password => 'password').should eq owner\n    end\n  end\n\n  context 'authenticating an employee' do\n    let(:employee) { mock('Employee') }\n    before do\n      employee.stubs(:authenticate).returns(employee)\n      Employee.stubs(:where).returns([employee])\n    end\n    it 'returns an employee' do\n      AuthenticationStrategy.run(:email => 'employee@example.com', :password => 'password').should eq employee\n    end\n\n  end\n\n  describe 'failing to authenticate' do\n    context 'with no attributes' do\n      it 'returns nil' do\n        AuthenticationStrategy.run.should be_nil\n      end\n    end\n    context 'with no match for owner or employee' do\n      it 'returns nil' do\n        AuthenticationStrategy.run(:email => 'test@example.com', :password => 'password').should be_nil\n      end\n    end\n  end\nend\n```\n\nNow it was time to make these specs green! The strategy file goes into\n`app/strategies/authentication_strategy.rb`\n\n```ruby\nclass AuthenticationStrategy\n  def self.run(attributes = nil)\n    return nil if (attributes.nil? || attributes[:email].blank? || attributes[:password].blank?)\n    Owner.authenticate(attributes) || Employee.authenticate(attributes)\n  end\nend\n```\n\nAnd finally to clean up the controller\n\n```ruby\ndef create\n  if user = AuthenticationStrategy.run(params[:user])\n    session[:user_id]    = user.id\n    session[:user_class] = user.class\n    redirect_to dashboard_path\n  else\n   render :action => :new\n  end\nend\n```\n\nIn the end this may appear to be more work than is necessary. Keep in\nmind that app requirements will expand to support more models. The wins should be obvious\nconsidering that context. If the requirements grow to 5 or 6 models perhaps at that point it makes sense to\nactually break the authentication up into [Identities](http://en.wikipedia.org/wiki/Identity_management) with a [polymorphic\nassociation](http://guides.rubyonrails.org/association_basics.html#polymorphic-associations) to the different models.\nBut we'll cross that road when we get there.\n"},{"title":"Love Your lib Directory","tags":["rails"],"summary":"Patterns for happy hacking","legacy":false,"illustration_alt":"Dump","illustration":"https://i.imgur.com/aEAcAz4.jpg","id":"2012/02/14/love-your-lib-directory","employee":"Brian Cardarella","date":"2012-02-14T00:00:00","body":"\n\n[Be sure to check out Bryan Helmkamp's blog post on the same topic](http://blog.codeclimate.com/blog/2012/02/07/what-code-goes-in-the-lib-directory)\n\nThe `lib/` directory is the Red Headed Stepchild of your Rails\napplication. Let's discuss some conventions for keeping it clean and\nwhat should and shouldn't go in there.\n\n## It's not a dump ##\n\n![Dump](https://i.imgur.com/aEAcAz4.jpg)\n\nDoes this look familiar? It does to me. This is what my `lib/` directory\nlooked like before I got fed up with it. That truck, that was me dumping more\ncode into `lib/`.\n\nIn my experience there is one outstanding reason why code ends up\ngetting dumped into the lib/ directory: A poor understanding of what a\nmodel is. Rails has this way of reinforcing bad habits. Perhaps because\nit is so easy to get going some developers never bother to learn that a\nmodel does not in any way need to be attached to a persitence layer.\n(i.e. ActiveRecord)\n\nLet's all agree to the following:\n\n1. All Business Logic Goes Into A Model\n2. All Models Go Into `app/models`\n\nWhen we say \"Business Logic\" we are of course talking about \"Application\nSpecific Business Logic\". There is always the case of something you're\nworking on that is so generic it can be shared with other applications\nyou are (or will be) working on. Or, even better, with the community in\ngeneral as Open Source. That brings me to the next point.\n\n## Understanding the load path ##\n\nIf you have written a Rubygem, or at the very least, looked through one,\nyou know that the `lib/` directory is special. The short version of the\nstory is that Rubygems iterates over all of the libraries you have\ninstalled as a gem, and appends any `lib/` directories onto Ruby's Load\nPath. This is basically how Ruby gem files are exposed, so when you as\ndo a gem require it will iterate through every path in the load path and\ngive you the first match.\n\nThis is also true with Rails. After all of your gems are loaded and your\napplication is up Rails will append `./lib/` to your load path. Any\nfiles you put in there can now be required the exact same way gems are.\nThis gives us an excellent path to extracting general functionality out\ninto. You can even play tricks with this, in your `application.rb` file\nput the following at the top:\n\n```ruby\n$:.unshift(File.expand_path('../../lib', __FILE__))\n```\n\nNow in your lib directory create an 'active_record' directory and add a\nfile called 'base.rb'. Inside that file add the following:\n\n```ruby\nraise \"ZOMG I BROKE RAILS!\"\n```\n\nLoad up your Rails app and watch it throw an exception. Why? Because\nyour app's `lib/` directory was prepended to the load paths and when the\nlookup for `active_record/base` happened the first match was in your\napp's `lib/` instead of in the proper gem. This of course is more of an interesting hack than anything really\nuseful. But it does do a good job of demonstrating how Rubygems' lookup\nhappens.\n\n## Use initializers for initializing, that is all ##\n\nI have seen developers dump code into initializers that has no business\nbeing there. Yes, it loads and it works. That is not the point. We have\nconventions for a reason. Any code that you feel needs to go into an\ninitializer and has nothing to do with actually setting preferences or\nsomething of that manner almost always should go into the `lib/`\ndirectory. If you **must** monkey patch. Put it into the `lib/`\ndirectory. If you are creating a new class or module that has no\nbusiness being in `app/models` put it in to the `lib/` directory.\n\n## Using lib/ to extend core, stlib, or a gem ##\n\nFar too often I've needed to extend a class that is being defined\noutside of my project. There are a few ways to deal with this. You can\nuse a [Composite](http://en.wikipedia.org/wiki/Composite_pattern) to\ndefine a new class that you can then play around with. The downside to\nthis is that I sometimes want to modify a class that is being inherited\nby other classes. This is when I think it is appropriate to [Monkey\nPatch](http://en.wikipedia.org/wiki/Monkey_patch).\n\nThe pattern I have fallen upon is to define a `gem_ext/` directory and a\n`gem_ext.rb` file in lib. I then make sure the extensions are loaded up\nusing an initializer. For lack of a better term I call this\n`lib_loader.rb`. Lets start with the loader.\n\n```ruby\n# config/initializers/lib_loader.rb\n\nrequire 'gem_ext'\n```\n\nSimple enough. Now for this example I'll use a [Haml](http://haml-lang.com/) custom filter I wrote.\nThis filter allows me to write [Handlebars](http://handlebarsjs.com)\ntemplates in my views like so:\n\n```haml\n-# app/views/home/show.html.haml\n\n:handlebars\n  // handlebars code goes here\n```\n\nNow I can easily add handlebar templates to any haml file. This is how I\ndid it.\n\nUnder `lib/gem_ext` I defined a `haml/` directory and a `haml.rb` file. Then I defined `haml/custom_filters.rb` and inside that file\nI added\n\n```ruby\n# lib/gem_ext/haml/custom_filters.rb\n\nmodule Haml::Filters\n  module Handlebars\n    include Base\n\n    def render_with_options(text, options)\n      type = \" type=#{options[:attr_wrapper]}text/x-handlebars#{options[:attr_wrapper]}\"\n      <<-END\n<script#{type}>\n//<![CDATA[\n  #{text.rstrip.gsub(\"\\n\", \"\\n    \")}\n//]]>\n</script>\n      END\n    end\n  end\nend\n```\n\nNow in `haml.rb` I added\n\n```ruby\n# lib/gem_ext/haml.rb\n\nrequire 'gem_ext/haml/custom_filters'\n```\n\nAnd finally in `gem_ext.rb` I added\n\n```ruby\n# lib/gem_ext.rb\n\nrequire 'gem_ext/haml'\n```\n\nThis gives me a very clean approach to extending classes without\nworrying about muddying up the load path with name collisions or other\nsurprises. In addition this pattern can\nbe repeated for `Core` and `Stdlib` classes in `core_ext` and `stdlib_ext`\nrespectively.\n\n## Using lib/ as a pattern to extracting Rubygems ##\n\nA pattern I have fallen upon when wanting to extract functionality out\nof an app into a Rubygem has been to first extract that code into the\n`lib/` directoy. From there I have a nice way to test the code in\nisolation. I am also forced to write the code as a class independent\nfrom my app. After I am satisfied with what I have I can think about\nextracting that into an external gem.\n\nA great example of this is something that [Patrick Robertson](http://p-rob.me) wrote for\n[BostonRB](http://bostonrb.org)\n\nWe wanted to show the next upcoming event at the top of the website. All\nof our events are stored in a Google Calendar. Unfortunately most of the\nGoogle Calendar gems out there are crap. Patrick decided to roll his\nown.\n\nYou can see that the [boston_rb_calendar.rb](https://github.com/bostonrb/bostonrb/blob/master/lib/boston_rb_calendar.rb)\nis requiring several files just like any Gem would. Because of the\nisolation [he was able to test the class very easily](https://github.com/bostonrb/bostonrb/blob/master/spec/lib/boston_rb_calendar_spec.rb).\n\nFrom here, if Patrick wanted to release this as a gem it wouldn't take\ntoo much effort. Some renaming of classes would be required but he has\nall of the major parts in place.\n\n## Go forth and show some <3<3<3<3 ##\n\nKeeping your code clean pays itself forward in many way. The team you\nare apart of or the team you are handing off to will thank you. Heck,\nyour future self might thank you. The patterns I've described here are\nones that I have found success with. If you have noticed other patterns\nconcerning the `lib/` directory please feel free to comment!\n"},{"title":"Get those instance variables out of my specs!","tags":["testing"],"summary":"Clean up your specs with let and subject","legacy":false,"id":"2012/02/15/get-those-instance-variables-out-of-my-specs","employee":"Brian Cardarella","date":"2012-02-15T00:00:00","body":"\n\nIf you've been writing [RSpec](https://www.relishapp.com/rspec) for any\nperiod of time I'm sure you've come across [let](https://www.relishapp.com/rspec/rspec-core/v/2-8/docs/helper-methods/let-and-let) and [subject](https://www.relishapp.com/rspec/rspec-core/v/2-8/docs/subject/explicit-subject). (please take a moment to check out the links if you have no idea what I'm talking about) In most cases you can write the same specs with instance variables. For example:\n\n```ruby\ndescribe '.find_good_cars' do\n  before do\n    @car_1 = Factory(:good_car)\n    @car_2 = Factory(:good_car)\n    @car_3 = Factory(:bad_car)\n    @good_cars = Car.find_good_cars\n  end\n\n  it 'only finds good cars' do\n    @good_cars.should eq [@car_1, @car_2]\n  end\nend\n```\n\nHere is what it looks like when using `let` and `subject`\n\n```ruby\ndescribe '.find_good_cars' do\n  let!(:car_1) { Factory(:good_car) }\n  let!(:car_2) { Factory(:good_car) }\n  let!(:car_3) { Factory(:bad_car)  }\n  subject      { Car }\n  its(:find_good_cars) { should eq [car_1, car_2] }\nend\n```\n\nMaybe it is just me but this *feels* cleaner. I treat instance\nvariables in my specs as a smell and you should too.\n"},{"title":"Single quotes or double quotes?","tags":["code guidelines"],"summary":"An opinion on when to use the different quoting styles with some performance notes","legacy":false,"id":"2012/02/16/single-quotes-or-double-quotes","employee":"Brian Cardarella","date":"2012-02-16T00:00:00","body":"\n\nI have a simple rule when it comes to strings: I always start out with\nsingle quotes\n\n```ruby\n'Hello world!'\n```\n\nWhen I need to interpolate in the string or add an escaped character it\nis time to upgrade to double quotes\n\n```ruby\n\"Hello #{planet}!\"\n\n\"To: John Adamsn\\nFrom: Thomas Jefferson\"\n```\n\nNow what happens when the string style is part of that string itself?\nFor example, I don't need to interpolate and the only escaped character\nneeded is a single quote. This is when I've been using [string\nexpressions](http://web.njit.edu/all_topics/Prog_Lang_Docs/html/ruby/syntax.html#string).\nA string literal of `%q` is the equivalent of a single quote string and\na `%Q` is the equivalent of a double quote string. The string literals\nare contained withing a non-alphanumeric delimiter.\n\n```ruby\n# single quote\n%q{Wayne's world!}\n\n# double quote\n%Q{#{name}'s world!}\n\n# ZOMG also a double quote!\n%{#{name}'s world!}\n```\n\nI try to follow this rule. I don't think it saves anything other than it\njust looks nicer to me. A very simple (and completely unscientific)\nbenchmark shows that the difference between the two is a wash\n\n** Update: These benchmarks may be wrong, please see the comments for more information **\n\n```ruby\nrequire 'benchmark'\n\nBenchmark.measure { 1..10_000_000.times { a = 'hey now' } }\n# =>   1.960000   0.000000   1.970000 (  1.958126)\n\nBenchmark.measure { 1..10_000_000.times { a = \"hey now\" } }\n# =>   1.980000   0.010000   1.980000 (  1.988363)\n```\n\nAny given run of this and the times would flip. The string is probably\njust being optimized somewhere so this benchmark is not very good. At the \nvery least it shows that execution time is similar. Let's see what happens \nwhen interpolating:\n\n```ruby\nBenchmark.measure { 1..10_000_000.times { |i| a = \"hey now #{i}\" } }\n# =>   6.110000   0.010000   6.120000 (  6.111669)\n```\n\nNow we can see a significant jump in time. (over 3 times longer) Why does this take so much longer?\nA clue as to what is happening can be seen when we compare this benchmark to string concatenation using single quotes\n\n```ruby\nBenchmark.measure { 1..10_000_000.times { |i| a = 'hey now ' + i.to_s } }\n# =>   6.490000   0.020000   6.510000 (  6.502408)\n```\n\nThis ends up being about the same execution time as string interpolation.\nBefore we answer the previous question let's take a look at one more option\n\n```ruby\nrequire 'benchmark'\n\nBenchmark.measure { 1..10_000_000.times { |i| a = 'hey now ' << i } }\n#  =>   2.990000   0.010000   3.000000 (  2.986346)\n```\n\nWhoa, this is much faster, more than 50% faster than interpolation and\nconcatenation. Why? What is happening here?\n\nWhat we are seeing is the difference between creating a new object and\nmodifying an existing object. It is not immediately obvious with string\ninterpolation as it is with concatenation. With the append we are actually \nmodyfing the object so there is no need to do any memory allocation.\n\nThere are several differences between the two styles, they aren't\nalways interchangable. Most of the time the decision comes down to a\nstyling preference but there are certain use cases where it can make a\ndifference. String interpolation is in Ruby as a nice convenience but if\nyou're doing anything that is relying upon interpolation quite heavily\nyou may want to consider other options.\n"},{"title":"Rails Engines and Monkey Patching","tags":["rails"],"summary":"A simple pattern for extending your Rails Engines in your app","legacy":false,"id":"2012/02/20/rails-engines-and-monkey-patching","employee":"Brian Cardarella","date":"2012-02-20T00:00:00","body":"\n\nWe've started extracting simple behavior into Rails Engines lately. An\nexample of this is our\n[Invitable](https://github.com/dockyard/invitable) engine. As you may\nhave guessed, it adds invitation request support to an existing app.\nIt's about 50% complete right now but for the purposes of this post it\nwill act as the example.\n\nAs an engine it has a very slim `Invitation` model that only\nexpects an `email` attribute. A client app we're currently\nbuilding requires two additional attributes to be gathered: `name` and `zipcode`.\n\nThere is no need to overwrite the model, I just want to extend it. The cleanest \nthing to do is just monkey patch it.\n\nLet's start with writing the spec of where I want the model to be (I am\nusing [ValidAttribute](https://github.com/bcardarella/valid_attribute) if\nthe specs don't look familiar, I suggest you try it test spec your\nvalidations)\n\n```ruby\nrequire 'spec_helper'\n\ndescribe Invitable::Invitation do\n  it { should     have_valid(:name).when('Henry Ford') }\n  it { should_not have_valid(:name).when(nil, '') }\n  it { should     have_valid(:zipcode).when('02115') }\n  it { should_not have_valid(:zipcode).when(nil, '', 'hello', '0211', '021156') }\nend\n```\n\nTo make this spec green there are two things that I have to do\n\n1. Add the `name` and `zipcode` columsn to the correct table\n2. Open up the class and add the proper validations on those attributes\n\nThe first is simple. I just create a new migration and add the columns\nto `invitable_invitations`.\n\nThe second is not so straight forward. If I open up the class in the client app and\nattempt to add the validations like so:\n\n```ruby\nmodule Invitable\n  class Invitation\n    validates :name, :zipcode, :presence => true\n    validates :zipcode, :format => /^\\d{5}$|^\\d{5}-\\d{4}$/\n  end\nend\n```\n\nThe app will raise a `NoMethodError` exception complaining that\n`validates` is undefined. In the load path there are two\n`app/models/invitable/invitation.rb` files and the one in the app takes precendence\nover the one in the engine. This is fine because you might want to\noverwrite the model entirely, but in this case I want to extend it. So\nyou must explicitly require the engine's model at the top of the app's model.\n\nThankfully the engine itself has a nice helper `called_from` that tracks its full path\non the file system. In this example we access it with\n`Invitable::Engine.called_from`. This will point to the `lib/invitable` directory\nin the gem itself. Here is what I ended up with in the model:\n\n```ruby\nrequire File.expand_path('../../app/models/invitable/invitation', Invitable::Engine.called_from)\n\nmodule Invitable\n  class Invitation\n    validates :name, :zipcode, :presence => true\n    validates :zipcode, :format => /^\\d{5}$|^\\d{5}-\\d{4}$/\n  end\nend\n```\n\nIt's verbose and this could be better so let's clean that up.\n\nIn my engine I've added a spec to `spec/lib/invitable/engine_spec.rb`\nwith the following (I'm using [Mocha](https://github.com/floehopper/mocha) for the stubbing)\n\n```ruby\nrequire 'spec_helper'\n\ndescribe Invitable::Engine do\n  before { Invitable::Engine.stubs(:called_from).returns('/lib/invitable') }\n\n  describe '.app_path' do\n    it 'returns the path to the engine app directory' do\n      Invitable::Engine.app_path.should eq '/app'\n    end\n  end\n\n  describe 'controller_path' do\n    it 'returns the path to the named engine controller' do\n      Invitable::Engine.controller_path(:test_controller).should eq '/app/controllers/invitable/test_controller.rb'\n    end\n  end\n\n  describe 'helper_path' do\n    it 'returns the path to the named engine helper' do\n      Invitable::Engine.helper_path(:test_helper).should eq '/app/helpers/invitable/test_helper.rb'\n    end\n  end\n\n  describe 'mailer_path' do\n    it 'returns the path to the named engine mailer' do\n      Invitable::Engine.mailer_path(:test_mailer).should eq '/app/mailers/invitable/test_mailer.rb'\n    end\n  end\n\n  describe 'model_path' do\n    it 'returns the path to the named engine model' do\n      Invitable::Engine.model_path(:test_model).should eq '/app/models/invitable/test_model.rb'\n    end\n  end\nend\n```\n\nThis looks good enough to me. Now to make it green I added the following\nto `lib/invitable/engine.rb`\n\n```ruby\ndef self.app_path\n  File.expand_path('../../app', called_from)\nend\n\n%w{controller helper mailer model}.each do |resource|\n  class_eval <<-RUBY\n    def self.#{resource}_path(name)\n      File.expand_path(\"#{resource.pluralize}/invitable/\\#{name}.rb\", app_path)\n    end\n  RUBY\nend\n```\n\nAnd now in the app model I can do the following\n\n```ruby\nrequire Inivitable::Engine.model_path :invitation\n\nmodule Invitable\n  class Invitation\n    validates :name, :zipcode, :presence => true\n    validates :zipcode, :format => /^\\d{5}$|^\\d{5}-\\d{4}$/\n  end\nend\n```\n\nNice and clean!\n\nThis simple pattern can be applied to the controllers, mailers, etc... any class you want to actually\nextend from the engine instead of overwrite entirely.\n\nFinally, I'd like the address a question I'm sure some of you have. Why\nnot subclass? For this engine the `Invitable::InvitationsController` is\nexpecting a class of `Invitation` within the context of the `Invitable`\nmodule. So if I were to subclass\n\n```ruby\nclass Inivtation < Inivitable::Invitation\n```\n\nYou would then have to subclass the controller\n\n```ruby\nclass InvitationsController < Invitable::InvitationsController\n```\n\nAnd because the `InvitationsController` is referencing\n`InvitationMailer` within the context of the `Invitable` module you\nwould have to subclass the mailer\n\n```ruby\nclass InvitationMailer < Invitable::InvitationMailer\n```\n\nFinally, because you've subclassed the controller the mount in\n`routes.rb` becomes meaningless. If you head down the subclass path you\ndefeat the purpose of using the engine in the first place.\n"},{"title":"Retrospective: Using Phonegap, jQueryMobile, Backbone, and other thoughts","tags":[],"summary":"A summary of our recent retrospective","legacy":false,"id":"2012/02/21/retrospective-phonegap-jquerymobile-backbone","employee":"Brian Cardarella","date":"2012-02-21T00:00:00","body":"\n\nWrite me\n"},{"title":"Browsers don't let developers be restful with status codes","tags":[],"summary":"Web browsers don't create disincentives for web developers to use semantically correct status codes","legacy":false,"id":"2012/02/22/browsers-dont-let-developers-be-restful-with-status-codes","employee":"Brian Cardarella","date":"2012-02-22T00:00:00","body":"\n\nWrite me\n"},{"title":"Dan McClain is a DockYarder","tags":["office"],"summary":"DockYard welcomes Dan McClain","legacy":false,"illustration_alt":"Dan McClain","illustration":"https://i.imgur.com/641zQv4.png","id":"2012/02/27/dan-mcclain-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-02-27T00:00:00","body":"\n\n![Dan McClain](https://i.imgur.com/641zQv4.png)\n\nToday I'm happy to announce that Dan McClain is joining our team! I've\ngotten to know Dan over the past few months through\n[BostonRB](http://bostonrb.org). He's been [building out some features for\nthe BostonRB site](https://github.com/bostonrb/bostonrb/commits/master?author=danmcclain), specifically adding\nthe start of an admin interface (which is huge for me as I was doing all\ndata entry through the Rails console) and setting BostonRB up on\n[TravisCI](http://travis-ci.org/#!/bostonrb/bostonrb).\n\nFor the past few weeks Dan has been working as a contract-to-hire for\nus. Already he's made a big impact by setting up a company instance\nof Jenkins and keeping us honest with our test suites.\n\nWelcome aboard Dan!\n\n[Follow Dan on Twitter](http://twitter.com/_danmcclain)\n"},{"title":"Our Continuous Integration Setup","tags":["testing","linux"],"summary":"What we are doing to keep our developers honest with their tests","legacy":false,"id":"2012/03/05/our-ci-setup","employee":"Dan McClain","date":"2012-03-05T00:00:00","body":"\n\nWhen I started at DockYard, Brian tasked me with setting up a continous\nintegration (CI) server so that we could keep an eye on our RSpec test\nsuite. We went with Jenkins since we are writing client code, so\n[travis-ci.org](http://travis-ci.org) is out of the question (for now).\n\nOur CI server is running on Ubuntu 10.04. We are using nginx as a\nreverse proxy infront of our Jenkins server. Our basic setup is the same\nas [the presentation I gave at Boston RB in January](http://bostonrb.org/presentations/jenkins-rails).\nThere are a few upgrades I have made since then.  First, I set up the\nGitHub authentication plugin. The other plugin I installed was the\nCampfire notification plugin. Since we are all remote, we use Campfire\nas our main line of communication. Having Jenkins notify us in Campfire\nallows us to see when new code is pushed to master, and when someone\nbreaks the build.\n\n## RSpec HTML formatter + Jenkins = Every Build is successful (even when it isn't)##\n\nAs we found out the hard way, using the RSpec HTML formatter from within\njenkins is not the best idea.  The problem is the HTML formatter returns\nthe same exit code regardless of whether or not the suite passes. This\nis a huge problem, as you end up with false positives.\n\n## Enter ci_reporter ##\n\nThe [ci_reporter](https://github.com/nicksieger/ci_reporter) gem provides a rake\ntask that generates a set of xml reports that Jenkins can interpret and\ngive us a more complete picture of our test suite. Jenkins will plot the\nnumber of failure over time, display test duration, and provide a number \nof other stats you can utilize. \n\n## Capybara-webkit + Xvfb + headless = Javascript without opening a browser ##\nWe are using capybara to run our [request\nspecs](http://railscasts.com/episodes/257-request-specs-and-capybara).\nWhen our request spec needs javascript, we use \n[Capybara-webkit](https://github.com/thoughtbot/capybara-webkit) as our\njavascript driver. Capybara-webkit is a\nwebkit capybara driver, allowing you to run javascript in a headless\nwebkit instance.  It accomplishes this by using QtWebKit. On Ubuntu, to\nutilize capybara-webkit, you need an X Server running when you run your\ntest.  To accomplish this, I installed Xvfb, which will create a\nvirtual framebuffer.  To instantiate xvfb, I used the headless\ngem, which is a ruby wrapper for xvfb.  With headless, I don't have to\ndo any bash scripting to get a framebuffer ready before we run our\ntests. \n\nI added the following code to our `spec_helper.rb` file\n\n```ruby\nconfig.before(:suite) do\n  @headless = Headless.new\n  @headless.start\nend\n \nconfig.after(:suite) do\n  @headless.destroy\nend\n```    \n\nThe above spippet creates the headless instance and creates the\nframebuffer at the beginning of the test suite, and destorys it\nafterwards.\n\n## Conclusion ##\nOverall, I'm pretty happy with our set up as it is. The one issue I have\nwith it is the way ci\\_reporter and jenkins interact. Since Jenkins was\norigianlly built for Java, builds are BROKEN when they don't build, but\nUNSTABLE when their tests fail.  UNSTABLE builds are seen as successful.\nI would rather an UNSTABLE build be seen as a failure, since the\ncampfire notification plugin plays the same sound for successful and\nunstable builds.  I may poke around with the plugin or ci\\_reporter to\nhave jenkins notify us of builds in a way that makes more sense.\n"},{"title":"Use Association Extensions to Build Join Attributes on a HMT","tags":["rails"],"summary":"Russ lays down a use case for ActiveRecord association extensions","legacy":false,"illustration_alt":"Diagram","illustration":"https://i.imgur.com/8JgW3es.png","id":"2012/04/03/use-association-extensions-to-build-join-attributes-on-a-hmt","employee":"Russ Jones","date":"2012-04-03T00:00:00","body":"\n\nIt's common in Rails to use a `has_many :through` relationship to model User/Group Memberships. \nSometimes we have extra data in the join that we would like to make use of, but getting that \ndata in there can be combersome depending on our approach. For example, given the\nfollowing diagram and schema:\n\n![Diagram](https://i.imgur.com/8JgW3es.png)\n\n```ruby\nActiveRecord::Schema.define(:version => 20120324170519) do\n  create_table \"groups\", :force => true do |t|\n    t.string   \"name\"\n    t.datetime \"created_at\", :null => false\n    t.datetime \"updated_at\", :null => false\n  end\n\n  create_table \"memberships\", :force => true do |t|\n    t.integer  \"user_id\"\n    t.integer  \"group_id\"\n    t.string   \"role\"\n    t.datetime \"created_at\", :null => false\n    t.datetime \"updated_at\", :null => false\n  end\n\n  create_table \"users\", :force => true do |t|\n    t.string   \"name\"\n    t.datetime \"created_at\", :null => false\n    t.datetime \"updated_at\", :null => false\n  end\nend\n```\n\nWe might deal directly with the join table to assign our additonal data.\n\n```ruby\n@user = User.create(name: 'User 1')\n@user = Group.create(name: 'Group 1')\n@membership = Membership.create do |m|\n  m.user = @user\n  m.group = @group\n  m.role = 'admin'\nend\n@user.admin? # => true\n@user.editor? # => false\n```\n\nThere's a better way to pull this off ...\n\n```ruby\n@group.admins << @user\n@user.admin? # => true\n@user.editor? # => false\n```\n\nAnd this is how it's done ...\n\n```ruby\nclass User < ActiveRecord::Base\n  has_many :memberships\n  has_many :groups, :through => :memberships\n\n  def admin?\n    memberships.where(:role => 'admin').first\n  end\n\n  def editor?\n    memberships.where(:role => 'editor').first\n  end\nend\n```\n\n```ruby\nclass Membership < ActiveRecord::Base\n  belongs_to :group\n  belongs_to :user\nend\n```\n\n```ruby\nclass Group < ActiveRecord::Base\n  has_many :memberships\n  has_many :users, :through => :memberships\n\n  has_many :admins, :through => :memberships, :source => :user,\n    :conditions => \"memberships.role = 'admin'\" do\n      def <<(admin)\n        proxy_association.owner.memberships.create(:role => 'admin', :user => admin)\n      end\n  end\n\n  has_many :editors, :through => :memberships, :source => :user,\n    :conditions => \"memberships.role = 'editor'\" do\n      def <<(editor)\n        proxy_association.owner.memberships.create(:role => 'editor', :user => editor)\n      end\n  end\nend\n```\n\nWe're defining an extension on our group's `has_many` association which overrides\nthe `<<` method on that collection. We then tell the proxy association's owner\n(which is our group object) to create the user/group join record, but with an additional\nrole assignment of 'admin'.\n\n```ruby\n@group.admins << @user\n@user.admin? # => true\n@user.editor? # => false\n```\n\nPretty expressive, thanks to ActiveRecord!\n\n```ruby\nrequire 'test_helper'\n\nclass GroupTest < ActiveSupport::TestCase\n  setup do\n    @user_1 = User.create(name: 'User 1')\n    @user_2 = User.create(name: 'User 2')\n    @user_3 = User.create(name: 'User 3')\n    @group = Group.create(name: 'Group 1')\n  end\n\n  test \"No Memberships\" do\n    assert_equal @user_1.memberships.count, 0\n  end\n\n  test \"@group.users << @user_1 sets nil role on membership\" do\n    @group.users << @user_1\n    assert_equal @user_1.memberships.count, 1\n    assert_equal @user_1.memberships.first.role, nil\n  end\n\n  test \"@group.admins << @user_2 sets 'admin' role on membership\" do\n    @group.admins << @user_2\n    assert_equal @user_2.memberships.count, 1\n    assert_equal @user_2.memberships.first.role, 'admin'\n  end\n\n  test \"@group.editors << @user_3 sets 'editor' role on membership\" do\n    @group.editors << @user_3\n    assert_equal @user_3.memberships.count, 1\n    assert_equal @user_3.memberships.first.role, 'editor'\n  end\n\n  teardown do\n    User.delete_all\n    Group.delete_all\n    Membership.delete_all\n  end\nend\n```\n"},{"title":"Tmux, for fun and profit","tags":["workflow"],"summary":"Pair programming at distance","legacy":false,"id":"2012/04/10/tmux-for-fun-and-profit","employee":"Dan McClain","date":"2012-04-10T00:00:00","body":"\n\n## Screen - the gateway drug ##\n\nI had been using [screen](http://www.gnu.org/software/screen) for a while to multiplex my terminal when\nworking on Ruby projects.  I would have a tab for\n[git](http://git-scm.org) (was using [MacVim](http://code.google.com/p/macvim/)), on for `rails s` or `tail\nlog/development.log`, one for running tests (now using `guard` or\n`autotest`), one for `rails c` and lastly one for `rails db`. Detaching\nfrom a screen session allowed me to have a full environment running\nuntil my next reboot, I could switch back into the project quickly, and\nI had configured my `.screenrc` to open these tabs everytime I started\nscreen.\n\nI also utilized screen to keep sessions open on a remote server between\nSSH connects. Instantiating a screen session on the remote server\nwould keep processes running even when my SSH connection would get\nkilled. This would prevent an `apt-get upgrade` from fragging the system\nincase I disconnected, or allow me to drop the connection during a long\nrunning process.\n\nAs much as I used it, I was still a screen newb, as my `.screenrc` was\npretty vanilla. I hadn't taken the time to read the man\npages/tutorials out there to understand some of the more subtle\nfeatures.\n\n## Tmux and Brian P. Hogan's 'tmux' book ##\n\nI had noticed that [tmux](http://tmux.sourceforge.net) was getting a decent amount of attention, so\nwhen I started at DockYard, I told myself I would only use tmux.  I also\nswitched from MacVim to terminal vim, which works better when pair\nprogramming.  [Brian P. Hogan](http://www.bphogan.com) recently wrote\n[tmux: Productive Mouse-Free Development](http://pragprog.com/book/bhtmux/tmux) for Pragmatic Programmers.  After reading his book, I have a solid `.tmux.conf` and a great understanding of tmux.\n\n## Tmux and Pair Programming ##\n\nThe one disadvantage of everyone at DockYard working remotely is that you can't\njust turn around and ask someone to come to your desk to pair up. Tmux\nallows multiple users to connect to a specific session.  With a bit of\n[dynamic DNS](http://en.wikipedia.org/wiki/Dynamic_DNS) magic, port forwarding, and ssh tunneling, multiple people\ncan connect to the same tmux session, work in the same vim window, and\nsee the same development server.\n\nThe first step is dynamic DNS and port forwarding, which I won't cover\nhere, since everyone has different modems and routers. You want to\nforward port 22 through your router/firewall to your development\nmachine. Using dynamic DNS, you can connect to your coworkers via a\ndomain like `dan.example.com` instead of figuring out your IP and\nsending that to your partner.\n\nWe use the following ssh command to forward connection on our local\nmachine to the other person's\n\n```\nssh dan.example.com -L 3000:127.0.0.1:3000\n```\n\nThe above command forwards any request on port 3000 on my machine the\none to which I am connected. That way, I can see what my partner sees\nwhen we edit files on his machine.  Once connected, I just attach to my\npartner's tmux session.  At this point, we are programming in the same\nterminal session, and we can both see the edits as we make them.  We use\na Google+ Hangout to communicate while we pair program.\n\n## Conclusion\n\nWith a tmux, ssh port forwarding, and Google+ Hangout, you can create a\nuseful pair programming environment with your remote coworkers.  We find\nthis setup very effective and use it often to work together and tackle\nan issue.\n"},{"title":"Using Backbone Views With Rails jQuery-ujs","tags":["backbone","rails","jquery"],"summary":"Throwing them together in a way that makes sense.","legacy":false,"id":"2012/04/16/using-backbone-views-with-rails-jquery-ujs","employee":"Russ Jones","date":"2012-04-16T00:00:00","body":"\n\nI often meet Rails developers that have unwittingly jumped on the unobtrusive javascript bandwagon. \nThey throw ':remote => true' on a form and benefit from its conventions, but don't know how to make it really work for them. \nThey're probably still inclined to write out procedural jQuery code the same way they were doing it before [jquery-ujs](https://github.com/rails/jquery-ujs) became popular. \nThere's a helpful [wiki page](https://github.com/rails/jquery-ujs/wiki/ajax) that describes its custom events and how to use them, but they probably don't know about it.\n\nMaybe they've worked on improving some client side code with Backbone recently, and maybe they're trying to do things the Backbone way but don't know how to tie that together with existing Rails views. \nHere's a quick example of how Backbone views can listen for jquery-ujs custom events. You can view a working fiddle [here](http://jsfiddle.net/codeofficer/mpyXT/).\n\n```javascript\nvar FormView = Backbone.View.extend({\n  el: '#form',\n\n  events: {\n    // Fired automatically when a file-type input is detected with a\n    // non-blank value. You can use this hook to implement a handler that\n    // will deal with those non-blank file inputs. Returning false will\n    // disallow standard form submission.\n    'ajax:aborted:file'     : 'ajaxAbortedFile',\n\n    // Fired when there are required inputs which have been left blank.\n    // You can use this handler to deal with those blank required inputs.\n    // Returning false will submit the form anyway.\n    'ajax:aborted:required' : 'ajaxAbortedRequired',\n\n    // First event fired for any remote enabled form. Stopping this event\n    // will cancel the ajax request\n    'ajax:before'           : 'ajaxBefore',\n\n    // Fired before the ajax request is sent. Stopping this event will\n    // cancel the ajax request. Commonly used to customize certain request\n    // headers\n    'ajax:beforeSend'       : 'ajaxBeforeSend',\n\n    // Fired after completion, if the HTTP response was a success\n    'ajax:success'          : 'ajaxSuccess',\n\n    // Fired after completion, if the server returned an error\n    'ajax:error'            : 'ajaxError',\n\n    // Fired after the request has been completed, no matter what outcome\n    'ajax:complete'         : 'ajaxComplete'\n  },\n\n  ajaxAbortedFile: function(e, elements){\n  },\n\n  ajaxAbortedRequired: function(e, elements){\n  },\n\n  ajaxBefore: function(e){\n  },\n\n  ajaxBeforeSend: function(e, xhr, settings){\n  },\n\n  ajaxSuccess: function(e, data, status, xhr){\n  },\n\n  ajaxError: function(e, xhr, status, error){\n  },\n\n  ajaxComplete: function(e, xhr, status){\n  }\n});\n\n$(function(){\n    window.view = new FormView();\n});\n```\n\n```text\n<form id=\"form\" action=\"#\" method=\"POST\" data-remote=\"true\">\n  <p><input type=\"text\" value=\"...\"></p>\n  <p><input type=\"submit\" value=\"Continue &rarr;\"></p>\n</form>\n```\n\n"},{"title":"Sleep helper for your request tests","tags":["testing"],"summary":"A clean helper for giving visual feedback on long sleeps in your request tests","legacy":false,"id":"2012/05/01/simple-sleeper-for-request-testing","employee":"Brian Cardarella","date":"2012-05-01T00:00:00","body":"\n\nWe have been using [capybara-webkit](http://github.com/thoughtbot/capybara-webkit) quite a bit.\nBecause of the async nature of JavaScript you sometimes have to use\n[sleeps](http://rubydoc.org/stdlib/core/1.9.2/Kernel#sleep-instance_method) in your tests if the action is taking longer than the default\nCapybara 2 second timeout.\n\nLately I have had the need to sleep for up to 30\nseconds for certain actions and I wanted a clean visual indicator of how\nmuch time was remaining. So I whipped up the following:\n\n```ruby\ndef sleep_for(sleep_time, message = 'Sleeping...')\n  sleep_time.times do |i|\n    print_message = \"#{message} #{sleep_time - i} seconds remaining\"\n    print print_message\n    sleep 1\n    print [\"\\b\", \" \", \"\\b\"].map { |c| c * print_message.length }.join\n  end\nend\n```\n\nI hope others find this useful!\n"},{"title":"Rails 4.0 Sneak Peek: Expanded ActiveRecord Support for PostgreSQL Datatypes","tags":["rails","postgres"],"summary":"Support added to ActiveRecord for INET, CIDR and MACADDR types for PostgreSQL","legacy":false,"id":"2012/05/18/rails-4-sneak-peek-expanded-activerecord-support-for-postgresql-datatype","employee":"Dan McClain","date":"2012-05-18T00:00:00","body":"\n\nThis week, I had a [pull request accepted](https://github.com/rails/rails/commit/835df6f3ed9b1575fd6a1fb62516d8ebeffbf114#diff-0)\ninto Rails which adds support for\n[PostgreSQL's MACADDR, INET, and CIDR datatypes](http://www.postgresql.org/docs/current/static/datatype-net-types.html).\nIn Rails 4.0, the following migration will be supported:\n\n```ruby\ncreate_table :network_types do |t|\n  t.cidr :cidr_address\n  t.inet :ip_address\n  t.macaddr :mac_address\nend\n```\n\nAlso, the schema dumper supports these types as well (previously they\nwould appear as `string` types in the schema.rb file).\n\nActiveRecord will also cast the values of the INET and CIDR types to\nRuby's [IPAddr](http://www.ruby-doc.org/stdlib-1.9.3/libdoc/ipaddr/rdoc/IPAddr.html),\nwhile MACADDR will continue to be converted to a string.\n"},{"title":"Chris Gill is a DockYarder","tags":["office"],"summary":"DockYard welcomes Chris Gill","legacy":false,"illustration_alt":"Chris Gill","illustration":"https://i.imgur.com/XxdPnRN.png","id":"2012/06/01/chris-gill-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-06-01T00:00:00","body":"\n\n![Chris Gill](https://i.imgur.com/XxdPnRN.png)\n\nToday I'm happy to announce that Chris Gill is joining our team!\nChris and I worked together at the [DNC](http://dnc.org) and I credit\nhim with sparking my interest in [PostgreSQL](http://www.postgresql.org)\n\nChris' pragmatic approach to software development and his years of\nexperience in politics is a huge addition to our growing team. He is\nlocated in DC and we hope to soon build out a team in that area.\n\nWelcome aboard Chris!\n\n[Follow Chris on Twitter](http://twitter.com/gilltots)\n"},{"title":"BostonRB Goes Live","tags":["community"],"summary":"Live streaming and expansion comes to BostonRB","legacy":false,"illustration_alt":"BostonRB","illustration":"https://i.imgur.com/raigWYs.png","id":"2012/06/11/bostonrb-goes-live","employee":"Brian Cardarella","date":"2012-06-11T00:00:00","body":"\n\n![BostonRB](https://i.imgur.com/raigWYs.png)\n\nStarting tomorrow night (June 12th, 2012) [The Boston Ruby Group](http://bostonrb.org)\nwill be streaming its monthly meeting live via [Google Hangouts on Air](http://googleblog.blogspot.com/2012/05/google-hangouts-on-air-broadcast-your.html)\nThe streaming will start at 6:45 PM US Eastern Time and the meeting itself will start at 7pm or a few minutes after. The meeting should run until 9pm.\n\nThis will allow those that cannot attend the meeting to watch the raw\nstream live from anywhere in the world on [YouTube](http://youtube.com).\nWe will also reserve a few seats in the Google Hangout itself for other\nuser groups in the New England area to join. Questions will be allowed from\nthese user groups after each presentation just as any\naudience member will be able to.\n\nWe're very excited about using this technology to expand\n[BostonRB](http://bostonrb.org). If things go well we will want to\ninvite more user groups to virtually attend our meetings in the future.\nIf you are an organizer of a small local group and have difficulty\npulling in some of the larger names in the Ruby community for\npresentations we want you to leverage BostonRB.\n\nIn addition, even though Boston is a great tech-hub we still are far\nenough away where it is difficult for some presenters to travel. We\nwould like to invite presenters to BostonRB to present their material\nvia Google Hangouts.\n\nIn the coming months we plan on using the Google Hangouts technology in\nnew ways to reach out to our community. Imagine having live office hours\nwhere local expert Ruby devs can answer questions. Or online classes\nwhere students can follow along. We understand that getting to some of our\nevents can be difficult or even intimidating. Now we can eliminate that\nbarrier.\n\nSo please follow the [BostonRB Twitter Account](http://twitter.com/BostonRB). Tomorrow night\nwe'll tweet the link to the live stream. We'll also embed the YouTube player\nonto the BostonRB homepage. In the future we'll be making other very\ncool announcements as well.\n\nAs always, if you are in Boston we [invite you come to the meeting](http://guestlistapp.com/events/107814)\nand if you are not in Boston or cannot make it you now have a new\noption.\n"},{"title":"node.js vs Ruby on Rails is so stupid","tags":[],"summary":"Why comparing the too frameworks is dumb and how Ruby is still the best choice","legacy":false,"id":"2012/06/11/nodejs-vs-rails-is-so-stupid","employee":"Brian Cardarella","date":"2012-06-11T00:00:00","body":"\n\nLet me start this by admitting a few things:\n\n1. I am a Ruby/Rails developer\n2. My consulatncy, [DockYard](https://dockyard.com) specializes in Rails\n3. I organize [The Boston Ruby Group](http://bostonrb.org)\n\nOk, so now that we have established that a grieat argument can be made\nthat I am not impartial I'm going to ask that read this as if I am. I\nknow, crazy! This is not a \"Rails\" is better than node blog post. I'm\nhoping to show some hard data to prove my points. Please feel free to\nleave a comment as I'm sure some will disagree.\n\n## The Superficial Debate ##\n\nA few months ago [node.js](http://nodejs.org) passed [Ruby on Rails](http://rubyonrails.org)\nfor the [#1 Watched Repo on Github!](https://www.google.com/search?sugexp=chrome,mod=12&sourceid=chrome&ie=UTF-8&q=nodejs+more+followers+than+rails).\nMany took this as a changing of the guard, node was now the new king\nshit. But does the number of watchers on Github actually mean anything?\nIf we are to believe that the mission of Github is \"Social Coding\" then\nI would argue that the number of contributors is a more significant\nnumber.\n\nAs of this writing Rails has 1,779 contributors while Node has 362. You\ncan grab these numbers for yourself:\n\n```text\n$ git shortlog -s | wc -l\n```\n\nRails has been under development for over 8 years and node for over 3.\nThat means Rails has averaged adding over 220 unique contributors per\nyear and node has only averaged about 120. Keep in mind that Rails did\nnot move to Github until 2008, don't think that made much of a\ndifference check this out this contributor visualization (Rails' move to\nGithub happens around 5:05)\n\n<iframe src=\"http://player.vimeo.com/video/2979844\" width=\"593\"\nheight=\"333\" frameborder=\"0\" webkitAllowFullScreen mozallowfullscreen\nallowFullScreen></iframe>\n\n## Does this mean anything? ##\n\nI don't think so, but I just wanted to highlight how pointless the\n\"Watcher\" debate is. I do think within the context of Github\ncontributions are more important but ultimately it comes down to code\nquality, more more difficult to measure.\n\nOk, let's put that behind us. The next argument is comparing the\nperformance in Rails to Node \n"},{"title":"Amanda Cheung is a DockYarder!","tags":["office"],"summary":"DockYard welcomes Amanda Cheung","legacy":false,"illustration_alt":"Amanda Cheung","illustration":"https://i.imgur.com/mwQmXZ0.jpg","id":"2012/06/14/amanda-cheung-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-06-14T00:00:00","body":"\n\n![Amanda Cheung](https://i.imgur.com/mwQmXZ0.jpg)\n\nYesterday was Amanda's first day with DockYard, she joins our growing\nteam as a designer with a desire to develop. She brings excellent design\nskills and much needed illustration skills.\n\n[Please take a moment to check out her portfolio](http://acacheung.com)\n"},{"title":"postgres_ext: Adding Postgres data types to Rails","tags":["postgres","rails","gems"],"summary":"Announcing postgres_ext, a gem that adds support for PostgreSQL data types to ActiveRecord","legacy":false,"id":"2012/06/18/postgres_ext-adding-postgres-data-types-to-active-record","employee":"Dan McClain","date":"2012-06-18T00:00:00","body":"\n\nOver the past few weeks, I have been working on a new gem which adds\nsupport to Rail's ActiveRecord for PostgreSQL's native data types. I am\nhappy to announce that I have released the\n[postgres\\_ext](https://github.com/dockyard/postgres_ext) gem.\n\npostgres\\_ext supports for ActiveRecord version 3.2 and above (at this\ntime). Parallel to my development, I plan to submit pull request to\nRails master, so that postgres\\_ext will not be needed in Rails 4.0.\n\n## Features\n\n### Migration/Schema support\n\npostgres\\_ext adds migration and `schema.rb` support for the following\nPostgresSQL type:\n\n * INET\n * CIDR\n * MACADDR\n * UUID\n * Arrays\n\nYou can create columns with the following migration methods:\n\n```ruby\ncreate_table :examples do |t|\n  t.inet :ip_address\n  # INET Column\n\n  t.cidr :subnet\n  # CIDR Column\n\n  t.macaddr :mac_address\n  # MACADDR Column\n\n  t.uuid :unique_id\n  # UUID Column\n\n  t.integer :int_array, :array => true\n  # Integer[] Column\nend\n```\n\nThese migrations will be captured in your `schema.rb` file, so you don't\nhave to use the `structure.sql` file if these types are your only reason. In\nfact, if you are using these only supported types with `structure.sql`,\nincluding the postgres\\_ext gem should allow you to correctly `rake\ndb:schema:dump` your database.\n\n[Migration/Schema.rb support documentation](https://github.com/dockyard/postgres_ext#migrationschemarb-support)\n\n### Type Casting\n\npostgres\\_ext converts INET and CIDR values to\n[IPAddr](http://www.ruby-doc.org/stdlib-1.9.3/libdoc/ipaddr/rdoc/IPAddr.html) instances,\n and coverts arrays to array objects of the column type (integer arrays\nare cast as an array of integers, INET arrays to are cast to an array of\nIPAddrs).\n\n### INET Type Casting example\n\n```ruby\ncreate_table :inet_examples do |t|\n  t.inet :ip_address\nend\n\nclass InetExample < ActiveRecord::Base\nend\n\ninetExample = InetExample.new\ninetExample.ip_address = '127.0.0.0/24'\ninetExample.ip_address\n# => #<IPAddr: IPv4:127.0.0.0/255.255.255.0>\ninetExample.save\n\ninet_2 = InetExample.first\ninet_2.ip_address\n# => #<IPAddr: IPv4:127.0.0.0/255.255.255.0>\n```\n\n### Array Type Casting example\n\n```ruby\ncreate_table :people do |t|\n  t.integer :favorite_numbers, :array => true\nend\n\nclass Person < ActiveRecord::Base\nend\n\nperson = Person.new\nperson.favorite_numbers = [1,2,3]\nperson.favorite_numbers\n# => [1,2,3]\nperson.save\n\nperson_2 = Person.first\nperson_2.favoite_numbers\n# => [1,2,3]\nperson_2.favoite_numbers.first.class\n# => Fixnum\n```\n\n[Type casting documentation](https://github.com/dockyard/postgres_ext#type-casting-support)\n\n## Another gem born out of necessity\n\nI have also released\n[pg\\_array\\_parser](https://github.com/dockyard/pg_array_parser), a C\nextension which parses PostgreSQL array values and returns an array of\nstrings.  This gem is used by postgres\\_ext to retrieve the array values\nbefore casting them to the required type.\n\n## Plans for postgres\\_ext\n\n[INET, CIDR and MACADDR support has already been added to Rails 4.](http://reefpoints.dockyard.com/ruby/2012/05/18/rails-4-sneak-peek-expanded-activerecord-support-for-postgresql-datatype.html)\nMy next step is to submit a pull request to add UUID migration support\nand Array support to Rails master.  Then I plan to backport Rails 4's\nhstore support back to postgres\\_ext. After adding support for the other\nPostgreSQL types, I plan to add support to arel for PostgreSQL type\nspecific where clauses (ie ANY for array comparison, `<<` and `>>` for\nINET and CIDR comparisons.\n"},{"title":"Lessons Learned: The First Six Months of Running a Software Consultancy","tags":["business","consulting"],"summary":"Brian talks about what has worked, what has not worked, and the changes that have been made at DockYard during its first six month","legacy":false,"id":"2012/06/21/lessons-learned-six-month-of-running-dockyard","employee":"Brian Cardarella","date":"2012-06-21T00:00:00","body":"\n\nBefore I get into it, I'm writing this because when I was first setting\nout with DockYard there was little to no guidance. It seems that most\nagencies are hush-hush on how they work internally. Or I just suck at\nthe Googles. In any event, I wanted to share our experience in the hope\nthat others can learn and give feedback.\n\n## Clients ##\n\nBe selective! If your gut tells you something is wrong listen to it. I\nmade a huge mistake with taking our very first client and an even bigger\nmistake about re-signing with said client. It ended ugly, I always felt\nit might. The client was bad (no I won't say who it was) and it really\nput us in a very difficult position when we were getting started. I went\nback to re-sign because the first contract ended in December. It turns\nout December is a *terrible* month for finding new work. I panicked,\nrookie move. Thankfully we have had great clients since. That's not to\nsay we haven't had to dodge potentially bad clients from time to time.\n\nSome clients are just bad, but many are just \"bad for us\". Those two\nstatements are very different and recognizing the difference is\nimportant. \"Bad for us\" clients might be fantasic people but the\nprojects aren't in our wheel house, in those cases I try my best to help\nthose people find other consultancies/freelancers.\n\n## Employees ##\n\n### Salary ###\n\nDockYard started as bringing together three freelance developers. The\nfirst mistake I made was not insisting that everyone start on fulltime\nsalary. We were still paying out the full hourly rates then paying taxes\non top of that. Needless to say, accounting is not my strong point. It\ntook 2 months before I figured out why we weren't making any money.\nWhoops.\n\n### Process ###\n\nI've changed from the \"anything goes\" type boss to the \"I'm going to be\nthe hard-ass\" over the past six months. Here is why: we want to balance\nmultiple projects. Finding a client that has enough of a budget for a 6\nperson team is great but not very likely if we stick with startups. So\nour team sizes are small, but we need to be redundant. I tell everyone\non my team that they \"need to be replacable\". Don't take this statement\nthe wrong way, I'm clear that this doesn't mean they're getting canned\nat the drop of a hat. It means that I don't want to be in a position\nwhere someone gets sick, goes on vacation, or leaves for another\nopportunity and we plug someone else into that project and it takes that\nperson a week to ramp up because we need to figure out what the last\nperson was doing. *Process is very important*, I would rather have good\ndevelopers that buy into our process than have awesome developers that\ndon't. We function best as a team. So when someone isn't buying into the\nprocess we've been outlining I need to be the guy that says \"no\". A few times this\nhas turned into debates, sometimes into arguments. I'm willing to modify\nour process if something better is proposed but I'm not willing to\nswitch into the \"just get it done\". At the start I avoided uncomfortable conversations, \nif something was happening that I didn't think was right for DockYard I would wait it out.\nThis was a bad idea, the best time to correct something is now. Today I \nam jumping on these things immediately. I would rather have an airing of grievances \nwhen the issue is small rather than let it blow up.\n\nHere are some things that, arguably, are\n[bikeshedding](http://en.wikipedia.org/wiki/Parkinson's_Law_of_Triviality)\nbut I have been insisting on:\n\n### The trivial ###\n\n* Whitespace\n* Single quotes instead of double quotes\n* Verbose variable names\n* Consistency between backend model names and HTML markup class names\n\n### The important ###\n\n* Testing\n* Code quality\n* CoffeeScript\n* File/class naming conventions and organization\n\n### Remotes ###\n\nWe started as entirely remote team. Angelo in Rhode Island, Russ in\nMaine, and myself in Boston. This is OK but I must admit I'm not a big\nfan of this. We have been hiring in Boston and will continue to grow a\nteam here.\n\n## Rates ##\n\nWe originally started at $120/hour. We have since moved to a flat\n$4,000/week per developer. This buys the client about 32 hours of our\ntime.\nThis has been the single best change we've made. Keeping track of every\nhours sucks, and I had to be on everyone's ass making sure they got\ntheir hours in. Now it is pretty simple. The clients also prefer this\nsystem of invoicing, especially many of the large enterprise type\nclients we are looking to go after.\n\nThat being said, I think our rate is below our market value. I've spoken\nwith many other consultancies and the average seems to be $6k - 7k per\nweek for full stack (which we are). We are planning on raising our rates\nto $5k in September then hopefully up to $6k by next year. It's not that\nI don't think we are technically qualified to justify those rates yet,\nits that I want to build out our portfolio first.\n\nI've noticed that many people don't want to talk about money. I actually\ndon't mind it, to the point that some people might find it annoying. In\norder for the market to adjust properly I think an open discussion on\nrates is necessary.\n\nI have also started telling potential clients our minimum project budget\n($30k) before we get into any details of the engagement. Some might find\nthis off-putting. Here is my perspective: the client's time is valuable\nand I don't want to waste their time. In most cases budget is a deciding\nfactor, let's get that out into the open immediately rather than dealing\nwith surprises a month from now.\n\nWe have reduced our rates to work on interesting projects. We're nearly\ndone with a real-time chat app using an EventMachine backend with a\nwebsocket front end. That was a fun one to build, we reduced our rate by\n17% because of the client's limited budget.\n\n## Business Development ##\n\nThis is something I have learned as I go. Not to toot my own horn but I\nbelieve one of my strengths is selling DockYard as a business to\npotential clients. Finding new clients has not been easy. Here are some\nthings that led directly to client contact (sorted by most effective):\n\n* Writing blog posts\n* Giving presentations to general tech audiences (more beginners than\n  experts)\n* LinkedIn\n* Referrals\n* Being found on Google\n\nLinkedIn?? Yeah, it actually worked. But I did something incredibly\ndouchey. I modified my LinkedIn profile to basically be an ad for\nDockYard then I went to LinkedIn's \"People you may know\" page and\nclicked on over a thousand people. I got flagged for spamming but it\nworked. Yes, I know it was a huge douchebag move. However, I suspected\nthat people would look at my profile to see if they knew me, or wanted\nto be connected. If they happened to have a development need they would\ncontact me, if they didn't they wouldn't. At the very least I was\nexposing DockYard to many people. I went from less than 100 LinkedIn\nconnections to close to 1000 in a week. We got two contracts from doing\nthis, it was worth it.\n\nHere are things that have not worked for us (yet)\n\n* Running Community Events\n* Sponsoring\n* Open Source Development (see the comments for some interesting debate on this topic)\n\nI organize [BostonRB](http://bostonrb.org), it is one of the largest\nRuby user groups in the world. We have awesome speakers every month.\nEvery now and then when I talk shop with someone about work I get the\n\"I'm sure running BostonRB doesn't hurt\" with a wink. I find this\nannoying. I've gone out of my way to make sure BostonRB doesn't get\nco-opted by any one company for promotional purposes. There is another\n\"Boston Rails Meetup\" in Newton, MA that is essentially used to boost\nSEO for another consultancy. I think this is bullshit. I'll say it right\nnow: We have never been contacted by a client because of running\nBostonRB. I'm not saying I would turn any down, but in my experience\nrunning a user group is not driving clients to us.\n\nNow that I'm getting off my soapbox in the upcoming months DockYard will\nbe listed as a Sponsor for BostonRB, along with every other company that\nis donating time, pizza, meeting space, etc...\n\nI'm a huge advocate for Open Source Development, but it also has very\npoor ROI if your goal is to get clients. I believe there is a threshold\nfor this, if you're on a certain tier (i.e. core committer to a popular\nframework) it might be different.\n\n## Targeting Startups ##\n\nOn any given day people will hear me complain about startups. By their\nvery definition startups don't have money. As a consultancy we are\nlooking to make money by engaging clients. If anybody tells you they're\nconsulting because it is their passion or work with startups, they are\nfull of shit. This is a cash game. Demand is at an all time high, there\nis a lot of opportunity to do well and work for yourself. While some of\nthe technology challenges startups present are very interesting I am\nalso running a business. This is why we have begun to favor enterprise.\nWe can get longer term contracts and these companies pay on time. The\ndownside is the technology is not terribly interesting.\n\nWe are striving to find a balance here. I would be interested in hearing\nothers experience.\n\n## Doing Too Much ##\n\nRight now I'm the guy wearing all of the hats. On any given day I'm\ndoign the following:\n\n* Biz development\n* Marketing\n* Lead Development\n* Project Management\n* Paying bills\n\nThankfully I haven't burnt out yet but this cannot continue much longer.\nThe biggest mistake I have made over the first six months was not making\nan early hire to take some of this load off. I must admit, this one\nstumps me. I know how to hire a good developer, I know how to hire a\ngood designer. I have no idea how to hire for non-tech positions. We\nhave already hired a accountant to handle some of the larger items but\nI'm still responsible for every day invoicing and book keeping. In my\nmind, here are the priority hires:\n\n1. Business developer. I have had light feelers out for this position\n   over the past few months. We really need someone focused on this\nfulltime. Ideally someone that wants to hook into the startup community\nin Boston or has existing sales relationships in the enterprise world.\nOr if you happen to be in DC and have existing connection in the\npolitical world we'd love to talk. [Contact\nus](mailto:contact@dockyard.com).\n\n2. Office manager. We will be moving into our own space in the Fall. At\n   that time we will be looking to fill this position.\n\n3. More developers and designers.\n\n## Our Process ##\n\nWe have modified how to engage clients. This is what we are currently\ndoing\n\n### Initial Engagement ###\n\nPhone call, get to know the client. Determine if we are a good fit. If\nso and the client is happy with references, rate, etc... we move\nforward.\n\n### Kick off ###\n\nWe charge for this. Currently it is $1000. We will sit down the client and\nwill run through what they want soup to nuts. We'll have development and\ndesign on hand for this meeting.\n\n### Design Phase ###\n\nWe originally combined development and design after the kickoff. This\nwas a mistake. There is a lot to be learned by doing an upfront design\nphase. It helps us make informed estimations. The clients are happier\nwhen we can deliver what we estimate. This phase we generally go for\nwireframes and workflow. Nothing polished. We like to wireframe in\nHTML/CSS.\n\n### Development Phase ###\n\nNow that we have the general design worked out we begin development.\nThere will also be design done during this phase as well.\n\nI would love to hear about other processes. What works, what doesn't\nwork.\n\n## Conclusion ##\n\nI hope some peope find this information useful. Please feel free to ask\nany questions or if you need me to elaborate on anything. If you feel\nI'm off the mark or have suggestions feel free to comment as well. We're\nalways looking to improve.\n\n"},{"title":"Rails 4.0 Sneak Peek: Queueing","tags":["rails"],"summary":"A look at the new Queueing API","legacy":false,"id":"2012/06/25/rails-4-sneak-peek-queueing","employee":"Brian Cardarella","date":"2012-06-25T00:00:00","body":"\n\nRecently a [queueing system was added to Rails](https://github.com/rails/rails/commit/adff4a706a5d7ad18ef05303461e1a0d848bd662).\nLet's dive in and see how to use it.\n\n## Run, baby, run! ##\n\nThe queueing API is very simple. You push an object on to the queue and\nthat object is expected to respond to a `run` method. Let's take a look:\n\n```ruby\nclass TestJob\n  def run\n    puts \"I am running!\"\n  end\nend\n\nRails.queue.push(TestJob.new)\n=> \"I am running!\"\n```\n\nFor most people, that is pretty much it. The queue is running in a\nseparate thread from the app thread, so your app shouldn't notice any\nresponse impact from an expensive job.\n\nThe basic queue that comes with Rails is not a long-term solution. The\ngoal here is to establish a common API that more robust queueing systems\ncan plug themselves into. In most cases you shouldn't need to change any\nof your app code if you want to switch from\n[Resque](https://github.com/defunkt/resque) to\n[Sidekiq](https://github.com/mperham/sidekiq). You should take care that\nthe objects you are enqueing can be properly marshalled.\n\nYou can even write your own queue, let's take a look at the API of a\ncustom queue\n\n```ruby\nclass MyQueue\n  def push(job)\n    job.run\n  end\nend\n```\n\nThen in your `application.rb`\n\n```ruby\nconfig.queue = MyQueue\n```\n\nThis example is straight from the Rails test suite. This will define a\nqueue that does not run jobs asynchronously. As soon as the job is\npushed onto the queue it is run. Let's make an actual queue (without relying on\nthe Queue class)\n\n```ruby\nclass MyQueue\n  def initialize\n    @queue = []\n  end\n\n  def push(job)\n    @queue.push(job)\n  end\n\n  def pop\n    @queue.pop\n  end\nend\n```\n\nIn this example we have implemented a simple queue. You will next need\nto tell Rails's QueueConsumer to use this queue. You can do this in\n`application.rb` with an initializer block:\n\n```ruby\nintializer 'start queue consumer' do |app|\n  app.queue_consumer = config.queue_consumer.start(app.queue)\n  at_exit { app.queue.consumer.shutdown }\nend\n```\n\nand if we now push to our new queue:\n\n```ruby\nRails.queue.push(TestJob.new)\n```\n\n...we get nothing. Why? Inspect the QueueConsumer:\n\n```ruby\nRails.application.queue_consumer\n=> #<Rails::Queueing::ThreadedConsumer @queue=#<MyQueue @queue=[]>, @thread=#<Thread dead>>\n```\n\n\nSo you'll notice that the thread is `dead`. We can force the queue to\nprocess by doing:\n\n```ruby\nRails.application.queue_consumer.start\n=> \"I am running!\"\n```\n\nLet's back up to understand what is going on here. First we'll start by looking at `ThreadedConsumer#start`\n\n```ruby\ndef start\n  @thread = Thread.new do\n    while job = @queue.pop\n      begin\n        job.run\n      rescue Exception => e\n        handle_exception e\n      end\n    end\n  end\n  self\nend\n```\n\nSo this thread is only staying alive as long as the `@queue.pop` returns a truthy value.\nIt's not reasonable or us to keep shoving something into the queue, so let's see what is happening \nin `Queue#pop`. For this we'll look at Rubinius' implementation\n\n```ruby\n# Retrieves data from the queue.  If the queue is empty, the calling thread is\n# suspended until data is pushed onto the queue.  If +non_block+ is true, the\n# thread isn't suspended, and an exception is raised.\n#\ndef pop(non_block=false)\n  while true\n    @mutex.synchronize do\n      @waiting.delete(Thread.current)\n      if @que.empty?\n        raise ThreadError, \"queue empty\" if non_block\n        @waiting.push Thread.current\n        @resource.wait(@mutex)\n      else\n        retval = @que.shift\n        @resource.signal\n        return retval\n      end\n    end\n  end\nend\n```\n\nThis now starts to make sense. `Queue#pop` is an infinite loop that will wait until it has\ncontent before each iteration. Our simple `MyQueue` class would return `nil` when `ThreadConsumer#start`\nis called because there is nothing in the queue and the thread would die. Even if we put something in\nqueue it would pop once, run the job, try to pop againg, then die.\n\nFor the sake of simplicity let's just have `MyQueue` inherit from\n`Queue`\n\n```ruby\nclass MyQueue < Queue\nend\n```\n\nNow we can run\n\n```ruby\nRails.queue.push(TestJob.new)\n=> \"I am running!\"\n```\n\nThe queue system in Rails 4.0 is a very simple solution, I'm looking\nforward to the release and the support for it to be added to many of the\nleading background job processing libraries.\n\nKeep in mind that as of this writing the master branch is still\nversioned as 'beta'. This API could change.\n"},{"title":"Rails 4.0 Sneak Peek: Asynchronous ActionMailer","tags":["rails"],"summary":"How to send your emails using the new Rails 4.0 Queue","legacy":false,"id":"2012/06/26/rails-4-sneak-peek-async-actionmailer","employee":"Brian Cardarella","date":"2012-06-26T00:00:00","body":"\n\nMy previous [deep dive into the Rails 4.0 Queueing system](http://reefpoints.dockyard.com/ruby/2012/06/25/rails-4-sneak-peek-queueing.html)\n was motivated by a patch to Rails I was working on while at [RailsCamp New England](http:/railscamps.org) this past weekend. I'm happy to say that [Rails 4.0 now has an optional asynchronous ActionMailer](https://github.com/rails/rails/pull/6839).\n\nThe API for pushing your emails to the background is very simple. If you\nwant to make this change application wide simply set it in your\n`application.rb` (or in any of the environment files)\n\n```ruby\nconfig.action_mailer.async = true\n```\n\nOr if you want to only make specific mailers asynchrounous\n\n```ruby\nclass WelcomeMailer < ActionMailer::Base\n  self.async = true\nend\n```\n\nThat's it! Any messages that are being delivered will be sent as a\nbackground job. In fact, the rendering is happening on the background as\nwell.\n\nYou will need to take care that the arguments you are passing your\nmailers can be properly marshalled. Instead of:\n\n```ruby\nWelcomeMailer.welcome(@user).deliver\n```\n\nYou should do:\n\n```ruby\nWelcomeMailer.welcome(@user.id).deliver\n```\n\nThen in your mailer:\n\n```ruby\nclass WelcomeMailer < ActionMailer::Base\n  def welcome(id)\n    @user = User.find(id)\n    ...\n  end\nend\n```\n\n## Switching it up ##\n\nThe default queueing system is `Rails.queue`, but you can override this to use any queueing system you\nwant by overriding `ActionMailer::Base#queue`.\n\n```ruby\nclass WelcomeMailer < ActionMailer::Base\n  def queue\n    MyQueue.new\n  end\nend\n```\n\nYour custom queue should expect the jobs to respond to `#run`, same as\n`Rails.queue`.\n\n## Credit ##\n\nMuch of the original code was cribbed (with permission) from [Nick\nPlante](http://blog.zerosum.org)'s\n[resque_mailer](https://github.com/zapnap/resque_mailer) gem.\n"},{"title":"Lessons Learned: The First Hire","tags":["business"],"summary":"What to expect when you start hiring","legacy":false,"id":"2012/08/30/lessons-learned-the-first-hire","employee":"Brian Cardarella","date":"2012-08-30T00:00:00","body":"\n\nIn February we made our first full-time hire with Dan McClain. He came\non board at a time when our company was not very stable but we needed to\ngrow to accomodate the larger contracts we wanted. I want to discuss the\nrisks and benefits on making the first hire.\n\n## You will lose money ##\n\nOne of the first things you learn about making your first full-time hire\nbeyond the founders is that you will most likely lose money. Which is\nkind of backwards because the entire point of hiring is so more money\ncan be made. Brian Kaney at [Vermonster](http://vermonster.com) told me this after we had already\nhired Dan. I was accustomed to balancing 3 people's salaries and now a\n4th was in play and we didn't have any extra money coming in. So we the\npartners had to take less money. After Brian told me that Vermonster had\nsimilar growing pains it made me feel better. I've since spoken with\nothers that have said the same. I suspect this is partly due to my\ninexperience as a first time business owner, if I ever start another\ncompany I can plan better for this. It is also due simply to the fact\nthat we didn't have any extra work coming in and were now dividing the\nmoney 4 ways instead of 3. The employees have to be paid, the partners\ndon't. I took on the brunt of the risk and actually just started paying\nmyself for the first time in 2012 at the start of August. It was totally\nworth it.\n\n## Be picky who you hire ##\n\nI'd like to say that Dan hired himself rather than we hired him. He was\nsomewhat new to the Boston Ruby community but was going out of his way\nto make himself known. He took the initiative to introduce himself to\nme and wanted to make contributions to the [BostonRB website](https://github.com/bostonrb/bostonrb).\nHe developed a feature, made a pull request, and I gave him feedback.\nWhat impressed me was how quickly he adapted to the feedback I gave him.\nThis told me one thing: Dan was a very quick learner. Before DockYard\nwas even looking to hire Dan contacted me and expressed interest in\nbeing hired. When it came time for us to make a hire he was the first\nname that came to mind. I think the lesson to learn here is if you want\nto work somewhere, don't wait for them to hire for your talent. Contact\nthem, let them know you are interested even if they don't have anything\navailable. When the time comes they'll remember you.\n\n## Make full-time hires, don't contract to hire ##\n\nWe hired Dan on a contract-to-hire basis. The idea at the time was to\nhave Dan on a \"trial\" period, test him out, see how he fit. I didn't\nlike how this went and I don't think it was fair to Dan to hire this\nway. If you are hiring for a position, hire full-time. If things aren't\nworking out you are always within your rights to let the person go.\nWhenever you are hiring someone there is always the risk that it won't\nwork out.\n\n## Be mindful of taxes, benefits, salaries, etc... ##\n\nNow that we had our first full-time on board we had to standardize\neverything. The best way to describe how I was handling all of this up\nuntil our first hire is \"half-assed\". I was the only one living in\nMassachusetts where it was required to have health-care so I was using\nthe MA Health Connector (a terrible service), we were handling time-off\nas \"whenever you want\" which of course doesn't fly well as you scale,\nand taxes were a mystery to me. Let's break each one down to see what\nwe've done:\n\n### Benefits ###\n\nI went for the best health-care I could find for employees. When it\ncomes down to it we're only talking about the difference of a few hundred\ndollars each month. If we go under because of this cost then I deserve\nto lose my company. If one of my employees cannot see the doctor they\nneed to because of sub-standard health coverage I run the risk that they\nwill not be back to work as quickly as they would otherwise. This risk\ncosts far more than the extra $$$ for the better plans.\n\nDockYard is currently covering 3/4 of the healthcare and I hope to bring\nthat up to 100% in 2013.\n\nWe're doing 3 weeks of paid vacation per year. Employees can take off\ntwo weeks at a time. I am also experimenting with how to handle\novertime. Because we're doing client work and sometimes deadlines have\nto be met I've told everyone that there will be a day when they get\nLumberged. I'm going to be the guy that will have to ask people to work\nover a weekend, I don't like it and I would be pissed if I was on the\nreceiving end of that. So, to compensate we'll offer an added vacation\nday in exchange for each weekend day. Of course employees can say \"no\"\nto working on the weekend. I understand that there are sometimes plans\nthat are made well in advance.\n\n### Payroll ###\n\nThis is something we have struggled with. Everyone has always been paid\nbut sometimes it has been a day late because of mistakes on my part.\nOriginally I was cutting checks to everyone and mailing them myself. I\nwould manually enter the data into QuickBooks for our accountant. This\nsucks. I eventually got it down to where it would only take me 5 minutes\nto do but for a while it was pretty disruptive. We eventually moved over\nDirect Deposit through QuickBooks. This was much better, and quicker. If\nyou are not doing Direct Deposit you should highly consider it.\n\nWe've recently moved from QuickBooks to Less Accounting and Sure\nPayroll. QuickBooks blows. We only used it because our accountant\nsuggested it. Here is some advice: don't let your accountant make\nsoftware decisions for you, especially if you are a software\nconsultancy. Our accountant is awesome, but QuickBooks is not. We lost\nan entire month of payroll, tax, and vendor payment data because a\nQuickBooks file corrupted. Never again.\n\n### Salaries, taxes ###\n\nOne *huge* mistake I made even before hiring Dan but continued into a\nmonth after he was hired was not withholding taxes from paychecks. We\nwere losing money after our first quarterly taxes were paid and I couldn't figure it out. In retrospect it is\npretty obvious what I should have been doing but keep in mind this was\nmy first company, I never had to deal with this before, and simply\nfucked up. Things turned around after I corrected this. I didn't ask for\nemployees to payback the money. I'm not trying to push this idea that\nI'm a \"good guy\" but this was my screw up and I took the hit.\n\nAlso, pay people well. \"Industry average salary\" will earn you \"industry\naverage employees\". If it is well known that you are paying high\nsalaries you will attract talented people. Talented people will more\nthan make up the difference.\n\n## Hiring ain't easy ##\n\nI've heard the term \"peak people\" thrown around a lot recently. It\nrefers to the huge talent shortage that the tech industry has. It's\ntrue, it exists. You know why? Because everybody wants to hire top\ntalent and nobody wants to train. I think it is pretty bullshit for\ncompanies to not train developers. Personally I would rather hire a\ndeveloper that requires training that is a quick learner than hire a\nmid-level dev that is set in his/her ways. We got lucky with Dan, he\nrequired very little ramping up. Mostly just a push here and a push\nthere. We've recently hired Doug Yun as a trainee. I told Doug that we\nare experimenting with him, I want to establish a training program at\nDockYard. So there will be ups and downs to it as we establish a\nplaybook. I realize we run the risk of devs training up, then bouncing\nout. There are ways to address this. We can offer employment term\nbenefits. If you are at DockYard for a year your salary will increase by\nX% every year. Let them know what the path for advancement is. We need\nto get better at this and it is something I want to focus on over the next\nfew months. I would love to hear feedback and how others are\napproaching this.\n\n## It pushes you to make things happen ##\n\nThe best benefit of hiring is that it personally motivates me to grow\nthe company. When it was just the co-founders we always had the fallback \nthat a payroll period could be skipped. As I mentioned earlier that is\nnot a choice when you have employees. Money must come in, people must\nget paid. Personally I have found this to be a good motivator for\ngrowing DockYard.\n\n## Share your experiences! ##\n\nIf you agree/disagree with anything I said, have a different\nperspective, or any general advice I'd love to hear it.\n"},{"title":"The New Iron Triangle: Security, Privacy, and Convenience","tags":[],"summary":"Pick two","legacy":false,"id":"2012/08/31/the-new-iron-triangle-security-privacy-and-convenience","employee":"Brian Cardarella","date":"2012-08-31T00:00:00","body":"\n\nIf you have not heard of [The Iron Triangle](http://en.wikipedia.org/wiki/Project_management_triangle) here is the basic idea: in a\nsoftware project you generally have three constraints: time, money, and\nquality. If you need the project done more quickly but maintain quality you will need to\nincrease the budget. If you want to increase quality you will need to\neither increase the time or increase the budget. It basically means that\nno contraint can be changed without there effecting any of the others.\nThe total area of the triangle remains the same, the lengths of the\nsides change to maintain this and reflect the priority of each.\n\nThis concept is not just for software projects, it is just where I hear\nit the most. Let me introduce you to a new iron triangle: security,\nprivacy, and convenience.\n\nImagine the a government agency is providing a service. One criticism\nthat government software always gets is how inconvenient it is. There\nare different levels of authentication that people must go through to\nactive accounts and the data that one agency has is sometimes not in\nsync with what another agency has. Imagine how simple signing up would\nbe with less security. I could have everything linked to an email\naccount. Of course this is rediculous and not going to happen but it is\none constraint we could give up. Another more realistic constraint is\nprivacy. It is very understandable that people are concerned about their\nprivacy especially when it comes to government. But consider how much\neasier and more cost-effective it would be to build out government\nsystems if a single-sign-on solution existed. Instead of a social\nsecurity number everybody gets their government issues account that is\naccessible by every agency. This would be far more effecient and\nconvenient. Odds are neither the security or privacy constraints will be\nrelaxed for government run software so expect it to continue to be\ninconveient.\n\nA more secure system will have to give up on conveience but can go\neither way on privacy. Two-factor authentication is far less conveinet\nbut far more secure. More and more systems are implementing 2-factor\nauthentication, but it is annoying for me to give my cell phone number.\nOne could argue either way about privacy. Is a system less secure with\nyour personal information breing stored or is it more secure because you\ncan personally identify your account later?\n\nI'd like to get some feedback on this. If you agree with this idea or\nnot let your voice be heard!\n"},{"title":"Doug Yun is a DockYarder!","tags":["office"],"summary":"DockYard welcomes Doug Yun","legacy":false,"illustration_alt":"Doug Yun","illustration":"https://i.imgur.com/netbX9E.png","id":"2012/09/05/doug-yun-is-a-dockyarder","employee":"Brian Cardarella","date":"2012-09-05T00:00:00","body":"\n\n![Doug Yun](https://i.imgur.com/netbX9E.png)\n\nDoug has been training with us for the past month and this week we've\nreleased him from his cage on the nearest client app. He's running wild!\n\nThis rounds out our Boston team to 4! ZOMG!\n\nFollow him on the [Twitters](http://twitter.com/DougYun) and\n[github](https://github.com/duggieawesome)\n"},{"title":"Rails 4.0 Sneak Peek: PostgreSQL array support","tags":["rails","postgres"],"summary":"Storing arrays natively in PostgreSQL is now supported by Rails","legacy":false,"id":"2012/09/18/rails-4-sneak-peek-postgresql-array-support","employee":"Dan McClain","date":"2012-09-18T00:00:00","body":"\n\nI'm happy to announce that [Rails 4.0 now has support for PostgreSQL\narrays](https://github.com/rails/rails/pull/7547). You can create an\narray column easily at the time of migration by adding `:array => true`.\nCreating an array column will respect the other options you add to the\ncolumn (`length`, `default`, etc). \n\n```ruby\ncreate_table :table_with_arrays do |t|\n  t.integer :int_array, :array => true\n  # integer[]\n  t.integer :int_array, :array => true, :length => 2\n  # smallint[]\n  t.string :string_array, :array => true, :length => 30\n  # char varying(30)[]\nend \n```\n\nIt should be noted when setting the default value for an array column,\nyou should use PostgreSQL's array notation for that value\n(`{value,another value}`). If you want the default value to be an empty\narray you would have `:default => '{}'`.\n\n```ruby\ncreate_table :table_with_arrays do |t|\n  t.integer :int_array, :array => true, :default => '{}'\n  # integer[], default == []\n  t.integer :int_array, :array => true, :length => 2, :default => '{1}'\n  # smallint[], default == [1]\nend \n```\n\n## An example of a model with an array value\n\nLet's say that we have a user model, which has a formal first and last\nname, and also a number of nicknames (I rarely ever go by Daniel). The\nfollowing code would create the table we need to store this.\n\n```ruby\ncreate_table :users do |t|\n  t.string :first_name\n  t.string :last_name\n  t.string :nicknames, :array => true\nend\n```\n\nAnd we have a simple model for this table:\n\n```ruby\nclass User < ActiveRecord::Base\n  attr_accessible :first_name, :last_name, :nicknames\nend\n```\n\nWhere we don't have a default value, if we instantiate a User object\nwith the following\n\n```ruby\njohn = User.create(:first_name => 'John', :last_name => 'Doe')\n```\n\nIf we call `john.nicknames`, `nil` would be returned, and is stored as\n`NULL` in PostgresSQL. We can set the nicknames attribute at the time of\ncreation with\n\n```ruby\njohn = User.create(:first_name => 'John', :last_name => 'Doe',\n  :nicknames => ['Jack', 'Johnny'])\n```\n\nIf we then retrieved this record from the database, the `nicknames`\nvalue would be casted to an array, instead of returning the string of\n`{Jack,Johnny}`.  Rails 4.0 has a pure ruby array value parser, but if\nyou would like to speed up the parsing process, the previously mentioned\n[pg\\_array\\_parser](https://github.com/dockyard/pg_array_parser)\ngem will be used if it is available. PgArrayParser has\na C extension, and a Java implementation for JRuby (although the gem\ncurrently broken in JRuby, this is something I am fixing now).\n\nOne important thing to note when interacting with array (or other\nmutable values) on a model.  ActiveRecord does not currently track\n\"destructive\", or in place changes. These include array `push`ing and\n`pop`ing, `advance`-ing DateTime objects. If you want to use a\n\"destructive\" update, you must call `<attribute>_will_change!` to let\nActiveRecord know you changed that value. With our User model, if we\nwanted to append a nickname, you can do the following:\n\n```ruby\njohn = User.first\n\njohn.nicknames += ['Jackie boy']\n# or\njohn.nicknames = john.nicknames.push('Jackie boy')\n# Any time an attribute is set via `=`, ActiveRecord tracks the change\njohn.save\n\njohn.reload\njohn.nicknames\n#=> ['Jack', 'Johnny', 'Jackie Boy']\n\njohn.nicknames.pop\njohn.nicknames_will_change!\n# '#pop' changes the value in place, so we have to tell ActiveRecord it changed\njohn.save\n```\n\nOne last note about arrays in PostgreSQL: there are no element count\nconstraints, and any array can be multidimensional. With the\nmultidimensional arrays, they must be \"square\" (the sub arrays must all\nhave the same number of elements).\n\n```ruby\n[[1,2,3], [2,3,4], [4,5,nil]]\n# Valid array value in PostgreSQL, each subarray has the same number of\n# elements\n[1,2,[3,4]]\n# Invalid array, we are mixing values and arrays at a single level\n```\n\nIn my next article, I will talk about querying PostgreSQL arrays in both\npostgres\\_ext and Rails 4.0. Go forth and use arrays in Rails 4.0!\n"},{"title":"Making of the DockYard Narwin","tags":[],"summary":"Animated gif of the evolution of the narwin","legacy":false,"illustration_alt":"DockYard","illustration":"https://i.imgur.com/gadHFL4.jpg","id":"2012/09/20/making-of-the-dockyard-narwin","employee":"Amanda Cheung","date":"2012-09-20T00:00:00","body":"\n\nHalf narwhal, half penguin. He's a cute lil' fella with quite the personality. He set the stage for the redesign of our website while becoming DockYard's new brand mascot.\n\nThe Final Version:\n![DockYard](https://i.imgur.com/gadHFL4.jpg)\n\nThe Evolution:\n![DockYard Narwin](https://i.imgur.com/dxjG83r.gif)\n"},{"title":"Querying PostgreSQL datatypes in ActiveRecord with postgres_ext","tags":["rails","postgres","gems"],"summary":"Returning records based on array elements and network subnets","legacy":false,"id":"2012/09/21/querying-postgresql-datatypes-in-active-record-with-postgres_ext","employee":"Dan McClain","date":"2012-09-21T00:00:00","body":"\n\nI created the [postgres\\_ext](https://github.com/dockyard/postgres_ext) gem to add ActiveRecord support for \nPostgreSQL datatypes in Rails 3.2+. So far, I have added support for\nthe CIDR, INET, MACADDR, UUID, and array datatypes. [Please open an issue on GitHub if you'd like other datatypes supported that aren't currently](https://github.com/dockyard/postgres_ext/issues).\nSince we can now add these columns via Rails migrations, and have\nINET/CIDR and array columns converted to Ruby `IPAddr` and `Array`\nobjects, resepectively.\n\nRails 4.0 has also added support for CIDR, INET, MACADDR and array\ndatatypes.\n\nIt would be great if we could take advantage of\nPostgreSQL's query support for these datatypes. Wait, we can already do\nthat!\n\n## Querying against arrays using `ANY` and `ALL`\n\nIn PostgreSQL, you can query for records where any or all elements match\na given predicate.\n\n```sql\nSELECT *\nFROM users\nWHERE 'johnny' = ANY(nicknames)\n-- Finds any record that has 'johnny' stored in the nicknames array\n\nSELECT *\nFROM user_scores\nWHERE 1000 > ALL(scores)\n-- Finds any record that has over 1000 stored in every element in the\n-- scores array\n```\n\nWe can actually use arel to generate these queries.\n\n```ruby\nuser_arel = User.arel_table\n\nany_nicknames_function = Arel::Nodes::NamedFunction.new('ANY', [user_arel[:nicknames]])\npredicate = Arel::Nodes::Equality('test', any_nicknames_function)\n\nsql_statement = user_arel.project('*').where(predicate).to_sql\n#=> SELECT * FROM \\\"users\\\" WHERE 'test' = ANY(\\\"users\\\".\\\"nicknames\\\")\n\nusers_with_nickname = User.find_by_sql(sql_statement)\n```\n\nIn the above example, we have to create an `Equality` node manually\nsince the left hand side of the predicate is the value, instead of the\ncolumn. If you need `<` in your predicate, you would create a `LessThan`\nnode instead of an equality node.\n\nThis example applies to both Rails 3.2+ with postgres\\_ext and Rails 4.0\nwith native array support.\n\n## Array overlap\n\nIn PostgreSQL, you can check if two arrays have one or more elements in\ncommon by using the overlap operator, `&&`.\n\n```sql\n'{1,2,3}' && '{4,5,6}'\n-- f\n'{1,2,3}' && '{3,4}'\n-- t\n```\n\nIn postgres\\_ext, I added a new Arel predicate node for the \noverlap operator.  For the time being, it is named `ArrayOverlap`\nand can be called from a `Arel::Attribute` as `#array_overlap`. It\nis likely that this will be renamed to `Overlap` and `#overlap`,\nrespectively, in the next release of postgres\\_ext.\n\n```ruby\nuser_arel = User.arel_table\n\nUser.where(user_arel[:tags].array_overlap(['one','two'])).to_sql\n# => SELECT \\\"users\\\".* FROM \\\"users\\\" WHERE \\\"users\\\".\\\"tags\\\" && '{one,two}'\n```\n\nOne case that we have used an array column in tandem with the overlap\noperator was adding tags to a user. We had three tags that could be\nplaced on a user, so we stored this data an array column. We then had a\nsearch form which had a multiselect field for that tags column. The\nmultiselect would give us an array of possible values that we wanted to\nfind records that had any of those selected values. So instead of\ncrafting a statement with multiple `ANY` queries `OR`ed together, we\nused overlap instead, resulting in only one predicate.\n\n## INET/CIDR subnet inclusion\n\nIn PostgreSQL, you can see if a particular INET address is contained in\na specific subnet with the contained within operator, `<<`.\n\n```sql\ninet '192.168.1.6' << inet '10.0.0.0/24'\n-- f\n\ninet '192.168.1.6' << inet '192.168.1.0/24'\n-- t\n```\n\nIn postgres\\_ext, I added a new Arel predicate node for the \ncontained within operator. It can be called from a\n`Arel::Attribute` with `#contained_within`. I also added a visitor for\nIPAddr objects so that they are correctly converted to quoted strings\nwhen called within a Arel predicate.\n\n```ruby\nuser_arel = User.arel_table\n\nUser.where(user_arel[:ip_address].contained_within('10.0.0.0/8').to_sql\n#=> SELECT \\\"users\\\".* FROM \\\"users\\\" WHERE \\\"users\\\".\\\"ip_address\\\" << '10.0.0.0/8'\n```\n\n## We're not done yet\n\nWe have only scratched the surface of the datatype specific functions\nand operators in PostgreSQL. There are many more to be implemented, and\nthe plan is to support them all. This post highlights what has been\nimplemented so far, and also what you can do with Arel already. I plan\nto put together some pull requests for Arel to add in some of the\nPostgreSQL operators. If there is an operator missing in postgres\\_ext\nthat you want/need, please [open an issue on\nGithub](https://github.com/dockyard/postgres_ext/issues?state=open)!\n"},{"title":"ClientSideValidations 3.2 Released!","tags":["rails","gems"],"summary":"Better late than never","legacy":false,"id":"2012/10/09/client-side-validations-3-2-released","employee":"Brian Cardarella","date":"2012-10-09T00:00:00","body":"\n\nI just released [ClientSideValidations 3.2](https://github.com/bcardarella/client_side_validations)\n\nThis is a very big release for the gem, one that took *way* too much\ntime to get done. I want to start by re-introducing people to the gem,\nwhat the value is, and what the changes for 3.2 are.\n\nClientSideValidations is just that, it will extract the validations from\nyour model and apply them to your forms on the client. The\n[README](https://github.com/bcardarella/client_side_validations/blob/master/README.md)\nhas more comprehensive instructions. But here is the quick guide:\n\nAdd `rails.validation.js` to your asset pipeline, then add `:validate =>\ntrue` to your form like so:\n\n```erb\n<%= form_for @user, :validate => true do |f| %>\n```\n\nAnd that is it. If you have more [complex validators](https://github.com/bcardarella/client_side_validations/blob/master/README.md#conditional-validators) or \n[custom validators](https://github.com/bcardarella/client_side_validations/blob/master/README.md#custom-validators)\non your models then you can quickly support these as well.\n\n## Changes ##\n\nVersion 3.2 brings many changes to the gem. The first of which is that\nfrom this version on we will be following [Semantic Versioning](http://semver.org) or trying our best to do so.\n\nThe next change, and the biggest backward-incompatible change, is that\nthe support for `SimpleForm`, `Formtastic`, `Mongoid`, and `MongoMapper`\nhave been removed. These have been put into their own\n[plugins](https://github.com/bcardarella/client_side_validations/wiki/Plugins):\n\n* [SimpleForm](https://github.com/dockyard/client_side_validations-simple_form)\n* [Formtastic](https://github.com/dockyard/client_side_validations-formtastic)\n* [Mongoid](https://github.com/dockyard/client_side_validations-mongoid)\n* [MongoMapper](https://github.com/dockyard/client_side_validations-mongo_mapper)\n\nThis will be the convetion from now on. The `ClientSideValidations` gem\nitself will only support `Rails` out of the box. If there are additional\nFormBuilders or ORMs that people need support for these will be done so\nvia the plugins. This will allow for quicker bug fixes and less\ncomplexity in the core gem.\n\nI have also released a gem for [Turbolinks support](https://github.com/dockyard/client_side_validations-turbolinks).\nTurbolinks support will be part of the core gem for the next release\n(4.0).\n\nThere have been a significant number of bug fixes for this release. If\nyou ran into a bug before odds are it is now resolved.\n\n`Proc`s are now fullow supported in `ActiveModel` validators, you just\nhave to force the validation to evaluate:\n\n```erb\n<%= f.text_field, :validate => { :length => true } %>\n```\n\nI have also added a FormBuilder method for adding validations for\nattributes that are not being written to the form but may be added\ndynamically later:\n\n```erb\n<%= f.validate :age, :weight %>\n```\n\nThis method can also take validator specific options.\n\n## JavaScript API Additions and Changes ##\n\nThe first major change is that `data-validate=\"true\"` is no longer\nrendered on the inputs server-side. It is added to the input at\nrun-time.\n\nThe second is the addition of some [jQuery functions](https://github.com/bcardarella/client_side_validations/blob/master/README.md#enabling-disabling-and-resetting-on-the-client):\n\n```javascript\n$(form or input).enableClientSideValidations();\n$(form or input).disableClientSideValidations();\n$(form).resetClientSideValidations();\n```\n\n* `$.fn.enableClientSideValidations()` acts upon either a form or input\n  and will enable them for ClientSideValidations. If you are adding\nforms or inputs dynamically to the DOM via AJAX or some other means you\n*need* to call this function on them.\n\n* `$.fn.disableClientSideValidations()` acts upon either a form or an\n  input and will disable them for ClientSideValidations.\n\n* `$.fn.resetClientSideValidations()` will reset the validations. This\n  means disabling, removing all error messages, and enabling\nvalidaitons.\n\n## Security ##\n\nThere have been some security fixes. Mostly around the `Uniqueness`\nmiddleware.\n\n* Calls to the uniqueness middleware only act upon models and\nattributes that have a uniqueness validator defined in the model.\n\n* The [API for turning off uniqueness app-wide has been changed](https://github.com/bcardarella/client_side_validations/blob/master/README.md#security).\n\n## Backwards incompatiable changes ##\n\n* If you were relying upon `data-validate=\"true\"` being rendered on the\n  inputs from the server your code will break.\n\n* `ClientSideValidations::Config.uniqueness_validator_disabled` has been\n  removed. Please add `ClientSideValidations::Config.disabled_validators\n= [:uniqueness]` to your initializer if you require this functionality.\n\nPlease give the gem a try and [let me know](http://twitter.com/bcardarella) what you think!\n"},{"title":"Expanding the Yard","tags":[],"summary":"The story of how we reimagined our site.","legacy":false,"id":"2012/10/11/expanding-the-yard","employee":"Angelo Simeoni","date":"2012-10-11T00:00:00","body":"\n\n<div class=\"one\">\n  <div class=\"content\">\n    <h2>Outgrowing simplicity</h2>\n    <p>The first version of our site was contained within a single page. At the time, it served its purpose well. As we added more, it began to feel like it trying to do too much. Upon recognizing this, we began reimagining our site.</p>\n  </div>\n</div>\n\n<div class=\"two\">\n  <div class=\"content\">\n    <h2>Structural changes</h2>\n    <p>The very first step we took was to establish a reasonable structure of our new site. This helped to inform the site content, and much of the new site design.</p>\n    <p>We decided to make the landing page an overview of DockYard. Our work deserved its own place to be shown. We have added people to our team, and we wanted a page dedicated to community & open source projects. We have this blog thing, and we also wanted a dedicated contact page.</p>\n  </div>\n</div>\n\n<div class=\"three\">\n  <div class=\"content\">\n    <h2>Design & code</h2>\n    <p>After the structural decisions had been made, it was time to put down some design. This was done primarily in the browser using actual code. This allowed rapid iteration over page layout, content tweaks, and especially mobile design. Being able to try things almost right away in browser informed many design decisions.</p>\n    <p>With the new design, the Narwin (half narwhal, half penguin) was introduced as our mascot and overseer of all things nautical. We have high confidence that he will serve us loyally now and in the future.</p>\n  </div>\n</div>\n\n<div class=\"four\">\n  <div class=\"content\">\n    <h2>Well done</h2>\n    <p>It was a lot of fun to reimagine our site and we are all proud of the result. It is designed to grow and evolve along with us.</p>\n    <p>There are plenty of hidden surprises in the new site. See if you can find an easter egg or two.</p>\n  </div>\n</div>\n"},{"title":"OpenHack Boston 1.0","tags":[],"summary":"Come one, come all!","legacy":false,"illustration_alt":"OpenHack","illustration":"https://i.imgur.com/a3LfvgG.png","id":"2012/10/26/openhack-boston","employee":"Brian Cardarella","date":"2012-10-26T00:00:00","body":"\n![OpenHack](https://i.imgur.com/a3LfvgG.png)\nLast night we hosted Boston's first\n[OpenHack](http://openhack.github.com/)\nevent.\n\n[Nick Quaranto](http://twitter.com/qrush) started OpenHack at his [CoWorkBuffalo](http://coworkbuffalo.com/) office space,\nbased upon [BostonRB](http://bostonrb.org)'s former (don't get me\nstarted) Hackfests. The idea is pretty simple: a quiet space with food,\ndrinks, and wifi is provided. Developers show up and hack on some\nsoftware for a few hours.\n\nOn 2-day notice we had 11 in attendance and all around everyone had a\nvery productive night. Currently our office maxes out at 20 chairs so until we buy more\nwe cannot accept over 20, but next month we will open the\nevent to a wider audience. We want to welcome more than just Ruby devs\n(with the exception of 2 all were Ruby devs) to the event.\n\nFollow [@DockYard](http://twitter.com/dockyard) for all Boston OpenHack\nannouncements.\n"},{"title":"Integration is Hard","tags":["postgres"],"summary":"A description of techniques used to integrate with various vendors on a recent DockYard project for the AFL-CIO's Super PAC Worker's Voice.","legacy":false,"id":"2013/01/03/integration-is-hard","employee":"Chris Gill","date":"2013-01-03T00:00:00","body":"\n\nThere's no one-size-fits-all approach to integrating with external\nsystems because each system comes with its own unique requirements and\nconstraints.  This article aims to describe some of the varying\napproaches we used to integrate with external systems in a recent\nproject we built for the [AFL-CIO](http://www.aflcio.org)'s Super PAC\n[Worker's Voice](http://www.workersvoice.org).\n\nFor this project, integration with external vendors was the biggest technical hurdle to clear in order to ensure a successful launch.  The project, called [RePurpose](http://repurpose.workersvoice.org/), gives volunteers and activists a way to choose how the movement's resources get deployed.  The more volunteering and activism a person does, the more RePurpose points they earn, which they can then use to direct the funding of things like more canvassers, direct mail pieces or online ads.  \n\nIt's a way to give the people on the ground a say in how the money gets spent.\n\nThe volunteering and activism data for which RePurpose points get awarded exists in several separate systems:\n\n* [VAN](http://www.ngpvan.com)\n\n    VAN is the de facto standard tool used everywhere in progressive politics - from small local races all the way up to the Obama campaign.  It's an organizing tool that stores volunteer records, canvass records (door knocks and phone calls), activist codes, and other organizing data used by progressive campaigns and organizations.\n\n* [Salsa Labs](http://www.salsalabs.com)\n\n    Salsa has a platform with a rich API and tools to create fundraising and advocacy campaigns and manage organizer data.  It stores supporter records, online donation records, and pledges to take action - among other things.\n\n* [Amicus](http://amicushq.com/)\n\n    Amicus is a new online tool that leverages Facebook connections of volunteers to enhance fundraising and advocacy campaigns.  It stores a set of volunteer records, friend invite records, and social calling records.\n\nThe goal was straightforward - RePurpose needed to know when a volunteer\nwas performing tasks in external systems, so that the user could receive\npoints in RePurpose for those tasks.  RePurpose itself has a Task model\nthat supports multiple kinds of tasks in the various external systems -\nsurvey tasks, activist code tasks, and\n[canvass](http://en.wikipedia.org/wiki/Canvassing) tasks in VAN, donation tasks and action tasks in Salsa, and friend invite tasks and call tasks in Amicus.  So a RePurpose administrator could set up a task that would award 10 RePurpose points each time a volunteer knocked on a door, made a phone call, or made a donation.\n\nHere's how we did it in each system:\n\n## VAN Sync ##\n\nVAN, which was recently voted [Most Valuable\nTech](http://rootscamp.neworganizing.com/awards/2012/) at [RootsCamp\n2012](http://rootscamp.neworganizing.com/), has a\n[SOAP](http://en.wikipedia.org/wiki/SOAP)-based API that allows us to list survey questions, list activist codes, and create and list volunteers (among other things) - all of which we use to get that data into RePurpose, but the API doesn't support retrieving the raw canvasser data - which is the piece we really need to award credit.  To get this data the two options were a nightly sync of flat files, or getting direct access to a replicated database.  We opted for the flat file sync as we knew it had worked for other organizations (among them the Democratic National Committee) and the replicated database approach would have incurred extra time, expense, and risk.\n\nWe worked with the great folks at VAN to get a nightly data sync into\nplace.  Each night around 3am, VAN uploads a zipped TSV (tab-separated\nvalues) export of the relevant data from all the relevant tables in the\nAFL-CIO's VAN database.  This is not a delta - because the data size is\nrelatively low (< 1 GB), we receive the full data dump each night.  We\nthen unzip, verify that all the files we expect are present, convert\ncharacter encodings from\n[CP1252](http://en.wikipedia.org/wiki/Windows-1252) to\n[UTF8](http://en.wikipedia.org/wiki/UTF-8) (VAN uses [MSSQL\nServer](http://en.wikipedia.org/wiki/Microsoft_SQL_Server)), and load\nthis data into auxiliary tables in the RePurpose database using\n[PostgreSQL](http://www.postgresql.org)'s\n\"[COPY](http://www.postgresql.org/docs/9.2/static/sql-copy.html)\" command.  All told it takes about 5 minutes each night to process, load, and index around 700MB of data from flat files to get it into PostgreSQL and ready to be used.  Then based on the new data we award credit to volunteers for completing tasks.  This approach handles the most data of any of the external integrations and does so reliably.  It has one drawback which is that the data can be at most 24 hours stale by the time we receive it, which is not ideal but is certainly workable.  In practice this has not been a problem for us.\n\n## Salsa API ##\n\nSalsa has a\n[REST](http://en.wikipedia.org/wiki/Representational_state_transfer)-based\n[API](http://en.wikipedia.org/wiki/Application_programming_interface) for authenticating and for creating and retrieving objects in the Salsa system.  For RePurpose, that meant creating and listing supporters (Salsa's name for a volunteer record), listing donation pages, listing donations, and listing completed actions like making a pledge or writing a letter to an editor.  In the context of RePurpose we were most interested in listing completed donations and completed actions so we could award the person who completed the task with their RePurpose points.  Since we could get all this information via the API, and since the API can list objects created since a certain timestamp, we set up a scheduled job to poll the API and ask for anything new that has come in since the last record we retrieved.  This job runs every 10 minutes and gets us pretty close to realtime - if you make a donation through one of the Salsa donation pages that's connected to a RePurpose task, your points will be credited to you within 5 minutes on average.\n\n## Amicus Exports ##\n\nThe Amicus API was still a work in progress during the RePurpose project, so we could not use it - but they did have an on-demand user export that could be programmatically triggered.  Since the user export contained all the information we needed about how many calls a user had attempted and how many friends they had invited on Facebook, this would get us where we needed to be.  We would import the Amicus users nightly on a schedule and load them into auxiliary tables in the RePurpose database, which were then used to award credit to the folks making calls and inviting friends.  Since we could trigger the export on demand, we also added a button to the RePurpose admin area to allow administrators to reload the Amicus data on demand and credit any new arrivals.\n\n## Matching ##\n\nYou've heard how we get the data into the RePurpose system, but how do we match the volunteers from the various external systems up with the users in RePurpose?  \n\nThere are all kinds of pitfalls in implementing person matching, like trying to match up on variations of a first name, or variations of a street address, or keeping track of previous known-good addresses.  Complexity can quickly spiral out of control for marginal benefit.  For this project we went with a simple assumption - all matching would occur via email address.  So if a user was doing things in the field, which gets recorded into VAN - they should use the same email address that they would use to create their RePurpose account.  Likewise for Salsa and Amicus.  Since each of these external systems stores an email address for the volunteer, with this simple assumption, the matching logic becomes simple - comparing lowercase versions of email addresses.\n\n## Awarding Credit ##\n\nThere were some wrinkles with awarding credit for tasks performed in external systems.  Since each task hinged on an external datapoint, it was critical to uniquely identify these datapoints.  For most tasks, the granularity of data allowed us to use the primary key of the foreign data source as the unique identifier.  In some cases the data would just be an aggregate count, like \"15 calls made\" - in which case we would generate our own idempotent IDs for those calls so as to award credit once and have a way to prevent awarding credit for the same call a second time.  In addition to keeping things crediting properly, this had the added benefit of allowing any RePurpose points in the system can be traced back to the explicit data point in the external system that was responsible for creating them.\n\n## Wrapping Up ##\n\nNow that you've seen how we took three different approaches to integrate\nwith three different systems, you're probably thinking that integration\ncan be tricky.  But if you're in a progressive organization that uses\nVAN, Salsa, or Amicus - remember that [here at DockYard we have the\nexpertise and experience to make it look\neasy](https://dockyard.com/contact).\n"},{"title":"DismissibleHelpers released","tags":["rails","gems"],"summary":"Add simple to implement help text that users can dismiss","legacy":false,"id":"2013/01/04/dismissible_helpers-released","employee":"Dan McClain","date":"2013-01-04T00:00:00","body":"\n\nHave an application where you want to add some help text for the user,\nbut they really only need to see it once? With the\n[`dismissible_helpers`](https://github.com/dockyard/dismissible_helpers)\ngem, you can quickly add dismissible help text to your application.\n\n* [View the project on GitHub](https://github.com/dockyard/dismissible_helpers)\n* [View the demo here](http://dismissible-helpers-example.herokuapp.com/)\n* [View the demo source code](https://github.com/dockyard/dismissible_helpers_example)\n\n## What you get\n\nDismissibleHelpers includes:\n\n * DismissibleHelpers View Helper - Renders the help text only if the visitor\nhas not dismissed it\n * DismissedHelpers Routes and controller - Handles the JavaScript requests\nto store the dismissal state\n * DismissedHelpers Javascript - Handles the front end interactions with\nthe help text\n\nBy default, `dismissible_helpers` will use a cookie to store the\ndismissal status of the help text.\n\n## Three minute setup\n\nTo start using `dismissible_helpers` without any customization, you only\nthree steps away.\n\n<ol>\n\n  <li><p> Add <code>dismissible_helpers_routes</code> to your <code>config/routes.rb</code>\n\n```ruby\nYourApplication::Application.routes.draw do\n  dismissible_helpers_routes\n\n  # Your other routes\nend```\n  </p></li>\n\n  <li><p> Add the Javascript: Add the following to your <code>app/assets/javascripts/application.js</code>.\n\n```javascript\n// Your other require statments\n//=require dismissible_helpers\n//=require_self\n\n$(function(){\n  $('.dismissible').dismissible()\n})```\n  </p></li>\n\n  <li><p> Call the <code>render_dismissible_helper</code> method with the string you want to\n       render. The string passed to the method will be processed by the I18n method\n       <code>t</code>, so the content of the help message should be stored in your localization\n       file.\n\n```erb\n<%= render_dismissible_helper 'help.some_help_message' %>\n```\n  </p></li>\n\n</ol>\n\n## Advanced setup\n\n### Changing the way the help text is removed\n\nBy default, the dismissed helper is removed from the page via\n`$(helper).remove()`. This can be customized by passing a callback to the\n`.dismissible()` call. To use jQuery's `.slideUp()` you would use the\nfollowing call:\n\n```javascript\n$(function(){\n  $('.dismissible').dismissible({\n    success: function(helper){\n      helper.slideUp(); //'helper' is the jQuery-wrapped element\n    }\n  });\n});\n```\n\n### Storing dismissed helpers for authenticated users\n\n`dismissible_helpers` can store the help text dismissal state on a\nuser/account. That way, when a user dismisses some help text, it follows\nthem across browsers.\n\n`dismissible_helpers` will attempt to retrieve the authenticated user by\nchecking for a `current_user` helper method. If the\nApplicationController responds to `current_user`, `dismissible_helpers`\nwill check to see if the returned object has a `dismissed_helpers`\nattribute. It will then add the dismissed help text to that model.\n\n`dismissible_helpers` expects that the `dismissed_helpers` attribute is\nan array. With vanilla ActiveRecord, you can achieve this with attribute\nserialization:\n\nFirst, add the column to your model (we'll assume it's an Account class\nin this example)\n\n```ruby\nclass AddDismissedHelpersToAccounts < ActiveRecord::Migration\n  def up\n    add_column :accounts, :dismissed_helpers, :text\n  end\n\n  def down\n    remove_column :accounts, :dismissed_helpers\n  end\nend\n```\n\nThen add the `serialize` call to your model\n\n```ruby\nclass Account < ActiveRecord::Base\n  serialize :dismissed_helpers, Array\nend\n```\n\nIf you are using PostgreSQL as your database, you could use\n[postgres_ext](https://github.com/dockyard/postgres_ext) to\nadd native array support to your models. You would just need the\nfollowing migration to add the dismissed_helpers attribute\nto your model:\n\n```ruby\nclass AddDismissedHelpersToAccounts < ActiveRecord::Migration\n  def up\n    add_column :accounts, :dismissed_helpers, :string, :array => true\n  end\n\n  def down\n    remove_column :accounts, :dismissed_helpers\n  end\nend\n```\n\n## Wrapping up\n\nHopefully you find the gem useful. If you find any issues with it, \n[let us know](https://github.com/dockyard/dismissible_helpers/issues)!\n"},{"title":"Building an Ember app with RailsAPI - Part 1","tags":["javascript","rails"],"summary":"Setting up RailsAPI for writing an Ember App","legacy":false,"id":"2013/01/07/building-an-ember-app-with-rails-api-part-1","employee":"Brian Cardarella","date":"2013-01-07T00:00:00","body":"\n\n**This article was last updated on May 28, 2013 and reflects the state\n of Ember (1.0.0-rc4) and the latest build of Ember Data (0.13) as of\nthat date.**\n\n[Fork the project on Github!](https://github.com/bcardarella/ember-railsapi)\n\n[Use the app live on Heroku](http://ember-rails-api.herokuapp.com/)\n\nLately I've been playing with [Ember.js](http://emberjs.com) and I have\nreally grown to love it. I get the same \"AHA!\" feeling I got building my\nfirst [Rails](http://rubyonrails.org) app 7 years ago. Let's see how to\nbuild a simple\n[CRUD](http://en.wikipedia.org/wiki/Create,_read,_update_and_delete) app\nusing the [RailsAPI](https://github.com/rails-api/rails-api) as the\nbackend. We're going to build a new app and deploy to Heroku.\n\n## Part 1 - Getting Set Up\n\n```text\ngem install rails-api\nrails-api new ember-app\ncd ember-app\n```\n\nSimilar to the `rails` command `RailsAPI` comes with a `rails-api`\ncommand which under the hood is just using the normal `rails` CLI code\nbut overriding some of the templates generated. Out of the box\n`RailsAPI` won't generate the [asset pipeline](http://guides.rubyonrails.org/asset_pipeline.html) directories\nas there is [still some\ndebate](https://github.com/rails-api/rails-api/issues/50) if it will use\n[Sprockets](https://github.com/sstephenson/sprockets),\n[Rake-Pipeline](https://github.com/livingsocial/rake-pipeline) or some\nother solution. In this example we're going to use Sprockets as it will\nsave us a lot of time. `RailsAPI` is bundled with\n[ActionPack](https://github.com/rails/rails/blob/3-2-stable/actionpack/actionpack.gemspec)\nwhich has `Sprockets` as a dependency. All we need to do is add in the\ndirectories\n\n```text\nmkdir -p app/assets/{javascripts,stylesheets,images}\nmkdir -p vendor/assets/{javascripts,stylesheets,images}\n```\n\nNow we need to copy in the vendored asset files. You can either build yourself our run the following to copy directly from my Github project\n\n```text\ncd vendor/assets/javascripts\nwget https://raw.github.com/bcardarella/ember-railsapi/master/vendor/assets/javascripts/ember-data.js\nwget https://raw.github.com/bcardarella/ember-railsapi/master/vendor/assets/javascripts/ember.js\nwget https://raw.github.com/bcardarella/ember-railsapi/master/vendor/assets/javascripts/jquery.js\nwget https://raw.github.com/bcardarella/ember-railsapi/master/vendor/assets/javascripts/modernizr.js\ncd ../../..\n```\n\nNote that if you're a Mac user, just replace `wget` (the Linux command) with `curl -O` (the Unix command) on the above lines.\n\nLet's setup the directory structure for our Ember app\n\n```text\nmkdir -p app/assets/javascripts/{controllers,models,views,templates}\n```\n\nAnd now we'll setup the load order in our `app/assets/javascripts/application.coffee` file\n\n```coffeescript\n#= require modernizr\n#= require jquery\n#= require handlebars\n#= require ember\n#= require ember-data\n#= require bootstrap\n#= require_self\n#= require store\n#= require routes\n#= require_tree ./controllers\n#= require_tree ./models\n#= require_tree ./templates\n#= require_tree ./views\n\nwindow.App = Ember.Application.create()\n```\n\nAdd the `routes.coffee` and `store.coffee` files:\n\n```text\ntouch app/assets/javascripts/routes.coffee\ntouch app/assets/javascripts/store.coffee\n```\n\nAnd the `app/assets/stylesheets/application.sass` file\n\n```sass\n@import 'bootstrap'\n\nbody\n  padding-top: 60px\n```\n\nThat was a good amount of setup. Now we have the application structure for an Ember app in our asset pipeline. This will make things cleaner once we start coding.\n\nLet's setup the necessary gem dependencies in our `Gemfile`. Just replace the entire contents with the following:\n\n```ruby\nsource 'https://rubygems.org'\n\nruby '2.0.0'\n\ngem 'rails', '3.2.13'\ngem 'rails-api'\ngem 'thin'\ngem 'active_model_serializers', :github => 'rails-api/active_model_serializers'\n\ngroup :development, :test do\n  gem 'debugger'\n  gem 'sqlite3'\nend\n\ngroup :production do\n  gem 'pg'\nend\n\ngroup :assets do\n  gem 'sass-rails', '~> 3.2'\n  gem 'coffee-rails', '~> 3.2'\n  gem 'compass-rails'\n  gem 'uglifier'\n  gem 'bootstrap-sass', '~> 2.0.3.0'\n  gem 'handlebars_assets', '0.12.3'\nend\n\ngroup :development do\n  gem 'quiet_assets'\nend\n```\n\nThere are two gems to take note of:\n\n* [ActiveModelSerializers](https://github.com/rails-api/active_model_serializers) is a project that is written by the `Ember` core team which will normalize the [JSON](http://en.wikipedia.org/wiki/JSON) output for models in a `Rails` app.\n* [HandlebarsAssets](https://github.com/leshill/handlebars_assets) will allow the `AssetPipeline` to compile [Handlebars](http://handlebarsjs.com/) templates which is required for Ember. There is the [Ember-Rails](https://github.com/emberjs/ember-rails) gem which will also do this but I have found `HandlebarsAssets` to be a leaner solution.\n\nAfter this, don't forget to run `bundle install` from the command line to pick up the gems we just added.\n\nLet's create a simple model and the serializer\n\n```text\nrails-api g model User first_name:string last_name:string quote:text\nrails-api g serializer User\n```\n\nRun 'rake db:migrate' to run the migration for our User model. Now open up `app/serializers/user_serializer.rb` and add the fields that require serialization\n\n```ruby\nclass UserSerializer < ActiveModel::Serializer\n  attributes :id, :first_name, :last_name, :quote\nend\n```\n\nAgain, this will instruct `Rails` to turn our `ActiveRecord` object into a `JSON` object properly normalized for `Ember`. \n\nLet's write the Controller. Create and edit `app/controllers/users_controller.rb`\n\n```ruby\nclass UsersController < ApplicationController\n  def index\n    render json: User.all\n  end\nend\n```\n\nTake note that we are inheriting `ApplicationController` but in a `RailsAPI` app `ApplicationController` itself inherits from `ActionController::API` instead of `ActionController::Base`.\n\nThis basic controller will serve up all of our users to our Ember app. We'll add more later.\n\nNow let's add some routes to `config/routes.rb`\n\n```ruby\nEmberApp::Application.routes.draw do\n  class FormatTest\n    attr_accessor :mime_type\n\n    def initialize(format)\n      @mime_type = Mime::Type.lookup_by_extension(format)\n    end\n\n    def matches?(request)\n      request.format == mime_type\n    end\n  end\n\n  resources :users, :except => :edit, :constraints => FormatTest.new(:json)\n  get '*foo', :to => 'ember#index', :constraints => FormatTest.new(:html)\n  get '/', :to => 'ember#index', :constraints => FormatTest.new(:html)\nend\n```\n\nA few things are happening here:\n\n* We are constraining against the format with a custom `FormatTest` class. We only want to map certain routes to `JSON` requests and certain routes to `HTML` requesets.\n* The `get '*foo'...` will greedily match all routes except `/` so we have the following line. We want to direct all `HTML` requests to a single `controller#action`. I will go into the reason why in a bit.\n\nSo let's create that `Ember` controller. This will act as the primary application serving controller that is hit when people visit the app. Create and edit `app/controllers/ember_controller.rb`\n\n```ruby\nclass EmberController < ActionController::Base; end\n```\n\nNote that we are inheriting from `ActionController::Base` this time and not `ApplicationController`. This is so that the controller actions can respond to non `JSON` requests.\n\nNow we will add the view in `app/views/ember/index.html.erb`\n\n```erb\n<!DOCTYPE html>\n<html lang='en'>\n  <head>\n    <%= stylesheet_link_tag :application, :media => :all %>\n    <%= javascript_include_tag :application %>\n    <title>Title</title>\n  </head>\n  <body>\n  </body>\n</html>\n```\n\nThat is all the view that your Ember app will need. Ember will automatically attach its own default template to the `<body>` tag.\n\nLet's add some data to `db/seeds.rb`\n\n```ruby\nUser.create(:first_name => 'William', :last_name => 'Harrison', :quote => \"I'm just singin' in the rain!\")\nUser.create(:first_name => 'Abraham', :last_name => 'Lincoln', :quote => \"I'd like to see a show tonight.\")\n```\n\nNow run your migrations and seed\n\n```text\nrake db:migrate db:seed\n```\n\nOk, now our app is in a good spot to start developing an Ember app with. Let's review what we did\n\n1. Generated a new app using `rails-api`\n2. Set up the javascript and stylesheet assets\n3. Wrote a very simple JSON API for returning all users\n\nIn [Part 2](http://reefpoints.dockyard.com/ember/2013/01/09/building-an-ember-app-with-rails-api-part-2.html) we'll build the Ember app itself.\n\n"},{"title":"Building an Ember app with RailsAPI - Part 2","tags":["javascript","rails"],"summary":"Building the Ember app","legacy":false,"illustration_alt":"Welcome","illustration":"http://i.imgur.com/1j50C.png?1","id":"2013/01/09/building-an-ember-app-with-rails-api-part-2","employee":"Brian Cardarella","date":"2013-01-09T00:00:00","body":"\n\n**This article was last updated on May 28, 2013 and reflects the state\n of Ember (1.0.0-rc4) and the latest build of Ember Data (0.13) as of\nthat date.**\n\n[Fork the project on Github!](https://github.com/bcardarella/ember-railsapi)\n\n[Use the app live on Heroku](http://ember-rails-api.herokuapp.com/)\n\nIn [Part 1](/ember/2013/01/07/building-an-ember-app-with-rails-api-part-1.html) I showed you how to setup a `Rails-API` app for Ember. Now let's build the app itself.\n\nIn this part I will go over building the Ember app from the perspective of a Rails developer. I will be making comparisons to where Ember resembles common patterns in Rails and even Ruby itself.\n\nI know I promised a 2-part series but I'm going to extend this to 3-parts. This post was growing too large to cover everything.\n\n* Note: this post has been updated since it was originally written. If\nyou were following along you should start from the beginning of this\npost as changes have been made to reflect the changes on Ember's master\nbranch! *\n\n## Part 2 - Building with Ember\n\nWe need to start with something I forgot to setup in Part 1. Ember looks for templates in the `Ember.TEMPLATES` JavaScript object which is provided to us with the `handlebars_assets` gem we setup in Part 1. We just need to tell the gem to compile for Ember. We can do this in `config/initializers/handlebars_assets.rb`\n\n```ruby\nif defined?(HandlebarsAssets)\n  HandlebarsAssets::Config.ember = true\nend\n```\n\n*NOTE:* If you have skipped ahead and come back to this initializer you will need to run:\n\n```text\nrm -rf tmp/*\n```\n\nOtherwise your Ember templates won't compile properly.\n\nLet's dive in by creating our application layout template in `app/assets/javascripts/templates/application.hbs`\n\n```handlebars\n<div class='navbar navbar-inverse navbar-fixed-top'>\n  <div class='navbar-inner'>\n    <div class='container'>\n      <div class='nav-collapse collapse'>\n        <ul class='nav'>\n          <li>{{#linkTo 'index'}}Home{{/linkTo}}</li>\n          <li>{{#linkTo 'users'}}Users{{/linkTo}}</li>\n        </ul>\n      </div>\n    </div>\n  </div>\n</div>\n<div class='container' id='main'>\n  <div class='content'>\n    <div class='row'>\n      <div class='span12'>\n        <div class='page-header'></div>\n        {{outlet}}\n      </div>\n    </div>\n  </div>\n</div>\n```\n\n[Read more about Ember Templates](http://emberjs.com/guides/templates/handlebars-basics)\n\nThis is the Ember equivalent of a Rails layout template. The `outlet` is the Ember equivalent to `yield` in Rails. So this template will wrap the other templates we plan on rendering. I will come back to the `<li>`s in the nav later.\n\nNext we're going to setup a default route and render a template. In `app/assets/javascripts/routes.coffee`\n\n```coffeescript\nApp.Router.reopen\n  location: 'history'\n  rootURL: '/'\n\nApp.Router.map ->\n  @resource 'users'\n```\n\n[Read more about Ember Routes](http://emberjs.com/guides/routing)\n\nThis will tell the Ember Router to use the History API instead of the\ndefault 'hash' URLs for routes. The mapping of the `/` in our app is\nimplicit in Ember, and it will be assigned to a route of \n`index`. The Ember Router will use this string to make some\nassumptions. If there is a `App.IndexController` object it will use that\ncontroller. If not, it will just render out the `index` template. Now,\nunder the hood Ember is still using a `App.IndexController` controller\nbut it will define one on the fly. I will get into this in a future blog\npost. When you call `reopen` this is the Ember way to reopen and monkey\npatch a class. As you can see the Ember Router syntax is similar to the\none in Rails. This is by design. We need the 2nd route there so our\n`application.hbs` template can compile as it is referencing the\n`users.index` route.\n\nLet's write `app/assets/javascripts/templates/index.hbs`\n\n```text\n<h1>Welcome!</h1>\n```\n\nWe need to do one last thing before we check out the homepage. By default, Rails includes a sample `index` page in `public/index.html`. If we were to go to the homepage now, we would see that.\nBut we want to see the index page we just made. To remove the Rails default page, simply run\n\n`rm public/index.html`\n\nfrom the command line.\n\nThat's it. If you run your rails server and load the app you should see the following\n![Welcome](http://i.imgur.com/1j50C.png?1)\n\nCongratulations! You've built your first Ember app! Let's make it do\nsomething useful. We are going to add the `/users` page, so edit\n`app/assets/javascripts/templates/users.hbs`\n\n```handlebars\n<h1>Users</h1>\n<div class=\"span3\">\n  <table class='table table-striped'>\n    <tr>\n      <th>ID</th>\n      <th>Name</th>\n    </tr>\n  </table>\n</div>\n```\n\nReload your app and you can click back and forth between 'Users' and 'Home', thanks to the `linkTo` actions we setup in `application.hbs`. These actions map to controllers being automatically generated because we haven't created them yet; those controllers automatically render the templates with the same naming convention. Does that sound familiar? That's right, its our good friend [Convention Over Configuration](http://en.wikipedia.org/wiki/Convention_over_configuration)!\n\nNow, when clicking between the two pages the nav is not properly updating the `active` class on the `<li>` tags. In Ember, you can [bind element class names to actions](http://emberjs.com/guides/templates/binding-element-class-names). This will require a bit of code, but as we add more controllers I'll show how we can easily reuse what we're about to write. Let's start by adding the bindings to `application.hbs` Modify the `<li>` tags in the nav menu to:\n\n```handlebars\n<li {{bindAttr class=\"isHome:active\"}}>{{#linkTo 'index'}}Home{{/linkTo}}</li>\n<li {{bindAttr class=\"isUsers:active\"}}>{{#linkTo 'users.index'}}Users{{/linkTo}}</li>\n```\n\nThis binding of `isHome:active` tells Ember to make the class `active` if the `isHome` attribute on the controller is `true`. If it is `false` the value will be nothing. The same goes for `isUsers`. Because this code lives in `application.hbs` we need to add these attributes to `app/assets/javascripts/controllers/applicationController.coffee`\n\n```coffeescript\nApp.ApplicationController = Ember.Controller.extend\n  isHome: (->\n    @get('currentRoute') == 'home'\n  ).property('currentRoute')\n\n  isUsers: (->\n    @get('currentRoute') == 'users'\n  ).property('currentRoute')\n```\n\n[Read more about Ember Controllers](http://emberjs.com/guides/controllers)\n\nEach attribute is a function that will compare the `currentRoute` attribute to a value and return that boolean result. We instruct the attribute to be a [computed property](http://emberjs.com/guides/object-model/computed-properties). Computed properties are simple to understand: we tell Ember to automatically update the value of 'isHome' when `currentRoute` is `set` to a different value. Ember will then instruct anything bound to that attribute to update as well.\n\nFinally, we're going to update our routes to set `currentRoute` depending upon the route. Let's add two route classes to `app/assets/javascripts/routes.coffee`\n\n```coffeescript\nApp.IndexRoute = Ember.Route.extend\n  setupController: (controller, model) ->\n    @controllerFor('application').set('currentRoute', 'home')\n\nApp.UsersRoute = Ember.Route.extend\n  setupController: (controller, model) ->\n    @controllerFor('application').set('currentRoute', 'users')\n```\n\nTwo new concepts:\n\n* `setupController` is a function automatically called on each visit to the route. It will pass in an instance of the controller and a model if you supply one (we'll see this in a bit)\n* `this.controllerFor` When interacting with a specific controller you may want to modify a different controller. In this case the wrapping controller is `ApplicationController` and we need to update the `currentRoute` attribute. You *must* use the `set` function otherwise Ember won't know to notify any [computed property observers](http://emberjs.com/guides/object-model/computed-properties/).\n\nNow reload your app and click between the actions and you should see the active states properly set depending upon your route.\n\nNext, we're going to start using real data. We're going to fetch the collection of Users from the server and display them on the index page. Let's start with telling Ember what our data store looks like in `app/assets/javascripts/store.coffee`\n\n```coffeescript\nApp.Store = DS.Store.extend()\n```\n\n[Read more about Ember's REST Adapter](http://emberjs.com/guides/models/the-rest-adapter)\n\nThe REST adapter allows us to pull from an API backend assuming certain conventions are followed in the URIs and JSON response. Thankfully we set this up properly in [Part 1](http://reefpoints.dockyard.com/ember/2013/01/07/building-an-ember-app-with-rails-api-part-1.html)\n\nNow we'll create a new model in `app/assets/javascripts/models/user.coffee`\n\n```coffeescript\nApp.User = DS.Model.extend(\n  firstName: DS.attr('string')\n  lastName:  DS.attr('string')\n  quote:     DS.attr('string')\n  fullName: (->\n    \"#{@get('firstName')} #{@get('lastName')}\"\n  ).property('firstName', 'lastName')\n)\n```\n\n[Read more about Ember models](http://emberjs.com/guides/models)\n\nWe are defining each attribute that is coming over the wire, as well as a computed property that will combine `firstName` and `lastName`. If you're wondering about that call to `property`, you have to let Ember know when a method on an object is using a property computed from dependency properties on that object. Here `fullName` depends on `firstName` and `lastName`. When we call `property` and let Ember know which properties to observe, the `fullName` property will update if either the `firstName` or `lastName` changes. If you like, you can [read more about computed properties](http://emberjs.com/guides/object-model/computed-properties/).\n\nNow we need to modify the `users` route to fetch the data\n\n```coffeescript\nApp.UsersRoute = Ember.Route.extend\n  model: ->\n    App.User.find()\n  setupController: (controller, model) ->\n    @controllerFor('application').set('currentRoute', 'users')\n```\n\nThe `App.User.find()` makes a remote call, fetches the collection, and instantiates the models. This collection is then passed to `setupController` through the `model` attribute. We then assign this collection to the `users` attribute on the controller. \n\nNow edit `app/assets/javascripts/templates/users.hbs` to include a list of our users and an outlet through which we'll render a users index page and our users show page.\n\n```handlebars\n<div class=\"span3\">\n  <table class='table table-striped'>\n    <tr>\n      <th>ID</th>\n      <th>Name</th>\n    </tr>\n  \t{{#each controller}}\n  \t  <tr>\n  \t    <td>{{id}}</td>\n  \t    <td>{{#linkTo \"users.show\" this}}{{fullName}}{{/linkTo}}</td>\n  \t  </tr>\n  \t{{/each}}\n  </table>\n</div>\n\n<div class=\"span8\">\n  {{outlet}}\n</div>\n```\n\nWe are linking to the `show` named route and passing the instance of a `User` (which is what `this` refers to) as the paramater. Ember will pull out the id on the object and set that to the `:user_id` segment on the path.\n\nWe need to next update 'App.Router' for the proper mapping\n\n```coffeescript\nApp.Router.map ->\n  @resource 'users', ->\n    @route 'show',\n      path: '/:user_id'\n```\n\nNote how we are matching against `:user_id` and not `:id` that Rails developers are used to.\n\nI must confess I don't entirely understand why the `/` map is necessary under `/users`, I would have thought the top nesting could be used and it wouldn't be necessary to redefine a root path. Please enlighten me in the comments! Ok, the router maps are updated. Let's add the `show` route.\n\n```coffeescript\nApp.UsersShowRoute = Ember.Route.extend\n  model: (params) ->\n    App.User.find(params.user_id)\n  setupController: (controller, model) ->\n    controller.set('content', model)\n    @controllerFor('application').set('currentRoute', 'users')\n```\n\nAnd we'll add the `app/assets/javascripts/templates/users/show.hbs` template\n\n```handlebars\n<h1>{{fullName}}</h1>\n\n<div>\n  <q>{{quote}}</q>\n</div>\n\n<div class='page-header'></div>\n\n{{#linkTo 'users' class='btn'}}Back{{/linkTo}}\n```\n\nAnd finally, we'll add the 'app/assets/javascripts/users/index.hbs' template\n\n```handlebars\n<p>Please choose a user.</p>\n```\n\n\nReload your app and click through to the show page and you should see\n\n![Show](http://i.imgur.com/jNKhnrJ.png)\n\nSo we have only implemented the 'Read' of 'CRUD' in this part, but we have also introduced alot of new concepts. In [Part 3](http://reefpoints.dockyard.com/ember/2013/01/10/building-an-ember-app-with-rails-api-part-3.html) we will implement the 'Create Update Destroy' actions.\n"},{"title":"Building an Ember app with RailsAPI - Part 3","tags":["javascript","rails"],"summary":"CUD, it isn't just for cows","legacy":false,"illustration_alt":"New1","illustration":"http://i.imgur.com/kFC9arb.png","id":"2013/01/10/building-an-ember-app-with-rails-api-part-3","employee":"Brian Cardarella","date":"2013-01-10T00:00:00","body":"\n\n**This article was last updated on May 28, 2013 and reflects the state\n of Ember (1.0.0-rc4) and the latest build of Ember Data (0.13) as of\nthat date.**\n\n[Fork the project on Github!](https://github.com/bcardarella/ember-railsapi)\n\n[Use the app live on Heroku](http://ember-rails-api.herokuapp.com/)\n\nIn [Part 1](/ember/2013/01/07/building-an-ember-app-with-rails-api-part-1.html) I showed you how to setup a `Rails-API` app for Ember.\n\nIn [Part 2](/ember/2013/01/09/building-an-ember-app-with-rails-api-part-2.html) I showed you the basics of building an Ember app, reading from a backend API and displaying that information.\n\nToday we're going to do some coding on the Rails side and the Ember side to add Creating, Updating, and Destroying records.\n\n## Part 3 - The Big Finish\n\nIn [Part 1](http://reefpoints.dockyard.com/ember/2013/01/07/building-an-ember-app-with-rails-api-part-1.html) we setup the backend using [Rails API](https://github.com/rails-api/rails-api/). In [Part 2](http://reefpoints.dockyard.com/ember/2013/01/09/building-an-ember-app-with-rails-api-part-2.html) we built out the basics of an Ember app, reading from a remote data source and displaying that data. Now we're going to add the ability to Create, Update, and Destroy that data. This part will be a mix of Ember and Rails code.\n\n*Note: If you have been following along that [Part 2](http://reefpoints.dockyard.com/ember/2013/01/09/building-an-ember-app-with-rails-api-part-2.html) was recently updated to reflect new changes to the Ember Router, you will need to go back and update your code. Absolute make sure to update your ember.js and ember-data.js dependencies as they have been updated on the github repo*\n\n### Create ###\n\nLet's start by adding a `Create` button to our index page:\n\n```handlebars\n{{#linkTo 'users.new' class='btn btn-primary'}}Create{{/linkTo}}\n```\n\nWe need to add the proper route so the index page doesn't blow up. While we're in here we'll add the `edit` route as well.\n\n```coffeescript\nApp.Router.map ->\n  @resource 'users', ->\n    @route 'new'\n    @route 'edit',\n      path: '/:user_id/edit'\n    @route 'show',\n      path: '/:user_id'\n```\n\nAnd now we can add the `UsersNewRoute`\n\n```coffeescript\nApp.UsersNewRoute = App.UsersRoute.extend\n  model: ->\n    App.User.createRecord()\n  setupController: (controller, model) ->\n    controller.set('content', model)\n```\n\nDon't be fooled by the `createRecord()` call. This will not write anything to the backend. This call is simply used to create a new model. Now let's create the template `app/assets/javascripts/templates/users/new.hbs`\n\n```handlebars\n<h1>Create {{fullName}}</h1>\n<form>\n  <fieldset>\n    <div>\n      <label {{bindAttr for=\"firstNameField.elementId\"}}>First Name</label>\n      {{view Ember.TextField valueBinding='firstName' name='first_name' viewName='firstNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='lastNameField.elementId'}}>Last Name</label>\n      {{view Ember.TextField valueBinding='lastName' name='last_name' viewName='lastNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='quoteField.elementId'}}>Quote</label>\n      {{view Ember.TextArea valueBinding='quote' name='quote' viewName='quoteField'}}\n    </div>\n    <a href='#' {{action save}} class='btn btn-success'>Create</a>\n  </fieldset>\n</form>\n<div class='page-header'></div>\n\n<a href='#' {{action cancel}} class='btn btn-inverse'>Cancel</a>\n```\n\nNext we'll add `app/assets/javascripts/controllers/users/newController.coffeescript`\n\n```coffeescript\nApp.UsersNewController = Ember.ObjectController.extend\n  headerTitle: 'Create'\n  buttonTitle: 'Create'\n\n  save: ->\n    @content.save().then =>\n      @transitionToRoute('users.show', @content)\n    \n  cancel: ->\n    @content.deleteRecord()\n    @transitionToRoute('users.index')\n```\n\nThe first two functions `save` and `cancel` are actions that are mapped in the template. Let's break down each:\n\n* `save` will make a call to `this.store.commit()`. You will notice we are not modifying a model, assigning params, etc... as you would in a Rails app. Keep in mind that when you modify data that is bound in the form you are actually modifying the data in the model itself. The datastore in Ember needs to be directed when these modifications should be made \"permanent\", and because we are using the RESTAdapter Ember will attempt to write these changes to the backend.\n* `cancel` If the user decides to not create a new user we must delete the record we created then transition to the `index` page.\n\n[Learn more about the Ember Model Lifecycle](http://emberjs.com/guides/models/model-lifecycle)\n\nFinally we're going to hook up the back end in `app/controllers/users_controller.rb`\n\n```ruby\ndef create\n  user = User.new(params[:user])\n\n  if user.save\n    render json: user\n  else\n    render json: user, status: 422\n  end\nend\n```\n\nIt has been mentioned that `422` is the proper status code for validation failures. Personally I would prefer to use `respond_with` but it isn't part of the default Rails-API stack, [hopefully this will change](https://groups.google.com/forum/?fromgroups=#!topic/rails-api-core/QhPh2VG7yTU).\n\nNow let's run our app and see how it goes.\n\n![New1](http://i.imgur.com/kFC9arb.png)\n\nWhoops, we have `undefined undefined` for the `fullName`. Let's set default values of an empty string in our user model:\n\n```coffeescript\nApp.User = DS.Model.extend\n  firstName: DS.attr('string', defaultValue: '' )\n  lastName: DS.attr('string', defaultValue: '' )\n  quote: DS.attr('string')\n  fullName: (->\n    \"#{@get('firstName')} #{@get('lastName')}\"\n  ).property('firstName', 'lastName')\n```\n\nNow when we add data and create it will write to the back end, take us to the show page. When can then click `Back` and we can see the record has been automatically added to the collection on the `index` page.\n\nAdding `Edit` should be straight forward now that we have done create. Start will adding the route:\n\n```coffeescript\nApp.UsersEditRoute = Ember.Route.extend\n  model: (params) ->\n    App.User.find(params.user_id)\n  setupController: (controller, model) ->\n    controller.set('content', model)\n    @controllerFor('application').set('currentRoute', 'users')\n```\n\nYou'll notice that this route is identical to `App.UsersShowRoute` we wrote in Part 2, let's DRY this up\n\n```coffeescript\nApp.UserRoute = Ember.Route.extend\n  model: (params) ->\n    App.User.find(params.user_id)\n  setupController: (controller, model) ->\n    controller.set('content', model)\n    @controllerFor('application').set('currentRoute', 'users')\n\nApp.UsersShowRoute = App.UserRoute.extend()\nApp.UsersEditRoute = App.UserRoute.extend()\n```\n\nNext we'll add the edit link to `app/assets/javascripts/templates/users/show.hbs`\n\n```handlebars\n{{#linkTo 'users.edit' content class='btn btn-primary'}}Edit{{/linkTo}}\n```\n\nNow the edit template itself in `app/assets/javascripts/templates/users/edit.hbs`\n\n```handlebars\n<h1>Edit {{fullName}}</h1>\n<form>\n  <fieldset>\n    <div>\n      <label {{bindAttr for=\"firstNameField.elementId\"}}>First Name</label>\n      {{view Ember.TextField valueBinding='firstName' name='first_name' viewName='firstNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='lastNameField.elementId'}}>Last Name</label>\n      {{view Ember.TextField valueBinding='lastName' name='last_name' viewName='lastNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='quoteField.elementId'}}>Quote</label>\n      {{view Ember.TextArea valueBinding='quote' name='quote' viewName='quoteField'}}\n    </div>\n    <a href='#' {{action save}} class='btn btn-success'>Update</a>\n  </fieldset>\n</form>\n<div class='page-header'></div>\n\n<a href='#' {{action cancel target='controller'}} class='btn btn-inverse'>Cancel</a>\n```\n\nAnd now the controller `app/assets/javascripts/controllers/users/editController.coffee`\n\n```coffeescript\nApp.UsersEditController = Ember.ObjectController.extend\n  destroy: ->\n    @content.deleteRecord()\n    @store.commit()\n    @transitionTo('users.index')\n\n  save: ->\n    @content.save().then =>\n      @transitionToRoute('users.show', @content)\n\n  cancel: ->\n    if @content.isDirty\n      @content.rollback()\n    @transitionTo('users.show', @content)\n\n  buttonTitle: 'Edit'\n  headerTitle: 'Editing'\n```\n\nThis controller looks similar to `App.UsersNewController` but let's explore the differences\n\n* `save` here because the model already has an `id` we can commit to the datastore and transition.\n* `cancel` instead of deleting the record we want to rollback to its previous state. And we can only rollback if the record has changed.\n\nI'm sure you know what is next. The `new` template is nearly identical to the `edit` template. Let's create `app/assets/javascripts/templates/users/form.hbs`\n\n```handlebars\n<h1>{{headerTitle}} {{fullName}}</h1>\n<form>\n  <fieldset>\n    <div>\n      <label {{bindAttr for=\"firstNameField.elementId\"}}>First Name</label>\n      {{view Ember.TextField valueBinding='firstName' name='first_name' viewName='firstNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='lastNameField.elementId'}}>Last Name</label>\n      {{view Ember.TextField valueBinding='lastName' name='last_name' viewName='lastNameField'}}\n    </div>\n    <div>\n      <label {{bindAttr for='quoteField.elementId'}}>Quote</label>\n      {{view Ember.TextArea valueBinding='quote' name='quote' viewName='quoteField'}}\n    </div>\n    <a href='#' {{action save}} class='btn btn-success'>{{buttonTitle}}</a>\n  </fieldset>\n</form>\n<div class='page-header'></div>\n\n<a href='#' {{action cancel target='controller'}} class='btn btn-inverse'>Cancel</a>\n```\n\nAnd in both the `new` and `edit` template remove the markup and replace with\n\n```handlebars\n{{ template 'users/form' }}\n```\n\nNow we need to edit the two controllers. In `App.UsersNewController` add to the two attributes:\n\n```coffeescript\nheaderTitle: 'Create'\nbuttonTitle: 'Create'\n```\n\nAnd likewise in `App.UsersEditController`:\n\n```coffeescript\nheaderTitle: 'Edit'\nbuttonTitle: 'Update'\n```\n\nLast part for this section is to add the `update` action to `app/controllers/users_controller.rb`:\n\n```ruby\ndef update\n  user = User.find(params[:id])\n  if user.update_attributes(params[:user])\n    render json: user\n  else\n    render json: user, status: 422\n  end\nend\n```\n\nNow go through and everything should work! This allows us to treat the templates similar to a partial in Rails.\n\nFinally we're going to add the ability to delete records. Because this is an action we are going to limit to the `edit` page we will put the link below the `render` call\n\n```handlebars\n<a href='#' {{action 'destroy'}} class='btn btn-danger'>Destroy</a>\n```\n\nNow we add the action to the `App.UsersEditController`\n\n```coffeescript\ndestroy: ->\n  @content.deleteRecord()\n  @store.commit()\n  @transitionToRoute 'users.index'\n```\n\nAnd we add the `destroy` action to the backend\n\n```ruby\ndef destroy\n  user = User.find(params[:id])\n  if user.destroy\n    render json: user, status: 204\n  else\n    render json: user\n  end\nend\n```\n\nThe `204` status here is refers to `No Content`. Ember-data expects this to ensure the destroy action is a success.\n\nThat's it! You've just created your very first Ember app with all of the CRUD actions. Congratulations!\n"},{"title":"Introducing Ember-EasyForm","tags":["javascript","ember libraries"],"summary":"A SimpleForm-like FormBuilder for Ember","legacy":false,"id":"2013/02/21/ember-easy-form","employee":"Brian Cardarella","date":"2013-02-21T00:00:00","body":"\n\n[View the project on GitHub](https://github.com/dockyard/ember-easyForm)\n\nOne of the more tedious tasks in Ember is writing forms. It is not\nuncommon to have to write something like so:\n\n```handlebars\n<form>\n  <div class=\"input string\">\n    <label {{bindAttr for=\"firstNameField.field_id\"}}>First name</label>\n    {{view Ember.TextField valueBinding='firstName' name='first_name' viewName='firstNameField'}}\n  </div>\n  <div class=\"input string\">\n    <label {{bindAttr for=\"lastNameField.field_id\"}}>Last name</label>\n    {{view Ember.TextField valueBinding='firstName' name='last_name' viewName='lastNameField'}}\n  </div>\n  <div class=\"input string\">\n    <label {{bindAttr for=\"ageField.field_id\"}}>Age</label>\n    {{view Ember.TextField valueBinding='age' name='age' viewName='ageField'}}\n  </div>\n  <input type=\"submit\" value=\"Submit\">\n</form>\n```\n\nAnd this is just a very simple form, but what if we could write this:\n\n```handlebars\n{{#formFor controller}}\n  {{input firstName}}\n  {{input lastName}}\n  {{input age}}\n  {{submit}}\n{{/formFor}}\n```\n\nThat is *much* more concise! We pass the `controller` as the context to\nthe `formFor` Handlebars helper. Then we can simply call `input` for\neach property we want.\n\nBy default `EasyForm` will use text fields for the rendered input.\nHowever, in certain cases it will attempt to properly set the `type`. If\nthe property contains `email` the `type` will be set to `email` or of\nthe property contains `password` the `type` will be set to `password`.\nYou can override this and set the type yourself:\n\n```handlebars\n{{input code type=\"hidden\"}}\n```\n\nCurrently the only other input type supported is `textarea`, you can\ncreate one with:\n\n```handlebars\n{{input bio as=\"text\"}}\n```\n\nI plan on adding support for the other input types such as `select` in\nthe next few weeks.\n\n## Validations ##\n\nThis implementation has basic support for property validations.\nCurrently it works with `ember-data-validations` but that project might\nget rolled into a larger Ember Object Validation effort and at that time\nI will change `ember-easyForm` to support whatever that is.\n\nValidations will fire on `onFocusOut` for each input and will render\ninto a `<span class=\"error\">` element associated with the given input.\n\nIf your model doesn't have validations this behavior will be ignored.\n\n## Form Submit ##\n\nThe `submit` helper will render a submit input but you can just write\none yourself if you wish. The `onSubmit` action for the wrapping `form`\nelement will do the following:\n\n1. Attempt to validate for object. If validations are not supported it\n   will go to step 3.\n2. If validations fail form submit is interrupted and errors are\n   rendered. If not go to step 3.\n3. The view for the `form` element will attempt to call a `submit`\n   action on the controller. This is an action that you need to supply\nyourself:\n\n```javascript\nApp.NewUserController = Ember.ObjectController.extend({\n  submit: function() {\n    // handle form submit here\n  }\n});\n```\n\n## More to come! ##\n\nThis is very close to what I recently (and briefly) showed at\n[EmberCamp](http://www.embercamp.com)\nlast week. I hope to continue to build this project into a form builder\nthat evrerybody will be happy to use. [Please feel free to propose new\nidea in the issues for this project on GitHub](https://github.com/dockyard/ember-easyForm/issues)\n"},{"title":"Mike Sager Joins DockYard","tags":["office"],"summary":"Sager!!!!!","legacy":false,"illustration_alt":"Sager","illustration":"https://i.imgur.com/dtyb8Zg.png","id":"2013/03/19/mike-sager-joins-dockyard","employee":"Brian Cardarella","date":"2013-03-19T00:00:00","body":"\n\n![Sager](https://i.imgur.com/dtyb8Zg.png)\n\nI'm very happy to announce that Mike Sager has joined DockYard! Sager\nand I met while working on The Campaign That Shall Not Be Named (it was\na very \"special\" one in MA) we kept in touch on and off after that until\nwe recently worked together on a project for the AFL-CIO.\n\nSager brings an intimate knowledge of the progressive political tech\narena. DockYard is already making a great name for itself with political\ntech and NPOs and we're looking forward to the klout that Sager will\nbring to the table.\n\nWhile not yet \"official\" we will soon be opening an office in\nWashington, DC. Sager and Chris Gill will be running this office and we\nare looking to hire Rails developers that have experience building apps\nin politics. [Join us!](mailto:contact@dockyard.com)\n"},{"title":"Fixing Capybara 2.0 and Labels","tags":["testing"],"summary":"Capybara is broken, they refused to fix. Here is the monkey patch","legacy":false,"id":"2013/03/21/capybara-and-unique-labels","employee":"Brian Cardarella","date":"2013-03-21T00:00:00","body":"\n\nI love Capybara, it makes integration testing a breeze. However, one of\nthe decisions made for Capybara 2.0 confuses an annoys me. In Capybara\n1.x you could do the following:\n\n```ruby\nfill_in 'Password', :with => '123456'\nfill_in 'Password confirmation', :with => '123456'\n```\n\nAnd everything worked. In Capybara 2.0 this does not work. Capybara will\nnotice two labels that contain 'Password' and complain about an\nambiguous locator. The suggested work around is to attach meta data to\nthe input element and use that for the selector. There are two reasons\nwhy I don't like this. First, I am doing Ember development now and I\nhave no control of the ID, it is generated by the framework. Second, I\nbelieve that the integration test should be recreating the steps (as\nmuch as possible) as if a user were actually using the app. Something\nlike:\n\n```ruby\nfill_in '[data-name=\"password\"]', :with => '123456'\nfill_in '[data-name=\"password_confirmation\"]', :with => '123456'\n```\n\nDoesn't sit right with me. Users are looking at the text, not the selectors.\nI get that apps have the ability to show different languages but that doesn't conern me, I don't need\nto test if the Rails `i18n` works or not. I just care about asserting the happy and sad\npaths in my app.\n\nSo, to fix this problem simply add the\nfollowing code into your `test_helper.rb`\n\n```ruby\nmodule XPath::HTML\n  protected\n\n  def locate_field(xpath, locator)\n    locate_field = xpath[attr(:id).equals(locator) | attr(:name).equals(locator) | attr(:placeholder).equals(locator) | attr(:id).equals(anywhere(:label)[string.n.equals(locator)].attr(:for))]\n    locate_field += descendant(:label)[string.n.contains(locator)].descendant(xpath)\n    locate_field[~attr(:disabled)]\n  end\nend\n```\n\nAnd you should be all set!\n"},{"title":"Igata","tags":["products","business"],"summary":"We built an App Store for Heroku, got bored with it, and now open sourced it","legacy":false,"id":"2013/03/25/igata","employee":"Brian Cardarella","date":"2013-03-25T00:00:00","body":"\n\n[View the code](https://github.com/dockyard/igata)\n\n[Try it out!](http://igata.io)\n\nA year and a half ago I started thinking about a product I wanted to\nbuild. I am a big fan of Heroku and I felt something missing from their\neco-system was an App Store. Similar to the WordPress Theme Store. This\nHeroku App Store would allow developers to create fully realized\napplications and sell them to non developers. The person on the\npurchasing side wouldn't even need to know about Heroku. We built this\nproduct over the past year, got the \"thumbs up\" from Heroku, finally got bored with the idea of launching it, and\nare now open sourcing it for all to see. I will go into the challenges we\nfaced as a consulting firm building a product and why we decided to give\nthis away rather than \"go for it\".\n\n## Concept to reality ##\nThe concept was simple: App Store for Heroku. I built the original app\ncode in May of 2012. I would say about 50% of the app was completed in a\nweek. However, what I quickly learned is that balancing consulting a\nproduct development is not easy. Quickly development on Igata turned\ninto a see-saw. A day of work here and there in between contracts. It\nbecame very difficult to stay focused and keep interested in the\nproject. But I believed it was one that could do well if positioned\nproperly. The idea of proving an additional revenue stream to Heroku\nalso felt like a good challenge.\n\nI let the app sit for a few months while we were working on a very large\ncontract over the summer. Then the Rails Rumble came and I was a judge,\nI saw an app called [Deploy Button](https://deploybutton.com) and I\nfreaked out. This was essentially what we had already built but without\nthe purchasing aspect. I emailed my team and told them we weren't taking\nany more contracts until we finished Igata. This proved to not work very\nwell in reality. As a Rails consultancy we are not cheap but you don't\nrealize just how expensive you are until there is no money coming in. So\nwe went back on contract and shelved Igata, again. I kept coming back to\nit every so often. Finally I decided to open source it.\n\n## Validation ##\n\nIt wasn't until I made the decision to open source Igata that I started\nto get some validation of the concept. I was very secretive about the\napp as I figured if Heroku found out about it, and liked the idea, they\nwould just toss a few devs at it for a week or two and come out with an\n\"official\" app store. But now that I was going to OSS is fuck it, I'll\ntell everybody! I told a few friends that work at Heroku and in the end\nit was foolish of me to worry about that sort of thing. Several people\nencouraged me not to open source and just finish and release. So I went\nto Waza (Heroku's Conference) and met with a few people from Heroku's\nPartner program, once I showed them the app they loved it.\n\nI came home a few weeks ago, pumped to finish the app.\n\n## Back to Open Sourcing ##\n\nI wouldn't say doubt began to creep back in, just more that I really\ndidn't like the idea of what would come of Heroku if it it was a\nsuccess. Maintaining an app store and building it out really doesn't\ninterest me at all. I had a choice: shit or get off the pot. I've now\ndecided to get off the pot.\n\nI'm happy to go into more details on what our business model would have\nbeen in another post if people are interested. The app itself is about\n95% complete. There were some changes to the payment system we would\nmake. But overall I'm happy with what we built considering the very\ndisrupted development schedule on it. I hope this app can serve someone\nwell.\n"},{"title":"Concurrent Indexes in PostgreSQL for Rails 4 and Postgres_ext","tags":["rails","postgres"],"summary":"Prevent new indexes from locking up your tables","legacy":false,"id":"2013/03/26/concurrent-indexes-in-postgresql-for-rails-4-and-postgres_ext","employee":"Dan McClain","date":"2013-03-26T00:00:00","body":"\n\nPostgreSQL allows you to [create your indexes\nconcurrently](http://www.postgresguide.com/performance/indexes.html#create-index-concurrently)\nso that your table isn't locked as the index builds. This allows you to\navoid taking a performance hit when adding a new index to a large table.\nYesterday, I submitted a [pull request to\nRails](https://github.com/rails/rails/pull/9923) that as merged in this\nmorning that allows you to add concurrent indexes through the\n`add_index` method in your migrations. To create an index concurrently,\nyou add the `algorithm: :concurrently` option to the `add_index` call\n\n\n```ruby\nadd_index :table, :column, algorithm: :concurrently\n```\n\nA side effect of this commit is that it also enables the `algorithm`\noption for MySQL too, so MySQL users can create indexes using `DEFAULT`,\n`INPLACE` or `COPY` algorithm when creating indexes.\n\n## Postgres\\_ext gains concurrent index support as well\n\nThis morning I added support for concurrent indexes to\n[postgres\\_ext](https://github.com/dockyard/postgres_ext) as well, using\nthe same syntax as the Rails 4 example above. The 0.3.0 version of\npostgres\\_ext was released, which contains this, and a [slew of other\nimprovements as\nwell](https://github.com/dockyard/postgres_ext/blob/master/CHANGELOG.md#030).\nOne thing to note, the `index_type` option for `add_index` has been\nrenamed to `using` to match Rails 4.\n\nIf you have any features you want to see in postgres\\_ext or have any\nissues, [open an issue](https://github.com/dockyard/postgres_ext/issue)!\n"},{"title":"Adding route specific body class tags in Ember","tags":["javascript","design"],"summary":"For design!","legacy":false,"id":"2013/03/27/body-class-tags-in-ember","employee":"Brian Cardarella","date":"2013-03-27T00:00:00","body":"\n\nOur [designer](http://twitter.com/cssboy) likes to use body class tags\ndepending upon the context of the app he is designing. We're currently\nbuilding an Ember app and this is how I got it working:\n\n```javascript\nEmber.Route.reopen({\n  activate: function() {\n    var cssClass = this.toCssClass();\n    // you probably don't need the application class\n    // to be added to the body\n    if (cssClass != 'application') {\n      Ember.$('body').addClass(cssClass);\n    }\n  },\n  deactivate: function() {\n    Ember.$('body').removeClass(this.toCssClass());\n  },\n  toCssClass: function() {\n    return this.routeName.replace(/\\./g, '-').dasherize();\n  }\n});\n```\n"},{"title":"Running PostgreSQL 9.2 on Travis-CI","tags":["postgres"],"summary":"Test your gem against the latest PostgreSQL version (or an older one)","legacy":false,"id":"2013/03/29/running-postgresql-9-2-on-travis-ci","employee":"Dan McClain","date":"2013-03-29T00:00:00","body":"\n\nI spent most of yesterday trying to get PostgreSQL 9.2 running [Travis-CI](http://travis-ci.org).\nAfter almost 30 attempts, I successfully tested [postgres\\_ext](https://github.com/dockyard/postgres_ext) against PostgreSQL 9.2.\n\nHere is the final `before_script` needed to install PostgreSQL 9.2.\n\n```\nbefore_script:\n  - sudo /etc/init.d/postgresql stop\n  - sudo cp /etc/postgresql/9.1/main/pg_hba.conf ./\n  - sudo apt-get remove postgresql postgresql-9.1 -qq --purge\n  - source /etc/lsb-release\n  - echo \"deb http://apt.postgresql.org/pub/repos/apt/ $DISTRIB_CODENAME-pgdg main\" > pgdg.list\n  - sudo mv pgdg.list /etc/apt/sources.list.d/\n  - wget --quiet -O - http://apt.postgresql.org/pub/repos/apt/ACCC4CF8.asc | sudo apt-key add -\n  - sudo apt-get update\n  - sudo apt-get -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confnew\" install postgresql-9.2 postgresql-contrib-9.2 -qq\n  - sudo /etc/init.d/postgresql stop\n  - sudo cp ./pg_hba.conf /etc/postgresql/9.2/main\n  - sudo /etc/init.d/postgresql start\n```\n\n## Step by step explanation\n\n### Out with the old\nCurrently, Travis-CI has PostgreSQL 9.1 installed with a passwordless `postgres` superuser role. We first stop the current user by calling\n`sudo /etc/init.d/postgresql stop`. We also want to copy the current `pg_hba.conf`, since we can reuse it with PostgreSQL 9.2 to disable the need\nfor a password for the `postgres` role. We then remove the currently installed version via `sudo apt-get remove postgresql postgresql-9.1 -qq --purge`.\n\n### Add the apt.postgresql.org repositories\n\n[Postgresql.org](http://postgresql.org) maintains Debian and Ubuntu packages of the current PostgreSQL 8.3, 8.4, 9.0, 9.1 and 9.2 builds at\n[apt.postgresql.org](http://apt.postgresql.org) ([more\ninformation](https://wiki.postgresql.org/wiki/Apt)). Since Travis-CI\nworkers run Ubuntu, we can leverage these packages. We first load the\nUbuntu distribution environment variables via `source /etc/lsb-release`.\nUsing the `$DISTRIB_CODENAME` variable, we can set up the pgdg.list file\nthat we will add to the apt-get sources list directory. We do so with\nthe following command:\n\n```text\necho \"deb http://apt.postgresql.org/pub/repos/apt/ $DISTRIB_CODENAME-pgdg main\" > pgdg.list\nsudo mv pgdg.list /etc/apt/sources.list.d/\n```\n\nThe last thing we have to do before we can start installing the 9.2 is\nto import postgresql.org's apt key via\n\n```text\nwget --quiet -O - http://apt.postgresql.org/pub/repos/apt/ACCC4CF8.asc | sudo apt-key add -\n```\n\n### In with the new\n\nAfter we update our package listing via `sudo apt-get update`, we can\ninstall `postgresql-9.2` and `postgresql-contrib-9.2` (needed for the\nPostgreSQL extensions) via:\n\n```text\nsudo apt-get -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confnew\" install postgresql-9.2 postgresql-contrib-9.2 -qq\n```\n\nWe need the `Dpkg::Options` to automatically resolve any configuration\nfile conflicts left behind by 9.1 (even though we purge the files, for\nsome reason the `/etc/init.d/postgresql` file gets left behind). Without\nthe `Dpkg::Options`, apt-get will raise a user prompt that will hang the\nTravis-CI build.\n\nAt this point, we have a vanilla install of PostgreSQL 9.2, which will\nprompt for a password for the `postgres` role. We then need to stop the\nserver, replace the 9.2 `pg_hba.conf` with the custom Travis-CI one we\ncopied earlier, then restart the server:\n\n```text\nsudo /etc/init.d/postgresql stop\nsudo cp ./pg_hba.conf /etc/postgresql/9.2/main\nsudo /etc/init.d/postgresql start\n```\n\nAt this point, you can use any other `before_script` commands you were\npreviously using to create your database.\n\n## Conclusion\n\nAfter a decent amount of trial and error, I arrived at the above\n`before_script` to install PostgreSQL 9.2. I am currently adding support\nfor [ranges](http://www.postgresql.org/docs/9.2/static/rangetypes.html)\nto postgres_ext, which was added in 9.2. You should be able use this\n`before_script` to add 9.2 to your Travis-CI builds.\n"},{"title":"Government is ready for Rails","tags":[],"summary":"And not the other way around","legacy":false,"id":"2013/04/02/government-is-ready-for-rails","employee":"Brian Cardarella","date":"2013-04-02T00:00:00","body":"\n\nThe government software contract space is dominated by large, slow\nmoving, industry titans. .NET and Java are their tools of choice. At\nDockYard we aim to liberate government of these systems while at the\nsam$ie time giving agencies the agility of a quicker built project, with higher\nquality, and for less money. Read on.\n\n## Make room for the new boss ##\n\nGovernment is changing. Years ago Waterfall was all the rage, and for\nthe most part still is. It is understandable why Waterfall and\ngovernment got along so well: they are both very much top-down concepts.\nHowever, there is change in the air with more and agencies buying in\nAgile Development.\n\nRails, for those unfamiliar, is short for Ruby on Rails. It is a web\nframework that has been around since 2005. Built using the award-winning\nsoftware language Ruby it is meant to be opinionated in nature and allow\ndevelopers to not worry about the nonsense that exists in other\nlanguages in frameworks. Rails allows developers to work on business\nfeatures, no more mucking around having to re-invent the wheel each\ntime. And it is all free. Development happens more quickly in Rails than\n.NET brecause there is we avoid the black box of closed-source software.\nIs something not working as expected? We can read the source code, make\nthe change ourselves. We don't have to wait for Microsoft and we don't\nhave to pay Microsoft for support so those savings get passed back to\nthe client.\n\nRuby and the Rails framework have much more in common with the Java\neco-system than Microsoft's but many of there was a conscience effort to\navoid much of the ceremony and overhead that exists in Java and focus on\na framework and language that allowed us to \"get stuff done\".\n\nThe proof is out there, start-ups have known this for a long time. Rails\nis the most popular framework amongst them. Enterprise is catching up.\nMore and more often we are being contacted by large companies that are\nlooking to create new application or re-write existing ones in Rails\nbecause they have heard of the benefits.\n\nAgile is a core philosophy in Rails. Most Rails developers are doing\nTest Driven Development and most Rails consultancies and companies are\npracticing Agile.\n\nLet's address some of the concerns that some in government might have\nabout Rails:\n\n### Security ###\n\nSecurity is the most important concern for any government agency that is\nbuilding a software project. While it is true that .NET and Java are\ntraditionally thought of as leaders in this aspect the reality is that\nRails is every bit as good. In fact, in some cases perhaps better.\n\nThe first part about security you should understand is that most of the\nsecurity is out of the hands of the framework itself. This includes the\npeople, the server, and the database.\n\n#### People ####\n\nGovernment is already handling this level of security very well.\nClerance requirements and have trust-worthy people that are accessing\nthe system are always the first line of defense.\n\n#### The Server ####\n\nRails apps typically run on Linux-based servers and\nI would argue any day of the week that a Linux server properly locked\ndown is more secure than any Microsoft based server. And did I mention\nthat Linux is free? No more license fees, but finding a good Linux\nsys-op is not easy. If you have one on staff, pay that person very well.\nWe at [DockYard](https://dockyard.com) are very experienced in Linux. I\npersonally recommend using CentOS as it is (out of the box) the most secure of all the\nLinux distributions out there.\n\nSome of the obvious things to do for locking down Linux:\n\n* closing all ports except 80 (to allow web connections)\n* only allowing user processes to run the web app (and potentially\n  database depending upon the app)\n* we use nginx as a proxy server to our Rails apps. Generally this is\n  the only process that we allow to run as a super user (accessing port\n80 requires super user access)\n\n#### The Database ####\n\nThe database is the next layer of\nsecurity. We prefer PostgreSQL, it is a far better choice than MySQL in\nour opinion and can go toe-to-toe with Microsoft SQL Server or Oracle\nany day of the week on nearly every feature.\n\n### Security in Rails ###\n\nNow onto the framework itself. Out of the box Rails has baked-in Bcrypt\nauthentication. Bcrypt was developed by the NSA and can be fine tuned to\njust how secure a system is desired. We can increase the complexity and\npasswords become more and more difficult to decrypt. At\n[DockYard](https://dockyard.com) we have built a Rails Engine (plugin)\ncalled EasyAuth that allows us to quickly build out very secure identity\nbased accounts. By default is uses Bcrypt but we can quickly swap that\nout for different authentication strategy. We take security very\nseriously.\n\nRails handles SQL injection automatically. All queries that are passed\nthrough ActiveRecord (the Rails package that interacts with databases)\nare sanitized of any potentially malicious queries.\n\nRails also automatically handles all HTML and JavaScript injection by\nuser input. All data that Rails displays on page is automatically\nsantized. In fact, if you want to show the raw data we have to\nexplicitly flag that data to allow the unsanitized data \n\n### Internationalization (i18n) ###\n\nAs of Ruby 1.9 (current version is 1.9.3 with 2.0 just around the\ncorner) Ruby itself has met the most stringent internationalization\nstandards. It has fully implemented UTF-8 engine. Rails itself has a\nfully implemented i18n feature that allows for very quick to develop\nmulti-lingual applications. We can simply drop in what i18n text block\nwe want then provide that text in a global i18n file. We can even set up\na quick to edit system so that translators can directly edit and have\ncontrol over the given content rather than passing translations back to\nthe development team. Another example of the efficiency of using Rails.\n\n### Globalization (time) ###\n\nRails has automatic UTC offsets built in. Any Rails app can be defaulted\nto a given timezone. All datetime data is written to the database as\nUTC-0. Then custom offsets can be assigned to user accounts. This is out\nof the box in Rails and takes moments to implement. \n\n## Security Vulnerabilities ##\n\n[Every](http://www.cvedetails.com/vulnerability-list/vendor_id-26/product_id-3091/Microsoft-Asp.net.html)\n[major](http://www.cvedetails.com/vulnerability-list/vendor_id-93/product_id-19116/version_id-127974/Oracle-JDK-1.7.0.html)\n[framework]\n"},{"title":"We are hiring for a fulltime Ember.js developer","tags":["ember","javascript","office","job"],"summary":"Work at DockYard building Ember.js apps!","legacy":false,"id":"2013/04/04/we-are-hiring-for-an-emberjs-dev","employee":"Brian Cardarella","date":"2013-04-04T00:00:00","body":"\n\nWe are looking for an Ember.js Developer. Our ideal\ncandidate:\n\n* Work on cutting-edge Ember.js applications\n* Passionate about new HTML/JavaScript technologies\n* Has experience building complex client side applications\n* Some backend experience would be nice\n* Some database experience would be nice\n* Enjoys contributing to open source, writing blog posts, giving talks\n* Willing to live in Boston (we can relocate for the right candidate)\n\nOur current tech stack:\n\n* [Ruby on Rails](http://rubyonrails.org)\n* [Ember.js](http://emberjs.com)\n* [PostgreSQL](http://postgresql.com)\n* [CoffeeScript](http://coffeescript.org)\n* Most of our apps deploy to [Heroku](http://heroku.com), if not then\n  to [Linode](http://linode.com)\n\n[DockYard](https://dockyard.com) is a Boston-based consultancy that always wants to work with\nthe best people and the best technology. We are committed to Ember.js as\na client side framework. We help organize the Boston [Ember.js\nmeetup](http://www.meetup.com/Boston-Ember-js) and\nI recently spoke at [Ember Camp in San Francisco](http://embercamp.com). We are already [building\ntools around Ember.js](https://github.com/dockyard/ember-builds) and hope to continue to improve and build new ones\nin the upcoming years.\n\nPlease email [contact@dockyard.com](mailto:contact@dockyard.com) with\nall relevant information on why you would be an ideal candidate for a\nfulltime Ember.js developer.\n"},{"title":"Context Validations","tags":["rails","gems"],"summary":"An alternative to the normal Rails validations","legacy":false,"id":"2013/05/09/context-validations","employee":"Brian Cardarella","date":"2013-05-09T00:00:00","body":"\n\nI just released a new [gem called ContextValidations](https://github.com/dockyard/context_validations)\n\nContextValidations allows you to set validations on the instance of\nActiveRecord models. Any class-level validations you have already set\nin your models are ignored. You may be asking yourself \"Whaaaaaat?\" so\nlet's look into why.\n\n## Conditional Validations Are A Smell ##\n\nWhen applications grow in complexity the validation models required to\nsupport them usually grow too. Eventually you will have to \"work around\"\nthe validations with conditionals that rely upon state flags. In some\ncases you end up writing empty model objects for use with your forms to\navoid the mess that conditional validations introduce.\n\nThe problem here is that the model is defining a single set of\nvalidations but the model needs to absorb different sets of data under\ndifferent circumstances. Imagine you have a user account that where\ndepending upon how the users get to your app will depend upon what data\nthey need to provide. You might also be importing data from an external\nincomplete data set. Do you set these records aside into another table\nuntil the records are claimed and the user can complete registration? Or\ndo you allow the records to save and have the model enter a state of\n`unclaimed` to avoid authentication until `claimed`? You could just\navoid the validations all together but you definitely don't want to\nallow records that don't have the most basic of identifying information\nsuch as `email` or `username` to be saved.\n\nYou can imagine with this scenario the current solution with Rails is\neither a very complex and messy validation model or breaking things out\ninto other models and having a strategy to reconciling that at a later\npoint in time.\n\n## Context Matters ##\n\nI have come to believe that defining a monolithic validation set in your\nmodel is the wrong way to go. Context matters. If I am an admin I should\nbe able to write data to a record that might not be acceptable to a\nregular user. Even the simple case of not requiring a password unless\nthe record is new.\n\n### Controllers Are the Context ###\n\nI believe the rule of \"Fat Model, Skinny Controller\" has conditioned\nRails developers to never ever put anything more than a few lines of\ncode into your controllers. For the most part this is a good trend. But\nas we have seen with [Strong Parameters](https://github.com/rails/strong_parameters) \nthere are circumstances where adding a few more lines to our controllers\nisn't going to end the world. I submit the case is also true for\nvalidations. The controller is the context in which the user is\ninteracting with the data. Going back to the admin example, you most\nlikely have a `UsersController` and an `Admin::UsersController` defined.\nTwo controllers, same data. Different contexts. Not only should you\nallow mass assignment to the models differently for each context but\nwhat is considered \"valid data\" should also be different.\n\n## Context Validations ##\n\nTo handle this need I have just released\n[ContextValidations](https://github.com/dockyard/context_validations).\nThe goals of this gem are simple:\n\n1. Maintain simplicity\n2. Enable instance level validations\n3. Don't deviate from exisitng Rails validations\n4. Backwards compatibility with 3rd party libraries\n\nBefore I dive into each one let's see how a set of validations might be\napplied in a controller\n\n```ruby\nclass UsersController < ApplicationController\n  include ContextValidations::Controller\n\n  def create\n    @user = User.new(user_params)\n    @user.validations = validations(:create)\n    if @user.save\n      # happy path\n    else\n      # sad path\n    end\n  end\n\n  def base_validations\n    validates :first_name, :last_name :email, :presence => true\n    validates :email, :uniqueness => true, :format => EmailFormat\n    validates :password, :confirmation => true\n  end\n\n  def create_validations\n    validates :password, :presence => true\n  end\nend\n```\n\n### Maintain Simplicity ###\n\nAt this point some of you are probably thinking [Form Objects](http://rhnh.net/2012/12/03/form-objects-in-rails).\nPerhaps in the end, Form Objects will be the real answer for what I\nstrive for. But right now I don't see a justification for the increase\nin complexity. `ContextValidations` has attempted to keep the complexity\nas low as possible while still allowing for flexibility. The\n`ContextValidations::Controller` module can be mixed into any object,\nnot just controllers. Let's say you had a [Service Object](http://stevelorek.com/service-objects.html)\n\n```ruby\nclass UserService\n  include ContextValidations::Controller\n\n  def initialize(params)\n    @params = params\n  end\n\n  def create\n    @user = User.new(create_params)\n    @user = validations(:create)\n  end\nend\n```\n\nAt this point the code looks identitly to the controller example from\nabove. The validations are accessible anywhere, from any object.\n\n### Instance level validations ###\n\nThe real key here is that the instance of the model is able to declare\nwhat its validations are rather than the class. To that end you must\nmixin the `ContextValidations::Model` module into any model you want to\nuse `ContextValidations`\n\n```ruby\nclass User < ActiveRecord::Base\n  include ContextValidations::Model\nend\n```\n\nThis mixin will do several things to you `ActiveRecord` model\n\n1. A `#validations` setter and getter is added. The default for\n`#validations` is an empty array. When any arrays are assigned they are\nwrapped in an array and falttened out.\n\n2. The `:validate` callbacks are completed removed. This allows the\nmodel to accept validations set on the class by 3rd party libraries but\nthese validations will never run.\n\n3. The `#run_validations!` protected method is overwritten to run\nthrough the instance level validations instead of running the\n`:validate` callback.\n\n### Don't deviate from exisitng Rails validations ###\n\nThe only difference from writing your validations now is they are\nwritten on the instance. The `#validates` method functions exactly the\nsame way. You can still pass conditional validations if you'd like but I\nwouldn't recommend it.\n\n### Backwards compatibility with 3rd party libraries ###\n\nAs mentioned above we don't want your Rails app to crash if 3rd party\nlibraries are declaring regular Rails validations in your models. They\nare just ignored.\n\n## Moving forward ##\n\nThere are a few directions things could move in. I still haven't come\nup with a simple way to test `ContextValidations`. There will also be\nvalidations that are always used regardless of the context. I don't\nthink it makes sense to constantly rewrite these validations. One\npossibility would be to consider the class validations the\n`base_validations` that are always run then you can declare context\nvalidations on the instance. This might cause issues with 3rd party\nlibraries that are using conditional validations. But, we could easily\nget around that by ignoring any class level validations that have\nconditionals on them.\n\nI am eager to get feedback on this. I am sure this might cause some\nfriction as it moves outside of the comfort zone for many Rails devs but\nnow I am happy with the direction.\n"},{"title":"Tilde's Ember Training","tags":["training"],"summary":"We sent a group of developers to the Ember.js training that Tilde taught at Bocoup Loft","legacy":false,"id":"2013/05/09/tildes-ember-training","employee":"Dan McClain","date":"2013-05-09T00:00:00","body":"\n\nA couple weeks ago, Yehuda Katz and Tom Dale of [Tilde](http://tilde.io) ran\ntheir 3-day [Introduction to Ember.js Training](http://www.tilde.io/training/)\nat [Bocoup](http://bocoup.com/) here in Boston. I, along with Amanda,\nDoug and Chris, attended the training.\n\n## Format\n\nThroughout the training, attendees were building a simplified Rdio/Spotify clone\nusing Ember. It was broken up into a series of exercises, which built\nupon each other. The exercises were test driven, each having set of QUnit tests that defined the\nexercise. Before each exercise, Tom and Yehuda would explain and demo\nthe concepts via slides and JSBin.\n\n### Day 1\n\nDay 1 was spent outlining the core concepts of\n[Handlebars](http://handlebarsjs.com) and Ember. We\nstarted with Handlebars, which is what Ember uses as its templating\nlanguage. After covering the basics of Handlebars, we learned about how\n[Ember handles routing and outlets](http://emberjs.com/guides/routing/).\nAfter we finished routing, we moved onto creating Handlebars helper\nfunctions.\n\n### Day 2\nOn day 2, we started off with\n[Ember controllers](http://emberjs.com/guides/controllers/) and how they\nserve as proxy objects for the model of your current resource. After\ncontrollers, we covered\n[computed properties](http://emberjs.com/guides/object-model/computed-properties/).\n[Views](http://emberjs.com/guides/views/) followed computed properties,\nthen we wrapped up the day with creating custom controls with Ember and\nHandlebars.\n\n### Day 3\n\nOnce we had built the majority of the app, we had a couple more\nexercises that built upon all the exercise we had completed. Tom and\nYehuda also went over how we would use\n[Ajax requests to pull in data from a remote source with Promises](http://eviltrout.com/2013/03/23/ember-without-data.html).\nAfter wrapping up the remainder of the exercises, we covered how the\n[Ember Run Loop works](http://stackoverflow.com/questions/13597869/what-is-ember-runloop-and-how-does-it-work),\nand discussed approaches to testing Ember applications.\n\n## Feedback\n\nYehuda and Tom provided a great balance of not-to-dense information,\nuseful demos and exercises. They did a great job of, what Tom stated as,\n\"Providing a sufficient level of confusion\" in the exercises. Before\neach exercise, they would provide all the information needed for the\nexercise, but would not give you a list of steps to complete the task.\nYou may struggle a bit, but they answer any questions you would\nhave during the exercise. This would help the attendees actually learn\nthe concepts, rather than just copy/paste a set of code and modify it\nhere and there and have it work. I, personally, felt that this worked\nreally well.\n\nI have worked on a couple side project with Ember before taking this\ntraining, and had a very shallow understanding of some of the concepts.\nComing out of this training, I feel I have a great place to start building\nEmber apps. I really fleshed out my understanding of Ember and am really\nexcited about the technology. I am planning on using it for\nany upcoming side projects, to really explore it further. \n"},{"title":"Marin Abernethy is a DockYarder","tags":["office","intern"],"summary":"Our first developer intern","legacy":false,"illustration_alt":"Marin","illustration":"https://i.imgur.com/SiT4FRr.jpg","id":"2013/06/19/marin-abernethy-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-06-19T00:00:00","body":"\n\n![Marin](https://i.imgur.com/SiT4FRr.jpg)\nMarin comes to us as from Trinity College for the summer. We've been\noverwhelming her with Ruby, Linux, SQL, JavaScript, and VIM. She's\nexcelled and we're excited to see what she can accomplish over the\nremainder of the summer.\n"},{"title":"Michael Dupuis is a DockYarder","tags":["office"],"summary":"Grow baby grow!","legacy":false,"illustration_alt":"Michael","illustration":"https://i.imgur.com/DctpNjW.jpg","id":"2013/06/19/michael-dupuis-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-06-19T00:00:00","body":"\n\n![Michael](https://i.imgur.com/DctpNjW.jpg)\nRecently we added another great mind to the DockYard team: Michael\nDupuis. Mike joins our Boston office and has already been busy building\nout client apps in Ruby on Rails and Ember.js for us! He also comes with\nsome design chops. Welcome Mike!\n"},{"title":"Introducing destroyed_at","tags":["rails","gems"],"summary":"An ActiveRecord mixin for safe destroys","legacy":false,"id":"2013/06/28/introducing-destroyed_at","employee":"Michael Dupuis","date":"2013-06-28T00:00:00","body":"\n\n[See the project on GitHub](https://github.com/dockyard/destroyed_at)\n\nWe've found that more and more clients are requesting \"undestroy\"\nfunctionality in their apps. We recently extracted this common pattern into a gem\nwe're calling [DestroyedAt](https://github.com/dockyard/destroyed_at), an ActiveRecord mixin that makes un-destroying records\nsimple.\n\nBy\nsetting the datetime of the `#destroyed_at` field of your record, you can\nmark records as destroyed, without actually deleting them. By default, the\nmodel in which you `include DestroyedAt` is scoped to only include\nrecords that have not been destroyed. So something like\n`User.all` will only return `User`s with `#destroyed_at` values of `nil`;\nand `User.unscoped.all` will return all `User` records.\n\nWhen you want to bring a\nrecord back, simply call `#undestroy` on the instance and its\n`#destroyed_at` will be set to `nil`.\n\nWe've baked a bunch of other functionality in as well, including\nundestroy callbacks. For the full rundown, head over to [DestroyedAt's\nGitHub page](https://github.com/dockyard/destroyed_at) .\n"},{"title":"Sean Hussey is a DockYarder","tags":["office"],"summary":"We snag one of the tallest guys in Ruby","legacy":false,"illustration_alt":"Sean Hussey","illustration":"https://i.imgur.com/SNr5ZrZ.png","id":"2013/07/01/sean-hussey-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-07-01T00:00:00","body":"\n\n![Sean Hussey](https://i.imgur.com/SNr5ZrZ.png)\nToday is the first day for Sean Hussey at DockYard. He has been\ncontracting with us for the past few months and I was finally able to\nlock him down recently. Sean and I have known one another for years as\nhe hired me for my first Ruby job at\n[RakutenUSA](http://global.rakuten.com/en/). He brings years of Sr.\nlevel Ruby experience to our team.\n"},{"title":"DockYard Acquires Dobot","tags":["business","office"],"summary":"Joining forces","legacy":false,"illustration_alt":"DockYard acquires Dobot","illustration":"https://i.imgur.com/5vrk992.gif","id":"2013/07/08/dockyard-acquires-dobot","employee":"Brian Cardarella","date":"2013-07-08T00:00:00","body":"\n\nToday I'm very happy to announce that we have acquired local design firm\n[Dobot](http://dobotdo.com), its two partners Steven & Logan have joined us full-time.\nThis is a huge move for DockYard, and a simple one for Dobot (they have\nbeen working out of our office for the past few months so they don't\nactually need to move anywhere).\n\n![DockYard acquires Dobot](https://i.imgur.com/5vrk992.gif)\n\nPlease see the announcement for [Steven\nTrevathan](http://reefpoints.dockyard.com/announcement/2013/07/08/steven-trevathan-is-a-dockyarder.html)\nand the announcement for [Logan\nFaerber](http://reefpoints.dockyard.com/announcement/2013/07/08/logan-faerber-is-a-dockyarder.html).\n"},{"title":"Logan Faerber is a DockYarder","tags":["office"],"summary":"DockYard absorbs Dobot!","legacy":false,"illustration_alt":"Logan","illustration":"https://i.imgur.com/hmv9VHG.jpg","id":"2013/07/08/logan-faerber-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-07-08T00:00:00","body":"\n\n![Logan](https://i.imgur.com/hmv9VHG.jpg)\nAlong with his other fellow Dobot-er we welcome Logan Faerber to the\nDockYard team today!\n\nLogan is a [kick ass illustrator](http://www.loganfaerber.com/) who\nhas done work for New York Life, Dynamo Labs, CareShare, CustomMade,\n[Bioware](http://www.biowarestore.com/garrus-screenprint-poster.html),\nand [Archaia](http://www.archaia.com/archaia-titles/hawken-genesis/).\n\nLogan has been working out of our office for the last few months and we\nare excited to have his unique talents at DockYard.\n\n[Follow Logan on Twitter](http://twitter.com/loganfaerber)\n"},{"title":"Steven Trevathan is a DockYarder","tags":["office"],"summary":"DockYard absorbs Dobot!","legacy":false,"illustration_alt":"Steven","illustration":"https://i.imgur.com/XbSfLIm.jpg","id":"2013/07/08/steven-trevathan-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-07-08T00:00:00","body":"\n\n![Steven](https://i.imgur.com/XbSfLIm.jpg)\n\nI'm very happy to announce today that DockYard has joined forces with\nBoston design firm Dobot! Leader designer Steven Trevathan has come on\nas a partner and Creative Director (until we come up with a title he\nprefers) of DockYard.\n\nThis is a huge step forward for us. While we have had in-house designers\nwe have been actually leaning on Steven from time to time for our\nconcept design needs. Now with Steven coming on as part of our team he\nwill focus on building out the design side of DockYard and putting\ntogether a formal concept design process for us.\n\n[Follow Steven on Twitter](http://twitter.com/strevat)\n"},{"title":"First Month at DockYard","tags":["intern"],"summary":"Our summer intern shares her thoughts on her first month with us","legacy":false,"id":"2013/07/09/first-month-at-dockyard","employee":"Marin Abernethy","date":"2013-07-09T00:00:00","body":"\n\nI came to the programming party a little late in my [college](http://www.trincoll.edu/Pages/default.aspx) career, \nonly having a year and a half of classroom experience under my belt. Due\nto my limited CS background, I was rather anxious to start work at a\nweb development startup, fearing my qualifications were not up to par.\nHowever, my feelings of inadequacy quickly subsided after starting at\nDockYard! I was welcomed by a comfortable learning environment and an\natmosphere of positivity and productivity. My coworkers are very\napproachable and always willing to answer my questions. Because of\nDockYard's intimate size I am able to see all sides of the business, and\nget to know everyone in the office.\n\nIt has now been a month since I began working and already I feel I am\nlight-years ahead of where I started. My nerves have been replaced by an\neagerness to continue learning and grow as a developer. The amount of\ninformation that has been thrown my way is rather overwhelming. I have\nalready pored through 6 books, including: [Agile Web Development with\nRails](http://pragprog.com/book/rails32/agile-web-development-with-rails-3-2) by Sam Ruby and, [Secrets of the JavaScript Ninja](http://jsninja.com/) by John Resig, in\naddition to other readings on [CoffeeScript](http://coffeescript.org), version control ([git](http://git-scm.com)), and\n[user stories](http://en.wikipedia.org/wiki/User_story). Not to mention my introduction to vim and all the commands\nthat accompany it. While I cannot claim all of the information has\nstuck, the exposure will surely breed understanding. I have learned that\nit isn't about having all the answers, but the efficiency of finding\nthem that is important.\n\n\nIn addition to all the reading, I have worked on a small side project: a\nsimple blog site (my introduction to [test-driven\ndevelopment](http://en.wikipedia.org/wiki/Test-driven_development)) that I\nrebuilt 3 times, each time adding more features. The saying, \"repetition\nis the mother of all learning\", has certainly resonated with me after\nthis exercise.  Also [pair programming](http://en.wikipedia.org/wiki/Pair_programming) with others in the office has also\nbeen extremely helpful, giving me an idea of the day-to-day. Overall, I\nfeel lucky to be at DockYard in the midst of the growing field of web\ndevelopment. Already I can say my experience has been invaluable and I\nthoroughly look forward to the rest of the summer.\n"},{"title":"Design Patterns: The Template Method Pattern","tags":["design patterns"],"summary":"Exploring design patterns and their use cases","legacy":false,"id":"2013/07/10/design-patterns-template-pattern","employee":"Doug Yun","date":"2013-07-10T00:00:00","body":"\n\n## Introduction\n\nAs the field of software development grows, we developers are\ncontinuously trying to catch up with the latest technologies.\nFortunately, the craft of writing maintainable code is language\nagnostic, and in this series of blogposts, we'll focus on a powerful set of\ntimeless tools: *Design Patterns*.\n\nI highly recommend Russ Olsen's book [Design\nPatterns in Ruby](http://designpatternsinruby.com/). Our series\nwill draw inspiration from it and is brief in comparison. So if you\nenjoy these posts (and I hope you do!), the book will be a great\ninvestment.\n\nWe'll explore various design patterns and learn\nwhen to apply them. Our topic for today will be the *Template Method*\npattern, the simplest design pattern.\n\n## Our First Day in Construction\n\n### The Right Tools\n\nQuite simply, design patterns are just tools that help us construct software. However,\njust like tools, we need to use the correct and proper one for the task. We\ncould use a hammer on screws, but we'd damage the wood planks and using a\npower drill will be much more efficient. Before using any one of the numerous design patterns, it is\ncrucial to understand the problem we wish to solve.\n\n*It is incorrect to use a particular design pattern on the wrong\ntype of problem*. In other words, it is in poor practice to use a\nparticular design pattern on a problem that does not require the\naforementioned design pattern.\n\n### Let's Build Some Walls\n\nToday, we've been asked by our foreman to build a couple of walls. All\nthe walls will share the same dimensions and will be made from the same\nmaterial (for this construction project, our foreman has given us an\n\"easy\" set of requirements).\n\n```ruby\n# Blueprints for Wall\nrequire 'minitest/autorun'\n\ndescribe Wall do\n  let(:wall) { Wall.new }\n\n  it 'should state its dimensions' do\n    wall.dimensions.must_equal 'I am 30ft. long and 20ft. wide!'\n  end\n\n  it 'should be made from brick' do\n    wall.made_from.must_equal 'I am made from brick!'\n  end\nend\n```\n\nWhat a nice boss, he's handed us the blueprints!\nNow it's just up to us to build out the `Wall`.\n\n```ruby\nclass Wall\n  def dimensions\n    'I am 30ft. long and 20ft. wide!'\n  end\n\n  def made_from\n    'I am made from brick!'\n  end\nend\n```\n\nNice! Our tests pass, everybody is happy, and we're off to lunch!\n\n### A Hammer or a Nailgun?\n\nComing back to the site, our foreman has informed us that we need more\nwalls. \"That's a piece of cake,\" we reply, recalling how easy it was to\nbuild out the `Wall`.\n\n\"Not so fast,\" our foreman retorts. We're given new blueprints with\ndifferent wall requirements.\n\n```ruby\n# Blueprints for a BrickWall\ndescribe BrickWall do\n  let(:brick_wall) { BrickWall.new }\n\n  it 'should state its dimensions' do\n    brick_wall.dimensions.must_equal 'I am 30ft. long and 20ft. wide!'\n  end\n\n  it 'should be made from brick' do\n    brick_wall.made_from.must_equal 'I am made from brick!'\n  end\nend\n\n# Blueprints for a ConcreteWall\ndescribe ConcreteWall do\n  let(:concrete_wall) { ConcreteWall.new }\n\n  it 'should state its dimensions' do\n    concrete_wall.dimensions.must_equal 'I am 30ft. long and 20ft. wide!'\n  end\n\n  it 'should be made from concrete' do\n    concrete_wall.made_from.must_equal 'I am made from concrete!'\n  end\nend\n\n# Blueprints for a WoodWall\ndescribe WoodWall do\n  let(:wood_wall) { WoodWall.new }\n\n  it 'should state its dimensions' do\n    wood_wall.dimensions.must_equal 'I am 10ft. long and 20ft. wide!'\n  end\n\n  it 'should be made from wood' do\n    wood_wall.made_from.must_equal 'I am made from wood!'\n  end\nend\n```\n\nHmm... A couple of ideas run through our heads. We could follow the initial `Wall` class and\ndefine each method, hardcoding each string output, for the `BrickWall`, `ConcreteWall`, and `WoodWall`\nclasses. That seems like an okay idea, but we'd have to hard code each\ninstance method. What if our house requires a dozen different types of walls?\n\n### Open That Toolbox!\n\nSipping on our after-lunch coffee, we realize that we've got a tool right\nfor the job, the *Template Method* pattern.\n\nIn the *Template Method* pattern, the creation of a *skeletal class* will\nserve as the basis for various *subclasses* or *concrete classes*. Within the *skeletal class*\nthere are *abstract methods*, which in turn, will be overridden by the\nmethods of *subclasses*. Essentially, we'll define a `Wall` class (our\n*skeletal class*) and its *subclasses*, `BrickWall`, `ConcreteWall`, and\n`WoodWall`.\n\nGoing over the blueprints, we notice that the three different classes of\nwalls each contain the methods `#dimensions` and `#made_from`, which\nresult in slighty different strings. With this knowledge, let's\ncreate our `Wall` class and its subclasses.\n\n```ruby\nclass Wall\n  def dimensions\n    \"I am #{length}ft. long and #{width}ft. wide!\"\n  end\n\n  def made_from\n    \"I am made from #{material}!\"\n  end\n\n  private\n\n  def length\n    30\n  end\nend\n\nclass BrickWall < Wall\n  private\n\n  def width\n    20\n  end\n\n  def material\n    'brick'\n  end\nend\n\nclass ConcreteWall < Wall\n  private\n\n  def width\n    20\n  end\n\n  def material\n    'concrete'\n  end\nend\n\nclass WoodWall < Wall\n  private\n\n  def length\n    10\n  end\n\n  def width\n    20\n  end\n\n  def material\n    'wood'\n  end\nend\n```\n\n## Discussion\n\n### Hook Methods\n\nWithin the `Wall` class we have defined a private method called `#length`\nbecause we see that `BrickWall` and `ConcreteWall` share the same\nlength. As for the `WoodWall` class, we simply overwrite the `#length`\nand give it a value of `10`. These are examples of *Hook Methods*.\n\n*Hook Methods* serve two purposes:\n\n1. Override the skeletal implementation and define something new\n2. Or, accept the default implementation\n\nPlease note that the default implemetation, within the skeletal class, does\nnot necessarily need to define a method. For example, we could have had:\n\n```ruby\nclass Wall\n\n  ...\n\n  private\n\n  def length\n    raise NotImplementedError, 'Sorry, you have to override length'\n  end\nend\n\nclass BrickWall < Wall\n  private\n\n  ...\n\n  def length\n    30\n  end\nend\n```\n\nIn the example above, the `#length` method within the `Wall` class\nserved as a placeholder for the `#length` for the `BrickWall`, it's\n*concrete class*. Essentially, *hook methods* inform all *concrete\nclasses* that the method may require an override. If the base\nimplementation is undefined the subclasses must define the *hook\nmethods*.\n\n## Those Are Some Nice Walls\n\nOur foreman is delighted with the results and we're going to call it a\nday. As we can see, using the *Template Method* pattern is not difficult\nat all. We first defined a base class, within which we defined necessary\n*hook methods* to be overridden by our *subclasses*. Of course, this\nparticular design pattern does not solve every conceivable problem, but\nhelps keep our code clean by the use of inheritance.\n\nNext we'll be discussing the *Strategy* method pattern. Stay tuned!\n"},{"title":"Design Patterns: The Strategy Pattern","tags":["design patterns","ruby"],"summary":"Exploring design patterns and their use cases","legacy":false,"id":"2013/07/25/design-patterns-strategy-pattern","employee":"Doug Yun","date":"2013-07-25T00:00:00","body":"\n\n## Walls are sooooo last week...\n\nIn our last post, we discussed the *[Template\nMethod](http://reefpoints.dockyard.com/ruby/2013/07/10/design-patterns-template-pattern.html)*\npattern and its benefits, finding it most useful when we need to simply shape\nbehavior of *subclasses*. However, due to the reliance on *inheritance*,\nthere are a couple of limitations to this pattern:\n\n* Subclasses are tightly bound to a superclass or baseclass\n* Runtime flexibility is hindered\n* Only a portion of the desired alogrithm is varied\n\nThankfully, there is another design pattern that resolves these\nproblems: the *Strategy* pattern.\n\n## Summertime and the Livin' is Easy\n\n### Hot dogs, hamburgers, and veggie patties\n\nIt's the middle of July, and there's no better time to throw a day\nparty. Our pals are bringing the tasty beverages, so we just need to prepare the food.\n\nWe'll first create a superclass `Food` that will delagate `#type` to its\nsubclasses: `HotDog`, `Hamburger`, and `VeggiePatty`. Notice that this\nis the *[Template\nMethod](http://reefpoints.dockyard.com/ruby/2013/07/10/design-patterns-template-pattern.html)*\npattern in action.\n\n```ruby\nclass Food\n  def type\n    raise NotImplementedError, 'Ask the subclass'\n  end\nend\n\nclass HotDog < Food\n  def type\n    'hot dogs'\n  end\nend\n\nclass Hamburger < Food\n  def type\n    'hamburgers'\n  end\nend\n\nclass VeggiePatty < Food\n  def type\n    'veggie patties'\n  end\nend\n```\nNow, let's get the grill ready.\n\n```ruby\nclass Grill\n  attr_accessor :food\n\n  def initialize food\n    @food = food\n  end\n\n  def grilling\n    \"Grilling the #{food.type}!\"\n  end\nend\n```\nNice. Now let's get grilling! We'll start with some hot dogs.\n\n###\n\n```ruby\ngrill = Grill.new(HotDog.new)\ngrill.grilling # => \"Grilling the hot dogs!\"\n```\n\nOh watch out, these dogs are almost done... time to throw on the\nhamburger and veggie patties.\n\n```ruby\ngrill.food = Hamburger.new\ngrill.grilling # => \"Grilling the hamburgers!\"\n\ngrill.food = VeggiePatty.new\ngrill.grilling # => \"Grilling the veggie patties!\"\n```\n\nWasn't that easy? We were able to switch out items without\ncreating a new class of `Grill`.\n\n## Discussion\n\n### Strategies and Context\n\nThe *Strategy* pattern employs *strategies*, objects of which\npossess identical behavior. Our grill party relies on *strategies* to\ntell us what `#type` of food they were. It's important that all strategy objects\nhave the same responsiblity and support the same interface, which in our case\nwas `grill.grilling`.\n\nThe `Grill` class is our *context* class, the operator of the\n*strategies*, which uses the `HotDog#type`, `Hamburger#type`, and\n`VeggiePatty#type` interchangeably.\n\nThrough our contrived example, we see the immediate benefits of this\ndesign pattern:\n\n* *Separation of concerns*\n* *Strategies* at runtime\n\nWe've achieved *separation of concerns* by designating the `#type`\nmethod as our desired set of *strategies*. `HotDog`, `Hamburger` and\n`VeggiePatty`  are unaware of our implementation of `Grill#grilling`.\n\nAs for runtime flexibility, we're able to switch out the items up on the\ngrill.\n\n### Special Patties: Lambdas\n\nAs we're grilling our hamburger and veggies patties, a last minute guest\narrives, and she has brought some bacon, jalapeños, and onions.\nLet's make some custom patties, but avoid creating more subclasses of\n`Food`. What could we do here?\n\nA quick and awesome solution would be to use *lambdas*!\n\nSince we expect our *strategies* to return `Strings` for food `#type`,\nwe can create a *lambda* which will behave just like the other strategy\nobjects and return a `String`.\n\n```ruby\nCUSTOMPATTY = lambda { |type| \"#{type}\" }\n```\n\nNext, let's get back to our `Grill` class and alter the class a little\nbit.\n\n```ruby\nclass Grill\n  attr_accessor :food\n\n  def initialize food\n    @food = food\n  end\n\n  def grilling\n    \"Grilling the #{print_food}!\"\n  end\n\n  private\n\n  def print_food\n    food_is_string? ? food : food.type\n  end\n\n  def food_is_string?\n    food.is_a? String\n  end\nend\n```\n\nSince we know the *strategies* are `Strings`, we've created two\n`private` methods, `#print_food` and `#food_is_string`.\n`#food_is_string` will check if `Grill` has received a\n`String` or not, and `#print_food` will handle *lambdas* or *classes* of\nfood.\n\nNow let's try grilling some hot dogs and custom patties!\n\n```ruby\njalapeños = CUSTOMPATTY.call 'spicy jalapeños patties'\nbacon = CUSTOMPATTY.call 'greasy, yummy bacon patties'\n\ngrill = Grill.new jalapeños\ngrill.grilling # => \"Grilling the spicy jalapeños patties!\"\n\ngrill.food = bacon\ngrill.grilling # => \"Grilling the greasy, yummy bacon patties!\"\n\ngrill.food = HotDog.new\ngrill.grilling # => \"Grilling the hot dogs!\"\n```\n\n### Mmm-mmmm... That is a tasty burger.\n\nThe *Strategy* pattern is a delagation-based design pattern, and shares\nsome similarities with the *Template Method* pattern. However, instead\nof depending so heavily on inheiritance between a superclass and\nsubclasses to use our target algorithm, we take our algorithm and\nconsider it as a separate object. As long as we remember the\nrelationship between the *strategies* and the *context*, we earn real\nadvantages over the *Template Method*, as seen in our custom patty\nexample.\n\nI hope you had fun at our day party, and we'll next explore the\n*Observer* pattern.\n"},{"title":"Putting things next to things with Susy","tags":["design"],"summary":"The little grid framework that can","legacy":false,"id":"2013/07/29/putting-things-next-to-things-with-susy","employee":"Angelo Simeoni","date":"2013-07-29T00:00:00","body":"\n\nI've often lamented that one of the most challenging things to do on the front end is to put things next to other things. Things on top of things? Easy. Things by themselves? Piece of cake. This thing next to that thing? Things just got complicated.\n\nShould you roll your own layout, coming up with and refining conventions, browser testing to make sure everything still works? Do you rely on a front-end framework and all of the cluttered, confusing markup that comes going from that route? \n\nWhat about something different? This is where Susy saves the day.\n\n## The little framework that can\n\nSusy is a grid framework for Compass. With Susy, you simply define your grid settings and start laying things out. If you want to come back and adjust your grid later, that's totally fine. Susy will recalculate all your layouts.\n\n```css\n$total-columns: 12\n$column-width: 4em\n$gutter-width: 1em\n$grid-padding: $gutter-width\n```\n\nTwo main mixins do the bulk of the lifting. These are 'container' and 'span-columns'. Container is used to define the container of the grid. Span-columns is applied to elements within a container context. The syntax is easy.\n\n```css\n.page\n  +container\n  article\n    +span-columns(8, 12)\n  aside\n    +span-columns(4 omega, 12)\n```\n\nThis makes '.page' the grid container. The article takes up eight of twelve columns, the aside the final (omega) four of twelve columns.\n\nSusy really shines at figuring stuff out on its own. Say I wanted to have two columns of different widths with different padding for each column, both nested within the article above?\n\n```css\narticle\n  +span-columns(8, 12)\n  .one\n    +span-columns(3, 7, 1em)\n  .two\n    +span-columns(4 omega, 7, .5em)\n```\n\nWhere did the seven columns come from? Susy doesn't care. They are within the context of the article. Susy will figure out the math and make seven columns. The third option is the column padding. Susy will do the math there too. Thanks, Susy!\n\n## Susy, breakpoints and you\n\nSusy is made to build responsive grids. The default layout is called 'magic'. It's a fixed width layout that fluidly scales if the viewport is smaller than the width of the grid. You can also opt for a fully fluid layout, or a static layout for pixel precision.\n\nAny of these layouts can be further modified with the +at-breakpoint mixin. This mixin makes accessing media queries within the context of our grid simple and straightforward.\n\n```css\n.one, .two\n  +at-breakpoint(30em)\n    +span-columns(7, 7, .5em)\n```\n\n## \u0010The one true grid\n\nEverything Susy does is within context of a grid. You can  define multiple grids, and nest these grids inside one another. You can define abritrary values within any context. Many useful features, such as push, pull, and bleed are there to make life even easier.\n\nWith all of this power comes some responsiblity. As with any tool, Susy just does what you ask it to do. It cannot explain  why your layout isn't working. If you try to put too many things inside a grid, your layout will break. I'd recommend taking Susy for a spin. It's really easy to [get started](http://susy.oddbird.net/guides/getting-started/).\n"},{"title":"Testing Context Validations","tags":["rails","gems","context validation","testing"],"summary":"We moved your model validations to your controller, now we're going to help you test them","legacy":false,"id":"2013/08/05/testing-context-validations","employee":"Dan McClain","date":"2013-08-05T00:00:00","body":"\n\n## Quick Refresher on ContextValidation\nA few months ago, Brian released the [ContextValidations gem](http://reefpoints.dockyard.com/ruby/2013/05/09/context-validations.html).\nContextValidations moves your model validations to the controller,\nallowing you to vary your validations by context, rather than relying on\nconditional validations.\n\n## Let's validate our user\n\nWe have a user model, that requires a password and a username when a\nuser signs up. They can change their username and password, but if they\ncan leave the password blank when updating their account, it will retain\nthe old password. Whenever they enter a password , it must be 9\ncharacters or greater. We're going to ignore the actual implementation\nof the password saving scheme and password confirmation in this example.\nAlso, this example ignores setting up the test helper for [valid\\_attribute](https://github.com/bcardarella/valid_attribute)\nand MiniTest::Spec.\n\n### Implementing the Tests and Validations in the Model\n\nTo test the above requirements model validations, we'd do the following:\n\n```ruby\ndescribe OldUser do\n  describe 'new user' do\n    subject { OldUser.new password: 'password_to_confirm' }\n\n    it { must have_valid(:username).when('bob', 'test1234') }\n    it { wont have_valid(:username).when('', nil) }\n    it { must have_valid(:password).when('validpassword1234') }\n    it { wont have_valid(:password).when('', nil, 'tooshort') }\n  end\n\n  describe 'existing user' do\n    subject { old_users(:example) }\n\n    it { must have_valid(:username).when('bob', 'test1234') }\n    it { wont have_valid(:username).when('', nil) }\n    it { must have_valid(:password).when('', nil, 'validpassword1234') }\n    it { wont have_valid(:password).when('tooshort') }\n  end\nend\n```\n\nAnd here is the implementation of the model:\n\n```ruby\nclass OldUser < ActiveRecord::Base\n  attr_accessor :password\n  validates :username, presence: true\n  validates :password, presence: true, if: :new_record?\n  validates :password, length: { minimum: 9 }, allow_blank: true\nend\n```\n\n### Implementing the Tests and Validations in the Controller with ContextValidations\n\nWe've been using ContextValidations with our client work since its\nrelease and realized we could unit test the controller to test the\nvalidations.\n\nOur unit tests for the controller are here:\n\n```ruby\ndescribe UsersController do\n  describe '#create' do\n    subject { User.new(validations: validations_for(:create)) }\n\n    it { must have_valid(:username).when('bob', 'test1234') }\n    it { wont have_valid(:username).when('', nil) }\n    it { must have_valid(:password).when('validpassword1234') }\n    it { wont have_valid(:password).when('', nil, 'tooshort') }\n  end\n\n  describe '#update' do\n    subject { User.new(validations: validations_for(:update)) }\n\n    it { must have_valid(:username).when('bob', 'test1234') }\n    it { wont have_valid(:username).when('', nil) }\n    it { must have_valid(:password).when('', nil, 'validpassword1234') }\n    it { wont have_valid(:password).when('tooshort') }\n  end\nend\n```\n\nNote the use of `validations_for`. It is a MiniTest\nhelper method defined by ContextValidations, which looks up the name\nof the controller from the describe block, creates an instance of it,\nand retrieves the validations for the context passed in. This prevents\nyou from needing to create your own instance and calling `validations`\non it. The resulting tests end up looking very similar to what your\nmodel tests would look like.\n\nOur model implementation is very light:\n\n```ruby\nclass User < ActiveRecord::Base\n  include ContextValidations::Model\n\n  attr_accessor :password\nend\n```\n\nAnd our validations are defined in the controller:\n\n```ruby\nclass UsersController < ApplicationController\n  include ContextValidations::Controller\n\n  private\n\n  def base_validations\n    validates :username, presence: true\n    validates :password, length: { minimum: 9 }, allow_blank: true\n  end\n\n  def create_validations\n    validates :password, presence: true\n  end\nend\n```\n\nAll of the examples are part of [this repository](https://github.com/dockyard/testing_context_validations).\n\n## Wrapping it up\n\nAs you can see, writing the validation tests for the controller are\nalmost identical to writing them for the model. There are a few\ndifferences in setting up the subject for the tests, but the only major\ndifference is that you are testing the controller instead of the model.\nIf you have any feedback on the tests we came up with, feel free to let\nus know!\n"},{"title":"Design Patterns: The Observer Pattern","tags":["design patterns","ruby"],"summary":"NSA Edition: Exploring design patterns and their use cases","legacy":false,"id":"2013/08/20/design-patterns-observer-pattern","employee":"Doug Yun","date":"2013-08-20T00:00:00","body":"\n\nNote: We won't be going over the Ruby\nmodule\n[*Observable*](http://ruby-doc.org/stdlib-2.0/libdoc/observer/rdoc/Observable.html).\nInstead, we'll building out the pattern ourselves.\n\n## Your First Day at the NSA\n\nWelcome to the National Security Agency, [Agent\nSmith](http://www.forodecostarica.com/attachments/201136d1337091462-los-gringos-se-burlan-de-nuestro-pais-agent-smith.jpg).\nYou have quite an impressive background, and we believe your \"go-getter\"\nattitude will instill a new kind of vigor within the organization.\n\nYour cubicle is down to the left... here are some NDAs for\nyou to fill out. I'll swing by your desk in the afternoon and pick them\nup from you later. Oh, and before I forget, here is your first assignment.\n\nGo get 'em, tiger!\n\n## The First Assignment\n\n```\nAgent Smith\nSpook First Class\n[REDACTED]\nNSA                                                     08-20-[REDACTED]\n\n                     Operation [REDACTED] Observers\n\nWelcome, Agent Smith:\n\nBluntly, we'd like to track everyone's emails.\n\nAttached are two documents.\n\nThe first document will show you the basic structure of a typical email,\nand the second document will provide you a basic profile of a suspicious\nperson.\n\nIf there are any questions, please reach me at [REDACTED].\n\nBest of luck,\n\n\n\n\n\nAgent [REDACTED]\n[REDACTED]\n[REDACTED]\nNSA\n```\n\n```ruby\n# Document 1:\n# Basic structure of an email\n\nmodule Email\n  extend self\n\n  def send(subject, sender, receiver)\n    puts %Q[\n      Subject: #{subject}\n      From:    #{sender}@example.com\n      To:      #{receiver}@example.com\n      Date:    #{Time.now.asctime}\n    ]\n  end\nend\n```\n\n```ruby\n# Document 2:\n# Characteristics of a suspicious person\n\nclass Person\n  include Email\n  attr_reader :name\n\n  def initialize(name)\n    @name = name\n  end\n\n  def send_email(subject, receiver)\n    Email.send(subject, name, receiver)\n  end\nend\n```\n\nAs we look through the `Email` module, we see that it contains\n`Email.send` which takes three arguments: `subject`, `sender`, and\n`receiver`.\n\nGazing at the suspicious `Person` class, we see that it includes the\n`Email` module. `Person#send_email` takes two parameters: a subject\nand a receiver. `Person#name` will stand in as the sender of the email.\n\nHypothetically, let's see how a suspicious person would send an email:\n\n```\nbill = Person.new 'Bill'\nbill.send_email 'Fishing Trip', 'Fred'\n  # =>\n      Subject: Fishing Trip\n      From:    Bill@example.com\n      To:      Fred@example.com\n      Date:    Wed Aug 16 20:35:09 2006\n```\n\nHmm... as you sit in your cubicle, you ponder the numerous possible ways of\ntracking emails. You won't need anything too complicated, just\nsomething to kick off a notification once an email has been sent.\n\nVolia! You realize you can use the *Observer* pattern!\n\n## The Subject and its Observers\n\nFirst, let's start off by creating two *observer* classes,\n`Alert` and `Agent` classes.\n\n```ruby\nclass Alert\n  def gotcha(person)\n    puts \"!!! ALERT: #{person.name.upcase} SENT AN EMAIL !!!\"\n  end\nend\n\nclass Agent\n  def gotcha(person)\n    puts \"!!! TIME TO DETAIN #{person.name.upcase} !!!\"\n  end\nend\n```\n\nNext, let's create a `Subject` module.\n\n```ruby\nmodule Subject\n  attr_reader :observers\n\n  def initialize\n    @observers = []\n  end\n\n  def add_observer(*observers)\n    observers.each { |observer| @observers << observer }\n  end\n\n  def delete_observer(*observers)\n    observers.each { |observer| @observers.delete(observer) }\n  end\n\n  private\n\n  def notify_observers\n    observers.each { |observer| observer.gotcha(self) }\n  end\nend\n```\n\nHere within the `Subject#initialize`, we create an empty array which\nwill contain a list of *observers*. `Subject#add_observer` simply pushes\nour desired *observers* into the array.\n\nFinally, we can alter the suspicious `Person` class, which will act as\nthe *subject* class. Let's include the `Subject` module now.\n\n```ruby\nclass Person\n  include Email, Subject\n  attr_reader :name\n\n  def initialize(name)\n    # 'super' requires a parentheses because we're calling\n    # super on the superclass, 'Subject'\n    super()\n    @name = name\n  end\n\n  def send_email(subject, receiver)\n    Email.send(subject, name, receiver)\n    notify_observers\n  end\nend\n```\n`Subject#notify_observers` calls `#gotcha` on each *observer*, which\ninforms each *observer* that `Person#send_email` has been kicked off.\n\nNow let's give it a whirl...\n\n```ruby\nalert = Alert.new\nagent = Agent.new\n\nbill = Person.new 'Bill'\n\nbill.add_observer alert, agent   # Bill now has two observers watching him\n\nbill.send_email 'Fishing Trip', 'Fred'\n  # =>\n      Subject: Fishing Trip\n      From:    Bill@example.com\n      To:      Fred@example.com\n      Date:    Wed Aug 16 20:35:09 2006\n\n!!! ALERT: BILL SENT AN EMAIL !!!\n!!! TIME TO DETAIN BILL !!!\n```\n\nPerfect, it works! Now we can start protecting our freedom!\n\n## Discussion\n\nIn our example above, we have two *observers*, the `Alert` and `Agent`\nclasses, and a *subject*, `Person`. By creating the `Subject` module,\nany instance of `Person` now informs and updates any *observer* through\n`#notify_observers`, ultimately removing any implicit coupling from `Alert` and\n`Agent`.\n\nThere are a few similarities between the *Observer* and\n[*Strategy*](http://reefpoints.dockyard.com/2013/07/25/design-patterns-strategy-pattern.html)\npatterns. Both patterns employ an object (the Observer's *subject* and\nthe Strategy's *context*) that makes calls to another object (the\nObserver's *observer* or Strategy's *strategy*). The difference between\nthe two patterns is the purpose and use case. The *Strategy* pattern\nrelies on the *strategy* to do the work, while the *Observer* pattern\ninforms the *observers* of what is going on with the *subject*.\n\nHope you enjoyed this short example, thanks for reading!\n"},{"title":"Announcing Postgres_ext version 1.0 and 2.0","tags":["rails","gems","postgres_ext","postgres"],"summary":"Today, I released not 1 but 2 versions of PostgresExt","legacy":false,"id":"2013/08/23/announcing-postgres_ext-version-1-0-and-2-0","employee":"Dan McClain","date":"2013-08-23T00:00:00","body":"\n\nTwo versions of PostgresExt have been released today.\n\n## 1.0.0 (and the 1-0-stable branch)\n\nThe [1.0.0](https://github.com/dockyard/postgres_ext/tree/v1.0.0)\n version is the first production release of PostgresExt. It\nsupports Rails 3.2.x, adding in both data type and advanced querying\nsupport for ActiveRecord and Arel.\n\n## 2.0.0 \n\nI have also released version [2.0.0](https://github.com/dockyard/postgres_ext/tree/v2.0.0),\nwhich supports ActiveRecord and Arel 4.0.x. Most of the 1.0.0 code\nis gone from 2.0.0, since Rails 4.0.0 supports all the data types\nthat PostgresExt added to Rails 3.2.x.\n\n## The Future\n\nI'm focusing on Rails 4.0.0 for all future features of PostgresExt. I\nwill gladly pull in additional features for 1.0.0, but Rails 3.2.x is no\nlonger the primary focus of PostgresExt. Maintenance on 1.0.0 will be\nminimal, since [Rails 3.2.x will no longer be receiving releases for bug\nfixes](http://weblog.rubyonrails.org/2013/2/24/maintenance-policy-for-ruby-on-rails/),\nbut pull requests for bug fixes would be graciously accepted.\n"},{"title":"Alex Navasardyan is a DockYarder!","tags":["office"],"summary":"Our first fulltime Ember.js dev","legacy":false,"illustration_alt":"Alex","illustration":"https://i.imgur.com/PyRe08M.png","id":"2013/09/04/alex-navasardyan-is-a-dockyarder","employee":"Brian Cardarella","date":"2013-09-04T00:00:00","body":"\n\n![Alex](https://i.imgur.com/PyRe08M.png)\n\nAlex has been friend for a while now, I got to know him when I started\nattending the [Boston Ember meetup](www.meetup.com/Boston-Ember-js/).\nAlex has been a very active in the Ember.js community and helped with\nthe 1.0 release last week as well as\n[Ember.ListView](http://emberjs.com/list-view/)\n\nWe're very dedicated to the future of Ember.js and with Alex on board\nwe're well on our way to building out one of the best teams around.\n\n[Follow Alex on Twitter](http://twitter.com/twokul)\n"},{"title":"Computed Properties in Ember.Js","tags":["ember"],"summary":"Computed Properties magic explained","legacy":false,"id":"2013/09/04/computed_properties_in_ember_js","employee":"Alex Navasardyan","date":"2013-09-04T00:00:00","body":"\n\nNote: Short version of this post is a part of [Ember.Js\nGuides](http://emberjs.com/guides/object-model/computed-properties/).\n\n## What Are Computed Properties?\n\nIn a nutshell, it's a property whose value is computed the first time\nit's asked for. You can define the computed property as a function and\nwhen someone asks for it, Ember will automatically invoke the function\nand treat the return value like value of the property.\n\nHere's a very well-known example:\n\n```javascript\nApp.Person = Ember.Object.extend({\n  firstName: null,\n  lastName: null,\n  fullName: function() {\n    return this.get('firstName') + ' ' + this.get('lastName');\n  }.property('firstName', 'lastName')\n});\n\nvar ironMan = Person.create({\n  firstName: \"Tony\",\n  lastName:  \"Stark\"\n});\n\nironMan.get('fullName');\n// \"Tony Stark\"\n```\n\nThe code above defines a computed property `fullName` by calling\n`property()` on the function with two dependencies `firstName` and\n`lastName` and whenever it gets called, it returns `firstName` + `lastName`.\n\n## Inception\n\nLet's take a look at another example. Say we want to add a description\ncomputed property to `App.Person`. It will aggregate other properties like\n`fullName`, `age`, `country`:\n\n```javascript\nApp.Person = Ember.Object.extend({\n  firstName: null,\n  lastName: null,\n  age: null,\n  country: null,\n  fullName: function() {\n    return this.get('firstName') + ' ' + this.get('lastName');\n  }.property('firstName', 'lastName'),\n  description: function() {\n    return this.get('fullName') + '; Age: ' +\n           this.get('age') + '; Country: ' +\n           this.get('country');\n  }.property('fullName', 'age', 'country')\n});\n\nvar captainAmerica = Person.create({\n  fullName: 'Steve Rogers',\n  age: 80,\n  country: 'USA'\n});\n\ncaptainAmerica.get('description');\n// \"Steve Rogers; Age: 80; Country: USA\"\n```\n\nNotice that you can use an existing computed property as a dependency for a\nnew one.\n\n## Caching\n\nBy default, all computed properties are cached. That means that once you\nrequested the value of computed property (called `get` on it), it's going\nto compute and cache its value:\n\n```javascript\ncaptainAmerica.get('description');\n// computes the value and returns \"Steve Rogers; Age: 80; Country: USA\"\ncaptainAmerica.get('description');\n// returns cached \"Steve Rogers; Age: 80; Country: USA\"\n```\n\nA computed property gets recomputed when any of the properties it depends on change:\n\n```javascript\ncaptainAmerica.set('country', 'United States of America');\ncaptainAmerica.get('description'); // computes the value and returns\"Steve Rogers; Age: 80; Country: United States of America\"\n```\n\n## Read Only\n\nThis property is `false` by default. You won't be able to set the value of\nthe computed property if you call `readOnly` on it:\n\n```javascript\nApp.Person = Ember.Object.extend({\n  description: function() {\n    // implementation\n  }.property('fullName', 'age', 'country').readOnly()\n});\n\nvar captainAmerica = Person.create();\ncaptainAmerica.set('description', 'hero');\n// \"Cannot Set: description on: <(unknown mixin):ember133>\"\n```\n\n## Alternative syntax for defining Computed Properties\n\nThis code:\n\n```javascript\nApp.Person = Ember.Object.extend({\n  firstName: null,\n  lastName: null,\n  fullName: Ember.computed('firstName', 'lastName', function() {\n    return this.get('firstName') + ' ' + this.get('lastName');\n  })\n});\n```\n\ndoes exactly the same thing as this code:\n\n```javascript\nApp.Person = Ember.Object.extend({\n  firstName: null,\n  lastName: null,\n  fullName: function() {\n    return this.get('firstName') + ' ' + this.get('lastName');\n  }.property('firstName', 'lastName')\n});\n```\n\nwith the difference that the first example works if you disable [Ember's\nprototype extension](http://emberjs.com/api/#property_EXTEND_PROTOTYPES).\n\n## How are Computed Properties different from Observers and Bindings?\n\nThe concept of `observer` is pretty simple. You have something that you want to track the change of. You add an observer to it, so next time it changes, a certain event is going to be fired notifying you that that something has changed.\n\nThere are two types of observers: `before` (observesBefore) and `after` (observes). When observer event (callback) is fired, it's called with two arguments: `obj` and `keyName`. It doesn't pass the value of the property to the event (callback). The reason is because the property you're watching might be lazily computed.\n\n`Observers` are used by CP internally to invalidate CP's cache when its dependency keys were changed. Observers (like CPs) don't use runloop magic (fired \"right away\").\n\n`Observers` are not going to fire if the value is unchanged from before (changing existing `lastName` from `Stark` to `Stark` won't trigger the observer callback).\n\n`Bindings` is an internal concept that is not meant to be used. I'm not saying you can't, it's better not to. Typically, you don't need to use it in your application, using CP is plenty enough.\n\n`Bindings` are meant to keep a property of two objects in sync. Their update (sync) happens through run loop, so there might be a period of time when two objects have the same property with different values and only by the end of a `sync` queue those values are going to be the same.\n\nFor example, in Ember those two objects are controller and view (any time a controller's property changes, view's property changes as well).\n\n## What do I use and when?\n\n**Computed properties** are good for combining other properties or doing\ntransformations on the property.\n\n**Observers** are good for tracking changes of a property and reacting to\nthem. Observers should contain behaviour that reacts to the change.\n\n**Bindings** are used to make sure that the properties from the different objects\nare in sync. They are rarely used and most of the times can be replaced\nwith computed properties.\n\n## Futher reading\n\nYou can read more about Computed Properties and Ember's Object Model\nover\n[here](http://emberjs.com/guides/object-model/computed-properties/).\nHappy Coding!\n"},{"title":"Postgres_ext adds rank and common table expressions","tags":["rails","gems","postgres_ext","postgres"],"summary":"In postgres_ext 2.1, complex queries get much easier","legacy":false,"id":"2013/09/06/postgres_ext-adds-rank-and-common-table-expressions","employee":"Dan McClain","date":"2013-09-06T00:00:00","body":"\n\nThis week, I released [postgres\\_ext](https://github.com/dockyard/postgres_ext) 2.1.0, which includes\nActiveRecord::Relation methods to simplify queries that require the use\nof [Common Table\nExpressions](http://www.postgresql.org/docs/current/static/queries-with.html)\n(CTEs) and the [`rank()` windowing\nfunction](http://www.postgresql.org/docs/9.2/static/functions-window.html).\n\n## Common Table Expressions\n\nIn a sentence, CTEs allow you to define a temporary table to be used in\na larger query. Let's look at an example:\n\n```SQL\nWITH scores_for_game AS (\nSELECT *\nFROM scores\nWHERE game_id = 1\n)\nSELECT *\nFROM scores_for_game\n```\n\nIn the above, somewhat arbitrary, example, we create a temporary table\nof `scores_for_game` which we then select from. CTEs allow you to\norganize your more complex queries, and can be really helpful in certain\ncases.\n\nWe can make the same SQL call in ActiveRecord with postgres\\_ext.\n\n```ruby\nScore.from_cte('scores_for_game', Score.where(game_id: 1))\n```\n\nWe can also query against the CTE expression by chaining off the\nresulting ActiveRecord::Relation\n\n```ruby\nScore.from_cte('scores_for_game',\n  Score.where(game_id: 1)).where(user_id: 1)\n```\n\nwould generate the following:\n\n```SQL\nWITH scores_for_game AS (\nSELECT *\nFROM scores\nWHERE game_id = 1\n)\nSELECT *\nFROM scores_for_game\nWHERE scores_for_game.user_id = 1\n```\n\nYou can also include CTEs in your normal queries to join against by\nusing `with`\n\n```ruby\nScore.with(my_games: Game.where(id: 1)).joins('JOIN my_games ON scores.game_id = my_games.id')\n```\n\nwill generate the following SQL:\n\n```SQL\nWITH my_games AS (\nSELECT games.*\nFROM games\nWHERE games.id = 1\n)\nSELECT *\nFROM scores\nJOIN my_games\nON scores.games_id = my_games.id\n```\n\n## Rank\n\nPostgreSQL provides a `rank` windowing function, which will take into\naccount ties when ranking results. You would add rank to your\nprojection, like the following example:\n\n```SQL\nSELECT scores.*, rank() OVER (ORDER BY scores.points DESC)\nFROM scores\n```\n\nThe results set will return ordered by the rank, which is determined the\norder passed into the `rank`'s `OVER`. In the above example, the scores\nwould be ranked by their scores descending, so highest score first. If\nthere was a tie at first place between two scores, they would both\nranked 1, and the next result would be ranked `3`. We can achieve the\nsame in ActiveRecord with postgres\\_ext:\n\n```ruby\nScore.ranked(points: :desc)\n# or\nScore.ranked('points desc')\n```\n\nRank will rank independently of any sort order applied to the query, so\nyou could have your scores ranked by points, but then ordered by their\ncreation time.\n\n```ruby\nScore.ranked(points: :desc).order(:created_at)\n```\n\nwill generate the following query:\n\n```sql\nSELECT scores.*, rank() OVER (ORDER BY scores.points DESC)\nFROM scores\nORDER BY scores.created_at ASC\n```\n\nAlso, if you apply a sort order to your relation, and want to sort by\nit, you do not have to tell ranked what order you'd like to use, as it\nwill reuse the order. \n\n```ruby\nScore.ranked.order(points: :desc)\n```\n\nOne thing to watch out for if you use `ranked` without an explicit\norder and want to call [`first`](http://api.rubyonrails.org/classes/ActiveRecord/FinderMethods.html#method-i-first)\noff your relation, if the results of the\nrelation have yet to be retrieved, the first will use your table's\nprimary key for an `ORDER BY` statement on the query. This has already\nbitten us before we discovered the behavior of `first`. To avoid this\nbehavior in `first`, use\n[`take`](http://api.rubyonrails.org/classes/ActiveRecord/FinderMethods.html#method-i-take)\nwhich does not use any implied order.\n\nWe've been using CTEs and rank on one of our client projects, and it's\nalready cleaned up the `from_sql` queries we were previously\nusing. Let us know if you hit any snags, or have any suggestions on how\nelse we can make complex SQL queries easier to call from ActiveRecord!\nWe only implement the `rank` windowing function right now, but plan to\nadd the others shortly.\n"},{"title":"Vim: Staying on Home Row via Map","tags":["vim","workflow"],"summary":"Map commands for quick escapes and saves","legacy":false,"id":"2013/09/11/vim-staying-on-home-row-via-map","employee":"Doug Yun","date":"2013-09-11T00:00:00","body":"\n\nHere at DockYard, the majority of us are using Vim. I don't want to\nwrite about the benefits of using this sweet editor, as that would take too long,\nbut instead, I'd like to share a couple of my favorite mappings for\nescaping and saving files.\n\nVanilla Vim: Escaping and Saving\n--------------------------------\nEscaping out to *Normal* mode from the other modes in Vim is straightforward:\nsimply hit the `Esc` key.\nSaving files is accomplished by, from `Normal` mode, pressing `:w` and then `Enter`.\n\nSo... What's the Problem?\n--------------------\nDuring a session, especially when I'm writing large pieces of text,\nI'd find myself in a repetitive rut:\n\n* I just typed out a couple of sentences and want to save my progress\n* I'd remove my left hand from home row to hit the `Esc` key\n* Saving the file required me, once again to leave home row, to hit `:w`\n  and then the `Enter` or the `Return` key\n* To continue on, I'd press `i` and type along\n* Repeat, repeat, repeat...\n\nSee where I'm getting at?\n\nLet's Talk About Map\n-------------------\nBefore we review and\n[copy-pasta](http://www.flickr.com/search/?q=pasta)\nthe portion of my `.vimrc`, let's briefly go over the very basics of the\npertinent map commands.\nYou can find the entire [map documentation here](http://vimdoc.sourceforge.net/htmldoc/map.html)\nor by typing `:help map` within a Vim session.\n\nProtip: To open help texts into a full buffer, `:h map | only` or to open them in a separate tab `:tab h map`.\n\n### Recursive Map\nFirst, we're going to talk about *recursive* map commands. A *recursive*\ncommand will transform one result to another result, if there is another\nbinding to that key. An example can be found at the `.vimrc` below.\n\nHere are the basic *recursive* map commands.\n\n* `map`  - command to transform the operation of typed keys within *ALL* modes\n\nYou can prepend the first letter of the desired mode to `map`.\n\n* `nmap` - transform the operation of typed keys within *Normal*\n  mode\n* `imap` - transform the operations of typed keys within\n  *Insert* mode\n* `vmap` - transform the operations of typed keys within\n  *Visual* and *Select* mode\n\nFor example, if I had this within my `.vimrc`:\n\n```\n\" ~/.vimrc\n\"\n\" Note: double quotes signifies comments\n\nnmap 0 gg\nimap n N\n\n\" Time for a little recursive map\nimap d D\nimap D wat\n```\nSince `0` is mapped to `gg` within *Normal* mode, I'll be sent to the\ntop of the file by pressing `0`.\nMoreover, while in *Insert* mode, every character `n` that I type will turn into `N`.\nLastly, because of the recursive mapping, typing `d` in *Insert* mode\nwill return `wat`. You can think of it as something like: `d` => `D` =>\n`wat`.\n\nThankfully, there's a *non-recursive* map.\n\n### Non-recursive Map\n*Non-recursive* map commands are signified by adding `nore` after the\n mode modifier.\n\n* `nnoremap` - non-recursive map for *Normal* mode\n* `inoremap` - non-recursive map for *Insert* mode\n* `vnoremap` - non-recursive map for *Visual* and *Select* mode\n\n```\n\" ~/.vimrc\n\ninoremap c C\ninoremap C nope\n```\nNow, in *Insert* mode, if we type `c`, we will return `C`; the transformation of\n`c` to `nope` will not occur.\n\nEnter the .vimrc\n----------------\nNow that we got the basics out of the way, here is an example of my\n`.vimrc`.\n\n```\n\" ~/.vimrc\n\" *** The Two Hand system ***\n\"\n\" <Cr> signifies the \"return\" key\n\ninoremap ;a <Esc>\ninoremap ;d <Esc>:update<Cr>\ninoremap ;f <C-O>:update<Cr>\nnnoremap ;f :update<CR>\n```\nI'm using `:update` here, which is \"like `:write`, but only write when the buffer has been\nmodified.\"\n\nLet's go over these mappings.\n\nThe first one, `inoremap ;a <Esc>` maps the *semi-colon* and *a* key\ntogether when in *Insert* mode. By pressing `;` and then `a` immediately afterwards, we mimic\nthe functionality of the *Escape* key.\n\nThe second map, `inoremap ;d <Esc>:update<Cr>` maps the *semi-colon* and the *d* key.\nPressing `;` and then `d` immediately afterwards returns the sequence of:\n\n* From *Insert* mode, escape to *Normal* mode\n* Type `:` to get inside the *Command* mode, and type the `update`\n  command\n* Complete the sequence by \"hitting\" *Return*, thus saving the file\n\nThe third map command, `inoremap ;f <C-O>:update<Cr>`, allows us to\ntype `;` and then `f` to return:\n\n* From *Insert* mode, escape out to *Normal* with `<C-O>`, which allows\n  us to escape out for *ONE* command.\n* Type `:` to get inside *Command* mode, and then type `udpate`. This is\n  our one command for `<C-O>`\n* \"Hit\" the *Return*, thus saving the file\n* We're back in *Insert* mode, thanks to `<C-O>`\n\nFinally, the `nnoremap ;f :update<CR>` mapping means by typing `;` and\nthen `f` in *Normal* mode, it will result in:\n\n* Since, we're already in *Normal* mode, we get into *Command* mode by\n  typing `:`\n* Type the `update` command\n* \"Hit\" the *Return* key, and save the file\n* We remain in *Normal* mode\n\nThe snippet below restricts these commands to your right hand.\n\n```\n\" ~/.vimrc\n\" *** The Right Hand system ***\n\ninoremap ;l <Esc>\ninoremap ;k <Esc>:update<Cr>\ninoremap ;j <C-O>:update<Cr>\nnnoremap ;j :update<CR>\n```\n\nAs you can see, I kept `;` as a prefix to my map commands. This\nconveniently keeps me at homerow. I've played with mapping everything\nwith my right hand, but it just didn't feel \"right\" (apologies for the\nbad pun).\n\nOverall, this snippet makes me happy and I believe this will make your\nday as well. If there are some other tricks\nconcerning escaping and saving files, please let me know in the\ncomments! Thanks!\n"},{"title":"Vim: Moving Lines Ain't Hard","tags":["vim","workflow"],"summary":"Quick ways to move lines","legacy":false,"id":"2013/09/26/vim-moving-lines-aint-hard","employee":"Doug Yun","date":"2013-09-26T00:00:00","body":"\nIn the last post, we briefly discussed the power of the\n[*map* command](http://reefpoints.dockyard.com/2013/09/11/vim-staying-on-home-row-via-map.html).\nIn today's post, we're going to use *map* again in order to move\nlines and blocks around.\n\nLet's use an example:\nOur goal is to move the *first line* to its proper location. From this:\n\n```\n--- second line ---\n--- third line ---\n--- first line ---\n```\n\nTo this:\n\n```\n--- first line ---\n--- second line ---\n--- third line ---\n```\n\nDelete, Then Paste\n------------------\n\nHere is one of the most common ways, it ain't pretty but it gets the job done.\nWe'll delete the desired line and paste it to the target location.\n\n```\n--- second line ---\n--- third line ---\n--- first line ---\n\n# Delete the \"first line\", move to the \"second line\", and paste the registered\n# \"first line\" above the \"second line\".\n#\n# :3 --> <ENTER> --> dd --> j --> P\n#\n# or...\n#\n# :3d --> <ENTER> --> :2P --> <ENTER>\n```\n\nI Like the Way You Move\n--------\n\nThe second way, use the *move* command with `:m`. I like this method a lot, as it\nrequires fewer keystrokes. It does require line numbers though. When using\nabsolute line numbers, the destination will be below the line number you specify,\nso use `:m0` to move to the top of the file.\nTry using\n[hybrid mode](http://jeffkreeftmeijer.com/2013/vims-new-hybrid-line-number-mode/).\n\n```\n--- second line ---\n--- third line ---\n--- first line ---\n\n# Move your cursor on the \"first line\" (the third line), use the *move* command and\n# pass your desired line number as an argument. Hit enter.\n#\n# :3 --> <ENTER> --> :m0 --> <ENTER>\n#\n# or...\n#\n# :3m0 --> <ENTER>\n```\n\nLazy Moving\n-----------\n\nNow getting to the *map* command, I've found this pretty handy when\nI need to move a line or block of lines a couple of lines upward or downward.\n\n```\n\" In your ~/.vimrc\n\"\n\" Normal mode\nnnoremap <C-j> :m .+1<CR>==\nnnoremap <C-k> :m .-2<CR>==\n\n\" Insert mode\ninoremap <C-j> <ESC>:m .+1<CR>==gi\ninoremap <C-k> <ESC>:m .-2<CR>==gi\n\n\" Visual mode\nvnoremap <C-j> :m '>+1<CR>gv=gv\nvnoremap <C-k> :m '<-2<CR>gv=gv\n```\n\nNow you can move lines by holding *CTRL* and *j* (for up a line) or\n*k* (for down a line).\n\n```\n--- second line ---\n--- third line ---\n--- first line ---\n\n# Move to the \"first line\", hold <CTRL> and move up twice.\n#\n# :3 --> <ENTER> --> <CTRL> + kk\n```\n\nNow let's move a block of lines:\n\n```\n--- fourth line ---\n--- fifth line ---\n--- first line ---\n--- second line ---\n--- third line ---\n\n# Move to the \"first line\".\n# Select the \"first line\", \"second line\", and the \"third line\" with Visual mode.\n# Hit CTRL and move upwards twice.\n#\n# :3 -- <ENTER> --> <SHIFT> + V --> jj --> <CTRL> + kk\n```\n\nOther Ways\n----------\n\nThere are plenty of other tricks that move around lines in Vim. The preceding\nexamples were just a few that I employ everyday. If you've got something cool to\nshare, please let me know!\n"},{"title":"Design Patterns: The Composite Pattern","tags":["design patterns","ruby"],"summary":"Exploring design patterns and their use cases","legacy":false,"id":"2013/10/01/design-patterns-composite-pattern","employee":"Doug Yun","date":"2013-10-01T00:00:00","body":"\n\n## Coffee Coffee\n\nIf you're anything like me, you'll agree that every morning needs to start\nout with a cup of coffee. And, if you're anything like me, you'll have\nat least three different coffee making apparatuses. And, if you're\nanything like me... you'll soon realize you may have an addiction.\n\nJoke aside, each coffee contraption requires a specific procedure\nto be completed in order to brew a cup of joe; each having multiple parts,\ntaking differing amounts of time, requiring various numbers of steps, etc.\n\nOur coffee making process can be described by a basic example\nof the *Composite* method pattern.\n\n## The Best Part of Waking Up is a Composite Pattern in Your Cup\n\nWe can start by thinking of each coffee maker and coffee related task as a *subclass* of\nour `CoffeeRoutine`. `CoffeeRoutine` will be known as the *component*, the base\nclass or interface that possesses the commonalities of simple and complex\nobjects. `CoffeeRoutine#time` is the common trait among all\ncoffee related classes.\n\n```ruby\nclass CoffeeRoutine\n  attr_reader :task\n\n  def initialize(task)\n    @task = task\n  end\n\n  def time\n    0.0\n  end\nend\n```\n\nNext, we'll create a couple of *leaf* classes, which represent\nindivisble portions of our pattern. Here are a couple of *leaf* classes\nthat come to mind: `GrindCoffee` and `BoilWater`. These *leaf* classes are\nour most basic steps to making coffee.\n\n```ruby\nclass GrindCoffee < CoffeeRoutine\n  def initialize\n    super 'Grinding some coffee!'\n  end\n\n  def time\n    0.5\n  end\nend\n\nclass BoilWater < CoffeeRoutine\n  def initialize\n    super 'Boiling some water!'\n  end\n\n  def time\n    4.0\n  end\nend\n\nclass AddCoffee < CoffeeRoutine\n  def initialize\n    super 'Adding in the coffee!'\n  end\n\n  def time\n    1.0\n  end\nend\n```\n\n```\ng = GrindCoffee.new\n\ng.task    # => 'Grinding some coffee!'\ng.time    # => 0.5\n```\n\nNow, we can get to the namesake of the pattern: the *composite* class. A\n*composite* class is a *component* that also contain\n*subcomponents*. *Composite* classes can be made up of smaller\n*composite* classes or *leaf* classes.\n\nOur various coffee making apparatuses can be thought of as *composites*.\nLet's check out the `FrenchPress` class:\n\n```ruby\nclass FrenchPress < CoffeeRoutine\n  attr_reader :task, :steps\n\n  def initialize(task)\n    super 'Using the French press to make coffee'\n    @steps = []\n    add_step BoilWater.new\n    add_step GrindCoffee.new\n    add_step AddCoffee.new\n  end\n\n  def add_step(step)\n    steps << step\n  end\n\n  def remove_step(step)\n    steps.delete step\n  end\n\n  def time_required\n    total_time = 0.0\n    steps.each { |step| total_time += step.time }\n    total_time\n  end\nend\n```\n\nHowever, we can simplify the `FrenchPress` class by pulling out the\n*composite* functionality into its own class.\n\n```ruby\nclass CompositeTasks < CoffeeRoutine\n  attr_reader :task, :steps\n\n  def initialize(task)\n    @steps = []\n  end\n\n  def add_step(step)\n    steps << step\n  end\n\n  def remove_step(step)\n    steps.delete step\n  end\n\n  def time_required\n    total_time = 0.0\n    steps.each { |step| total_time += step.time }\n    total_time\n  end\nend\n```\n\nNow we can create *composite* coffee makers easily... They'll look\nsomething like this:\n\n```ruby\nclass FrenchPress < CompositeTasks\n  def initialize\n    super 'Using the FrenchPress to make coffee!!!'\n    add_step GrindCoffee.new\n    add_step BoilWater.new\n    add_step AddCoffee.new\n    # ... Omitted actual steps to make coffee from a French press ...\n    # ... Imagine PressPlunger class has been defined already ...\n    add_step PressPlunger.new\n  end\nend\n\nclass DripMaker < CompositeTasks\n  def initialize\n    super 'Using the DripMaker to make coffee!!!'\n    add_step GrindCoffee.new\n    add_step BoilWater\n    add_step AddCoffee.new\n    # ... Imagine PressStartButton class has been defined already ...\n    add_step PressStartButton.new\n  end\nend\n```\n\nSwell... now we can call the `FrenchPress` and `DripMaker` coffee makers.\n\n```\nfrenchpress = FrenchPress.new\n\n# => #<FrenchPress:0x007f88fcf46410\n       @task=\"Using the FrenchPress to make coffee!!!\",\n       @steps=\n         [#<GrindCoffee:0x007f88fcf46370 @step=\"Grinding some coffee!\">,\n         #<BoilWater:0x007f88fcf46320 @step=\"Boiling some water!\">]>\n         #<AddCoffee:0x007f88fcf46329 @step=\"Adding in the coffee!\">]>\n         #<PressPlunger:0x007f88fcf46098 @step=\"Pressing the plunger down!\">]>\n\ndripmaker = DripMaker.new\n\n# => #<DripMaker:0x137t88fcf57109\n       @task=\"Using the DripMaker to make coffee!!!\",\n       @steps=\n         [#<GrindCoffee:0x007f88fcf46370 @step=\"Grinding some coffee!\">,\n         #<BoilWater:0x007f88fcf52520 @step=\"Boiling some water!\">]>\n         #<AddCoffee:0x007f88fcf46123 @step=\"Adding in the coffee!\">]>\n         #<PressStartButton:0x007f88fcf46432 @step=\"Pushing the start button!\">]>\n```\n\nNow we can also check the time required for each coffee maker.\n\n```\nfrenchpress.time_required # => 12.4\ndripmaker.time_required   # => 8.5\n```\n\n## Discussion\n\nImplementing the *Composite* pattern is pretty simple.\n\nWe create a *component* class that ties the numerous simple and\ncomplex characteristics together. In our example, `CoffeeRoutine`\ndefines an elementary method `#time` and each child class implements\nits own amount.\n\nNext, we create *leaf* classes, `AddCoffee`, `BoilWater`, and `GrindCoffee`,\nthat share the same characteristics with one another. Remember that it's the nature\nof *leaf* classes to be simple. If you happen across a *leaf* class that\ncould be broken up, it might potentially be a *composite* class in disguise.\nBreak up those actions into individual *leaf* classes and turn the original class\ninto a *composite*. All of our *leaf* classes had a `#time` method.\n\nThe *composite* class handles all the subtasks, essentially using the child classes\nat its will. We can see that our two *composite* classes and their methods, `FrenchPress#time_required`\nand `DripMaker#time_required`. manipulate the method `#time` from the *leaf* classes.\nUltimately, our coffee makers are able to treat each step,\n`GrindCoffee`, `BoilWater` and `AddCoffee` uniformly.\n\nHope this helps you with your morning routine!\n"},{"title":"Namespaced Pages","tags":["ruby","rails"],"summary":"New functionality for the gem","legacy":false,"id":"2013/10/06/namespaced-pages","employee":"Brian Cardarella","date":"2013-10-06T00:00:00","body":"\n\n## Simple Namespacing ##\n\nWe've been using our [Pages](https://github.com/dockyard/pages) gem in\nnearly all of our projects for over a year now. Its been great but could\nonly support pages on the root. I just released `0.2.0` of the gem that\nnow supports namespacing:\n\n```ruby\nnamespace :work do\n  pages :client_1, :client_2\nend\n```\n\nThis will give you the routes of `/work/client_1` and `/work/client_2`.\nYour views will go into `app/views/work/pages`. For more details see the\n[README](https://github.com/dockyard/pages#namespacing).\n\nIn a future release of `Pages` we plan on adding support automatic\npages. For example, you will no longer need to declare the pages in your\n`config/routes.rb` file. As long as the templates exist in the\n`app/views/pages` directory the route will happen automatically. In\naddition we will also add support for pages nested under different\nnamespaces, or accessible from certain authentication state. All in the\nname of serving up static page goodness!\n"},{"title":"Buffers, Windows, Tabs... Oh My! Part 1: Vim Buffers","tags":["vim","workflow"],"summary":"A painless tutorial on Vim buffers","legacy":false,"id":"2013/10/22/vim-buffers","employee":"Doug Yun","date":"2013-10-22T00:00:00","body":"\nFirst off, [GO SOX](http://boston.redsox.mlb.com)!!!11\n\nNow that I've reinforced my allegiance to America's favorite baseball team, let's\ntalk about Vim. In this series of posts, we'll explore buffers,\nwindows, and tabs.\n\nToday, our topic will be *buffers*, editable files that are\navailable in-memory.\n\nWhen you first open a file through a Vim session, you are creating and working\nin a buffer, typically through a window. For the sake of today's discussion,\nwe will consider working with multiple buffers through only one window, our\nviewport of the working buffer.\n\n### Let's open a buffer\n\nWe're going to setup an easy exercise for today's post. If you don't want to\nfollow along, feel free to try the exercise in your own project.\n\nLet's create a dummy directory and some of text files:\n\n```\nmkdir dummy && cd dummy\necho 'The Red Sox rule!' > redsox.txt && echo 'Cardinals drool!' > cardinals.txt\n```\n\nNext, open up the `redsox.txt` file.\n\n```\nvim redsox.txt      # => The Red Sox rule!\n```\n\nCongratulations, you're already using buffers!\n\n### Buffer indicators\n\nLet's open the `cardinals.txt` file in a *hidden* buffer. We can accomplish\nthis through the current `redsox.txt` buffer by using `:badd` or `:bad`. Next, we'll\nlist out all buffers, hidden or active, with `:ls`.\n\n```\n# Inside the current buffer, get into Vim's command mode and use the command `:badd`.\n# List all buffers with `:ls`.\n\n:badd candinals.txt     # 'badd' => 'Buffer ADD'\n                        # You can also use `:bad`\n:ls\n  ### =>   1    %a   \"redsox.txt\"              line 1\n           2         \"cardinals.txt\"           line 1\n```\n\nThe `:ls` command returns information about each buffer: the unique buffer\nnumber, buffer indicators, file name, and the line number of your current\nposition within the file.\n\n* Buffer number: A unique number to identify individual buffers.\n* Buffer indicators:\n  * `%`: buffer in the current window\n  * `#`: alternate buffer, which can be accessed by `CTRL-6`\n  * `a`: active buffer, loaded and visible\n  * `h`: hidden buffer, loaded but not visible\n  * `-`: a buffer that cannot be modified, `modifiable` off\n  * `=`: a buffer that is readonly\n  * `+`: a buffer that has been successfully modified\n  * `x`: a buffer with read errors\n  * ` `: if there is no buffer indicator, it signifies a buffer that has not been\n  loaded yet\n* Buffer name: The name of the file.\n* Buffer line number: The current line number that the cursor is on.\n\n### Working with multiple buffers\n\nAs we can see, our `cardinals.txt` has yet to be loaded. Let's open it into\nour window and view our current buffers.\n\n```\n:e cardinals.txt   # => Cardinals drool!\n\n:ls\n  ### =>   1    #    \"redsox.txt\"              line 1\n           2    %a   \"cardinals.txt\"           line 1\n```\n\nNice! We can see that our `redsox.txt` file is our alternate buffer. Let's switch\nto the `redsox.txt` by hitting `CTRL-6`.\n\nNow we'll create a new text file, `worldseries.txt`, write `World Series!` inside that file,\nand check out our list of buffers.\n\n```\n:e worldseries.txt   # Write \"World Series!\" inside the file and save it.\n:ls\n  ### =>   1    #    \"redsox.txt\"              line 1\n           2         \"cardinals.txt\"           line 1\n           3    %a   \"worldseries.txt\"         line 1\n```\n\nOur alternate buffer is the `redsox.txt` file. Remember, if we want to quickly\nswitch to the alternate buffer, we can use `CTRL-6`. What if we want to open the\n`cardinals.txt` into our current window?\n\nWell, we have a couple of options. From the `worldseries.txt` file, we can use the\nfollowing vim commands:\n\n* `:bp` :  Switch to the previous buffer\n* `:b2` :  Switch to buffer number 2\n  * `:b` : Takes a buffer number as an argument\n\nGo ahead and give it a try.\n\nHere are some other pertinent buffer commands:\n\n* `:bn` : Switch to the next buffer\n* `:ball` : Open all buffers into windows\n* `:brew` : Go back to the first buffer in the list - \"Buffer REWind\"\n* `:bd` : Delete the buffer - also takes buffer numbers as arguments\n  * `:bd 1 2 3` : Will remove buffer numbers 1, 2, and 3\n  * *Note*: `:q` is not the same as `:bd`... try it and verify with `:ls`!\n\n### So what good are buffers?\n\nTo be honest, I just realized the power of buffers about a month ago.\nPreviously, thanks to a large monitor, I would have multtple windows\n- as many as 6-8 - open during one Vim session.\nMultiple windows are great, however, if I really needed to focus on a few\nfiles, I'd have to close each insignificant file window.\n\nNowadays, my workflow comprises of two or three windows, with multiple buffers in the background.\nThis has allowed me to rapidly move between files that I actively open and edit.\n\n### Remapping buffer commands\n\nHere are some key remappings that speed up buffer movement:\n\n```\n\" ~/.vimrc (or wherever else you keep your .vimrc)\n\n\" Move to the previous buffer with \"gp\"\nnnoremap gp :bp<CR>\n\n\" Move to the next buffer with \"gn\"\nnnoremap gn :bn<CR>\n\n\" List all possible buffers with \"gl\"\nnnoremap gl :ls<CR>\n\n\" List all possible buffers with \"gb\" and accept a new buffer argument [1]\nnnoremap gb :ls<CR>:b\n```\n\n*Note*: Remapping `gp` will remove the Vim default functionality of `gp`.\nUse `:h gp` to read more about it.\n\n\nHope that provides some insight into the capabilities of Vim buffers!\nIf there is anything you'd like to add, please feel free and\ncomment in the discussion area. Thanks!\n\n* [1] Special thanks to [romainl](http://www.reddit.com/r/vim/comments/1p2a62/a_painless_tutorial_on_vim_buffers/ccxzq7e).\n"},{"title":"Design Patterns: The Command Pattern","tags":["design patterns","ruby"],"summary":"Exploring design patterns and their use cases","legacy":false,"id":"2013/11/05/design-patterns-command-pattern","employee":"Doug Yun","date":"2013-11-05T00:00:00","body":"\n\n## Let's get ready for some football!\n\nOne of my favorite sports is American football; it's strategic, physical,\nand wild! As a fan - and once high school player - of the sport, I've gained some\nvaluable lessons from my experiences. For example, I've learned that \"persistence\nis key\", \"giving up is for losers\", and that \"water sucks, Gatorade is better.\"\n\nWhile those are fine gems of wisdom, today we'll be\ncovering one of the most overlooked teachings in football: the power\nof **Command** pattern.\n\nThe **Command** design pattern intends to separate and decouple an object of invocation\nfrom the object that receives the message of invocation. We will\nencapsulate all pertinent information of a method and execute the method\nat a later time. Essentially, the **Command** pattern gives us the ability\nto queue a series of operations for a later time. Let's dig in.\n\n## Put me in, Coach!\n\nLet's start by creating a `BostonNarwin` class from which our\nfootball players will inherit from.\n\n```ruby\n# football.rb\n\nclass BostonNarwin\n  attr_reader :action\n\n  def initialize(action)\n    @action = action\n  end\n\n  def name\n    self.class\n  end\nend\n```\n\nNext, we'll need some key players; let's create `Quarterback` and `Receiver` classes.\nFor fun, we're going to add a `TeamOwner` class too.\nAll three of these classes are going to possess a method called `#execute`.\n\nEach of these classes can be considered as instances of separate\n**commands**.\n\n```ruby\n# football.rb\n\nclass Quarterback < BostonNarwin\n  attr_reader :path, :play\n\n  def initialize(path, play)\n    super 'Hut! Hut! Red 19! Red 19! Hike!'\n    @path = path\n    @play = play\n  end\n\n  def execute\n    file = File.open path, 'w'\n    file.write \"#{name}: #{play}\\n\"\n    file.close\n  end\nend\n\nclass Receiver < BostonNarwin\n  attr_reader :path, :play\n\n  def initialize(path, play)\n    super 'Run, run, run!!!'\n    @path = path\n    @play = play\n  end\n\n  def execute\n    file = File.open path, 'a'\n    file.write \"#{name}: #{play}\\n\"\n    file.close\n  end\nend\n\nclass TeamOwner < BostonNarwin\n  attr_reader :path, :target\n\n  def initialize(path, target)\n    super \"We are moving the team from #{prettify path} to #{prettify target}!\"\n    @path = path\n    @target = target\n  end\n\n  def execute\n    FileUtils.mv path, target\n    file = File.open target, 'a'\n    file.write \"#{name}: We moved from #{prettify path} to #{prettify target}!\"\n    file.close\n  end\n\n  def prettify(pathname)\n    (pathname.chomp File.extname(pathname)).capitalize\n  end\nend\n```\n\nNext, let's create a class that keeps track of the `Quarterback`, `Receiver`, and\n`TeamOwner` commands. We can use the\n[**Composite** pattern](http://reefpoints.dockyard.com/2013/10/01/design-patterns-composite-pattern.html)\nto create this new class.\n\n```ruby\n# football.rb\n\nclass CompositeCommand < BostonNarwin\n  attr_accessor :commands\n\n  def initialize\n    @commands = []\n  end\n\n  def add_command(*args)\n    args.each { |arg| commands << arg }\n  end\n\n  def execute\n    commands.each { |command| command.execute }\n  end\nend\n```\n\nNow, we can kickoff some football commands!\n\n```\nload 'football.rb'\n\nquarterback = Quarterback.new('boston.txt', 'I'm going to throw a perfect pass!')\n# => #<Quarterback:0x007ff6f5c5c148\n     @action=\"Hut! Hut! Red 19! Red 19! Hike!\",\n     @path=\"boston.txt\",\n     @play=\"I'm going to throw a perfect pass!\">\n\nreceiver = Receiver.new('boston.txt', 'I'm going to catch the ball!')\n# => #<Receiver:0x007ff6f5c949f8\n     @action=\"Run, run, run!!!\",\n     @path=\"boston.txt\",\n     @play=\"I'm going to catch the ball!\">\n\nteam_owner = TeamOwner.new('boston.txt', 'somerville.txt')\n# => #<TeamOwner:0x007ff6f5ccd028\n     @action=\"We are moving the team from Boston to Somerville!\",\n     @path=\"boston.txt\",\n     @target=\"somerville.txt\">\n```\n\nGreat! Now we'll create an instance of the `CompositeCommand`, add\neach sub-command with `#add_command`, and then execute each command\nwith `#execute`.\n\n```\ncommand = CompositeCommand.new\n# => #<CompositeCommand:0x007ff6f5b82948 @commands=[]>\n\ncommand.add_command quarterback, receiver, team_owner\n# => [#<Quarterback:0x007ff6f5c5c148\n     @action=\"Hut! Hut! Red 19! Red 19! Hike!\",\n     @path=\"boston.txt\",\n     @play=\"I'm going to throw a perfect pass!\">,\n     #<Receiver:0x007ff6f5c949f8\n     @action=\"Run, run, run!!!\",\n     @path=\"boston.txt\",\n     @play=\"I'm going to catch the ball!\">,\n     #<TeamOwner:0x007ff6f5ccd028\n     @action=\"We are moving the team from Boston to Somerville!\",\n     @path=\"boston.txt\",\n     @target=\"somerville.txt\">]\n\ncommand.execute\n# ...  Omitted for brevity ...\n\nexit\n```\n\nFinally, let's list out the files in our current directory and view the contents\nof our recently created text file.\n\n```\n$ ls\n# => football.rb   somerville.txt\n\n$ less somerville.txt\n# => Quarterback: I'm going to throw a perfect pass!\n     Receiver: I'm going to catch the ball!\n     TeamOwner: We moved from Boston to Somerville!\n```\n\nWow! The **Command** pattern in action!\n\n## Discussion\n\nThe **Command** pattern suggests that we create objects that perform\nspecific tasks and actions. For our example, the `Quarterback` object\ncreated a file, the `Receiver` appended to the file, and the `TeamOwner`\nobject moved it. Each of the command objects completed their action\nthrough `CompositeCommand#execute`.\n\nHaving one object, an instance of `CompositeCommand`, that executes all\nstored commands presents us with solutions ranging from simple file\nmanipulation to user triggered interaction. The **Command** pattern\nalso allows us to \"store\" and \"remember\" commands prior to and after\nexecution.\n\nHope you enjoyed our example and go Boston Narwins!\n"},{"title":"Introducing Capybara-Extensions","tags":["testing","ruby"],"summary":"Write more descriptive tests with additional finders and matchers for Capybara.","legacy":false,"id":"2013/11/11/capybara-extensions","employee":"Michael Dupuis","date":"2013-11-11T00:00:00","body":"\n\nToday we're happy to announce [CapybaraExtensions](https://github.com/dockyard/capybara-extensions).\n\n## Testing with Capybara\nWe love [Capybara](https://github.com/jnicklas/capybara) at DockYard. We use it for virtually all of our integration tests and\nrely on it for writing tests that not only replicate how users flow\nthrough an application, but also for how they interact with page\nelements.\n\nBriefly, let's take a look at a Rails application with and without\nCapybara. Without Capybara, inheriting from `ActionDispatch::IntegrationTest` provides\nsome helpful `RequestHelpers` like `get`, which takes a path, some\nparameters, and headers (via [RailsGuides](http://guides.rubyonrails.org/testing.html#integration-testing-examples)):\n\n```ruby\nrequire 'test_helper'\n\nclass UserFlowsTest < ActionDispatch::IntegrationTest\n  fixtures :users\n\n  test \"login and browse site\" do\n    # login via https\n    https!\n    get \"/login\"\n    assert_response :success\n\n    post_via_redirect \"/login\", username: users(:david).username, password: users(:david).password\n    assert_equal '/welcome', path\n    assert_equal 'Welcome david!', flash[:notice]\n\n    https!(false)\n    get \"/posts/all\"\n    assert_response :success\n    assert assigns(:products)\n  end\nend\n```\n\nCapybara adds some syntactic sugar with its\n`Capybara::Session#visit` method, and produces code that reads a lot cleaner and mimics\nhow a user engages with the application:\n\n```ruby\nrequire 'test_helper'\nrequire 'capybara'\nrequire 'capybara_minitest_spec' # MiniTest::Spec expectations for Capybara\n\nclass PostsTest < ActionDispatch::IntegrationTest\n  fixtures :users\n\n  test \"login and browse site\" do\n    visit login_path\n\n    within find('form#session-new') do\n      fill_in 'username', with: users(:david).username\n      fill_in 'password', with: users(:david).password\n      click_button 'Submit'\n    end\n\n    current_path.must_equal welcome_path\n    page.must_have_content 'Welcome david!'\n\n    visit posts_path\n    page.must_have_content 'Welcome to ReefPoints!'\n  end\nend\n```\n\nJonas Nicklas, who maintains Capybara, writes how the library leads to [cleaner tests and clearer intent](http://www.elabs.se/blog/51-simple-tricks-to-clean-up-your-capybara-tests). This is exactly what we\nwant from our tests, which not only test our code, but also\ndocument our application's behavior. A lot more could be written about\nthis idea, but I'm going to assume I'm preaching to the choir here and\njump into DockYard's newest gem:\n[CapybaraExtensions](https://rubygems.org/gems/capybara-extensions).\n\nCapybaraExtensions extends Capybara's finders and matchers. Our goal is\nto cull many of the `find` statements from our tests and remove the\nverbose CSS and\nxpath locators that come along with them.\n\n## Finders\n### find_\\<element\\>\nThe library contains helper\nmethods for finding elements like `form`, `table`, and lists, as well as\nmany HTML5 elements like `article`, `aside`, `footer`, and `header`.\n\nSo the above code in which we pass a CSS selector\n\n```ruby\nwithin find('form#session-new') do\n  ...\nend\n```\nbecomes the following:\n\n```ruby\nwithin form('Login') do\n  ...\nend\n```\n\nIn this example, \"Login\" is text found in the form. Passing the text contained within the element we're looking for better reflects what a user is thinking when she sees a form that\nsays \"Login.\"\n\nFinder methods are also aliased so that you can call `#form`\ninstead of `#find_form` (which you might expect from a finder method).\nThis makes for better readability with the oft-used `Capybara::Session#within` method.\n\n### first_\\<element\\>\nEach \"find\" method also has a corresponding \"first\" method. So when you\nhave multiple `article` elements on a page with the text 'Lorem ipsum,' you can call\n`first_article('Lorem ipsum')` without returning an ambiguous match in\nCapybara.\n\n### \\<element\\>_number\nIn instances when you have lists or tables and you'd like to verify the\ncontent of a specific `li` or `tr`, CapybaraExtensions allows\nyou to target the nth occurence of the element via\n`#list_item_number` and `#row_number`.\n\nSo given the following HTML:\n\n```html\n<ul>\n  <li>John Doe</li>\n  <li>Jane Doe</li>\n  <li>Juan Doe</li>\n</ul>\n```\n\nYou can find the second `li` with:\n\n```ruby\nlist_item_number(2) # => 'Jane Doe'\n```\n\nUse these methods for testing how elements are being ordered.\n\n## Matchers\nCapybaraExtensions extends Capybara's matchers with methods for\nverifying the presence of images, the value of input fields, and the\npresence of meta tags. All of these methods return a boolean.\n\n### field_values\nCapybaraExtensions comes with a `#has_field_value?` method which checks\nthe value of a form field. Ensuring that your records save and update\ncorrectly should be the domain of your unit tests, however this method\ncan come in handy when you're not persisting data to the back-end. For\nexample, after performing a search, you may want to ensure that the\nquery persists in the search field after redirect.\n\n```ruby\nwithin form('Search') do\n  has_field_value?('search', 'capybara images')\nend\n# => true\n```\n### images\nAsserting that text appears on the page is easy with Capybara's\n`#must_have_content` method; asserting\nthat a particular image appears has always been a little tougher.\n`#must_have_image` takes a hash with the `src` and/or `alt` attributes\nyou're looking for. You can pass a string for either of these keys, and\nan instance of `Regexp` to the `src` attribute when you want to hone in\non a portion of the `src` attribute without worrying about the rest of\nthe URL.\n\n```ruby\npage.has_image?(src: 'http://gallery.photo.net/photo/8385754-md.jpg',\nalt: 'Capybara')\n# => true\n```\n\n### meta_tags\n`#has_meta_tag` checks the `head` for meta tags. Just pass in the `name`\nand `content` you're expecting to find. We use this method quite a bit to ensure that our pages are looking good\nfrom a search engine optimization standpoint.\n\n```ruby\npage.has_meta_tag?('title', 'Introducing CapybaraExtensions')\n# => true\n```\n\nWe hope this gem makes your tests a little more descriptive and your `test_helper.rb` a little lighter. As always, we welcome pull requests and issues via Github. Thanks!\n\n## Resources\n* Install CapybaraExtensions from [Rubygems](http://rubygems.org/gems/capybara-extensions)\n* Follow CapybaraExtensions on [Github](https://github.com/dockyard/capybara-extensions)\n* Read up on CapybaraExtensions on\n[RubyDoc.info](http://rubydoc.info/gems/capybara-extensions/frames)\n\n"},{"title":"Think","tags":["ruby","community","opinion"],"summary":"Don't do what others tell you to do without thinking about it","legacy":false,"id":"2013/11/15/think","employee":"Dan McClain","date":"2013-11-15T00:00:00","body":"\n\nEver since [Matt Aimonetti's talk at\nWicked Good Ruby](http://wickedgoodruby.com/2013/speakers/matt_aimonetti)\non there being such thing as bad code, I've felt I've\nneeded to write a blog post about the [cargo\nculting](https://en.wikipedia.org/wiki/Cargo_cult) that happens in\nthe development world.\n\n## Sandi Metz's Rules\n\nBack in January, [Sandi Metz was on Ruby\nRogues](http://rubyrogues.com/087-rr-book-clubpractical-object-oriented-design-in-ruby-with-sandi-metz/)\nto discuss her book, **[Practical Object-Oriented Design in Ruby](http://www.amazon.com/Practical-Object-Oriented-Design-Ruby-Addison-Wesley/dp/0321721330/)**.\nOut of this conversation came \"[Sandi Metz's\nrules](https://gist.github.com/henrik/4509394)\". Many\nin the Ruby community took these rules as gospel, without knowing the\ncontext in which these rules were created.\n\nThe rules, for those unfamilar:\n\n  1. Your class can be no longer than 100 lines of code\n  2. Your methods can be no longer than five lines of code\n  3. You can pass no more than four parameters and you can't just make it one big hash\n  4. When a call comes into your Rails controller, you can only instantiate one object to do whatever it is that needs to be done\n\nSandi joined Matt during his talk at Wicked Good Ruby and [gave some background to the\nstory of her rules](http://www.youtube.com/watch?feature=player_embedded&v=VO-NvnZfMA4#t=1380).\nTo paraphase Sandi, at the time she was working with a group that had multi-thousand line controllers with\nmulti-hundred line methods. These controllers and methods represented\none end of a spectrum, which made code incredibly hard to read and maintain.\nThey were begging Sandi for guidelines with which they could try to\ncorrect this problem. What she did was create a set of rules that\nlived on the opposite side of the extreme, to force them to meet\nsomewhere in the middle.\n\nIn reality, these rules are a different way of looking at rules many of\nus strive for in the first place. An example: The 100 lines per class\nrule is really forcing you to create classes with the [Single\nResponsibility Principle](https://en.wikipedia.org/wiki/Single_responsibility_principle) in mind.\n\nMy issue is not with these rules as they exist, but with the\ncommunity's cargo culting of these rules and treating them as The Four\nCommandments. I don't have an issue with you following them, as long as\nyou understand why they exist, and you feel as though they are\nprinciples you believe in. Don't just make five line methods because\nSandi said so, and if you follow these rules, you feel like you'll be a\ngreat developer. Adhering to Sandi's rules does not make one great, it's\nunderstanding where these, or any rules, should and shouldn't apply.\nSometimes a method that spans more than five lines will be more readable\nand maintainable than the same method spread across five or six 5-line\nmethods. Striking that balance is where the power lies.\n\n## REMOTE\n\n37signals just published\n[REMOTE](http://www.amazon.com/Remote-Office-Required-Jason-Fried/dp/0804137501/), a book about\nthe benefits of allowing remote workers. I don't disagree that\nworking remote has many benefits. At DockYard, we work from home from time\nto time. We also strive to have people in the office more often than\nnot, not because Brian doesn't think we aren't working when we aren't in\nthe office, but because it enables greater collaboration.\n\nDockYard is a consultancy; we have client work with deadlines we have to\nmeet. With having our developers and designers in the office together more\noften than not, it removes the latency from discussing issues. I can\nwalk over to Steve and we can hash out an issue in a few minutes. If we\nwere all remote, I'd have to ping him on HipChat, hope he's at his desk,\ntry to go over the issue text-only until we realize we need to have a\nGoogle Hangout, etc. It makes more sense for us to be in the same place.\n\nThe other benefit of DockYard working from the office is that our junior\ndevelopers enjoy the same face-to-face benefits. Also, body language\nmakes a huge difference when teaching or learning topic. When someone pauses,\nhas a slightly puzzled look on their face and says \"....Ok\", it easy to\nrealize that a bit more background on the topic will really let them\ngrasp the topic, but an \"ok\" in HipChat removes all the body language we\ncould leverage.\n\nRemoving the latency between a junior developer having a\nquestion and getting the answer is crucial. If a junior developer has a\nquestion that's a show stopper, they can feel helpless while they wait\nfor someone to be around to answer that question. That helplessness is\nkiller; it makes someone feel like they aren't helping, and can\npotentially prevent them from asking other questions. If the that delay\nis interpreted as the senior developer blowing them off, they will be\nless inclined to ask questions in the future, hurting both themselves\nand the team.\n\nA product company that employs experts (or creators) of a framework has\na much different situation, where working remote makes a lot more sense.\nThe conversations they have will be at a different level. They'll all\nhave intimate knowledge of the code base, and so a few questions back\nand forth or a quick Google Hangout achieves a great deal. The\nconclusion was a result of the context they exist in. Remote workers\nwork great for them because they have the perfect mix of experts in\ntheir domain; are working on products, which have very different\nrequirements and issues of client work; and have a customer support\ngroup, which don't necessarily need to collaborate while working a\ncustomer through issues.\n\n## Figure Out What Works for YOU\n\nIn no way am I saying you should all work in the same office and\ndisregard Sandi's rules. What I'm asking of the community is a bit of\ncritical thought. Just because someone smart said one thing, it doesn't\nmean it's gospel. Realize that experience has led that person to that\nconclusion, weigh your experience against it, and apply it if you can.\n\nLet's just not hope that the gods give us food because we made bamboo\nairplanes. Let's realize that moving to XYZ comes with both drawbacks and\nbenefits, not just the benefits that everyone is touting.\n"},{"title":"Buffers, Windows, Tabs... Oh My! Part 2: Vim Windows","tags":["vim","workflow"],"summary":"A painless tutorial on Vim windows","legacy":false,"id":"2013/11/27/vim-windows","employee":"Doug Yun","date":"2013-11-27T00:00:00","body":"\n\nIn the second part of this series, we'll be covering Vim windows. Windows are simply\nthe **viewports** into [buffers](http://reefpoints.dockyard.com/2013/10/22/vim-buffers.html)\nand I'm 110% sure that they are a huge part of your daily workflow.\n\nYes, there are numerous plugins that make our lives a lot easier, but let's\ndive into a powerful defaults that Vim offers us.\n\nWe'll first cover the basics, and then learn some neat window management commands.\n\nStarting a Vim Session\n----------------\n\n### One File\n\nVim windows are not complicated to use; if you want to open a file, `file_one.txt`, simply:\n\n```\n$ vim file_one.txt\n```\n\n### Multiple Files\n\nIf you want to open multiple files, `file_one.txt`, `file_two.txt`, and `file_three.txt`, you can\ndo the following:\n\n```\n$ vim file_one.txt file_two.txt file_three.txt\n```\n\nThis opens the first file, `file_one.txt`, into a window.\nFiles `file_two.txt` and `file_three.txt` are opened as inactive buffers.\n\n\n### Multiple Horizontal Splits\n\nSay you want to view multiple files at once. Good news! You can\nopen all files and place them into **horizontal splits**.\n\n```\n$ vim -o file_one.txt file_two.txt file_three.txt\n```\n\n### Multiple Vertical Splits\n\nDon't like horizontal splits? Better news! You can open them all as **vertical splits**.\n\n```\n$ vim -O file_one.txt file_two.txt file_three.txt\n```\n\nWithin a Vim Session\n-----------------\n\nThere are two main arrangements for splitting windows, vertical and horizontal. Let's say\nwe're editing a file and want to open up another file. We can do the following:\n\n### Horizontal Splits\n\nThis will open `another_file.txt` as **horizontal split**.\n\n```\n:split another_file.txt\n```\n\nYou can use this abbreviation:\n\n```\n:sp another_file.txt\n```\n\nIn addition, you can specify how large the new split will be by passing\nin a numerical value. This value will represent the line numbers shown within the\nsplit.\n\nFor example, this will reveal 25 lines of `another_file.txt`.\n\n```\n:25sp another_file.txt\n```\n\nLastly, you can open a **split** window with `CTRL-W s`.\n\n### Vertical Splits\n\nYou can open files as **vertical splits** as well.\n\n```\n:vsplit another_file.txt\n```\n\nWhich is abbreviated as:\n\n```\n:vsp another_file.txt\n```\n\n**Vertical splits** can also take in a numerical value, which corresponds to the\ncharacter width of the column.\n\n```\n:30vsp another_file.txt\n```\n\nFinally, you can open a **vertical split** with `CTRL-W v`.\n\n### New Files\n\nLet's create a new file.\n\nUse, `:new` to create a new file inside the current window.\nAfter you save the file, it will be created within your current directory.\nYou can also use the abbreviation `:n`.\n\n```\n:n new_file.txt\n```\n\nIf we specify the path, we can also create files inside existing directories.\n\n```\n:n ../existing_dir/new_file.txt\n```\n\nUse `:vnew` or `:vne` to create a new file inside a new **vertical split**.\n\n```\n:vne new_file.txt\n```\n\nLastly, we can use `CTRL-w n` to create a new file inside a **horizontal split**.\nNote that we have not specified a file name. Upon saving the file with `:w`, we\ncan give the file a name. Such that:\n\n```\n# CTRL-w n\n\n:w this_is_a_new_file.txt\n```\n\n### Switching Windows\n\nSwitching windows ain't hard either!\n\n* `CTRL-w h` = Switch to the window to the left\n* `CTRL-w j` = Switch to the window below\n* `CTRL-w k` = Switch to the window above\n* `CTRL-w l` = Switch to the window to the right\n\n### Moving Windows\n\nI've realized that window placement is incredibly useful\nwhen pairing with another person. Here's are a some ways to adjust\nthe windows.\n\n* `CTRL-w T` = Move current window to a new tab\n* `CTRL-w r` = *Rotates* the windows from left to right - only if the windows\nare split vertically\n* `CTRL-w R` = *Rotates* the windows from right to left - only if the windows\nare split vertically\n* `CTRL-w H` = Move current window the far left and use the full height of the screen\n* `CTRL-w J` = Move current window the far bottom and use the full width of the screen\n* `CTRL-w K` = Move current window the far top and full width of the screen\n* `CTRL-w L` = Move current window the far right and full height of the screen\n\n### Resizing Windows\n\nSometimes windows open up funny or are rendered incorrectly after separating from\nan external monitor. Or maybe you want to make more room for an important file.\n\nWe can easily solve those problems with the following:\n\n* `CTRL-w =` = Resize the windows *equally*\n* `CTRL-w >` = Incrementally increase the window to the right\n  * Takes a parameter, e.g. `CTRL-w 20 >`\n* `CTRL-w <` = Incrementally increase the window to the left\n  * Takes a parameter, e.g. `CTRL-w 20 <`\n* `CTRL-w -` = Incrementally decrease the window's height\n  * Takes a parameter, e.g. `CTRL-w 10 -`\n* `CTRL-w +` = Incrementally increase the window's height\n  * Takes a parameter, e.g. `CTRL-w 10 +`\n\nWrapping Up\n-----------\n\nThat was a lot to cover, but I do believe incorporating these commands into\nyour workflow will prove pretty helpful. Thanks for reading!\n"},{"title":"Never Stop Exploring","tags":["illustration","art","design"],"summary":"Being true to yourself and creating passionate work.","legacy":false,"id":"2013/12/06/always-be-exploring","employee":"Logan Faerber","date":"2013-12-06T00:00:00","body":"\n\n## Never Stop Exploring\n\nOver the years, many artists seem to have fallen into a creative rut within their chosen career path. Some may have found a comfortable day job that sufficiently pays the bills. Others simply retired early, claiming to have burnt out creatively, and chose to throw in the artistic towel for a simpler lifestyle, one far less plagued by self doubt and critical objections, I’m sure. Whatever the reason is, we as a society are more often selecting to pursue comfort over curiosity and I believe it’s hurting the progression of our personal artistic expression in both our culture and as individuals.\n\nBy choosing to accept what’s handed to you by media, you’re merely absorbing other’s ideas or predefined popular interests that have become media friendly rather than participating as part of the cultural influence. This accounts for many of the current trends that appear in graphic design, illustration, web design, music, and movies these days. How else would you have ended up with Independence Day, Mars Attacks, and Men in Black hitting the top box office charts all within the same year? You couldn’t. Aliens and end of the world scenarios were accepted as hot topics at the time, but are any of them truly remembered as works of art? I would argue the answer to be, “No”. What makes something a genuine work of art is the passion with which it is made. A fresh and deeply personal idea that attempts to either break the rules of the medium or painstakingly craft them to best suit your particular need. \n\nFor example, as soon as iOS7 was shown to the public, a majority of the design community’s reaction was negative. But as soon as this same operating system was made public and write-ups began appearing online from major figureheads in the industry, people’s views started to change, as did their designs. The same people who appeared to be so opposed to this recent announcement were beginning to cater their latest designs to having an extremely minimal feel, embracing extra thin typefaces and overly saturated primary colors. While I for one have definitely come to appreciate specific things about the iOS7 operating system, there are definitely things about it’s design that are not necessarily applicable to other interface scenarios. In short, just because a big company is successful with their design doesn’t mean it’s the right fit for your project. No one’s remembered for who they’ve copied. They’re remembered for what innovations they’ve made or new ideas they’ve brought to the table. \n\nWhether this trend is a culturally specific problem or something that has plagued mankind for years, I’m unsure. What I am sure of though is that I for one don’t ever want to find myself in this predetermined rut. I think everyone has great ideas, and it’s important for them to take the time to properly express them. It’s a matter of finding the motivation in yourself to make it happen and take the risk of making it public. As the great Bill Nye said, “Everyone you will ever meet knows something you don't”.\n\nI for one keep a persistent list of ideas that I want to explore, both in a physical journal and on [Wunderlist](https://www.wunderlist.com/en/), just so that no matter how random the idea may seem, I can at the very least document it to be reviewed at a later date. When I do have down time between projects, I never have to search too hard for a new one to get started. For instance, my current side project is to keep an ongoing list of fictional band names that my friends and I have collected over the years and make actual merchandise out of them as if they were real bands. I treat these projects like tiny experiments and allow myself to try new things, technically and mentally. That way, when I do return to my other projects, they never feel stale. I’m once again excited to work on them and have a new set of skills or ideas to help make them even better. \n\nThis is why I think it’s important that no matter what you do, whether it’s a full time design job, freelance illustration, or something far removed from the art profession you had originally pursued, to always keep your mind fresh with new ideas. Explore all possibilities and try new things whenever you can. The more you create, the more apt you are to legitimately think outside the box, rather than work within it’s constraints. And that, my friends is how you will be remembered, for being true to yourself and creating genuine, passionate work.\n"},{"title":"Introducing easydir.vim","tags":["vim","workflow"],"summary":"A Vim plugin that allows you create directories and files at the same time!","legacy":false,"id":"2013/12/08/introducing-easydir-vim","employee":"Doug Yun","date":"2013-12-08T00:00:00","body":"\n\nOne of the things that I wish Vim had by default is the ability to create\ndirectories and files at the same time. Last month at our local\n[OpenHack meetup](http://openhack.github.io/), I had a conversation about\nit with a fellow developer and we both concluded that it wouldn't be too\ndifficult to write something up.\n\nWell, I'm happy to introduce [easydir.vim](https://github.com/dockyard/vim-easydir)!\n\nIt adds to the functionality of `:new`, `:edit`, `:write`, and more.\n\nHere are some quick examples:\n\n* Edit a new file inside of a previously nonexistent directory.\n\n```\n:e new_directory/new_file.txt\n\n# Write some things to \"new_file.txt\" and save it.\n\n:w\n\n# The directory \"new_directory/\" and the file \"new_file.txt\"\n# are saved!\n```\n\n* Open the new directory and file into a split window.\n\n```\n:sp another_directory/another_file.txt\n\n# Write to \"another_file.txt\" and save the file.\n\n:w\n\n# another_directory/another_file.txt is saved!\n```\n\n* Super nested directories\n\n```\n:n thank/you/sir/may/i/have/another.txt\n\n# Write some things to \"another.txt\" and save it.\n\n:w\n```\n\nThe directories and files will be saved under your current project's directory.\n\nThanks for checking it out and enjoy!\n"},{"title":"Be A Blunt Axe","tags":["illustration","art","design"],"summary":"Giving good feedback without being too aggressive.","legacy":false,"id":"2013/12/18/be-a-blunt-axe","employee":"Logan Faerber","date":"2013-12-18T00:00:00","body":"\n\n## Be A Blunt Axe\n\nSomething that was taught to us early on in College was how to make a \"compliment sandwich.\" I’m sure many of you have heard this term before, but for those of you who haven’t, it's a communication tool that can keep yourself humble when confronted with the daunting task of giving others critical feedback on their work. \n\nThe idea is that you as the critic would point out a positive aspect about their work or concept, the top layer of bread if you will. Then you’d follow this by mentioning something they could improve upon, which is the meaty and true substance of the discussion. At the end you’d conclude by providing another positive aspect, a la the last bit of bread. The reason we had to come up with this step-by-step process when approaching a critique environment was to avoid hurting anyone’s feelings. Rather than declaring an idea as stupid or bad, which honestly helps to accomplish nothing aside from increase the size of a critic’s ego, we had now formulated a way of give important and in-depth feedback that would actually help to improve an idea by simply being kind and genuinely interested in helping. Keeping to this method, people were much more adept to make the suggested improvements rather than declare themselves a failure, giving up before they’ve even begun to start. \n\nIt's important to remember that your feedback can and should be honest and frequent, but kindness prevails over being an asshole (every time). By being empathetic to the person receiving the critique, you get a better sense of what'll help them improve, rather than just tearing them down. With this, your critiques become genuine and no longer appear as a means to stroke an inflated ego. Without this, the whole world would be filled with broken hearts and ego-powered douche-bags. As they say, \"an eye for an eye makes the whole world blind\". Let's keep our eyes and hearts intact.\n"},{"title":"Simple Property Enum Cycling in Ember","tags":["ember"],"summary":"A quick demo of cycling between a set of values","legacy":false,"id":"2013/12/19/ember-enum-property-cycler","employee":"Brian Cardarella","date":"2013-12-19T00:00:00","body":"\n\nThis is a quick one. I needed to cycle between the values in a set.\nToggling between `true` and `false` in Ember is easy enough with the\n`toggleProperty` function but I had several properties I wanted to cycle\nbetween. So last night I wrote a simple function poorly named:\n`cycleEnumProperty`. You pass it the property you want to act upon and\nthe enum set to cycle. If the property is currently empty or if the\nproperty matches the last value in the set the property will be set to\nthe first value, otherwise the property will be set to the next value.\nTry it out:\n\n<a class=\"jsbin-embed\"\nhref=\"http://emberjs.jsbin.com/agaKuCoL/1/embed?js,output\">Ember\nStarter Kit</a><script\nsrc=\"http://static.jsbin.com/js/embed.js\"></script>\n"},{"title":"Lessons Learned: The First Two Years of Running a Software Consultancy","tags":["opinion","business","consulting"],"summary":"Brian talks about what has worked, what has not worked, and the changes that have been made at DockYard during its first two years","legacy":false,"id":"2013/12/22/lessons-learned-two-years-of-running-a-dockyard","employee":"Brian Cardarella","date":"2013-12-22T00:00:00","body":"\n\nThis is an update of [the previous post that reflected on the first six\nmonths of DockYard](/opinion/2012/06/21/lessons-learned-six-month-of-running-dockyard.html).\nA lot has changed over the past year and a half, and a lot has not. I\nwon't do a point-by-point comparison to the previous post but I will\naddress some as well as some of the feedback I got at the time. But\nfirst, let's talk about revenue.\n\n## Revenue\n\nAfter our first year we took in about $750,000 in revenue. DockYard\nofficially began in January of 2012  so we had a full calendar year to\nearn. From what I've been told this is pretty good for the first year as\na consultancy. In our second year we broke $1,500,000 at the beginning\nof December. I'm happy with that, we doubled revenue. I have set a\nrevenue goal of $2,500,000 for 2014. Assuming there are no major screw ups\nnext year we should exceed that goal.\n\nRevenue is great and all but kind of useless information without our\nprofit margin. We have averaged around 20% profit margin over the past\ntwo years. This year we were averaging in the mid to high 20s before we\nhit a lull at the end of November.\n\n### The Negative Stuff\n\nLet's get the negative stuff out of the way first so we can focus on positives\nfor the remainder of the post. We could have done better the previous year, we could have done better\nthis year. We lost money due to decisions that I made throughout the\npast two years. Those choices include two bad clients, a mistake in the\ndirection of our growth, and a lack of experience of running a\nconference.\n\n### Bad Clients\n\nIn the previous post I mentioned how DockYard nearly folded from the\nstart due to a bad client. That nightmare lasted for a year and half and\nwas finally settled in June of this year. It ended up being nearly a\n$50,000 loss for us. I am convinced this is due entirely to poor legal\ncounsel; I cannot stress enough how important it is to have a competent\nlawyer on your side. We didn't have someone that was willing to fight\nfor us, it cost us big time. We have since retained the law firm of\n[Gesmer Updegrove](http://gesmer.com). They're pricey, but it's worth it.\n\nHowever, before we ever engaged with our current lawyer we unfortunately\nhad another run with a bad client. This time to the tune of $20,000.\nThat hit came this year. What is really strange is that I knew walking\ninto this deal it was going to end badly, and I voiced my concerns\ninternally to my people at the time but I still OK'd the deal and it\nunfolded just as I thought it would. It was a dumb move and we paid the\nprice of it.\n\nOne of the plans for DockYard was to quickly grow into the political\ntech space in Washington, DC. I have experience working in political\ntech, I brought on a guy who I worked with at the DNC, and we hired another\nguy I worked with on a political campaign. We started making\nconnections. It didn't work out. Three reasons:\n\n#### Timing\n\nTiming is everything I guess. Especially in political tech, we set out\non this effort right when the 2012 cycle ended. It was a ghost town, and\nrightly so. There is no reason for campaigns or political groups to\nspend money on development efforts when the next election cycle is two\nyears away. While we spoke with a lot of people that were interested in\nwhat we could do from a technical perspective there simply were very\nlittle groups without any budget at the time.\n\n#### The People\n\nDuring my time at the DNC I worked with some awesome people. Nathan Woodhull,\nChris Gill, Brent Kimmel, Leo Zhadanovsky, and Nicole Aro to name a few.\nI've been lucky enough to work with a few of them since. Unfortunately I\nalso got to work with some really shitty people too. I don't think its\ntheir fault, the political tech space is a real drag. It doesn't \nattract a lot of talented people because the money to work on the inside\nis very bad compared with any other job out there. The tone you get is\nthat it is a privilege that you should be thankful for, and perhaps\nthat is the case. But that leaves a vacuum that gets filled with people\nthat frankly don't know their ass from a hole in the ground. Many of these\npeople are now in charge of making technology decisions in many\norganizations. I have no interest in working with those types of people\nagain, nor do I want to subject my employees to work with them.\n\n#### Politics\n\nI've always considered myself \"on the Blue team\" but the past year has\nreally pissed me off. NSA, Healthcare.gov, drone strikes, and the\nPresident trying everything he can muster to go to war with Syria. I\nwalked into our Business Developer's office one day and I said enough was\nenough. I could not in good conscience do work for the Democratic Party\nbecause of these issues.\n\n### Just Dumb Wasted Money\n\n[We ran a conference this year](http://wickedgoodruby.com) and due to my\nlack of experience running an event like this (and to be honest, being\ntaken advantage of by the venue we held the conference at) we lost $15,000.\n\nThere were also downtimes when we didn't have enough money coming in,\nbut I will get into detail about this later in this post. (and the\nchanges we've made to hopefully avoid this in the future)\n\nOverall I am pretty proud with our revenue over the past two years.\nWe didn't start with an \"industry superstar\" on our team or with a\nsignificant open source project in our pocket, nor were we on the \"inside\" of\nthe Boston tech scene. We've built a very strong brand for ourselves\nvery quickly.\n\n### Open Source\n\nThis is still a financial loser for us. I don't care what people say, that's a\nfact. However, [Pete Forde](https://twitter.com/peteforde) commented on\nmy last post and what he said was absolutely true: it will help you hire\ngood people. DockYard has been making a name for itself in the Ruby and\nEmber open source world. We have a good number of projects that people\nare actively using. I encourage all of our developers to contribute back\nto not just our projects but projects we use on a regular basis.\n\n### Personnel\n\nI've made missteps on hirings, that is also costly. I'll get into this\nlater in the article.\n\nOK, enough with the negative stuff. Let's get into what we did right.\n\n## Great Clients\n\nWe have had some awesome clients over the past year and a half. I am\npretty much happy with everyone we've had with the exception of the two\nclients I mentioned above. We have kept a balance of Startups and\nEnterprise, but we have been very careful about the people we work with.\nThis is how I have boiled it down to the clients we want to work with:\n\n1. Can they afford us? If you think it is callous to put this as the\n   first thing we look for, then you are probably not someone we want to\nwork with. We are running a business and there are plenty of great ideas\nout there and plenty of great people. But the sad fact is many of them\ncannot afford to build the applications they dream of, at least not\nthrough us. Financially vetting clients is very important. It makes no\nsense to waste our time in contract negotiations with someone that\ncannot afford our services. We try to discover this as soon as possible\nso we don't waste any of the client's time either. We try to make the\nbest recommendation on the next steps they can take. We never take\nequity.\n\n2. Is this an application we want to work on? I would make this the 2nd\n   No. 1 if I could. While it is very important to make sure we have\nclients that can pay us so we can pay our employees it is equally\nimportant to make sure we have projects that our employees actually want\nto work on. This is something that I butted heads over with our Business Developer\nearly on. He was not coming from a developer background and at the start\ndid not know what projects were good and which were shit, from an engineering\nperspective. Consultancies are a feeding ground for other companies to\npoach from. We try to retain our employees by paying well and by keeping\nthem on interesting and challenging projects.\n\n3. Is this a project that helps us grow? This is something we\n   have, over the past six months, started to think about when speaking\nwith clients. Is this a project we would be proud to put in our\nportfolio? Is this a project we can write a case-study on? Is this a\nproject that helps us make a sales pitch to an even larger client?\n\nIf we can stick to these three items when choosing clients I think we'll\nbe fine. That is not always the case and from time to time we have had\nto sacrifice up the chain. So the first to go is #3, then #2, and\nfinally #1 if we are desperate.\n\n## Our Tech Stack\n\nWhile we started out as a Rails shop we have moved very quickly over the\npast year to brand ourselves also as an [Ember](http://emberjs.com) shop.\n\nI believe in Ember as a technology, it is superior to any other\nJavaScript framework out there in every way except for the learning\ncurve. I see many developers that I have known in the Boston area hate\non Ember. Good, let them. More for us. We also chose Ember for business\nreasons.\n\nCompeting with all of the other Rails shops in Boston is just stupid.\nDown the street we have one of the most well know Rails consultancies in\nthe world (thoughtbot) and within a half a mile we have about 6 others\nlesser-known ones. From an ability perspective we are just as good as\nany of them, but then again that's the point of Rails. There is no\ntechnological advantage that any one shop has over another nowadays. We\nall pretty much do the same \"best practices\" and use nearly the same tech\nstack. There is nothing that distinguishes one shop from another. So we\nhave diversified our offerings.\n\nI chose Ember as a technology direction because it was, and still is,\nincredibly undervalued in the market. If I was playing a short game in\nour business I would invest in Angular, it is the tech-du-jour but a\nyear from now I seriously doubt that will be the case. While everyone\nelse is wasting their time specializing in Angular we're building an\nincredibly strong presence in the Ember world. When the scale tips we're\ngoing to be in a great position. At least that's the theory. Time will\ntell, maybe the next time I write on of these I'll be bitching about how\nwrong I was. We'll see.\n\n## Hiring\n\nFor the most part I've been very lucky with the team I've hired.\nRecently we just had our holiday party and I thought on my way to the\ndinner that this is the team I've always wanted. I can't imagine that is\na very common thing for people to think. And that's not to say we\nhaven't had missteps.\n\n### Finding The Right People\n\nFor us I hire for cultural fit. We have a good mix of senior and junior\ntalent. If we hire a junior developer I only hire people that show an\nability to learn fast. I really dislike white-board interviews so the\nface-to-face interview is for me to get a sense of their personality.\nThen I will ask some general knowledge questions to get a sense of where\nthey are at skill-wise. I will then send the candidate away for a week\nand give them a project to create. I try to pick criteria that puts them\noutside of their comfort zone. Have they done TDD before, have they done\nEmber? I will ask them to challenge themselves and I will ask for access\nto the GitHub repository. One indicator I use is how soon did the\ncandidate start this project? If it was started right away that shows an\neagerness to complete the work. Was is started and finished the night\nbefore? This might show a tendency to procrastinate and get things in at\nthe last minute. While these may be outside factors I do ask about them\nif they are extreme during the follow-up interview.\n\nRecently we have been able to build enough of a name for ourselves in\nthe development community where we have started to attract some good\nsenior development talent. We are putting a pause on hiring junior\ndevelopers and will likely focus on more senior developers for the next\nyear.\n\n### Firing People\n\nI've gotten permission to talk about this from Russ. Russ was a\nco-founder of DockYard and I fired him. It was around the time of the\nfirst post but I didn't want to reflect on it yet. In retrospect it was a\nlong-term mistake but perhaps the correct short-term decision. We were\nnot at the size when I was really thinking too long-term. I was not\ngetting from him what I needed and it was weighing me down mentally, but\nthis was my fault. I was not communicating to Russ properly what my\nexpectations were. Thankfully we're still friends and grab drinks every\nnow and then. If the roles were reversed I don't think I would be as\nmagnanimous.\n\nI've since fired two others. One was my fault, the other was not. It is\na strange thing to fire someone. People try to make it nice by saying\n\"let them go\", but in reality you've shit-canned them. When you are\nemploying someone, especially at a small company, you feel a sense of\nresponsibility for them. You are paying them money and provide them with\nhealth care they use to take care of their family. I wish we could\nmagically double the salaries of all of our employees but of course we\ncannot afford that. When it came time to firing someone it weighed on me\nand I considered the implications. I never did it lightly, but\nconsidering the alternative, each firing has turned out to be the correct move.\nEven with Russ, he's done much better without DockYard than he was doing\nwith DockYard. Sometimes its not a good fit, I am guilty of letting\nthings sit too long. I have learned to be quicker about acting upon\nthis.\n\n### Losing People\n\nWe have so far lost just one employee, one of our DC partners Chris\nGill. He got a job with the Department of Revenue that paid well beyond\nwhat we could afford. I was actually pretty proud of him that he landed\nit. I have left enough jobs in my career to know that I never want to be angry\nat someone that has decided to leave DockYard. If it is time to go, it\nis time to go. Considering the number of junior developers we have been training\nup I would like to think of it as an accomplishment of ours to see\npeople \"graduate\" from DockYard and go on to do great things in the\nindustry. (but don't leave us too quick!)\n\n## Business Development\n\nIn the summer of 2012 I was overwhelmed. I was Lead Developer, Business\nDeveloper, Office Manager, and Everything Else\\* at DockYard. The most\nimportant job I had was making sure new business was coming in. But\nfocusing on that was having a negative impact on the client projects I\nwas on as well as training any developers we had that required it. I\nstarted a search for a Business Developer. At first I hatched a plan to\nleverage the recruiters of Boston. It made sense: they already were\ntalking to companies but it was difficult for those companies to hire.\nWhy not just partner with DockYard and rent our services to those\ncompanies? At 8% the math actually worked out in their favor, however none of\nthem bit. I'm still struggling with this one and I think it speaks to\nthe state of recruitment. It was a good business opportunity but they\ncould not think outside the box.\n\nSo it was time to find someone for that position. I had never made a\nnon-technical hire before. I had no idea how to do that. I looked\nspecifically for \"Business Developers\" but that was a bust. I gave up\nfor a month or two then I realized that it was essentially a Sales\nposition. So I put an ad out for a someone in sales looking to take on a\nlarger role, a key role for the growth of a young company. I got about\n50 resumes and brought in two people for interview. I liked them both\nand settled on the one with the better references. It was a great\ndecision. Our Business Developer Dan Crowther has been huge for us. We butt\nheads on a few things; he's right sometimes and I'm right sometimes. But\nthe fact is we would not be where we are today without him.\n\nIt took him about six months to really get comfortable with the\nposition, this is very common from what I've been told of those\ntransitioning into this position. He's helped us open up business we\nwouldn't have known about otherwise. And most important I can focus on\nother things.\n\nWe sell DockYard on the quality of our work. While we started as a\ntechnology company, design has become a large part of who DockYard is and\nhas gone a long way to help sell our brand.\n\n## Design\n\nSince our first \"real\" contract with [Openbay](http://openbay.com) we\nworked with an outside designer, Steven Trevathan. He was recommended to\nme by two separate people. Steve along with his partner Logan Faerber\nwere starting their own consultancy Dobot. Steve and I got along \nwell and I brought them back for a few more contracts. We bonded over\nour mutual disdain for many of the people in the [C3 space at\nCIC](http://www.cambridgecoworking.com/aboutc3.html) and so when we\nfinally got our own office last year I invited Steven and Logan to work\nfrom there. We even brought them along to check out the office spaces\nwe were interested in. This past Spring it became obvious that we needed\nsomeone full-time at DockYard to take ownership of our design. Likewise\nDobot was also looking for a lead engineer. It would be funny if it\nwasn't so stupid that we were literally sharing the same office, worked\ntogether on several projects, and were still looking for one another. Steve and I\ngrabbed drinks and I laid it out: let's do this. He agreed and we\nbrought Steve on as our Creative Director and a partner. Logan came on as a lead illustrator. It\nis the best move we've made to date. Steve and Logan quickly took\nownership of the design direction of DockYard and have along with Amanda\nand Angelo put out a [website that really represents who we\nare](https://dockyard.com) and have also put together some amazing\ndesigns for our clients.\n\nWhile earlier I mentioned how it was very difficult to differentiate\nourselves from other Rails shops, the one place we can totally do that\nis with design. Ultimately design sells much better than engineering.\nThe engineering part of our contracts bring in more money, so we have to\nmake certain that the design contracts we pick up will convert to\nengineering contracts. We look at design as the best Lead Generator we\ncould get. It has worked, very well.\n\n## Office Manager\n\nThis is one that I was told multiple times that I should do sooner than\nlater. I am very bad with context switching, I have to either do all\nbusiness stuff one day or all of the engineering. I cannot do both effectively.\nAfter hiring Crowther I knew the next non-technical hire I wanted was an\noffice manager. What I did might be considered overboard.\n\nI put an ad on Craigslist. We got over 200 responses. I brought the list\ndown to around 100 and sent out invites and asked people to schedule\nthemselves for an interview through\n[YouCanBook.me](https://gb.youcanbook.me/) I blocked out over two weeks\nof time, and broke the interviews into 20 minute blocks. Over 60\ninterviews were scheduled. I ended up meeting with about 40 of people.\nIt was one of the crazier things I've done but this was a position I had\nno idea how to hire and the only way I could figure to find the right\nperson was to see a ton of candidates and waited to see what stuck. The\nperson we hired was the 2nd person to walk through the door, Mariel\nEbrahimi. We got real lucky, and I think I even came out of that\ninterview and told everyone that we were probably going to hire her.\nHowever, considering she was only the 2nd candidate I still went through\nthe next two weeks of interviews. It became obvious that she was well\nbeyond anybody else coming in and over the past few months she has kept\nDockYard running smoothly. Being able to let go of these small things in\nthe office is incredibly freeing and has allowed me to focus on the\nbigger picture.\n\nI have been toying with the idea of hiring a Project Manager in Boston.\nWe did that before in Washington, DC but we were in a very different position that\nwe are now and I think the position only works for us, at our size, in\nBoston. I am currently running PM on most projects, at least to a\ncertain degree. I allocate resources, and assign roles. Developers at\nDockYard look to me for what they should be doing next. It's time\nconsuming and only gets worse as we grow. We'll see what happens in the\nnext few months.\n\n## Building Our Own Products\n\nWe've tried it once and we failed. That simple. We failed for several\nreasons:\n\n1. We could not work on the product consistently. This killed us. We\n   were putting in days here and there in between client work. I was\nputting in hours on the weekend and this was burning me out for the rest\nof the week.\n\n2. It was not an idea that was very good beyond concept. We built out a\n   marketplace for Heroku called\n[Igata](https://github.com/dockyard/igata) It would allow developers to\nsell pre-baked applications for deployment on Heroku. I liked the\nchallenge of building the initial technology. But when I began to think\nabout the long term implications of maintaining a marketplace\napplication I lost all interest.\n\n3. Heroku was too much of an obstacle. I actually went out to Heroku and\n   met with some of their people to pitch them on the idea. They liked\nit but it became clear that if we really wanted to make money we should\njust make our own Heroku and not lose the money on hosting. Then it was\nan easy mental jump to \"let's forget about this marketplace and just\ncompete with Heroku\" which of course is a dumb idea.\n\nSo we bailed on the application and open sourced it. We are going to\nattempt another product built, this time we are going to save up a\nfinancial war chest so we can dedicate the proper amount of time to the project.\nI don't mind losing money on projects like this. They are fun to build\nand I think we come out the other end as a better shop once we dog food\nour own process.\n\n## Getting Our First Office\n\nI was pretty annoyed with all of the entrepreneurial bullshit that was\ngoing on in the CIC in Cambridge. It is a terrible working environment,\nespecially if you are a consultancy. You get bugged all the time by the\nworst people. The space is **incredibly** loud. If you go there to work\non the weekends it's fantastic. But it became obvious very quickly that\nwe needed our own office. We worked with [Jon\nFrisch](https://twitter.com/jfrisch21) at [T3\nAdvisors](http://www.t3advisors.com/). We were growing and we need\nspace to grow *into*. We decided upon a 2,200 square foot 2nd floor space\nin Downtown Crossing. I always wanted an office there because of how\ncentrally located it was. Thankfully, Downtown Crossing ends up being\nmuch cheaper real-estate than many of the other places around Boston \n(although this is already changing).\n\nWe had some difficulty moving in. We were supposed to start the build-out\nin July of 2012. I was getting married in late August. The owner kept\ndeflecting us, and deflecting. I went on my honeymoon and when I got\nback I asked him what the deal was. He said, \"OK, it's no longer an\nactive crime scene so I can tell you what happened.\"\n\nIt turns out that our office is a floor above a jewelery store. The\nfloor in our office is concrete. Two guys broke down a side door to the\nvacant space, brought some mini-jackhammers and drilled a man-size hole\ninto the store below. They then repelled down with ropes and started to\nclean the place out. There were some silent alarms that were set off and\nthey got busted. Exactly why it took them 2 months to clear the place to\nallow us to build I don't know. But considering how crazy the story is I\nwas OK with it.\n\nAnyway, we finally got into the space in October of 2012. Thankfully no\nmore jewelery heists have happened. We host a lot of community events at\nour office and I'm really happy with that. Currently we organize [Boston\nEmber](http://www.meetup.com/Boston-Ember-js/), [Boston OpenHack](http://openhack.github.io/boston/), [UX Boston](http://www.meetup.com/uxboston/), run classes for [Girl Develop It Boston](http://www.girldevelopit.com/chapters/boston), and\nhost [Boston\nPostgres](http://www.meetup.com/Boston-PostgreSQL-Users-Group-BPUG/).\n\n## Starting Over\n\nIf I had to start DockYard from scratch today I would do it differently.\nThe number one thing I would do different is not agree to a partnership\nuntil 6 months out. I would have awarded co-founder status to those\nthat started, but I would have held off on awarding partnerships\nuntil everyone settled into their roles. I think when you first get going you don't really\nunderstand what those roles are. Assigning roles on day zero\nand expecting everyone to just stick to these roles is not realistic if\nthis is everyone's first rodeo. Trial by fire is the best way to define\nthe roles. Once that is done then the partnership can be established.\nPerhaps someone that previously thought being partner was a good idea\nwas not actually interested in the added responsibility? Perhaps someone\nyou didn't think was \"partner material\" ends up being one of your key\npeople and that should be rewarded.\n\nI would also hire a little more slowly than we did at first. I have not\nyet been able to pay myself what I've set my salary to. The first year I\npaid myself 25% of that salary. This year I've hit my goal of paying\nmyself 50%. Next year I hope to hit 100% of that goal. Thankfully I've\ngot a wife that makes a good living and we've been able to lean on that\nwhen I've needed to take myself off of payroll. If our situation were\ndifferent I am not confident that DockYard would be around today, at\nleast not in its currently form. I've been able to take risks that\nothers might not be able to.\n\n## Conclusion\n\nAny success we have had is due in part to not just the great team we\nhave but honestly sometimes just luck. There have been several times in\nthe past two years where I have not been able to sleep due to the stress\nof thinking how we were going to make the next few payrolls. Every time\nwe got lucky, someone came along at the right moment and bailed us out.\nI would like to think we are out of those woods, we'll see.\n\nOne way I have changed how DockYard operates is moving away from always\nnew clients to retaining clients. I had lunch with [Andy\nSingleton](https://www.assembla.com/spaces/andy/wiki) and he stressed\nand convinced me that we were throwing away money by always looking\nfor new clients. The really successful consultancies had several large\ncontracts that would span multiple years. It was obvious but I had not\nseen it until it was spelled out for me. So we are going to look to\nretain and provide ongoing services for our existing clients. If\nsomeone is reading this and looking to get started that was probably\none of our biggest mistakes over the past two years; find a client that\nyou might even need to take a financial hit on but is always there to\nhelp you keep the lights on. Looking back it seem crazy that we were\nable to not just survive but thrive given out direction of always\nlooking for greenfield projects.\n\nIn the next few years I don't want to see the same rate of growth we've\npreviously had. I've said several times to my team I don't want to grow\nto more than 20. Any more than that and we'll have to consider some\nserious restructuring of the company. I also feel at that number the\nsmall team we have starts to feel more like a \"real company\". We just\nrecently made an offer to a new member of our team that will be joining\nin January. I have not met her yet and that is strange to me, but is\nalso an indicator that we have grown to that point that these things\nwill happen.\n\nI look forward to hearing the feedback from this article. I'm sure there\nwill be people that disagree with some of the things I've said and the\ndecisions we've made.\n"},{"title":"Lin Reid is a DockYarder!","tags":["office","announcement"],"summary":null,"legacy":false,"illustration_alt":"Lin Reid","illustration":"https://i.imgur.com/lEkTCoq.jpg","id":"2014/01/02/lin-reid-is-a-dockyarder","employee":"Brian Cardarella","date":"2014-01-02T00:00:00","body":"\n\n![Lin Reid](https://i.imgur.com/lEkTCoq.jpg)\n\nLin comes to us from Alaska. Normally that is all that you need to say\nbut Lin also brought us jerked-bear (actual Alaskan black bear) on his first day with us as an\nintern. From there it was easy street. Lin's published his own\n[gem](https://github.com/dockyard/stashable_params),\ncontributed back to several of our projects, and has been expanding his\ndeveloper horizons with Ember over the past few months. He is also the\n*co-founder* of [Pizza Time](http://pizza-time.herokuapp.com)\n\nFollow Lin on [Twitter](https://twitter.com/linstula) and on [GitHub](https://github.com/linstula)\n"},{"title":"Robert Jackson is a DockYarder","tags":["office","announcement"],"summary":null,"legacy":false,"illustration_alt":"Robert Jackson","illustration":"https://i.imgur.com/bI7Lcru.jpg","id":"2014/01/02/robert-jackson-is-a-dockyarder","employee":"Brian Cardarella","date":"2014-01-02T00:00:00","body":"\n\n![Robert Jackson](https://i.imgur.com/bI7Lcru.jpg)\nToday is Robert Jackson's first day at DockYard. Robert is joining our\nteam as a Sr. Rails and Sr. Ember developer by way of Florida (but he'll\nsoon be joining us in the Northeast). Robert is a member of the Ember\nRelease Management Team and has been saving my ass with several of our\nopen source Ember projects over the past few months.\n\nFollow Robert on [Twitter](http://twitter.com/rwjblue) and\n[GitHub](https://github.com/rwjblue)\n"},{"title":"Romina Vargas is a DockYarder!","tags":["office","announcement"],"summary":null,"legacy":false,"illustration_alt":"Romina Vargas","illustration":"https://i.imgur.com/LVxKfWm.jpg","id":"2014/01/02/romina-vargas-is-a-dockyarder","employee":"Brian Cardarella","date":"2014-01-02T00:00:00","body":"\n\n![Romina Vargas](https://i.imgur.com/LVxKfWm.jpg)\n\nRomina was a DockYard intern that we just recently hired to full-time!\nOver the past few months Romina has taken on all of the challenges we've\nthrown at her and excelled. Now she's TDD'ing, Vim'ing, Tmux'ing,\nEmber'ing with the best of them. She's also the co-author of the\nexciting new Ember application that is all the buzz: [Pizza\nTime](http://pizza-time.herokuapp.com)\n\n[Follow Romina on GitHub](https://github.com/rsocci)\n"},{"title":"Ember Conf: Ember for Rails Devs","tags":["ember","rails","ruby","announcement"],"summary":"Join our one day training session prior to Ember Conf in Portland, Oregon","legacy":false,"id":"2014/02/04/ember-conf-ember-for-rails-devs","employee":"Brian Cardarella","date":"2014-02-04T00:00:00","body":"\n\nWe invite you to learn from DockYard for a day before [Ember Conf](http://emberconf.com) in Portland, Oregon. We will be offering a one day training session for Ruby on Rails developers interested in\nlearning how to build Ember Applications. Over the course of the day we\nwill teach you the following:\n\n#### Introduction to Higher Level JavaScript Concepts\n\n* ES6 Modules\n* Promises\n\n#### Introduction to Ember Concepts\n\n* Client side MVC\n* Ember.Object\n* All the stuff under the hood of Router, Routes, Models, Controllers,\n  Components, Templates, and the Runloop\n* Ember Data\n\n#### Introduction to Ember Appkit Rails\n\n* How to build a new Ember project with Rails\n* Generators\n* Testing\n\nTogether we wil build two applications before the day is over. The first\nwill be a simple CRUD \"blog\" style application. Time permitting the second will be \na more advanced desktop-quality style applicaiton.\n\n[Seats are limited, be sure to get your ticket before they sell\nout!](http://emberconf.com/)\n\n## About The Instructors\n\n#### Brian Cardarella\n\nBrian is the CEO of DockYard and has been developing in Ember since late\n2012. He was a [speaker at the \"first\" Ember conference, Ember Camp, in\n      2013](https://www.youtube.com/watch?v=wmQovdFoMm0).\n      Brian is the author of some popular Ember libraries such as\n[ember-validations](https://github.com/dockyard/ember-validations) and [ember-easyForm](https://github.com/dockyard/ember-easyForm). Recently he has been focusing most\nof his open source time on building [Ember Appkit\nRails](https://github.com/dockyard/ember-appkit-rails), which is a\nre-implementation of [Ember App\nKit](https://github.com/stefanpenner/ember-app-kit) for the Rails Asset Pipeline.\n\n#### Robert Jackson\n\nRobert is a Sr. Developer at DockYard. He is a member of the Ember Release Management Team and a significant contributor to Ember. He spends much of his free time helping maintain a number of Ember related open-source projects including: [Ember Data](https://github.com/emberjs/data), [Ember Appkit Rails](https://github.com/dockyard/ember-appkit-rails), [Ember App Kit](https://github.com/stefanpenner/ember-app-kit), the [EAK/EAKR resolver](https://github.com/stefanpenner/ember-jj-abrams-resolver), [ember-rails](https://github.com/emberjs/ember-rails), [ember-easyForm](https://github.com/dockyard/ember-easyForm), and [ember-validations](https://github.com/dockyard/ember-validations).\n"},{"title":"Announcing PostgresExt-PostGIS","tags":["ruby","rails","postgres","postgis","postgres_ext","postgres_ext-postgis"],"summary":"PostgresExt-PostGIS adds PostGIS support to ActiveRecord","legacy":false,"id":"2014/02/07/announcing-postgres_ext-postgis","employee":"Dan McClain","date":"2014-02-07T00:00:00","body":"\n\nToday I released the first version of\n[postgres\\_ext-postgis](https://github.com/dockyard/postgres_ext-postgis), which\nextends ActiveRecord to support PostGIS data types and some querying.\nThis is definitely a beta release, but ready to the point where people\ncan play around with it.\n\n## Migrations\n\nWith postgres\\_ext-postgis, you can easily add geometry columns:\n\n```ruby\ncreate_table :districts do |t|\n  t.geometry :district_boundries\nend\n```\n\nIf you'd like to include your projection or geometry type, just include\nthem as options to your column:\n\n```ruby\ncreate_table :districts do |t|\n  t.geometry :district_boundries, spatial_type: :multipolygon, srid: 4326\nend\n```\n\n## Type Casting\n\nYour geometry columns will be typecasted into\n[RGeo](http://dazuma.github.io/rgeo/) objects. You can set your\nattributes with RGeo objects or EWKT/EWKB strings. EWKT/EWKB strings\nwill be converted to RGeo objects:\n\n```ruby\nuser.location = 'SRID=4623;POINT(1 1)'\n```\n\n## Querying\n\nFor now, the only added querying method for ActiveRecord is `contains`:\n\n```ruby\nDistrict.where.contains(district_boundries: user.location)\n```\n\nThe above query will utilize PostGIS's `ST_CONTAINS` to see if the\n`district_boundries` column contains the `user.location`. I plan to add\na convience method to convert EWKT strings to RGeo object, something\nlike `PostgreExt.geom('SRID=4623;POINT(1 1)')`, to make generating\nqueries from, say, a mobile user's current location a bit easier.\n\nAs I get feedback and use postgres\\_ext-postgis, more features will get\nadded. Stay tuned!\n"},{"title":"Native App Developers: We Can Help You","tags":["business","mobile"],"summary":"Have an existing application? We can help you out!","legacy":false,"id":"2014/02/07/native-app-developers-we-can-help-you","employee":"Dan McClain","date":"2014-02-07T00:00:00","body":"\n\nIf you have an existing app, and are looking for a server component,\nwhether it be adding a syncing service to your app, building out a web\nversion to extend your user experience, or need a site to showcase your\napp, we have both the design and development resources to make that\nhappen.\n\nYou might have realized that iCloud doesn't fit your needs, or you want\na web application that interacts with your app. We can build your API to\nfit your exact needs, so you don't need to fight iCloud to fit your\nneeds. You may be looking to build out a new RSS service that needs to\nparse and cache RSS feeds. We have the experience and resources that\nwill help you bring a server heavy component to your app.\n\nYou may have users looking to use your application when they aren't on\ntheir phone. We can design and build a rich web application that brings your\napp to the browser without losing the spirit of your app. You might need\na marketing site with video demos and screenshots of your app. We can\ndesign and build a site that really shows off your application.\n\n\nIf any of these sound like you, you should [get in touch with\nus](https://dockyard.com/hire-us).\n"},{"title":"A Simple Ember Data Route","tags":["ember"],"summary":"A basic pattern for routes with Ember Data content","legacy":false,"id":"2014/03/03/a-simple-ember-data-route","employee":"Brian Cardarella","date":"2014-03-03T00:00:00","body":"\n\nWhen working with an Ember Data model it is easy to forget to properly\nhandle the teardown of that model. For example, if you are creating a\nnew model and the user hits the backbutton that model is still in the\nlocal `store`. Or if a user edits a model and decides to click the\n`Cancel` button or clicks a link that transitions out of this route\nwithout saving the model. A basic approach can be as simple as:\n\n```javascript\nEmber.DSModelRoute = Ember.Route.extend({\n  deactivate: function() {\n    var model = this.get('controller.model');\n    model.rollback();\n    if (model.get('isNew')) {\n      model.deleteRecord();\n    }\n  },\n  actions: {\n    willTransition: function(transition) {\n      var model = this.get('controller.model');\n      if (model.get('isDirty') && !confirm('You have unsaved changes. They will be lost if you continue!')) {\n        transition.abort();\n      }\n    }\n  }\n});\n```\n\nRoutes inherited from `Ember.DSModelRoute` will always clean up after themselves. If the user has unsaved changes and attempts to leave the current route \nthe app will guard against the transition and allow the user to confirm with a notice that changes will be lost.\n"},{"title":"Using Database Templates in Rails","tags":["rails","postgres"],"summary":"Discover a helpful Postgres config option","legacy":false,"id":"2014/03/03/using-database-templates","employee":"Romina Vargas","date":"2014-03-03T00:00:00","body":"\n\nUsing Postgres as your application's database? If so, there is a handy\nconfiguration option that you may not be aware about. The `pg` gem provides a `template` option that\nallows for copying already existing data into an application as\nlong as you have matching schema. \n\nTo add this functionality, simply add the `template` option inside `config/database.yml`:\n\n```yaml\ndevelopment:\n  adapter: postgresql\n  encoding: unicode\n  database: myapp_development\n  template: my_template\n```\n\nLet's go through a quick example. Suppose we have an existing database, `food`, and it contains an abundant amount of data with the\nfollowing schema:\n\n```\nfoods: name (string), category_id (integer)\ncategories: category (string)\n```\n\nTo use the `food` database for our application, we are going to\ncreate a template by specifying our database with the following command: \n\n```bash\ncreatedb -T food my_food_template\n```\n\nWe must now set up our Rails application and make sure that our schema matches\nthat of our new template. Our Rails models will mimick `food`. Having done\nthat, we can now modify our `config/database.yml`.\n\n```yaml\ndatabase: myapp_development\ntemplate: my_food_template\n```\n\nRun migrations and voilà! Our database has been populated and is ready to be used.\n\n```bash\n> psql myapp_development\n\n> select * from foods;\n  id |  name  | category_id\n  --------------------------\n  1   apple       1\n  2   banana      1\n  3   spinach     2\n  4   ice cream   3\n\n> select * from categories;\n  id |  category\n  --------------\n  1   fruit\n  2   vegetable\n  3   other\n```\n"},{"title":"Ember Conf picks up where the Rails community left off","tags":["rails","ember","opinion"],"summary":"A summary of the first Ember Conference","legacy":false,"id":"2014/03/17/emberconf-picks-ups-where-the-rails-community-left-off","employee":"Brian Cardarella","date":"2014-03-17T00:00:00","body":"\n\nI'm writing this on my flight from Portland back to Boston. On this\nplane I count at least 12 other attendees of the first [Ember Conference](http://emberconf.com).\nA lot has been said about Ember in the past year but if this conference\nwas any indicator big things are happening and even bigger things are\ngoing to happen.\n\nFor me, the biggest take away from any conference is the people and\nthis conference was no exception. In fact, Ember Conf is now my gold\nstandard for a technology event. The only possible comparison I have is\nhow early Rails Confs felt. There is an energy and a scary amount of\ncreativity happening in the Ember community right now. Much like the\ncommunity felt around Rails back in 2006 - 2009 there is the\nunderstanding that those doing Ember now are going to be shaping the\nfuture of the web. Whether that is setting the bar higher for how users\nwill want to consume web applications in the future or being a large\ninfluence on what the future of the web standards themselves will be, Ember\nis the only web technology today that is positioned in the same place\nthat I feel Rails was years ago. We are the rebels. We are the\ncounter-culture. Ember is the future.\n\nBut, we're learning from the mistakes of the past. Where the Rails\ncommunity was the counter-culture of its time it suffered from a male\n(and very juvenile) dominated culture. This culture was the result of\nthe \"RockStar\" mentality set forth by its leader(s). Ember, in contrast,\nbegan its very first conference with Yehuda Katz and Tom Dale addressing\nthe entire crowd with their desire for Ember to be an open and diverse\ncommunity.\n\nThe conference was very well organized, big shoutout to Leah Silber at Tilde. She\nput on a great conference, I'm proud that my company had the opportunity\nto help make it happen.\n\nFrom a technology perspective **huge** things are on the horizon for\nEmber. If you have been on the cusp of getting involved you will be\nkicking yourself later for not doing so now. If you are already building\nin Ember nearly all of the pain-points that have existed will be\naddressed in the next 6 months. Testing as a first class citizen,\nfastest template rendering of any JavaScript framework/tool out there,\nanimation support, query params, a standardized project structure and\nbuild tool, and there was even talk of how we're going to package and\ndistribute dependencies. Ember Conf was a continuous roll of one great\ntalk after another loaded with the best tech on the web. I've already\nreally enjoyed writing Ember apps for the past year, the next year will\nbe amazing.\n\nI realize at this point the article smacks of cheerleading optimism. How\ncan it be this good? The real secret weapon of any open source software\nis its community. After this week I can tell you that I have not felt\nthis way about a community since the early days of Rails. There is\nsomething very special happening here. It isn't just me. [Go search\nTwitter for `#EmberConf` and see for\nyourself](https://twitter.com/search?q=%23emberconf&src=tyah).\n\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>People are crying, having\nspiritual awakenings and overall life-affirming moments at <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a>\n… Think I want whatever’s in their punch</p>&mdash; Rob Conery\n(@robconery) <a\nhref=\"https://twitter.com/robconery/statuses/449041727240695808\">March\n27, 2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>IT’S HAPPENING!! HTMLbars\neliminates &lt;script&gt; tags, {{bindAttr}}, and gives Ember the\nfastest bound templates on the planet. <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a></p>&mdash;\nTom Dale (@tomdale) <a\nhref=\"https://twitter.com/tomdale/statuses/448621833953083392\">March 26,\n2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>This scene with <a\nhref=\"https://twitter.com/tomdale\">@tomdale</a> <a\nhref=\"https://twitter.com/tehviking\">@tehviking</a> and <a\nhref=\"https://twitter.com/fivetanley\">@fivetanley</a> sums up <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a>\n- so much love ❤️❤️❤️ <a\n  href=\"http://t.co/AEUEeiq97i\">pic.twitter.com/AEUEeiq97i</a></p>&mdash;\nDan Gebhardt (@dgeb) <a\nhref=\"https://twitter.com/dgeb/statuses/449088566962814976\">March 27,\n2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>Ember makes you a badass\nweb developer. The productivity gains are unparalleled. Page flow is\nfirst class. <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a>\n<a\nhref=\"http://t.co/DlKqmmdVEU\">pic.twitter.com/DlKqmmdVEU</a></p>&mdash;\nJohn K. Paul (@johnkpaul) <a\nhref=\"https://twitter.com/johnkpaul/statuses/448510256097001472\">March\n25, 2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>Notes on the morning <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a>\nkeynote by <a href=\"https://twitter.com/wycats\">@wycats</a> <a\nhref=\"https://twitter.com/tomdale\">@tomdale</a> <a\nhref=\"http://t.co/rYKEruaxRe\">pic.twitter.com/rYKEruaxRe</a></p>&mdash;\nMichael Chan (@chantastic) <a\nhref=\"https://twitter.com/chantastic/statuses/448517744900976641\">March\n25, 2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p>hug <a\nhref=\"https://twitter.com/tomdale\">@tomdale</a> achievement unlocked <a\nhref=\"https://twitter.com/search?q=%23emberconf&amp;src=hash\">#emberconf</a>\n<a\nhref=\"http://t.co/nLOBPGJwKL\">pic.twitter.com/nLOBPGJwKL</a></p>&mdash;\nBen Rosas (@ballPtPenguin) <a\nhref=\"https://twitter.com/ballPtPenguin/statuses/449000521211203586\">March\n27, 2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p><a\nhref=\"https://twitter.com/ebryn\">@ebryn</a> <a\nhref=\"https://twitter.com/EmberConf\">@EmberConf</a> Such a wonderful\nexperience. One of the best conferences I&#39;ve ever attended, it was\nlike one big family finally united.</p>&mdash; Kasper Tidemann\n(@KasperTidemann) <a\nhref=\"https://twitter.com/KasperTidemann/statuses/449044965855723520\">March\n27, 2014</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n"},{"title":"Magic behind ES6 Generators","tags":["javascript","es6"],"summary":"Overview of ES6 generators","legacy":false,"id":"2014/03/30/magic_behind_es6_generators","employee":"Alex Navasardyan","date":"2014-03-30T00:00:00","body":"\n\n## Overview\n\nThe next version of JavaScript (ES6 or ES.next) is going to have a lot of\ngreat features built in that are going to make developer's life much easier.\n[Promises](http://wiki.ecmascript.org/doku.php?id=strawman:promises),\n[Modules](http://wiki.ecmascript.org/doku.php?id=harmony:modules),\n[WeakMaps](http://wiki.ecmascript.org/doku.php?id=harmony:weak_maps),\n[Generators](http://wiki.ecmascript.org/doku.php?id=harmony:generators) to name a few. In this\npost I want to talk about generators.\n\nGenerators are objects that encapsulate suspended execution context. What the heck does it mean?\nIn other words, generators allow you to pause execution of your code and return a value.\n\nLet's say you need to write a `cubic` function (for any given number, calculate a cubic number)\nand then print it out.\n\nCode without generators for 10 numbers:\n\n```javascript\nfunction out(n) {\n  console.log('Cubic number:', n);\n}\n\nfunction *cube(n) {\n  n = n * 3;\n  out(n);\n}\n\nfor (var i = 0; i < 10; i++) {\n  cube(i);\n}\n```\n\nCode with ES6 generators for 10 numbers:\n\n```javascript\nfunction *cube(n) {\n  var i = 0, j = n;\n  while (i < n) {\n    i++;\n    j = j * 3;\n    yield j;\n  }\n}\n\nvar c = cube(10);\nfor (var i = 0; i < 10; i++) {\n  console.log('Cubic number:', c.next().value);\n}\n```\n\nCan you spot the difference? Generator represents a sequence of numbers and every time you call\n`next()` it gives you the next number in the sequence (it actually gives you an object back\nwith two properties: `value` and `done`):\n\n```javascript\nc.next(); // => { value: 3, done: false }\n```\n\nOnce the limit is reached, generator will return:\n\n```javascript\nc.next(); // => { value: undefined, done: true }\n```\n\nPretty cool, eh?\n\nNote, that generators look *just* like functions, but with `*`s:\n\n```javascript\n// regular function\nfunction cube()  {}\n\n// es6 generator\nfunction *cube() {}\n```\n\nIf you're a Python developer, generators and `yield` are not new to you. But it's a big step forward\nfor JavaScript.\n\n## For-Of\n\nThe `for of` loop is a new iteration construct in ES6 which supports generators. This is really for\nperformance purposes. Instead of returning a full array, you can just return a generator which\nlazily gives values back on each iteration. That decreases memory allocation and you can express\ninfinite data structures (since no array allocation is needed).\n\nA really interesting use case for generators is async operations:\n\n```javascript\nspawn(function() {\n  var users = yield db.get('users');\n  var posts = yield db.get('posts');\n});\n```\n\n`spawn` is a function in [node.js](http://nodejs.org) that allows you to create child processes.\nYou can read about it [here](http://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options).\n\n`spawn` hands control over the function to the scheduler, which knows that the function will `yield`\npromises and will send the values back as soon as the promises are going to be resolved (fulfilled).\n\nThis is really powerful.\n\n## Availability\n\nIf you really want to use this feature, you're going to have to use transpilers, such as [Traceur](https://github.com/google/traceur-compiler)\nor [Regenerator](https://github.com/facebook/regenerator). The reason for that is two new language keywords\nintroduced by ES6 generators: `yield` and `function *`. There's a really good blog post about [polyfilling generators](http://gu.illau.me/posts/polyfilling-generators/)\nthat goes in depth about how transpilers deal with the new syntax.\n\nNative implementations of generators are available in Firefox and Chrome Canary\n(you will need to enable [harmony experimental flag](chrome://flags/#enable-javascript-harmony)).\n\nI encourage you to play around with the generators and get familiar with the syntax because in couple of\nyears from now, we all will be writing code using generators (hopefully).\n\nP.S.\n\nGreat article about [ES6 generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/New_in_JavaScript/1.7#Generators).\n"},{"title":"Designing Within The Browser","tags":["design","design process"],"summary":"Make room for accidental progress.","legacy":false,"id":"2014/04/04/design-within-the-browser","employee":"Steven Trevathan","date":"2014-04-04T00:00:00","body":"\n\nI employ a solid range of design tools and although I’m spending some of my time designing in the browser, the ideal of designing *entirely* in that context is often unrealistic and stifling.\n\n## Save time for discovery\nSometimes an accident leads to an interesting and useful discovery. In art and design this is especially true. In a browser, unfortunately, accidents don’t pleasantly surprise you in the way *”static”* designs may. In development an accident means broken code – plain and simple. You may stumble on a solution, but you’re not going to be surprised by a random glimpse of order and possibility in the muck of your own broken HTML. It’s broken until it’s fixed.\n\nSuch a quality of the web is necessary, but I don’t find it very helpful for discovering new solutions to visual or experience problems. In the early stages you become very focused on minute details when you should be thinking in broad strokes. In later stages you find yourself seeing larger visual problems and with less power to change it. In many ways, I find designing in the browser akin to designing in the dark.\n\nThere are plenty of browser based design tools attempting to free designers of heavy weights such as Photoshop and allow designers to work without learning advanced HTML and CSS. This is a positive direction, but I still haven’t seen the problem solved without losing the element of discovery. Instead of happy accidents, you may experience a gross misunderstanding between your intent, the front end code of the tool you’ve chosen, and the DOM. Maybe the tools will get better, and I’m sure they will, but I’m not optimistic they’ll be architected to facilitate discovery within the next few years.\n\nFor the time being my opinion is that, in terms of process, improvements in web standards and web technology aren’t going to change anything save for ensuring work may be completed in shorter order. We create tools (or products) and advance technology in order to *increase* efficiency and *improve* human capability. The computer added efficiency for designers by - among many, many other things - being faster and more forgiving than pen and ink, but we still use these older technologies today in tandem with computers.\n\n## The right tool at the right time\nWe can still integrate designing in the browser as a component of the design process. I don’t view this as an all–or–nothing deal and our process should be malleable enough to better facilitate reaching the goals of each and every project. Imagine, as an extreme example, that you were told to integrate sketching into your design process. You would absolutely not render your designs “pixel-perfect” in a sketch book. It beats the whole point of the sketch book and the whole experience would be tremendously debilitating. Instead, you’d probably do at least a little bit of preliminary sketching before opening Photoshop, and return when you need to massage another idea out of your head.\n\nThe benefit of designing in the web, or at least getting a product in the browser sooner, is that you can experience it and identify major problems before you’re past the point of no return. This is a pretty well established idea (that I believe in), but just like using the sketchbook we need to identify when it’s appropriate to pop open a text editor and start punching in markup and styles. I’ll kick this off with two cases where I think designing in the browser is appropriate: prototyping unique interactions and defining visual state changes.\n\n### Prototyping unique interactions\nWe should prototype and test core product interactions when they are unorthodox. Design patterns should be used where possible, but if we are knowingly going against the grain we need to test that experience in the browser and with users (as available) before making it permanent. This is sometimes after the static design has been completed, but in many cases can be done before anything static has been created.\n\n### Visual state changes\nWhen following design patterns there are still standard things to be fleshed out in the browser: hovers, presses, clicks, fades, sliding interactions, and so on. Generally, if you don’t know how an interaction will truly feel and it involves a state change: design it in the browser. At DockYard, we often propose a solution first in Photoshop and then weigh our options again in the browser. \n\n## An example\nWe completed a project last year with the ambition of the design stage being completely browser based, skipping the use of Photoshop altogether. The benefits of having a usable front end in place of static mockups are great: you can use your app as it is being designed and get a sense of the failure points before they become too ingrained in the experience. User testing can begin earlier. This is awesome. From the outside, designing solely in the browser seemed perfect.\n\nYou guessed it: I was wrong. It wasn't right for us then, nor for that project. We were less focused on the user’s experience and more focused on the organization and creation of markup, styles, and script. We began (and ended) by worrying about and writing lines of HTML, CSS, and JavaScript. We were worried about front end patterns, but the design patterns we were aiming to support weren’t fully identified yet. We introduced somewhat of a chicken and the egg problem, making our thinking more difficult and more sporadic than it should have been.\n\nFor us this meant spending hours and hours tweaking markup, all in the name of being able to feel and test the product as it was created. In some cases, for sure, this can be worth it. In our case we even had plenty of existing design assets to base our web interface off of, but that project had called for too many largely different iterations (and mixed opinions) of the same few designs.\n\nDesigning in the browser does not mean your project will turn out poorly. Ultimately, and fortunately, that project turned out well in the end, but we did spend a lot more time getting a complete idea of what we were actually designing and building. Our clients got to use the product before they bought into the concept, which was great for them. For us, however, it was as if we started designing a house by laying the concrete foundation before knowing what we were building.\n\n## Weigh your options\nA successful product depends on its content, design, engineering, market fit, team, tools, and infinitely more. When consulting, those elements are wildly varied from client to client, including the toolset. So we must be mindful of what is necessary, be malleable in our processes, and most important of all: make room for discovery."},{"title":"Vim: On Your Mark...","tags":["vim","workflow"],"summary":"An introduction to the mark motion","legacy":false,"id":"2014/04/10/vim-on-your-mark","employee":"Doug Yun","date":"2014-04-10T00:00:00","body":"\n\nThe strength of Vim's basic **movement** commands are immediately apparent.\nWe can jump four words over with `4w` or move to the beginning\nof a sentence with `(`. Once these movements are engrained to muscle memory,\nwe can move within files with ease. However, there are certain limitations\nto these basic movement commands; wouldn't it be great if we could move\nto different and specific spots within multiple files?\n\nToday, we're going to briefly cover a poweful motion strategy:\n**mark** motion.\n\n## What is a Mark? ##\n\nMarks are essentially *hidden* positions that, when set, allow us to\njump back to that specific location or line. What we mean by *hidden* is that these marks\nare not visible by default; marks are simply invisible points within a file.\n\nThe mark motion command starts with hitting `m` - `m` for mark - and then setting\na **destination marker** - either a lowercase letter or uppercase letter.\nWe'll introduce the differences among the destination markers soon.\n\nLet's start by covering a simple example of setting a **lowercase mark**.\n\n#### Example: Moving With A Lowercase Mark ####\n\n```bash\n# ~/example1.txt\n\nHere is Line 3\nHere is Line 4\nHere is Line 5\n\n# On Line #3, use `mn` to set a mark on the letter `n` within the word `Line`.\n# Move around the file.\n# Go back to the previous mark by hitting: `n\n```\n\n1. First, in `Normal` mode, move to Line #3. Place your cursor on the letter `n`\nwithin the word `Line`.\n\n2. Next, set a mark by hitting `m` and then the lowercase letter\n`n`. `n` is our lowercase **destination marker**.\nCongratulations, we've just set a **lowercase mark**!\nWe could of used any lowercase character, but by using the letter `n`, we've\nsetup a nice mnemonic device.\n\n3. Now move to Line #5. We're going to move to our mark now.\nHit `` `n `` - *backtick* and `n`, our previous destination marker.\n\n4. Notice where our cursor is (*hint*: it should be located on the letter `n`\nwithin the word `Line`).\nHuzzah, we are now back to our previous position within the file!\n\n5. Go back to Line #5.\n\n6. Now, hit `'n` - *single quote* and `n`.\n\n7. We are now at the beginning of Line #3!\n\n## Jumps, Marks and a Few Commands ##\n\nWe know how to set a mark with `m`, but let's clarify the two types of mark jumps\nand the different types of marks.\n\n## Two Types of Mark Jumps ##\n\n### Backtick ###\n\n`` `<mark> `` - The *backtick* places our cursor directly on the mark.\n\n### Single Quote ###\n\n`'<mark>` - The *single quote* takes us to the first non-blank character of the\nmark's line.\n\n## Three Types of Marks ##\n\n### Lowercase Marks ###\n\n**a - z** - These marks preserve locations within a *single* file. Each individual file\npossesses 26 settable lowercase marks. Lowercase marks are valid as long as the file\nremains in the buffer list. Furthermore, lowercase marks can be combined with other\noperators.  For example, ``c`n``, will change everything between the cursor to the\nmark, `n`.\n\n### Uppercase Marks ###\n\n**A - Z** - These marks preserve locations within *multiple* files. Also known\nas **file marks**. These marks, which are shared among all files within the buffer list,\ncan be used to jump from file to file. File marks can only be used in combination with\noperators if the mark is in the current file, i.e. when the current file opened contains\nthe global file mark.\n\n### Numbered Marks ###\n\n**0 - 9** - Numbered marks cannot be set directly, instead they are created\nautomagically and used by the **viminfo-file** (`:help viminfo-file`).\nEssentially, the numbered marks store the location of your cursor after closing Vim.\nFor example, mark `0` returns the position of the cursor during your last Vim session,\nwhile mark `1` returns the next to last Vim session, and so forth.\n\n## Some Pertinent Commands ##\n\n### Viewing current marks ###\n\n**:marks {argument}** - **:marks** will show you all current marks, their file location and\ndestination marker. We can pass in an *argument* to view a range of marks between two marks.\n\n* **:marks aC** - will return all marks that are between `a` and `C`.\n\n### Deleting Marks###\n\n**:delm[arks] {marks}** - We can use `:delm` or `:delmarks` and then pass in marks\nthat we want to delete.\n\n* **:delm aAbB** - will delete marks labeled `a`, `A`, `b` and `B`.\n\n## Okay, What's So Cool About Marks? ##\n\nMarks can speed up our navigation workflow! Here are a few examples:\n\n#### Discussion: Editing One Large File With Lowercase Marks ####\n\nI've found **lowercase marks** extremely useful when editing multiple portions of\na file. Instead of using `CTRL+u`, `CTRL+d`, `H`, or `L` to move up and down\nthe file, you can set local marks at heavily treaded locations at jump back\nand forth among them. Moveover, marks give us the ability to jump to an\nexact location - *backtick* - or to the beginning of the line - *single quote*.\n\n#### Example: Editing Multiple Files With Uppercase (File) Marks ####\n\nWhen I first started using Vim (and began programming), I had multiple windows\nopen constantly on the monitor.  Not only does it quickly become cluttered,\nremembering which file is which becomes hairy.\n\nFiles marks to the rescue!\n\n* Here are three files we are want to work on. Let's add some **file marks**.\nJust like lowercase marks, the actual uppercase letter we use does not matter\nas long as it is unique.\n\n```ruby\n# ~/sheep.rb\n\n# On the word `speak`, place a file mark with `mS` - `S` for \"sheep\"\ndef speak\n  puts \"Baah! Baah!\"\nend\n```\n\n```ruby\n# ~/cat.rb\n\n# On the word `speak`, place a file mark with `mC` - `C` for \"cat\"\ndef speak\n  puts \"Meow! Meow!\"\nend\n```\n\n```ruby\n# ~/doge.rb\n\n# On the word `speak`, place a file mark with `mD` - `D` for \"doge\"\ndef speak\n  puts \"Wow! Ahh yes method! Such quality!\"\nend\n```\n\n* If we are in `~/sheep.rb` and want to jump to the `speak` method defined\nwithin `~/cat.rb`, we can do so with `` `C ``. Now that we're in `~/cat.rb`,\nlet's go to the `speak` method within `~/doge.rb` with `` `D ``.\nPretty sweet, huh?\n\n## \"X\" Marks the Spot ##\n\nHope you enjoyed the basics of Vim **marks**. We've only covered the basics here, so if\nyou'd like to learn more check the docs.\n"},{"title":"Ember Object Self Troll","tags":["ember"],"summary":"Ember.Object.create explained","legacy":false,"id":"2014/04/17/ember-object-self-troll","employee":"Alex Navasardyan","date":"2014-04-17T00:00:00","body":"\n\nLet's say we have a `Month` object. A `Month` has `weeks`.\n\n```javascript\nvar Month = Ember.Object.extend({\n  weeks: Em.A()\n});\n```\n\nConsider the following code:\n\n```javascript\nvar a = Month.create();\nvar b = Month.create();\n\nconsole.log('before a', a.get('weeks')); // => []\nconsole.log('before b', b.get('weeks')); // => []\n\na.get('weeks').pushObject(1);\na.get('weeks').pushObject(2);\n\nconsole.log('after a', a.get('weeks')); // => [1, 2], as you expect\nconsole.log('after b', b.get('weeks')); // => [1, 2], and you're like O_o\n```\n\nAnd another one:\n\n```javascript\nvar Month = Ember.Object.extend({\n  weeks: Em.A()\n});\n\nvar a = Month.create({ weeks: Em.A([1, 2]) });\nvar b = Month.create();\n\nconsole.log('a', a.get('weeks')); // => [1, 2]\nconsole.log('b', b.get('weeks')); // => []\n```\n\nThe results of the first example are quite surprising, if you are not used\nto the prototypical inheritance.\n\nSo what's going on there? Let's take a look at the \"very scary\" Ember.js `create` [function](https://github.com/emberjs/ember.js/blob/master/packages_es6/ember-metal/lib/platform.js#L39-L52):\n\n```javascript\ncreate = function(obj, props) {\n  K.prototype = obj;\n  obj = new K();\n  if (props) {\n    K.prototype = obj;\n    for (var prop in props) {\n      K.prototype[prop] = props[prop].value;\n    }\n    obj = new K();\n  }\n  K.prototype = null;\n\n  return obj;\n};\n```\n\nWhen you don't pass any properties to create (`props`), all instances of\nthe `Object` will share the same prototype. That's pretty much the gist\nof the prototypical inheritance. It means that any changes on one object will\nreflect on the others. That explains the behaviour in the first example.\n\nIf you pass the properties (that ones that you specified at `extend` time) to `create`,\nthey are going to be replaced on the instance's prototype.\n\nThere are two ways of changing the default behavior:\n\n+ turn `weeks` into a [Computed Property](http://reefpoints.dockyard.com/2013/09/04/computed_properties_in_ember_js.html)\n+ set `weeks` on `init`\n\nUsing computed property:\n\n```javascript\nvar Month = Ember.Object.extend({\n  weeks: Ember.computed(function() {\n    return Em.A();\n  })\n});\n```\n\nIn this case, `weeks` is going to return a new `Ember.Array` on `get`.\nThe code will run as you expect, `weeks` are not going to be shared.\n\nUsing `init`:\n\n```javascript\nvar Month = Ember.Object.extend({\n  weeks: null,\n\n  init: function() {\n    this._super();\n    this.set('weeks', Em.A());\n  }\n});\n```\n\nThis is very clear and nice technique if you're not familiar with computed properties.\nOverriding `init` and calling `super` allows to run code upon the object's creation.\nYou can set the value for `weeks` there.\n\nYou can also use `on('init')` but it's discouraged because a subclass can provide\nits own implementation of `setWeeks`:\n\n```javascript\nvar Month = Ember.Object.extend({\n  setWeeks: function() {\n    this.set('weeks', Em.A());\n  }.on('init')\n});\n```\n\nHappy coding!\n"},{"title":"Artist: Ryo Takemasa","tags":["design","illustration","inspiration"],"summary":"Highlighting an inspiring artist","legacy":false,"illustration_alt":"“Cucumbers” by Ryo Takemasa","illustration":"https://i.imgur.com/PCmNbBH.jpg","id":"2014/04/25/ryo-takemasa","employee":"Logan Faerber","date":"2014-04-25T00:00:00","body":"\n\n## Artist: Ryo Takemasa\n\nIf you’re not using Pinterest yet to collect various reference material and inspirational artists, may I suggest doing so immediately? I typically like to keep a huge assortment of “mood boards” on various topics, ranging from product designs to comic books to grandiose natural landscape photography. It serves as an endless source of reference material, much like collecting magazine clippings and organizing them in various folders. Not only is it great for collecting all of the art you love in one place, it’s also a great platform for discovering new artists. A list of suggestions titled, “other pins like...” is displayed below the piece you’re currently viewing. This often times leads me down an endless tunnel of discovery - one that typically keeps me digging a hole into the wee hours of the morning.\n\n![“Cucumbers” by Ryo Takemasa](https://i.imgur.com/PCmNbBH.jpg)\n\nDuring one of these excavations, I discovered the artist [Ryo Takemasa](http://ryotakemasa.com/), who I at first mistook as [Charley Harper](http://en.wikipedia.org/wiki/Charley_Harper). The piece I saw was a series of stand alone fruits and vegetables, most of them cut in half to expose their cross section, which all shared a beautiful mixture of what appeared to be wood block print and cut paper. Their geometric and pattern infused forms created lovely shapes alongside color shifts that I’d typically only see in particular vintage illustrations. Accompanying this pin was a link to his site. It turns out he’s a modern Japanese illustrator who works primarily in the print world for a variety of publications.\n\n![“Yellow Pepper” by Ryo Takemasa](https://i.imgur.com/ys1BSS4.jpg)\n\nOnce I discovered this, I began to see the Japanese line work and [wood block printing](https://www.google.com/search?q=Japanese+wood+block+print&safe=active&es_sm=91&espv=210&source=lnms&tbm=isch&sa=X&ei=o__0UuZd5anRAdv0gJgP&ved=0CAgQ_AUoAg&biw=2840&bih=1495&dpr=0.9) aesthetics shine through in his work. The geometric forms and subtle color transparencies were clearly influenced by Japanese culture, but they still retained that vintage American aesthetic at times as well.\n\n![“Onion” by Ryo Takemasa](https://i.imgur.com/hTb6KCC.jpg)\n\nI’d be curious to learn what amount of influence Charley Harper’s art had on the world and whether it was a huge influence everywhere, such as territories in Japan. Similarly I would also like to know the amount of influence, if any, ancient Japanese wood block printing had on Charley Harper. Was it a conscious decision or had it inadvertently shown through? If there had been a direct influence, that would significantly alter my view of someone who I’ve alway seen as having emerged purely from American Modernist abstraction. Either way, it’s amazing to think that two people, so separated by distance, culture and era could have produced such distinct, yet aesthetically similar artwork. As is the beauty of influence in this world.\n"},{"title":"Don't override init","tags":["ember","best practices"],"summary":"Use events instead","legacy":false,"id":"2014/04/28/dont-override-init","employee":"Brian Cardarella","date":"2014-04-28T00:00:00","body":"\n\nToo frequently I see the following problem. Someone creates a new\nclass and overrides `init`:\n\n```javascript\nvar UsersController = Ember.ArrayController.extend({\n  init: function() {\n    // some custom stuff\n  }\n})\n\nexport default UsersController;\n```\n\n`init` is a popular function to override because it is automatically run\nafter the object is instantiated. It is the only lifecycle hook for\n`Ember.Object`, subclasses of `Ember.Object` add their own hooks to the\nlifecycle but the only one that is guaranteed to be there is `init`.\n\nThe problem is with the above example\nthe controller is broken. I forgot to make a call to `this._super()`\nwhich will call the original `init` from `Ember.ArrayController`. That\n`init` assigns the proper value to `content`. (via `ArrayProxy`)\n\nInstead of overriding `init` I have been writing functions that are\nspecific to the logic I want to kick off on object instantiation and\nhave that function trigger `on('init')`:\n\n```javascript\nvar UsersController = Ember.ArrayController.extend({\n  doSomething: function() {\n    // some custom stuff\n  }.on('init')\n})\n\nexport default UsersController;\n```\n\nNow I don't risk messing with the original behavior of the parent class.\n\nCalling up the `super` chain is a powerful and important feature in\nEmber but too often I was forgetting to call it. Now the only time I find\nmyself overriding `init` is if I want to **disrupt** the default instantiating\nbehavior of the object.\n"},{"title":"The first two months at DockYard","tags":["design thinking","design","user experience"],"summary":"Recurring themes, and principles I learned in breaking into user experience design.","legacy":false,"id":"2014/04/28/first-few-months","employee":"Maria Matveeva","date":"2014-04-28T00:00:00","body":"\n\n# The first two months at DockYard.\n\nRecurring themes, and principles I learned in breaking into user experience design.\n\n## Invisible\nThe way I see websites has changed after a month and a half of paying attention to website UI. One thing that stands out: good design can support the message and content in a quiet, almost invisible way. This principle applies in all areas of design, but I am particularly focusing on elegant solutions in web interfaces. It is a pleasure to observe, and sometimes find myself, effective use of subtle visual changes. \n\nThe principle of quiet, effective solutions comes up most often when my work-in-progress is reviewed by the whole team. In most cases, I find that I start a design with many elements in a very “loud” state, then evaluate the entire layout. Once I can prioritize things on the page, most elements can become more “quiet”.\n\n## Design for a typical case, not the worst case.\nBefore DockYard, my process relied heavily on finding out what the worst-case scenario could be, and designing for that. For example, I would consider a very long, but still plausible, title for an article, and then design the header to accommodate that comfortably. I’d always consider extreme cases early on, and design heavily around those. \n\nAt DockYard, I learned to design for the typical use case, and then consider how an extreme case would be accommodated. Looking back, I realize that this approach is less limiting and can result in better graphical solutions.\n\n## Information density\nDifferent use cases call for different densities of information. \n\nWhen you are scanning through many search results, it is sometimes appropriate to show a lot of detail at once. Search results are basically many repetitions of one type of item. Users may want to compare what they see according to different criteria, and it is useful to neatly show many details about each result. If I’ve done a good job prioritizing the detailed information, many details do not cause clutter.\n\nIn other cases, it is more important to convey the atmosphere around a brand, or to highlight one or two primary actions. Showing fewer items and fewer details can work better.  In these cases, the density of information may appear low, but each element has more prominence.\n\nI can make good progress towards solving the layout of a page by deciding whether it is a detailed type of page (like search results) or a page focused on emotional impact, but not details (like some landing pages).\n\n## Does it look “real”?\nDesign is often about deciding what kind of animal a chunk of information will be. Through visual design, we have to clearly answer questions like “how important is this thing, relative to others?”, “what can I do with this?” and even “what kind of thing is it?”. When I show a draft in a design review, I can see how the suggested changes “snap” to something that looks more real and interactive. I believe that the ability to make things look real quickly comes from experience, and also from paying attention to how user interface elements are crafted in products I use every day.\n\nThrough regular design reviews, close observation of UI design, and occasional experiments, I hope to continue improving my ability to judge my own work. This will allow for more efficient work, more refined design, and more awesomeness in the future.\n"},{"title":"The problem with server-rendered errors","tags":["ember"],"summary":"Handling validation errors returned from the server is no easy task","legacy":false,"id":"2014/04/29/the-problem-with-server-rendered-errors","employee":"Brian Cardarella","date":"2014-04-29T00:00:00","body":"\n\nThe 3rd most popular question with\n[ember-validations](https://github.com/dockyard/ember-validations) is\nhow can the library work with server-rendered validation errors, such as\nthe ones returned with [ember-data](https://github.com/emberjs/data).\n\nThe short answer for now: it can't.\n\n(btw, 2nd most popular question is about `uniqueness`/remote validations\nand the 1st most popular question is when will I provide a `dist/`\ndirectory... I'll cover the 2nd Q in an upcoming blog post. As far as\n`dist/` its never going to happen, ever)\n\nHere is the problem. When you are dealing with a client-side model and a\nserver-rendered model there won't always be a 1-to-1 representation of the\nmodel. In those cases you can rely on ember-data's serializer to\ntransform the properties on a server-rendered error object to ones that\nexist on the client data model. How about properties that don't exist at\nall in any form on the client? You could have a validation error on\nsomething only meant for server-rendered purposes. How do we best handle\nthis?\n\nLet's imagine for a moment that we can properly map all the properties\nback to their client-side equivalents. Now what? How do you resolve\nthese validation errors? How do you know in the UI when the validation\nerror has been resolved to clear the error message? Are you preventing data\nsubmission until your client model is valid? If the errors are happening\nserver-side the odds are high that these are not validations that can be\nknown to be resolved on the client unless you do another data\nsubmission and wait to see how the server responds.\n\nSo to re-cap the two issues are:\n\n1. Potential lack of context on which properties errors can map back to\n1. Inability to know when server-rendered validation errors are\n   satisfied on the client\n\nTo start to consider a possible solution I think we need to step back\nand consider the ultimate goal of client side validations. In my mind\nthis is purpose: *to help the user submit valid data to the server*.\n\nClient side validations are just UI sugar. They are there to guide your\nusers. ember-validations only has model-layer concerns, which means you\nhave to provide how the validation errors are displayed on your UI. This\nis why I also wrote\n[ember-easyForm](https://github.com/dockyard/ember-easyForm) which\nhandles the complexity of what I consider to be best practices of how\nvalidation messages should be displayed and cleared. To fix this problem\nwould have to tackle it from both sides:\n\n1. How will server-rendered errors be stored in the validation graph?\n   (ember-validations)\n1. How will server-rendered errors be displayed and resolved in the client?\n   (ember-easyForm)\n\n### Storing server-rendered errors\n\nIf you are already using ember-data then your data model is handling\nthis for you already. IMO you should never mix your validations into\nyour data model, they should be mixed into your controller:\n\n```javascript\nvar UserController =\nEmber.ObjectController.extend(Ember.Validations.Mixin, {\n  validations: {\n    firstName: {\n      presence: true\n    }\n  }\n});\n```\n\nThis way the controller has its own `errors` object which will not clash\nwith the `errors` object on your data model. One possibility of\nreferencing the model's server-rendered errors is to have a `base`\nvalidator that is not part of the validation graph but who's errors can\nbe used for presentation purposes.\n\n### Displaying server-rendered errors\n\nSo how do you properly display these error messages? Do you try to\nassociate them with a property? What if that property is not represented\nby a form input? What if you aren't even using a form? How do you know\nwhen to clear the errors?\n\nI believe this is a complex issue. My first pass at handling this in\nEasyForm will be to display all of the server-rendered errors in a\nsingle place. An upcoming version of EasyForm will simply group all\nerrors in `base` and display them. These errors will not clear out due\nto any corrections made by the client. They will only clear when some\nother action clears out those errors, for example when ember-data itself\nclears out or changes the content of its `errors` object.\n\n### Conclusion\n\nThis is far from ideal. This moves us away from the \"best practices\" for\n[high conversion forms outlined by Luke\nWroblewski](http://alistapart.com/article/inline-validation-in-web-forms).\nBut it is better than not guiding your users. If the server errors for\nany given reason we don't want our users sitting there without any\nfeedback.\n\nI am very interested in other approaches and brainstorming on the best\ndirection for this. Please feel free to comment below.\n"},{"title":"Understanding validation graphs","tags":["ember"],"summary":"The power behind ember-validations","legacy":false,"illustration_alt":null,"illustration":"http://i.imgur.com/QP2sYWT.gif","id":"2014/04/30/understanding-validation-graphs","employee":"Brian Cardarella","date":"2014-04-30T00:00:00","body":"\n\nIf you have heard me speak about\n[ember-validations](https://github.com/dockyard/ember-validations) then\nyou may have heard me mention the term **validation graph**. What is\nthis? Why is it important?\n\nIf you come from a Rails background then you are used to the validations\nbeing stored in an array on the instance of the model. When you validate\nyour model all of those validations will be run and an errors object is\nproduced. If you make a change to a property you have to run the\nvalidations again to determine the validity of the model.\n\nI would refer to the style of\nvalidations described above as *lazy validations*. Meaning the\nvalidity of the model may not be truly representative of its\ncurrent state. We have to opt-into running the validations again to\ndetermine this. Fortunately in most cases, the validations will run for us\nbefore we save. On the server this all happens within a request/response\ncycle so we don't really care too much about the validations\nbeing lazy because we care about the final result, not the state of the\nmodel at any given point during that cycle.\n\nember-validations has *eager validations*. This means when the property\nthat is associated with any number of validations changes those\nvalidations will run again to determine the state of the model. This is\ngreat for client side apps that need to show the current state of the\nentire model any time you make a change, say during a user sign up. I\nmight want to disable the Submit button if there are any failing\nvalidations. If I make a correction I want the error message to go away\nonce the correction is made. I should not have to wait upon form\nsubmission to see my errors.\n\nHow does ember-validations do this? Let's say you have the following\nvalidations:\n\n```javascript\nvar UsersController =\nEmber.ObjectController.extend(Ember.Validations.Mixin, {\n  validations: {\n    firstName: {\n      presence: true,\n      length: 5\n    },\n    password: {\n      confirmation: true\n    }\n  }\n});\n```\n\nThere are 3 validations on 2 properties. Each validation is an\ninstantiated class that can observe the one or more properties. In the\ncase of the `firstName` property the `Presence` and `Length` validators\nare observing it. The `Confirmation` validator is actually\nobserving `password` **and** `passwordConfirmation` for changes. Each\nvalidator has a `isValid` flag that is set to `true` or `false`\ndepending upon the result. Each of these validators are pushed onto a\n`_validators` array and the parent object is observing\n`_validators.@each.isValid` for any changes. If any of the validators\nare `false` the parent's `isValid` state is now `false`.\n\nPlease take a moment to re-read the above paragraph because it is very\nimportant to have a good handle on this before we move forward. **The\nvalidating object's `isValid` flag is the result of its validator's\n`isValid` flags**\n\nBecause we are in quack-quack duck-typed JavaScript we don't **have** to\npass validator instances into the `_validators` array. *What if we pass\nanother validatable object?* Now things get interesting.\n\nLet's say we have a `Profile` that belongs to a `User`. The `Profile`\ncan have its own set of validations as well as its own `isValid` flag.\nIf the `Profile` is mixed into the `Users`'s validation graph then the\n`User` will be invalid when the `Profile` is invalid. We can use this\npattern to build an incredibly deep and complex graph where the validation\nstate bubbles up to the root whenever a property change takes place\nanywhere in the graph.\n\nWe can do this simply with:\n\n```javascript\nvar UsersController =\nEmber.ObjectController.extend(Ember.Validations.Mixin, {\n  validations: {\n    firstName: {\n      presence: true,\n      length: 5\n    },\n    password: {\n      confirmation: true\n    },\n    profile: true\n  }\n});\n```\n\nNotice `profile: true` in the graph. As long as `profile` is the path to\nthe object to validate against ember-validations will work its magic.\n\nHowever, the above only really works if the validations exist on the\n`Profile` **model** and not the controller.\n\nA visualization of a complex validation graph might look like this. We\ncan see the `isValid` states bubbling up to the original root node:\n\n<img style=\"width: auto\" src=\"http://i.imgur.com/QP2sYWT.gif\"/>\n\n I welcome suggestions and thoughts on this API as well as the validation graph in general.\n"},{"title":"Alert messages in Ember Apps","tags":["ember"],"summary":"The wonder of Woof!","legacy":false,"id":"2014/05/01/alert-messages-in-ember-apps","employee":"Brian Cardarella","date":"2014-05-01T00:00:00","body":"\n\nSomething that feels missing from Ember is a way to send, from anywhere\nin my app, a general alert message. Something that would pop up in my\napp, display for a few seconds and disappear.\n\nClearly, this is something that should not be part of Ember itself but it\nis a common enough feature that someone should build it.\n\nI call it `Woof`.\n\n<iframe width=\"620\" height=\"465\"\nsrc=\"//www.youtube.com/embed/8wfG8ngFvPk\" frameborder=\"0\"\nallowfullscreen></iframe> \n\nIt currently only exists on [jsbin](http://jsbin.com)\n\n<a class=\"jsbin-embed\"\nhref=\"http://jsbin.com/luhoquxi/7/embed?output\">WoofWoof! Notifier for\nEmber</a><script src=\"http://static.jsbin.com/js/embed.js\"></script>\n\nSo for the time being you'll need to copy/paste. We'll be extracting it\ninto a plugin soon enough.\n\nBasically, Woof will inject itself into your routes, controllers, and\ncomponents. You will need to embed the Woof component somewhere in your\ntemplates:\n\n```handlebars\n{{x-woof}}\n```\n\nWoof injects a `woof` object similar to how `ember-data` injects a\n`store` object. You can push a message onto Woof using some of the\npre-defined types or create your own:\n\n```javascript\nthis.woof.info('This is an info message');\nthis.woof.pushObject({type: 'customType', message: 'Woof! Woof!\nWoof!'});\n```\n\nThis code comes with Twitter Bootstrap types setup:\n\n* *danger*\n* *info*\n* *success*\n* *warning*\n\nThe `x-woof` component will loop through all woofs in the array and\nprint out a div with the type as the class for specific styling\npurposes.\n\nThe code in the JSBin is setup and styled for Twitter Bootstrap.\nThe event handling is setup for removing the woof when the\ncss opacity transition completes. Browser support may vary.\n"},{"title":"What is holding up the uniqueness validator?","tags":["ember"],"summary":"One of the more requested features of ember-validations","legacy":false,"id":"2014/05/02/what-is-holding-up-uniqueness-validator","employee":"Brian Cardarella","date":"2014-05-02T00:00:00","body":"\n\n[ember-validations](https://github.com/dockyard/ember-validations) has\nnearly all of the [validator\nrules](https://github.com/dockyard/ember-validations#validators) one needs.\nOne glarring omission is the `Uniqueness` validator.\n\n### Not as straight forward as one would think\n\nBefore we even talk about the complication with implementing the remote\nvalidator, we should talk about if `uniqueness` should be both a remote \n**and** local validator.\n\nImagine you are working with\n[ember-data](https://github.com/emberjs/data), you attempt to create a\nnew record with an email `test@example.com`. If you already have a\nrecord with that value for email in ember-data's store should\n`uniqueness` first defer here before we hit remote? This ends up being a\nstrange thing because what if you have not persisted that first record\nyet. Do we only run uniqueness checks against local records that have\nbeen persisted? And how exactly would this fit in if you are mixing your\nvalidations into the controller instead of the model?\n\nIf the `email` example isn't working for you, imagine you are adding a\nbunch of line items to a parent record. None of these line items have\nbeen persisted yet. And you don't want to allow your users to add\nanother until the current one they are working on is \"valid\". Validating\nuniqueness locally is all of a sudden very valuable. But also very\ncomplex to implement properly.\n\n### No standard yet\n\nIf the local validator is too complex of an animal to tackle perhaps the\nremote validator implementation will be easier. It is, in part at least.\nWe can rely on `Ember.run.debounce` to ensure the the remote validator\ndoesn't fire too frequenly when many changes are happening to the value\nof a property. (i.e. entering text into a field)\n\nBut where do we send this request for uniqueness? This is where I am\ncurrently hung up. I really don't want to implement a backend api\nexpectation into ember-validations. I was hoping that something like\n[json-api](http://jsonapi.org) would define this for me then I could rely upon that as a\nstarting expected endpoint. But I don't think this is anywhere on their\nradar.\n\nThis being said, there is a possible solution. One of my co-workers [Lin\nReid](https://twitter.com/linstula) has put together a PR for\nintroducing remote uniqueness to ember-validations. It is lacking tests\n(hint hint, Lin!) but I think [this is moving in the right\ndirection](https://github.com/dockyard/ember-validations/pull/117).\n\nTo summarize, uniqueness is not forgotten. It is just a pain in the ass\nto do properly. Personally, I would prefer not to implement an API have\npeople buy into it now and have to change it (or be locked into it) a\nfew months from now.\n"},{"title":"Guarding with arrays","tags":["ruby","rails"],"summary":"A common pattern we use","legacy":false,"id":"2014/05/03/guarding-with-arrays","employee":"Brian Cardarella","date":"2014-05-03T00:00:00","body":"\n\nThis week I applied a pattern I've been using for years to two\nseparate pull requests from our devs. (I like to review almost all of the\ncode that DockYard devs write)\n\nIn both cases I was able to help them refactor their code to use an\nenumerator as code guards instead of conditional statements. Let's take a\nlook at each example:\n\n```ruby\nusers = User.where(type: 'employee')\n\nif users.any?\n  users.each do |user|\n    # ...\n  end\nend\n```\n\nIn this first example the `each` is avoided if the `users`\ncollection is empty. However, with arrays the enumerator only acts on each\nmember of the collection so we don't need to avoid if the collection is\nempty. We can refactor the above code into something like this:\n\n```ruby\nUser.where(type: 'employee').each do |user|\n   # ...\nend\n```\n\nMuch cleaner!\n\nThe next example may not be as straight forward but as we'll see with\nRuby we can clean this up nicely.\n\n```ruby\nif params[:ids]\n  params[:ids].each do |id|\n    # ...\n  end\nend\n```\n\nHere we have a situation where `params[:ids]` could contain a collection\nof data. Or it could be `nil`. Because of this we cannot just assume we\ncan always iterate over that value. In Ruby we can create a new `Array`:\n\n```ruby\nArray([1,2,3])\n# => [1,2,3]\n\nArray(nil)\n# => []\n```\n\nNotice in the second example that when we pass `nil` it creates an\n**empty array**. Knowing this we can refactor our code:\n\n```ruby\nArray(params[:ids]).each do |id|\n  # ...\nend\n```\n\nIf you find yourself putting guards around enumerators odds are you can\nrefactor in a similar manner as I've shown above.\n\nBTW, I've been using this pattern for years but I don't know if there is\nan actual name for this. If you do please share!\n"},{"title":"Stop using Ember Appkit Rails","tags":["ember","ruby","rails"],"summary":"Just stop","legacy":false,"id":"2014/05/04/stop-using-ember-appkit-rails","employee":"Brian Cardarella","date":"2014-05-04T00:00:00","body":"\n\nA few months ago I released a gem called [Ember Appkit\nRails](https://github.com/dockyard/ember-appkit-rails). Let me start by\napologizing for its existence. For those that began projects around\neak-rails it started with good intentions and felt right at first but we\nhave abandoned the gem at DockYard.\n\neak-rails was/is a merging of [Ember App\nKit](https://github.com/stefanpenner/ember-app-kit) and Rails. It does\nsome heavy monkey patching to Rails' Asset Pipeline to give as much\nproject hierarchical power to your Ember code as your Rails code\nenjoys.\n\nWe used eak-rails in smaller projects, and intro to Ember courses. In\nsmall doses eak-rails felt right. However, when the surface area of an\napplication increased eak-rails did not scale well. Having your Ember\nand Rails files mixed into the same directories created more problems\nthan it solved.\n\nThis week I will be focusing on how we are building Ember apps\nbacked with Rails at DockYard. Part of that will be in-line with what\nfellow DockYarder [Dan McClain presented at Boston Ember last\nmonth](https://www.youtube.com/watch?v=ceFNLdswFxs&t=1h8m20s).\n\nFor eak-rails users, we have not abandoned you. Anybody refusing to\nmigrate we'll continue any **critical** bug fixes but no new features.\nWe actually sunset the gem about 2 months ago.\n\nember-cli is the future.\n"},{"title":"Preserve scrolling position in Ember Apps","tags":["ember"],"summary":"A simple mixin for your views","legacy":false,"id":"2014/05/05/preserve-scroll-position-in-ember-apps","employee":"Brian Cardarella","date":"2014-05-05T00:00:00","body":"\n\nIf you have a long list of items on a page and a user follows a link\nthen goes back to that list, Ember will re-render the list and the user\nloses their place. This can be annoying if there is a very long list of\nitems and the user is expected to be switching back and forth between\nthe list and the item.\n\nWe can preserve the position by taking advantage of `didInsertElement`\non the list's view.\n\n<a class=\"jsbin-embed\"\nhref=\"http://emberjs.jsbin.com/nevaxipe/2/embed?output\">Ember Starter\nKit</a><script src=\"http://static.jsbin.com/js/embed.js\"></script>\n\n**Note: there seems to be a bug with the latest stable in Chrome where\nthe position is never reset if you hit the backbutton. In reality it is\nbut the position doesn't render until you scroll. Canary seems OK as do\nother browsers**\n\nIn the above example you can scroll down, click on an item, then head\nback to the list and be in your original position. This is all done with\nthe following mixin:\n\n```javascript\nvar ScrollableMixin = Ember.Mixin.create({\n  scrollingTimeout: 100,\n  bindScrolling: function() {\n    var self = this,\n    onScroll = function() {\n      Ember.run.debounce(self, self.runScrolled, self.scrollingTimeout);\n    };\n\n    Ember.$(document).on('touchmove.scrollable', onScroll);\n    Ember.$(window).on('scroll.scrollable', onScroll);\n  }.on('didInsertElement'),\n\n  unbindScrolling: function() {\n    Ember.$(window).off('.scrollable');\n    Ember.$(document).off('.scrollable');\n  }.on('willDestroyElement'),\n\n  preservePos: function() {\n    Ember.$(window).scrollTop(this.getWithDefault('controller.currentPos', 0));\n  }.on('didInsertElement'),\n\n  runScrolled: function() {\n    var position = Ember.$(document).height() - Ember.$(window).scrollTop();\n    var viewportHeight = document.documentElement.clientHeight;\n    this.set('controller.currentPos', Ember.$(window).scrollTop());\n  }\n});\n```\n\nYou then mix it into your list's view:\n\n```javascript\nThingsView = Ember.View.extend(ScrollableMixin);\n```\n\nEnjoy!\n"},{"title":"The other thing DHH mentioned","tags":["ruby","rails","opinion"],"summary":"The Design Pattern Cargo Culting of the Ruby Community","legacy":false,"id":"2014/05/06/the-other-thing-dhh-mentioned","employee":"Brian Cardarella","date":"2014-05-06T00:00:00","body":"\n\nBy now [you've probably seen DHH's Rails Conf 2014 Keynote](http://www.confreaks.com/videos/3315-railsconf-keynote). \nLove it or hate it, the one thing you can't do is deny it got people's attention. I wasn't there, and I admit I reacted to Twitter\nbefore actually viewing it. If you only listened on Twitter your\nperception of the keynote is most likely that DHH is anti-testing. That\nis very far from the truth. Go and watch the video, a lot of what he\ntalks about resonated with me. I still believe in \"testing first\" and\n\"red-green-refactor\" but my style is not as dogmatic as some other's. I\nrely on integration tests quite a bit, and I don't mind hitting the database\nduring unit tests. Slow tests that actually test how clients\nuse your app are much better than fast tests that actually test nothing.\n\nOn a side-note, I would be interested to know what DHH thinks about BDD\nas opposed to TDD, if he even thinks there is a difference. For me I\nfeel there is a distinct difference and I would characterize my style of\ndevelopment as BDD.\n\nBut I don't want to talk about testing. I want to talk about the other\nthing DHH came down on during his keynote: Design Patterns.\n\nNow before I get raked over the coals let me start by saying that\noverall design patterns are great. It was the MVC(ish) and ActiveRecord\npatterns that made Rails itself possible. When we speak in patterns it\nbecomes the lingua franca for programmers. I can jump from language to\nlanguage and can, with relative ease, recognize the patterns.\n\nHowever, in the Ruby/Rails communities we have gone overboard. Design\nPatterns are the new Holy Grail of software development. A few\nyears ago people were very excited about TDD, as DHH said it was sold to\nus as a necessary tool for \"professional software development\". Now that\neverybody just assumes TDD is happening the thought leaders went in\nsearch of the next intellectually challenging concept to hold everyone\naccountable for. This began to spring up maybe 2 years ago, at least\nthat's when I started to notice it. Design pattern talks at conferences, books\ndedicated to design patterns, podcasts talking about patterns, blog\nposts (of which we have written a few), code schools teaching design\npatterns - developers ate them up. The Ruby community was hungry for\npatterns.\n\nThere feels to me a loss of pragmatism in the ruby community. I think\nthis is due to there being no major problems to solve in Rails anymore.\nDevelopers are always looking for problems to solve, and in this case\nthe hive mind has decided to hyper optimize on patterns.\n\nI get it, they are intellectually stimulating. Implementing a pattern to\n\"perfection\" will give a developer that sense of self-satisfaction. \"My\ncode is clean\". Until the next feature comes in and you have to blow up\nwhat you've been perfecting.\n\nBe pragmatic. Don't follow the trends just because some guys behind a\nmicrophone say you should.\n"},{"title":"Building an Ember App with Rails Part 1","tags":["ember","ruby","rails"],"summary":"ember-cli & Rails","legacy":false,"id":"2014/05/07/building-an-ember-app-with-rails-part-1","employee":"Brian Cardarella","date":"2014-05-07T00:00:00","body":"\n*This is a four-part series:\n[Part 1](http://reefpoints.dockyard.com/2014/05/07/building-an-ember-app-with-rails-part-1.html),\n[Part 2](http://reefpoints.dockyard.com/2014/05/08/building-an-ember-app-with-rails-part-2.html),\n[Part 3](http://reefpoints.dockyard.com/2014/05/09/building-an-ember-app-with-rails-part-3.html),\n[Part 4](http://reefpoints.dockyard.com/2014/05/31/building-an-ember-app-with-rails-part-4.html)*\n\nThis series will take us through building and structuring an application\nwith an Ember front-end built with\n[ember-cli](https://github.com/stefanpenner/ember-cli) and a Ruby on\nRails backend. We'll discuss project structure, testing, and deployment\nto Heroku.\n\nDuring the course of this series I am going to re-build the\n[Boston Ember](http://bostonember.com) website. (if it looks terrible\nthat means I'm not done yet)\n\n## Getting setup with our tools\n\nLet's start by making sure all relevant dev tools are installed on our\nmachine. I am using the following:\n\n* Ruby 2.1.1\n* Rails 4.2.0\n* Node 0.12.0\n* npm 2.7.0\n* Postgres (only necessary because we are deploying to Heroku)\n\nVersions at or above these versions should be OK for following along. Please refer elsewhere on how to install these tools on your development\nmachine.\n\nNext I will install ember-cli\n\n```bash\nnpm install -g ember-cli\n```\n\nConfirm that you have `ember-cli` installed:\n\n```bash\nember --version\n```\n\nYou should see:\n\n```bash\nversion: 0.2.0\n```\n\nOr a greater version.\n\n## Setting up our project\n\nFor this project we will keep our Rails and our Ember apps in separate\ndirectories with a top-level directory containing the two. We'll have to\ndo some project generating and renaming.\n\nI first create a new top-level directory:\n\n```bash\nmkdir bostonember\ncd bostonember\n```\n\nNow we're going to generate our Rails project:\n\n```bash\nrails new bostonember -B -S -d postgresql\nmv bostonember rails\n```\n\nNote how we renamed the directory the Rails project is in to `rails`. This\ndoes not affect anything in that directory. If you do not have Postgres\non your machine omit `-d postgresql`\n\nNow the ember project:\n\n```bash\nember new bostonember --skip-git\nmv bostonember ember\n```\n\nNow it should be obvious why we moved the Rails project. We should now have\na structure like:\n\n```\nbostonember\n|- ember\n|- rails\n```\n\nLet's confirm that our ember app runs:\n\n```bash\ncd ember\nember server\n```\n\nIn your browser visit `http://localhost:4200` and you should see \"Welcome to Ember.js\"\n\nAt this point you can put everything in your top level directory under\nversion control:\n\n```bash\ngit init\ngit add .\ngc -m \"Initial commit\"\n```\n\nLet's make some modifications to our Rails app.\n\n```bash\nrm -rf rails/app/assets\n```\n\nIn `rails/Gemfile` remove the following:\n\n* coffee-rails\n* jquery-rails\n* turbolinks\n* jbuilder\n\nNow everything related to the Asset Pipeline is completely removed.\n\nAdd the following to the `Gemfile`:\n\n```ruby\ngem 'active_model_serializers', '0.9.3'\n```\n\nIf you don't have Postgres on your machine you can set this for\nProduction only:\n\n```ruby\ngroup :development, :test do\n  gem 'sqlite3'\nend\n\ngroup :production do\n  gem 'pg'\nend\n```\n\nRun `bundle install` in your `rails` directory. Let's commit our\nchanges:\n\n```bash\ngit add -A\ngc -m \"Removed asset pipeline and added active_model_serializers in Rails\"\n```\n\nThat wraps up Part 1. In [Part 2](http://reefpoints.dockyard.com/2014/05/08/building-an-ember-app-with-rails-part-2.html) will focus on Ember and creating\nsome functionality in our app.\n\n[Check out the actual code for this\npart](https://github.com/bostonember/website/commit/cf2d9e18342979b1c187328c4cf29de16599e61d)\n"},{"title":"Building an Ember App with Rails Part 2","tags":["ember","ruby","rails"],"summary":"Writing our first ember test","legacy":false,"illustration_alt":"Screen 1","illustration":"http://i.imgur.com/bufKV2c.png","id":"2014/05/08/building-an-ember-app-with-rails-part-2","employee":"Brian Cardarella","date":"2014-05-08T00:00:00","body":"\n\n*This is a four-part series:\n[Part 1](http://reefpoints.dockyard.com/2014/05/07/building-an-ember-app-with-rails-part-1.html),\n[Part 2](http://reefpoints.dockyard.com/2014/05/08/building-an-ember-app-with-rails-part-2.html),\n[Part 3](http://reefpoints.dockyard.com/2014/05/09/building-an-ember-app-with-rails-part-3.html),\n[Part 4](http://reefpoints.dockyard.com/2014/05/31/building-an-ember-app-with-rails-part-4.html)*\n\nFrom your project directory root, go to your ember directory and start your server:\n\n```bash\ncd ember\nember server\n```\n\nOpen your browser and go to: `http://localhost:4200/tests`\n\nYou should see something like the following:\n\n![Screen 1](http://i.imgur.com/bufKV2c.png)\n\nThis is a typical [Qunit](http://qunitjs.com/) test suite with some\n[JSHint](http://www.jshint.com/) tests already in our app. What you'll notice in the lower\nright-hand corner is a blank white box. This box is where our\nintegration tests will execute. This is an IFRAME so we can see our\napplications interacted with in real-time (albeit very fast real-time).\n\nLet's build out a landing page for our app. We will TDD this entire\napplication over this multi-part series. Create a new directory and file\n`ember/tests/integration/landing-page-test.js`.\n\nAll of our files will be in\n[ES6\nmodule](http://wiki.ecmascript.org/doku.php?id=harmony:specification_drafts)\nformat. If you are unfamiliar with ES6 modules I suggest you go and read\nup.\n\n```js\nimport Ember from 'ember';\nimport { module, test } from 'qunit';\nimport startApp from '../helpers/start-app';\n\nvar App;\n\nmodule('Integration - Landing Page', {\n  beforeEach: function() {\n    App = startApp();\n  },\n  afterEach: function() {\n    Ember.run(App, 'destroy');\n  }\n});\n\ntest('Should welcome me to Boston Ember', function(assert) {\n  visit('/').then(function() {\n    assert.equal(find('h2#title').text(), 'Welcome to Boston Ember');\n  });\n});\n```\n\nOnce you save this file go back to your browser. You should not need to reload anything, ember-cli has a live reload feature on file\nchange. Now you should see your failing test:\n\n![Screen2](http://i.imgur.com/l7y146I.png)\n\nLet's make the test pass:\n\nIn `ember/app/templates/application.hbs`\n\n```hbs\n<h2 id=\"title\">Welcome to Boston Ember</h2>\n{{outlet}}\n```\n\nCheck your test suite and it should be all green.\n\n![Screen3](http://i.imgur.com/242RLGf.png)\n\nCongratulations on your first ember test!\n\nIn [part 3](http://reefpoints.dockyard.com/2014/05/09/building-an-ember-app-with-rails-part-3.html) we'll build out some pages and write tests to interact with\nthese pages.\n\n[Check out the actual code for this\npart](https://github.com/bostonember/website/commit/b17a67b9368acec29c88f4aaa83eceb82a9f143d)\n"},{"title":"Building an Ember App with Rails Part 3","tags":["ember","ruby","rails"],"summary":null,"legacy":false,"illustration_alt":"Screen1","illustration":"http://i.imgur.com/dcdkJDo.png","id":"2014/05/09/building-an-ember-app-with-rails-part-3","employee":"Brian Cardarella","date":"2014-05-09T00:00:00","body":"\n\n*This is a four-part series:\n[Part 1](http://reefpoints.dockyard.com/2014/05/07/building-an-ember-app-with-rails-part-1.html),\n[Part 2](http://reefpoints.dockyard.com/2014/05/08/building-an-ember-app-with-rails-part-2.html),\n[Part 3](http://reefpoints.dockyard.com/2014/05/09/building-an-ember-app-with-rails-part-3.html),\n[Part 4](http://reefpoints.dockyard.com/2014/05/31/building-an-ember-app-with-rails-part-4.html)*\n\nLet's implement some navigation in the Boston Ember app.\n\nHere is a list of sections in the Boston Ember website I'd like to add:\n\n* About\n* Speakers\n\nFor this part we will work with faked out data. In a future part we will\nprovide the Rails backend.\n\nOur first navigation test will be an easy one, create\n`ember/tests/integration/about-page-test.js`\n\n```js\nimport Ember from 'ember';\nimport startApp from 'bostonember/tests/helpers/start-app';\n\nvar App;\n\nmodule('Integration - About Page', {\n  beforeEach: function() {\n    App = startApp();\n  },\n  afterEach: function() {\n    Ember.run(App, 'destroy');\n  }\n});\n\ntest('Should navigate to the About page', function() {\n  visit('/').then(function(assert) {\n    click(\"a:contains('About')\").then(function(assert) {\n      assert.equal(find('h3').text(), 'About');\n    });\n  });\n});\n```\n\nAfter writing this test we can confirm that our test is red in our browser. To make this green we need to add an `About` route, \na link from the landing page to the `About` route, and a template for the\n`About` route.\n\n```js\n// ember/app/router.js\nRouter.map(function() {\n  this.route('about');\n});\n```\n\n```js\n// ember/app/templates/application.hbs\n<h2 id=\"title\">Welcome to Boston Ember</h2>\n\n{{link-to 'About' 'about'}}\n\n{{outlet}}\n```\n\n```js\n// ember/app/templates/about.hbs\n<h3>About</h3>\n\n<p>Boston Ember is the monthly meetup where awesome people get together\nto do awesome Ember related things!</p>\n```\n\nYour test should now be green. If you navigate to the root path in your\nbrowser you should be able to click through the app. What about getting\nback to root? We can add a test to for this navigation as well.\n\n\n```js\n// ember/tests/integration/landing-page-test.js\ntest('Should allow navigating back to root from another page', function(assert) {\n  visit('/about').then(function() {\n    click('a:contains(\"Home\")').then(function(assert) {\n      assert.notEqual(find('h3').text(), 'About');\n    });\n  });\n});\n```\n\n```js\n// ember/app/templates/application.hbs\n{{link-to 'Home' 'application'}}\n{{link-to 'About' 'about'}}\n```\n\nGreat! A very simple navigation is setup and fully tested. How about something\nmore complex. Let's allow our visitors to see the people that have spoken at\nBoston Ember. Before we do that we need to add new dependencies to our app for\nmocking out remote requests.\n\nWe will be using\n[Pretender](https://github.com/trek/pretender/tree/0.0.5) by Ember Core\nmember Trek Glowacki. Pretender is a nice DSL for faking out remote\nresponses.\n\nWe can use the\n[ember-cli-pretender](https://github.com/rwjblue/ember-cli-pretender)\nEmber CLI Addon to quickly set up Pretender:\n\n```js\nnpm install --save-dev ember-cli-pretender\nember install:addon ember-cli-pretender\n```\n\nYou may need to restart your server at this point.\n\nTell `JSHint` to ignore the `Pretender` constant.  Open up\n`ember/tests/.jshintrc` and add `\"Pretender\"` to the end of the `\"predef\"`\narray.\n\nFinally we need ember-data to make requests namespaced under `api` to\nour server:\n\n```js\n// ember/app/adapters/application.js\nimport DS from 'ember-data';\n\nexport default DS.ActiveModelAdapter.extend({\n  namespace: 'api'\n});\n```\n\nWe should be in a good place to write our tests.\n\n```js\n// ember/tests/integration/speakers-page-test.js\nimport Ember from 'ember';\nimport startApp from '../helpers/start-app';\nimport Pretender from 'pretender';\n\nvar App, server;\n\nmodule('Integration - Speaker Page', {\n  beforeEach: function() {\n    App = startApp();\n    var speakers = [\n      {\n        id: 1,\n        name: 'Bugs Bunny'\n      },\n      {\n        id: 2,\n        name: 'Wile E. Coyote'\n      },\n      {\n        id: 3,\n        name: 'Yosemite Sam'\n      }\n    ];\n\n    server = new Pretender(function() {\n      this.get('/api/speakers', function(request) {\n        return [200, {\"Content-Type\": \"application/json\"}, JSON.stringify({speakers: speakers})];\n      });\n\n      this.get('/api/speakers/:id', function(request) {\n        var speaker = speakers.find(function(speaker) {\n          if (speaker.id === parseInt(request.params.id, 10)) {\n            return speaker;\n          }\n        });\n\n        return [200, {\"Content-Type\": \"application/json\"}, JSON.stringify({speaker: speaker})];\n      });\n    });\n\n  },\n  afterEach: function() {\n    Ember.run(App, 'destroy');\n    server.shutdown();\n  }\n});\n\ntest('Should allow navigation to the speakers page from the landing page', function(assert) {\n  visit('/').then(function() {\n    click('a:contains(\"Speakers\")').then(function(assert) {\n      assert.equal(find('h3').text(), 'Speakers');\n    });\n  });\n});\n\ntest('Should list all speakers', function(assert) {\n  visit('/speakers').then(function() {\n    assert.equal(find('a:contains(\"Bugs Bunny\")').length, 1);\n    assert.equal(find('a:contains(\"Wile E. Coyote\")').length, 1);\n    assert.equal(find('a:contains(\"Yosemite Sam\")').length, 1);\n  });\n});\n\ntest('Should be able to navigate to a speaker page', function(assert) {\n  visit('/speakers').then(function() {\n    click('a:contains(\"Bugs Bunny\")').then(function() {\n      assert.equal(find('h4').text(), 'Bugs Bunny');\n    });\n  });\n});\n\ntest('Should be able visit a speaker page', function(assert) {\n  visit('/speakers/1').then(function() {\n    assert.equal(find('h4').text(), 'Bugs Bunny');\n  });\n});\n```\n\nTake a look at the `beforeEach` function. There is an array of objects that contains the speaker data, currently only `id`s and `name`s.\nBelow that we are setting up the request stubs. Currently this feels\nlike a lot of boilerplate, and that is because it is. I'm sure\neventually someone will write a nice abstraction to clean this up. This\ncode simply stubs out the expected server-side calls and returns a JSON\nstring in the format ember-data expects.\n\nOur four tests are very simple. The first tests the navigation, the 2nd\ntests the speakers are in the list, the 3rd tests that we can navigate\nto an individual speaker, and the 4th tests that we can visit the speaker page directly.\n\nLet's make each pass:\n\n```js\n// ember/app/router.js\nRouter.map(function() {\n  this.route('about');\n  this.resource('speakers');\n});\n```\n\n```hbs\n// ember/app/templates/application.hbs\n{{link-to 'About' 'about'}}\n{{link-to 'Speakers' 'speakers'}}\n```\n\n```hbs\n// ember/app/templates/speakers.hbs\n<h3>Speakers</h3>\n\n{{outlet}}\n```\n\nThe first test should now be passing.\n\n```js\n// ember/app/router.js\nRouter.map(function() {\n  this.route('about');\n  this.resource('speakers', function() {\n    this.route('show', {path: ':speaker_id'});\n  });\n});\n```\n\n```js\n// ember/app/models/speaker.js\nimport DS from 'ember-data';\n\nexport default DS.Model.extend({\n  name: DS.attr('string')\n});\n```\n\n```js\n// ember/app/routes/speakers/index.js\nimport Ember from 'ember';\n\nexport default Ember.Route.extend({\n  model: function() {\n    return this.store.find('speaker');\n  }\n});\n```\n\n```hbs\n// ember/app/templates/speakers/index.hbs\n{{#each}}\n  {{link-to name 'speakers.show' this}}\n{{/each}}\n```\n\nThe 2nd test should now be passing.\n\n```hbs\n// ember/app/templates/speakers/show.hbs\n<h4>{{name}}</h4>\n```\n\nThe 3rd & 4th tests should now be passing.\n\nPassing tests are great and all, but let's actually make the app useable by getting our Rails backend\nin the game. \n\nLet's generate a model from our Rails app `rails g model speaker name:string`\n\nAdd some seed data:\n\n```ruby\n# rails/db/seeds.rb\nSpeaker.create(name: 'Bugs Bunny')\nSpeaker.create(name: 'Wile E. Coyote')\nSpeaker.create(name: 'Yosemite Sam')\n```\n\nCreate, migrate and seed `rake db:create db:migrate db:seed`.\n\nAdd a `speakers` resource under an `api` namespace:\n\n```ruby\n# rails/config/routes.rb\nnamespace :api do\n  resources :speakers\nend\n```\n\nNow add the controller:\n\n```ruby\n# rails/app/controllers/api/speakers_controller.rb\nclass Api::SpeakersController < ApplicationController\n  def index\n    render json: Speaker.all\n  end\n\n  def show\n    render json: Speaker.find(params[:id])\n  end\nend\n```\n\nFinally we need to generate a serializer `rails g serializer speaker`.\n\nAdd `name` to the list of attributes to serialize\n\n```ruby\nclass SpeakerSerializer < ActiveModel::Serializer\n  attributes :id, :name\nend\n```\n\nStart your Rails server with port `3000` and restart your ember server with the command \n`ember server --proxy http://localhost:3000`\n\nAny remote requests will be proxied to this location.\n\nNow you can point\nyour browser to `http://localhost:4200`, click on `Speakers` and you\nshould see:\n\n![Screen1](http://i.imgur.com/dcdkJDo.png)\n\nThat wraps up Part 3. In [Part 4](http://reefpoints.dockyard.com/2014/05/31/building-an-ember-app-with-rails-part-4.html) we will get into relationships.\n\n[Check out the actual code for this\npart](https://github.com/bostonember/website/commit/a21e06a9a29b19d405e50268a6d276b8db758261)\n"},{"title":"Avoid Rails When Generating JSON responses with PostgreSQL","tags":["ruby","rails","postgres","postgres_ext"],"summary":"Let's use PostgreSQL instead of Ruby to generate JSON responses","legacy":false,"id":"2014/05/27/avoid-rails-when-generating-json-responses-with-postgresql","employee":"Dan McClain","date":"2014-05-27T00:00:00","body":"\n\nWhat if I told you that you could generate the following JSON response\nin PostgreSQL?\n\n```json\n{\n  \"tags\":[\n    {\"id\":1,\"name\":\"Tag #0\",\"note_id\":1},\n    {\"id\":1001,\"name\":\"Tag #1000\",\"note_id\":1},\n    {\"id\":2001,\"name\":\"Tag #2000\",\"note_id\":1},\n    ...\n  ],\n  \"notes\":[\n    {\n      \"id\":1,\n      \"title\":\"Note #0\",\n      \"content\":\"Lorem ipsum...\",\n      \"tag_ids\":[9001,8001,7001,6001,5001,4001,3001,2001,1001,1]\n    },\n    {\n      \"id\":2,\n      \"title\":\"Note #1\",\n      \"content\":\"Lorem ipsum...\",\n      \"tag_ids\":[9002,8002,7002,6002,5002,4002,3002,2002,1002,2]\n    }\n  ]\n}\n```\n\nWhat if I told you that it is over 10X faster than plain [ActiveModel::Serializers](https://github.com/rails-api/active_model_serializers/)\nfor small data sets, and 160X faster for larger data sets?\n\nTypically when you have an API serving up JSON responses, your web\nframework serializes your data after retrieving it with its ORM. We'll\ntalk about Rails specifically in this article, but this will generally\napply to most frameworks. So the typical Rails request will roughly\nfollow this flow (I am purposely brushing over some parts of the request\nresponse cycle):\n\n  1. Rails receives the JSON request from the browser/client\n  2. Rails will apply some business logic and craft a query via\n     ActiveRecord\n  3. ActiveRecord serializes its query and sends the query to PostgreSQL\n  4. PostgreSQL will compile the result set and serializes the records\n     in its protocol format\n  5. ActiveRecord deserializes the records into a set of rows object\n  6. ActiveRecord will convert the set of rows into a set of model\n     object instances\n  7. Rails will convert the set of models objects into a JSON string\n  8. Rails will send the JSON string down to the browser\n\nMost of the time in this response cycle is spent in steps 6 and 7. Rails\nhas to deserialize one format, then store that deserialized content in\nmemory just to serialize it in a different format. Since [PostgreSQL\nsupports JSON responses](http://www.postgresql.org/docs/current/static/datatype-json.html),\nwe can use its [JSON functions](http://www.postgresql.org/docs/current/static/functions-json.html) to\nserialized our result set. That JSON response will still be serialized\nin PostgreSQL's protocol format, but ActiveRecord can deserialize it as\na single string object, instead of a set of objects which it then\nconverts and reserializes. We end up having this response cycle instead:\n\n  1. Rails receives the JSON request from the browser/client\n  2. Rails will apply some business logic and craft a query via\n     ActiveRecord\n  3. ActiveRecord serializes its query and sends the query to PostgreSQL\n  4. PostgreSQL will compile the result set, serializes it as JSON then \n     serializes the JSON in its protocol format\n  5. ActiveRecord deserializes the protocal format into a single JSON\n     string\n  6. Rails will send the JSON string down to the browser\n\nWe are only removing 2 steps, but it is the bulk of the time spent\ngenerating the response. We are also limiting the number of ruby objects\ncreated, so this reduces memory usage and time spent garbage collecting\nshort lived Ruby objects used only for JSONification.\n\n# What Do We Gain by Generating Massive Queries for PostgreSQL\n\nIt takes a lot of work to tell PostgreSQL to generate a specific\nJSON object; what exactly does that buy us?\nBy doing all this in PostgreSQL, we avoid using CPU cycles\nand memory on our web server. I've done some very naive and basic\ntesting with a new, unoptimized Rails project, and a database of 1000\nnotes, each have 10 unique tags, totalling 10000 tags. When retrieving\nall 11000 records with Rails and [ActiveModel::Serializers](https://github.com/rails-api/active_model_serializers), it took\nroughly 9 seconds to generate the request. Most of the time was spent\nin the View generating the JSON object in memory, with 657 milliseconds\nin ActiveRecord, which (I think until someone tells me otherwise)\nincludes creating all the model instances.\n\nWhen we apply the PostgreSQL technique outlined later in this article to the\nsame result set, the response only takes 72 milliseconds for the first\nrequest. If we rerun this same request, PostgreSQL caching kicks in and\nthe response time is 54 milliseconds. That is a **~160X** throughput\nincrease when we use PostgreSQL to generate JSON payloads.\n\nThe above numbers are a bit skewed by the size of this test payload.\n11000 objects would be completely crazy to present to an end user. If we\npare back our result set 10 notes and 100 tags, the first and second\nresponse times for Ruby side JSONification  are 187 and 118 milliseconds.\nWhen using PostgreSQL to generate our JSON payload, the response times\nare 92 and 12 milliseconds. That is a **2X/10X** increase. By utilizing\nPostgreSQL, we can increase our applications' response times and\nthroughput.\n\n# Announce PostgresExt-Serializers\n\nTo utilize PostgreSQL, we have to generate a fairly complex query\nmanually. That is, until you include the [PostgresExt-Serializers](https://github.com/dockyard/postgres_ext-serializers)\ngem into the project. PostgresExt-Serializers (PES) monkey\npatches ActiveModel::Serializers (AMS),\nand anywhere an ActiveRecord::Relation is serialized by AMS, PES will\ntake over and push the work to PostgreSQL. I wanted to use the awesome\nwork of AMS's DSL for generating JSON schemas without having to duplicate\nthat work. I am finding some pain points in terms of extracting the\ninformation I need to generate the SQL query from AMS, but right now the\ncode for PES is very immature, hence the 0.0.1 release.\n\n# Nitty-Gritty Details About How it All Works: Massive PostgreSQL Queries\n\nLet's say we have an Ember application that we are generating the JSON\nrequest for. The Ember app wants the list of notes, along with the tags\nassociated with the notes, and we will side load the tags. Side loading\nallows you to specify the ids of the tags on the note, and then include\na list of tags, which will be used to instantiate the tags on the note.\nThe benefit of side loading is that it allows you to save bandwidth by\nuse tag ids and an array of de-duplicated tags, instead of embedding the\nduplicate tags objects under the notes, where you would have to duplicate\nthe tag objects. We only want notes with `id < 40`, which is arbitrary\nin this example, but, as we will see, has implications on the query we\nneed to execute.\n\nHere is the whole query we need to generate the JSON required, which is\nalso the example JSON at the beginning of this article:\n\n```sql\n-- Note Ids\nWITH notes_ids AS (\n  SELECT id\n  FROM \"notes\"\n  WHERE \"notes\".\"id\" < 40\n),\n-- Tag Ids grouped by note id\ntag_ids_by_notes AS (\n  SELECT \"tags\".\"note_id\", array_agg(\"tags\".\"id\") AS tag_ids\n  FROM \"tags\"\n  GROUP BY \"tags\".\"note_id\"\n  HAVING \"tags\".\"note_id\" IN (\n    SELECT \"notes_ids\".\"id\"\n    FROM \"notes_ids\"\n  )\n),\n-- Tag records\ntags_attributes_filter AS (\n  SELECT \"tags\".\"id\", \"tags\".\"name\", \"tags\".\"note_id\"\n  FROM \"tags\"\n  WHERE \"tags\".\"note_id\" IN (\n    SELECT \"notes_ids\".\"id\"\n    FROM \"notes_ids\"\n  )\n),\n-- Tag records as a JSON array\ntags_as_json_array AS (\n  SELECT array_to_json(array_agg(row_to_json(tags_attributes_filter)))\nAS tags, 1 AS match\n  FROM \"tags_attributes_filter\"\n),\n-- Note records\nnotes_attributes_filter AS (\n  SELECT \"notes\".\"id\", \"notes\".\"content\", \"notes\".\"name\",\ncoalesce(\"tag_ids_by_notes\".\"tag_ids\", '{}'::int[]) AS tag_ids\n  FROM \"notes\"\n  LEFT OUTER JOIN \"tag_ids_by_notes\"\n  ON \"notes\".\"id\" = \"tag_ids_by_notes\".\"note_id\"\n  WHERE \"notes\".\"id\" < 40\n),\n-- Note records as a JSON array\nnotes_as_json_array AS (\n  SELECT array_to_json(array_agg(row_to_json(notes_attributes_filter)))\nAS notes, 1 AS match\n  FROM \"notes_attributes_filter\"\n),\n-- Notes and tags together as one JSON object\njsons AS (\n  SELECT \"tags_as_json_array\".\"tags\", \"notes_as_json_array\".\"notes\"\n  FROM \"tags_as_json_array\"\n  INNER JOIN \"notes_as_json_array\"\n  ON \"tags_as_json_array\".\"match\" = \"notes_as_json_array\".\"match\"\n)\nSELECT row_to_json(jsons) FROM \"jsons\";\n```\n\nLet's break it down. You'll notice that I am making use of [Common Table\nExpressions (CTEs)](http://www.postgresql.org/docs/9.3/static/queries-with.html). CTEs allow you to use temporary table definitions\nin queries instead of embedding the subqueries directly in your query.\n\n## Gathering our Note Ids\n\nThe first important step is getting the note ids of our final result\nset, which we do with:\n\n```sql\nWITH notes_ids AS (\n  SELECT id\n  FROM \"notes\"\n  WHERE \"notes\".\"id\" < 40\n),\n```\nWe are creating a CTE that represents the ids for our notes, we'll be\nusing this extensively to generate our tag related records.\n\n## Getting Tag Ids Grouped by Note Ids\n\nFrom our `note_ids`, we can assemble a list of tag ids grouped by notes.\nThis will be used to create the `tag_ids` attribute on the notes later\non.\n\n```sql\ntag_ids_by_notes AS (\n  SELECT \"tags\".\"note_id\", array_agg(\"tags\".\"id\") AS tag_ids\n  FROM \"tags\"\n  GROUP BY \"tags\".\"note_id\"\n  HAVING \"tags\".\"note_id\" IN (\n    SELECT \"notes_ids\".\"id\"\n    FROM \"notes_ids\"\n  )\n),\n```\n\nOur projection is the `note_id`, plus an [`array_agg`](http://www.postgresql.org/docs/9.3/static/functions-aggregate.html) of the id of the\ntags in our grouping. `array_agg` aggregates the group into an array.\nThis projection will return the following:\n\n```text\nnote_id | tag_ids\n=================\n      1 | [1,2]\n      2 | [1,3]\n```\n\nIn this example, the tags `belong_to` a note, so we are retrieving this\ndata from the `tags` table. If this was a many-to-many relation, this\nquery would execute against the join table (i.e. `notes_tags`).\n\nWe group our tags by the `note_id`, and we use the `HAVING` clause to\nonly group tags which have a `note_id` contained in the `note_ids` CTE\nthat we created at the beginning.\n\n## Generating Our Note Records\n\nMost of the time, we don't want to expose all of our record data to\nEmber, since whatever we send to the client will be accessible by the\nuser, whether we intend it to be or not. We filter down the attributes\nsent to Ember by limiting the columns in our projection.\n\n```sql\nnotes_attributes_filter AS (\n  SELECT \"notes\".\"id\", \"notes\".\"content\", \"notes\".\"name\",\ncoalesce(\"tag_ids_by_notes\".\"tag_ids\", '{}'::int[]) AS tag_ids\n  FROM \"notes\"\n  LEFT OUTER JOIN \"tag_ids_by_notes\"\n  ON \"notes\".\"id\" = \"tag_ids_by_notes\".\"note_id\"\n  WHERE \"notes\".\"id\" < 40\n),\n```\n\nAlso note that in the projection, we are using [`coalesce`](http://www.postgresql.org/docs/9.3/static/functions-conditional.html#FUNCTIONS-COALESCE-NVL-IFNULL)\nto ensure that we return an empty array if a specific note has no `tag_ids`.\nWe are using a [`LEFT OUTER JOIN`](http://www.postgresql.org/docs/9.3/static/queries-table-expressions.html#QUERIES-JOIN) to combine our previously generated\ntag id groupings with our notes. We use an `OUTER JOIN` instead of an\n[`INNER JOIN`](http://www.postgresql.org/docs/9.3/static/queries-table-expressions.html#QUERIES-JOIN) so that all our notes are returned, even if no tags are\nassociated with it. An `INNER JOIN` would only return notes that have\ntags associated with it. We also use the same `WHERE` predicate in this\nquery as we did in the `note_ids` CTE, to ensure our query only returns\nthe desired records.\n\n## Turning Our Note Records into a Single JSON Array\n\nSo now that we have our notes records filtered down, we need to create a\nJSON array of these records to use in our final query. At this point, we\nwill use two of PostgreSQL's [JSON functions](http://www.postgresql.org/docs/current/static/functions-json.html) and the `array_agg`\nfunction that we used earlier. `row_to_json` takes a PostgreSQL row and\nconverts it to a JSON object, where the columns of the row converted\ninto JSON properties.\n\n```text\nfoo | bar\n=========\n  1 |   2\n```\n\nWill be converted to\n\n```text\n     json\n================\n{ foo: 1, bar: 2 }\n```\n\nSo at this point, our result set is a series of rows with a single\ncolumn of JSON representing the original PostgreSQL row from our\n`notes_attribute_filter` CTE. We then use `array_agg` to turn the\nrows of JSON objects into a single row with a single PostgreSQL\nArray of JSON objects.\n\n```text\n     json\n================\n{ foo: 1, bar: 2 }\n{ foo: 1, bar: 2 }\n{ foo: 1, bar: 2 }\n```\n\nwill be converted to\n\n```text\n                    Array\n=======================================================\n{{ foo: 1, bar: 2 },{ foo: 1, bar: 2 },{ foo: 1, bar: 2 }}\n```\n\nLastly, we use `array_to_json` to convert the PostgreSQL array of JSON to a JSON array.\n\nAfter  combining these pieces, we get the following query:\n\n```sql\nnotes_as_json_array AS (\n  SELECT array_to_json(array_agg(row_to_json(notes_attributes_filter)))\nAS notes, 1 AS match\n  FROM \"notes_attributes_filter\"\n),\n```\n\nwhich yields\n\n```text\n    notes    | match\n====================\n[{},{},{},{}]|     1\n```\n\nWe are using the `notes_attributes_filter` as our source for all the\nJSON functions, and adding a column `match` with a value of `1`, which\nwe will need later.\n\n## Aggregating Our Tag Records\n\nWe apply the attribute filtering and the aggregation techniques to our\n`tags` table to generate our JSON array of tags. Note that when we\nfilter the tags attributes, we only include tags that have a `note_id`\nof a note we are returning.\n\n```sql\ntags_attributes_filter AS (\n  SELECT \"tags\".\"id\", \"tags\".\"name\", \"tags\".\"note_id\"\n  FROM \"tags\"\n  WHERE \"tags\".\"note_id\" IN (\n    SELECT \"notes_ids\".\"id\"\n    FROM \"notes_ids\"\n  )\n),\n\ntags_as_json_array AS (\n  SELECT array_to_json(array_agg(row_to_json(tags_attributes_filter)))\nAS tags, 1 AS match\n  FROM \"tags_attributes_filter\"\n),\n```\n\nwhich yields\n\n```text\n    tags     | match\n====================\n[{},{},{},{}]|     1\n```\n\n## Combining Our Notes and Tags\n\nSo at this point, we have 2 CTEs that represent our notes and tags. We\nneed to combine these two tables into a single row, so that we can convert\nthat row to a JSON object with a `notes` and `tags` property. This is\nthe reason we added a `match` column onto both CTEs; we join those two\ntable into our final table, which we then call `row_to_json` on to get\nour final JSON object, which mirrors the example at the beginning of\nthis article.\n\n```sql\njsons AS (\n  SELECT \"tags_as_json_array\".\"tags\", \"notes_as_json_array\".\"notes\"\n  FROM \"tags_as_json_array\"\n  INNER JOIN \"notes_as_json_array\"\n  ON \"tags_as_json_array\".\"match\" = \"notes_as_json_array\".\"match\"\n)\nSELECT row_to_json(jsons) FROM \"jsons\";\n```\n\nSo there you have it, you could generate this giant query by hand every\ntime you need to create an API endpoint, or you could use ActiveModel::Serializers\nand utilize the PostgresExt-Seriliazers optimizations to avoid Ruby and\nRails when generating API responses.\n"},{"title":"Building an Ember App with Rails Part 4","tags":["ember","ruby","rails"],"summary":null,"legacy":false,"illustration_alt":"image1","illustration":"http://i.imgur.com/jmHGxgS.png","id":"2014/05/31/building-an-ember-app-with-rails-part-4","employee":"Brian Cardarella","date":"2014-05-31T00:00:00","body":"\n\n*This is a four-part series:\n[Part 1](http://reefpoints.dockyard.com/2014/05/07/building-an-ember-app-with-rails-part-1.html),\n[Part 2](http://reefpoints.dockyard.com/2014/05/08/building-an-ember-app-with-rails-part-2.html),\n[Part 3](http://reefpoints.dockyard.com/2014/05/09/building-an-ember-app-with-rails-part-3.html),\n[Part 4](http://reefpoints.dockyard.com/2014/05/31/building-an-ember-app-with-rails-part-4.html)*\n\nBefore we get underway we need to update ember-data in our project to at\nleast `1.0.0-beta.8`. Open `ember/bower.json` and if you have any version\nless than 8 you'll need to update to at least 8. If you are already on 8\nor higher you won't need to do anything.\n\nOnce you've made the change save the file and run `bower install` from\nthe `ember/` directory. If you are asked to choose between different\nversions of ember-data make sure you choose the correct one.\n\nIn this part we'll add Presentations to each of the Speaker pages. This\nmeans we'll have to add a relationship between two models.\n\nIn `ember/tests/integration/speakers-page-test.js` modify the test\n\"Should list all speakers and number of presentations\"\n\n```javascript\n// ember/tests/integration/speaker-page-test.js\n\ntest('Should list all speakers and number of presentations', function() {\n  visit('/speakers').then(function(assert) {\n    assert.equal(find('a:contains(\"Bugs Bunny (2)\")').length, 1);\n    assert.equal(find('a:contains(\"Wile E. Coyote (1)\")').length, 1);\n    assert.equal(find('a:contains(\"Yosemite Sam (3)\")').length, 1);\n  });\n});\n```\n\nThe number in the parentheses will represent the number of presentations that this speaker \nhas given.\n\nNext we need to modify our `beforeEach` function\n\n```javascript\n// ember/tests/integration/speaker-page-test.js\n\nvar speakers = [\n  { id: 1, name: 'Bugs Bunny', presentation_ids: [1,2] },\n  { id: 2, name: 'Wile E. Coyote', presentation_ids: [3] },\n  { id: 3, name: 'Yosemite Sam', presentation_ids: [4,5,6] }\n];\n\nvar presentations = [\n  { id: 1, title: \"What's up with Docs?\", speaker_id: 1 },\n  { id: 2, title: \"Of course, you know, this means war.\", speaker_id: 1 },\n  { id: 3, title: \"Getting the most from the Acme categlog.\", speaker_id: 2 },\n  { id: 4, title: \"Shaaaad up!\", speaker_id: 3 },\n  { id: 5, title: \"Ah hates rabbits.\", speaker_id: 3 },\n  { id: 6, title: \"The Great horni-todes\", speaker_id: 3 }\n];\n\nserver = new Pretender(function() {\n  this.get('/api/speakers', function(request) {\n    return [200, {\"Content-Type\": \"application/json\"}, JSON.stringify({speakers: speakers, presentations: presentations})];\n  });\n\n  this.get('/api/speakers/:id', function(request) {\n    var speaker = speakers.find(function(speaker) {\n      if (speaker.id === parseInt(request.params.id, 10)) {\n        return speaker;\n      }\n    });\n\n    return [200, {\"Content-Type\": \"application/json\"}, JSON.stringify({speaker: speaker, presentations: presentations})];\n  });\n});\n```\n\nCompletely replace the `speakers` variable that was previously there. The only change to the API stub is that\n`presentations` is being added to the payload. The JSON here is the\nstyle of JSON that ember-data expects to be emitted. We are returning a\npayload that includes all speakers and presentations. The speaker\nrecords include ids referencing the presentations associated.\n\nWe can now add the Presentation model to our Ember app:\n\n```javascript\n// ember/app/models/presentation.js\nimport DS from 'ember-data';\n\nexport default DS.Model.extend({\n  title: DS.attr('string'),\n  speaker: DS.belongsTo('speaker')\n}); \n```\n\nWe've told ember-data to expect the Presentation model to belong to the\nSpeaker model. Let's set the inverse relationship\n\n```javascript\n// ember/app/models/speaker.js\nimport DS from 'ember-data';\n\nexport default DS.Model.extend({\n  name: DS.attr('string'),\n  presentations: DS.hasMany('presentation')\n});\n```\n\nModifying our existing Speaker model to add to relationship to its many\nPresentation models.\n\nFinally to make this tests green we need to change our template:\n\n```handlebars\n// ember/app/templates/speakers/index.hbs\n\n{{#each}}\n {{~#link-to 'speakers.show' this}}\n   {{name}} ({{presentations.length}})\n {{~/link-to}}\n{{/each}}\n```\n\nNotice that we we can call regular JavaScript properties like `length` on the association.\nThere is also a slight change that I've made to the `link-to`. Adding\n`~` will [tell Handlebars how to control\nwhitespace](http://handlebarsjs.com/block_helpers.html#whitespace-control).\n\nAt this point our new test should be green. Lets add another.\n\n```javascript\n// ember/tests/integration/speaker-page-test.js\n\ntest('Should list all presentations for a speaker', function(assert) {\n  visit('/speakers/1').then(function(assert) {\n    assert.equal(find('li:contains(\"What\\'s up with Docs?\")').length, 1);\n    assert.equal(find('li:contains(\"Of course, you know, this means war.\")').length, 1);\n  });\n});\n```\n\nThis new test is asserting that when we visit a given speaker's page all\nof those speaker's presentations will be listed. We first need to add\npresentation data to the API stub (within our `beforeEach` function) for visiting a speaker page.\n\n```javascript\n// ember/tests/integration/speaker-page-test.js\n\nthis.get('/api/speakers/:id', function(request) {\n  var speaker = speakers.find(function(speaker) {\n    if (speaker.id === parseInt(request.params.id, 10)) {\n      return speaker;\n    }\n  });\n\n  var speakerPresentations = presentations.filter(function(presentation) {\n    if (presentation.speaker_id === speaker.id) {\n      return true;\n    }\n  });\n\n  return [200, {\"Content-Type\": \"application/json\"}, JSON.stringify({speaker: speaker, presentations: speakerPresentations})];\n});\n```\n\nThis modification of the previously existing stub will build a new payload object that\nincludes the speaker matching the id requested and all of the\npresentations specific to that speaker.\n\nTying up this test is easy now, we just modify the Speaker's `show`\ntemplate:\n\n```handlebars\n<h4>{{name}}</h4>\n\n<h5>Presentations</h5>\n<ul>\n  {{#each presentations}}\n    <li>{{title}}</li>\n  {{/each}}\n</ul>\n```\n\nNow that we have a green test suite with our mocked out API let's add the\nreal Rails endpoint. We'll start by generating a new Presentation model.\nChange to the `rails/` directory in your project and run `rails generate\nmodel presentation title:string speaker_id:integer`.\n\nNext we'll generate the serializer: `rails generate serializer\npresentation`.\n\nLet's expand upon the `rails/db/seeds.rb` file:\n\n```ruby\n# rails/db/seeds.rb\n\nbugs = Speaker.create(name: 'Bug Bunny')\nwile = Speaker.create(name: 'Wile E. Coyote')\nsam  = Speaker.create(name: 'Yosemite Sam')\n\nbugs.presentations.create(title: \"What's up with Docs?\")\nbugs.presentations.create(title: \"Of course, you know, this means war.\")\n\nwile.presentations.create(title: \"Getting the most from the Acme categlog.\")\n\nsam.presentations.create(title: \"Shaaaad up!\")\nsam.presentations.create(title: \"Ah hates rabbits.\")\nsam.presentations.create(title: \"The Great horni-todes\")\n```\n\nTell our `Speaker` model that there is a relationship to `Presentation`\nmodels:\n\n```ruby\n# rails/app/models/speaker.rb\n\nclass Speaker < ActiveRecord::Base\n  has_many :presentations\nend\n```\n\nFinally we need to modify the serializers.\n\n```ruby\n# rails/app/serializers/presentation_serializer.rb\n\nclass PresentationSerializer < ActiveModel::Serializer\n  attributes :id, :title\nend\n```\n\n```ruby\n# rails/app/serializers/speaker_serializer.rb\n\nclass SpeakerSerializer < ActiveModel::Serializer\n  embed :ids, include: true\n\n  attributes :id, :name\n  has_many :presentations\nend\n```\n\nIn the `SpeakerSerializer` we have instructed the serializer to include\nthe associated `Presentation`s.\n\nLet's reset the database and re-seed `rake db:drop db:create db:migrate db:seed`\n\nMake sure you are running your Ember server with the proxy enabled:\n`ember server --proxy http://localhost:3000`\n\nNow you can hit your application and you should have a all of the\nnecessary data. \n\n![image1](http://i.imgur.com/jmHGxgS.png)\n![image2](http://i.imgur.com/plrKLvg.png)\n\n[Check out the actual code for this\npart](https://github.com/bostonember/website/commit/10f838ff1bfb0aa1307d4de6587889489697c8da)\n"},{"title":"The Process Paradox","tags":["process","agile"],"summary":null,"legacy":false,"id":"2014/06/06/process-paradox","employee":"Jon Lacks","date":"2014-06-06T00:00:00","body":"\n\nIf it feels like process, it is not working… It should feel like a logical means to achieve an end.\n\nFor much of my career as a Project Manager I have been inundated with software development process, theories, techniques, methodologies and related tools - which by association has trickled into the teams I have worked with.  Over time I have observed team members feeling the frustration that “Process” can bring to a project when it is applied in a theoretical way vs. a practical way.  Have you ever facilitated a planning meeting while team members glaze over and bury their heads into their laptops? To all my Project Management brethren - if this is something you are observing in your teams, don’t accept this reality; realize that your process \"is not working\".\n\nThe art of project management is not dictating process but finding practices that align with the team’s needs and context.   For purposes of this blog post these are the “logical means” I refer to in my opening statement above.  A little Scrum here, a little Waterfall there, and a sprinkle of Kanban might be the right recipe for a particular project - whereas it could be totally wrong for another.   \n\nIn many ways this context is driven by the pyramid of constraints - cost/scope/time, which is project management 101.  However, other contexts might be size of team, remote/co-located, green-field development, team member experience, criticality of deliverables to human life, number of stakeholders, thick/thin management hierarchy, complexity of business rules/logic, and many others which are industry specific.  \n\nOne of my biggest gripes with the “Agile” movement is that companies/teams are adopting variations of the methodology as a prescription to execute projects. I am pretty damn sure the pioneering thinkers who wrote the Agile Manifesto wanted teams to become more principled in thinking about the practices they chose to use vs. following the playbook blindly and not making sure it aligns with the project context.\n\nIt has been very affirming to know that engineers and designers in large and small companies loath process – I’d say this is pretty universal. However, I have found that these same people are incredibly logical people who are willing to do something non-engineering/design related if  they feel deep down it is a “logical means to achieve an end.” I believe it is the project manager’s responsibility as a servant leader to make sure teams don’t feel like process is holding them back but that it is helping them move forward.\n\nWhat I love about being a Project Manager at DockYard is the diversity of the project contexts that come through our door. For me it is and has been a great way to experiment, mix, and match processes to find the right practices for a team/project context.  I believe that DockYard’s acknowledgment of this reality allows us to better serve our clients’ unique contexts.  Not by accident - it is a very deliberate way to approach projects and one size never fits all.   \n"},{"title":"Swift and JavaScript","tags":["javascript","swift"],"summary":"Swift explained for JavaScript developers","legacy":false,"id":"2014/06/15/swift-and-javascript","employee":"Alex Navasardyan","date":"2014-06-15T00:00:00","body":"\n\nYou might have already heard about a new language from Apple, [Swift](https://developer.apple.com/swift/).\nIf you haven't, make sure to check it out. This is the language that is going to replace [Objective-C](https://en.wikipedia.org/wiki/Objective-C) in the future.\n\nSo why should a JavaScript developer be excited about a language like Swift?\nBecause semicolons are optional in Swift, too.\n\n### Variables\n\nLet's declare a variable in `JavaScript`:\n\n```javascript\nvar country = 'Argentina';\n```\n\nHere's how the same declaration looks like in Swift:\n\n```swift\nvar country: String = \"Argentina\";\n```\n\nHowever, the same statement can be rewritten as such:\n\n```swift\nvar country = \"Argentina\"; // inferred as String\n```\n\nSwift uses type inference. It looks on the right hand side of the assignment\nto figure out the type of the variable.\n\nSwift is type safe language. It performs type checks during compilation time\nand informs you if there are any type mismatch errors. Unlike in JavaScript,\nthat means that after you defined `country` variable and its type was\ninferred to be `String`, you can't re-assign with another type:\n\n```swift\ncountry = 2; // Cannot convert the expression's type to type 'String'\n```\n\n### Constants\n\nJavaScript doesn't have a concept of a `constant`. All \"constants\" are just\nvariables (typically in the outer scope). You can \"freeze\" the object using\n[Object.freeze()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze)\nto prevent new properties to be added and existing properties to be removed.\n\nThe next version of JavaScript is going to introduce [const](https://people.mozilla.org/~jorendorff/es6-draft.html#sec-13.2.1)\nkeyword and will support constants:\n\n```javascript\nconst y = 10; // Note that you need to specift the value of the constant\ny = 20;       // SyntaxError: Assignment to constant variable\n```\n\nIf you want to define a constant in Swift, you will use `let` keyword:\n\n```swift\nlet bestCity = \"Boston\";\nbestCity = \"Cape Town\"; // Cannot assign to 'let' value 'bestCity'\n\n// Swift allows you to use underscore as a delimiter\n// to improve readability of your code\nlet oneMillion = 1_000_000;\n```\n\n### Tuples\n\nSo what is a [tuple](http://en.wikipedia.org/wiki/Tuple)? TL;DR it's an ordered list of things.\n\nYou can think of a tuple as if it's an object:\n\n```javascript\nvar villain = {\n  name:     'Magneto',\n  realName: 'Max Eisenhardt',\n  powers:   ['Magnetic flight', 'Magnetic force fields']\n};\n\nvillain.name; // => 'Magneto'\n```\n\nIn Swift, the declaration of a tuple will look like this:\n\n```swift\nlet villain = (\n  name:     \"Magneto\",\n  realName: \"Max Eisenhardt\",\n  powers:   [\"Magnetic flight\", \"Magnetic force fields\"]\n);\n\nvillain.name; // => \"Magneto\"\nvillain.1;    // => \"Max Eisenhardt\"\nvillain.2;    // => [...]\n```\n\nTuples are useful when you want to return multiple values from a function as a single compound value (that is\nexactly what we do so often in JavaScript).\n\n### Arrays and Dictionaries\n\nDefinining an array or a dictionary looks very similar.\n\nIn JavaScript:\n\n```javascript\nvar names = ['Alex', 'Rob', 'Dan'];\nvar ages  = { 'Alex': 13, 'Rob': 5, 'Dan': 4 };\n\nnames[0];     // => 'Alex'\nages['Alex']; // => 13\n```\n\nIn Swift:\n\n```swift\nvar names = [\"Alex\", \"Rob\", \"Dan\"];\nvar ages  = [\"Alex\": 13, \"Rob\": 5, \"Dan\": 4];\n\nnames[0];     // => \"Alex\"\nages[\"Alex\"]; // 13\n```\n\n### Generics\n\nIn a very generic, hand wavy terms `Generics` introduce type safety and reusability of the code. They're frequently used\nin classes and methods that operate on them.\n\nTo illustrate what `Generics` are, let's implement a [`Queue`](https://en.wikipedia.org/wiki/Queue_(abstract_data_type)).\n\n```javascript\nfunction Queue() {\n  this._queue = [];\n}\n\nQueue.prototype.enqueue = function(item) {\n  this._queue.push(item);\n}\n\nQueue.prototype.dequeue = function() {\n return this._queue.shift();\n}\n\nvar queue = new Queue();\n\nqueue.enqueue(2);\nqueue.enqueue('3');\nqueue.enqueue(0.5);\n```\n\nNow wasn't that easy, eh?\n\nNote, that you don't have to care about types in JavaScript that much. You just `enqueue` a value of any type\nand you're all set.\n\nSwift is different. You can't push objects of different types onto the array.\n\nHere's a `Queue` class for `Integer` values:\n\n```swift\nclass Queue {\n  var _queue = Int[]();\n  \n  func enqueue(item: Int) {\n    _queue.append(item);\n  }\n\n  func dequeue() -> Int {\n    return _queue.removeAtIndex(0);\n  }\n}\n\nvar queue = Queue();\n\nqueue.enqueue(2);\nqueue.enqueue(3);\nqueue.enqueue(4);\nqueue.enqueue(\"4\"); // Cannot convert the expression's type to type 'Int'\n```\n\nWhat if you want to create a `Queue` class for `String` values? You're going to have copy implementation of `Queue<Int>` class\nand replace `Int` with `String`. A lot of code duplication. Here's where `Generics` shine.\n\n```swift\nclass Queue<T> {\n  var _queue = T[]();\n\n  func enqueue(item: T) {\n    _queue.append(item);\n  }\n\n  func dequeue() -> T {\n    return _queue.removeAtIndex(0);\n  }\n}\n\nvar intQueue    = Queue<Int>();\nvar stringQueue = Queue<String>();\n\nintQueue.enqueue(2);\nintQueue.enqueue(3);\nintQueue.enqueue(4);\n\nstringQueue.enqueue(\"2\");\nstringQueue.enqueue(\"3\");\nstringQueue.enqueue(\"4\");\n```\n\nNow you can create `Queue` of the different types with just one `Queue` implementation.\n\n### Conclusion\n\nSwift is a step in the right direction in my opinion. They lowered the \"language ramp up\" time by simplifying Objective-C syntax\nquite a bit without damaging the power of the language. I feel like it looks really compelling to JavaScript developers.\n"},{"title":"Making the DIY conference badges","tags":["design","conferences"],"summary":"What are badges for, anyway?","legacy":false,"illustration_alt":"Badges","illustration":"https://i.imgur.com/UgBuSJx.jpg","id":"2014/06/21/making-the-diy-badges","employee":"Maria Matveeva","date":"2014-06-21T00:00:00","body":"\n\nWhat are badges for, anyway? At any professional event with more than fifteen people, we wear some sort of name tag.\n\n## The current situation with badges:\nIf it's a smaller or low budget event, you get a shipping label and write your name with a sharpie, then stick to your shirt and hope it holds. (I always stick mine to a pant leg just because.) \n\nA step up would be vinyl stickers or shipping labels with something like the conference name printed on them, but again attendees must write their name. \n\nAt the highest level of badge, you arrive an event and receive a fully branded badge on a colorful lanyard with your name and photo printed on both sides, to prevent you from lending your $800 conference pass to a friend.\n\n## Three things badges do best:\n\n1. Prove that you've paid for your ticket\n2. Help brand the event\n3. Help you meet people\n\nOur focus for the badges was mostly to help people meet and talk, and if we get to show off the Wicked Good Conferences brand - that's cool too. We did not rely on the badges for ticketing because the event is relatively small, and held in a single location. There were no repeated check-ins at the door or strangers walking in off the relatively low traffic street.\n\nThis allowed me the freedom to experiment with the badges. The only restriction was the budget; we wanted to make about 200 customizable name badges with a budget range of $20–$50. This is not a realistic budget for high quality \"professionally\" printed badges (decent custom lanyards alone are at least $1 each).\n\n## No printed names\n\nWe decided to skip printing people's names altogether, and ask them to write names instead. This also allowed people to put a twitter handle and other useful information on the badges, and be funny with them. I am an introvert, so I appreciate any excuse to start a conversation. Stickers, twitter handles and stick figures on badges helped make interaction easier.\n\n![Badges](https://i.imgur.com/UgBuSJx.jpg)\n\n## No printed lanyards\n\nCustom printed lanyards, in the quality we wanted, were way above our budget. Instead, we tried a few DIY ideas: string, ribbon, rope and strips of jersey fabric. The fabric turned out to be the most comfortable to wear. Knit jersey (\"tee-shirt\") fabric will roll into a soft string if you cut 1\" wide strips and stretch them out. We used about 2.5 yards of 52\" wide fabric to make the 200 strips. We could make the strips a half to a third of the width of the fabric, depending on how long we wanted the strips to be.\n\n![Supplies](https://i.imgur.com/lRjE1Tf.jpg)\n\nAn added benefit of using fabric is a much better selection of colors compared to lanyards. We managed to get a near-perfect match to our attendee shirts!\n\n![Matched colors](https://imgur.com/tMhxpV7.jpg)\n\n## Actually, no printed anything\n\nTo make a color impression at a low cost we used a rubber stamp with a purple ink pad. We did not commit to placing any sponsor logos on the badges, so I had complete freedom with this design. We ordered a rubber stamp of the Wicked Good Conferences logo by itself so we can reuse it for the next conferences. To make the badge itself, we stamped and punched a hole in standard 3×5\" index cards.\n\n![Stamping...](https://i.imgur.com/Iai4JJ4.jpg)\n![Stamped!](https://i.imgur.com/OrrtLlj.jpg)\n\n## Budget breakdown\n* 1×2\" Custom rubber stamp\": $12 + shipping\n* Purple ink pad: $3.50\n* Index cards, 2 packs of 100: ~$7\n* Single hole punch: ~$5\n* Jersey fabric (we already had it, but if you need to buy it cost about $5/yard): free or $15\n\n## Lessons learned\nThe badges felt about right for the event, not too formal, not too shabby. Some lanyards turned out a bit short, but people were creative with placement, wearing them not only around the neck but on a sleeve, on the hat, tying them to the belt loop or a shirt button, and even wearing as a soft choker.\nNext time around we can also experiment with other paper types and have the paper cut to size, to allow for a sturdier badge in a wider range of colors.\n\nWere you at WGE? Let us know what you thought of the DIY badges!\n"},{"title":"Goodbye Heroku","tags":["opinion"],"summary":"Done with them","legacy":false,"id":"2014/06/23/goodbye-heroku","employee":"Brian Cardarella","date":"2014-06-23T00:00:00","body":"\n\nI've been a Heroku user since the beginning. And I understand they have\nhad their ups and downs but over the past 2 years the service has been\ndegrading and today was the last straw for me. Allow me to elaborate.\n\n## Downtime\n\nToday Heroku had a \"Scheduled Maintenance at 2pm EST\". First of all,\nthis is just stupid. Don't schedule a maintenance period at 2pm EST for\n**anything**. That period of time has to be one of the most heavily\ntrafficked timeslots on the web. Its an hour after everyone on the East\nCoast has come back from lunch. It is an hour before lunch on the West\nCoast. This, to me, demonstrates a lack of judgement on Heroku's part. I\nknow the counter-argument is going to be \"we've done plenty of other\nscheduled maintenances at 2pm EST without incident\". My reply is that\nthis counter-argument is *bullshit*. Just because you got away without\nproblems previously doesn't mean they won't happen in the future. Things\ngo wrong, people screw up. When Heroku has control over when those\nscrewups occur and they choose to push that risk at 2pm EST that is a\nproblem.\n\n## Reporting of Downtime\n\nI am convinced their Status team just sits on Twitter all day and waits\nfor enough people to bitch and complain that Heroku is down before they\nupdate the status page. I don't care what data they provide to the\ncontrary. Why is the updated status page important? When our customers\nemail us during our vacation pissed off that we are not around and we\nhave *nothing* to show to them to prove that this is Heroku's fault and\nnot ours, to me that status page being updated immediately **before**\nour customers discover on their own is very important.\n\n## Price\n\nIt has been heavily reported that AWS has cut their pricing quite a bit\nover the past few years. Yet, how many times has Heroku reduced its\nprice? (Heroku resells AWS) To my knowledge **zero**. So everytime Amazon\nreduces EC2 pricing Heroku just pockets the difference and gives a \"fuck\nyou very much!\" to all of its customers.\n\n## Fixes for All\n\nThe major downside to hosted devops is that when something goes wrong\nthat affects everyone you usually have to wait until they make the fix\nfor **everyone** before your app comes back up. What should probably be\na 5 minute downtime *at most* turns into a 30 minute downtime **at least**.\n\n## Buildpacks\n\nBuildpacks are just terrible.\n\n## Conclusion\n\nI get that I'm ranting and I'm pretty pissed off. But mistakes like\ntoday's are completely avoidable yet Heroku chose to expose everyone to\nthis increased risk for no good reason that I can see.\n\nWe will no longer be starting any new customers on Heroku. And we will\nrecommend to our current customers to move off of Heroku. We're big fans\nof Digital Ocean so we're likely to land there as our preferred hosting\nservice.\n"},{"title":"KAPOW! Writing prototypes with Framer","tags":["design","design process","prototyping"],"summary":"A look at Framer.js, a powerful prototyping tool.","legacy":false,"id":"2014/06/23/kapow-using-framer","employee":"Steven Trevathan","date":"2014-06-23T00:00:00","body":"\n\nI've finally used [Framer](http://framerjs.com/) on a client project and couldn't be happier with the result. I normally use [InVision](http://www.invisionapp.com/) and highly recommend it, but Framer is the obvious choice when we need the experience to feel significantly more real.\n\n[Every tool has its pros and cons](http://www.cooper.com/journal/2013/07/designers-toolkit-proto-testing-for-prototypes), however, so it won't *always* be the best choice for you.\n\nLet me start with Framer's big con: you must write JavaScript to knit a prototype together. The code itself is very easy to learn, but understanding how the Framer script interacts with your PSD's groups and layer organization is like flying blind. With practice you can get past this and work gets much, much faster.\n\nThe one other con is that their documentation is made more for developers than designers. So if you're not used to digging into developer docs you will likely be overwhelmed and unsure what you're looking for. Looking elsewhere won't help you either, there doesn't seem to be much community around this (yet).\n\nSomeone with less coding experience will find Framer difficult and more intimidating than it has to be. I'd recommend dealing with the learning curve by practicing on a few side projects before you put anything important on the line (not that side projects aren't important).\n\nWhere Framer really shines bright: you won't have to verbalize (or make embarrassing gestures) for how your app should feel, because you define that with enormous control. Oddly enough, the biggest con is your ally here, as writing custom JavaScript is what makes this control possible.\n\nFramer supports clicks and taps just the same, supports many animation options, is highly configurable, and runs very, very smoothly on all (of my) devices. I've tested it on iPhone, iPad, and a Mac. Because of this control and variability of use, your prototypes will feel much more real to the user in a testing scenario. This is especially good when your interactions help communicate state and position.\n\nIf you've used Framer before, let me know how you like it. There's only so much time in the world to play with prototyping tools, but my next experiment will be with [Origami](http://facebook.github.io/origami/).\n\n## Bonus!\nWhile doing user testing sessions, you may want the testee to work on the actual device. To do so you can use [Anvil](http://anvilformac.com/) to create a local web address using [Pow](http://pow.cx/). This will give you an address (something like `http://yourappname.youripaddress.xip.io/`) that you may access on your device.\n"},{"title":"Introducing Ember CLI Addons","tags":["ember","ember-cli"],"summary":null,"legacy":false,"id":"2014/06/24/introducing_ember_cli_addons","employee":"Robert Jackson","date":"2014-06-24T00:00:00","body":"\n\nDistribution of reusable Ember.js libraries has been a pain point for quite a while. During application development we have frequently wished for a silver bullet for the sharing of concepts/code from one project to another.\n\n[Ember CLI](https://github.com/stefanpenner/ember-cli) has given us the opportunity to set the conventions for sharing that we have been searching for.\n\nOver the last few weeks we have been focusing our efforts on the Ember CLI Addon story, and current support the following scenarios out of the box:\n\n* Performing operations on the `EmberApp` created in the consuming applications `Brocfile.js`. The most common things this would be used to call `app.import` (see [Ember CLI - Managing Dependencies](http://iamstef.net/ember-cli/#managing-dependencies) for more details) or process the various options provided by the consuming application. Examples: [ember-cli-pretender](https://github.com/rwjblue/ember-cli-pretender), [emberFire](https://github.com/firebase/emberFire), and [ember-cli-ic-ajax](https://github.com/rwjblue/ember-cli-ic-ajax)\n  \n* Adding preprocessors to the default registry. This allows us to use a custom preprocessor to handle our templates, JavaScript, and/or styles. Example: [ember-cli-esnext](https://github.com/rwjblue/ember-cli-esnext)\n\n* Providing a custom application tree to be merged with the consuming application. This allows you to distribute anything that might need to be imported in the consuming application; including components, templates, routes, mixins, helpers, etc. Example: [ember-cli-super-number](https://github.com/rondale-sc/ember-cli-super-number)\n\n* Providing custom express middlewares. This allows for an addon to completely customize the development servers behaviors, making things like automated mock Ember Data API's actually possible. This is currently only available on master (will be available in  0.0.37 and higher).\n\nOne of the design goals that the current crop of example addons follow is that they can all be installed and used simply via:\n\n```bash\nnpm install --save-dev <package name>\n```\n\n## Details\n\n### Discovery\n\nEmber CLI detects the presence of an addon by inspecting each of your applications dependencies and searching their `package.json` files for the presence of `ember-addon` in the keywords section. \n\n### Creation\n\nOnce the available addons are detected, Ember CLI will require the addon.  By default it will use standard Node.js require rules (see [here](http://nodejs.org/api/modules.html#modules_all_together) for a breakdown), but you can provide a custom entry point by specifying a `ember-addon-main` property in your `package.json`.\n\nEither way you go, during the various commands that cause a new build to be done (`ember server`, `ember test`, `ember build`, etc) Ember CLI will create a new instance of the class that your addon returns passing it the `Project` instance for the current project. The `Project` model has a few functions that might be useful to your addon. You can see a full list by inspecting the [source](https://github.com/stefanpenner/ember-cli/blob/master/lib/models/project.js), but to name a few:\n\n* `require` -- Lets you require files or packages from the consuming application.\n* `config` -- Returns the configuration for the provided environment.\n* `resolve` -- Looks up a file from the root of the project using standard Node require semantics, but with the projects root as the base directory.\n\n### Build Process Inclusion\n\nWhen the consuming application's `Brocfile.js` is processed by Ember CLI to build/serve/etc the addon's `included` function is called passing the `EmberApp` instance. You can use this to access the options provided (for configuration of your addon for example).\n\n### Intra Build Hooks\n\nThere are a few other points in the build process that your addon can hook into via the `treeFor` function. `treeFor` is called to setup the final build output for a few specific points in the build process. The addons `treeFor` function will be called with an argument that signifies which tree is being asked for.\n\nCurrently, the following trees can be customized by the addon:\n\n* `app` -- The tree returned by your addon for the `app` tree will be merged with that of the application. This is an excellent place to add custom initializers for your addon, add routes/controllers/views/components/templates/etc (anything that goes in `app/` really). For additional information read through the [blog post](http://hashrocket.com/blog/posts/building-ember-addons) describing how `ember-cli-super-number` was turned into an addon.\n* `styles` -- The tree returned by your addon for the `styles` tree will be merged with your applications styles (generally `app/styles/`).\n* `vendor` -- The tree returned by your addon for the `vendor` tree will be merged with your applications vendor tree (generally `vendor/`). \n\nAll of the trees returned by addons are merged into the corresponding tree in the application. The application's direct trees are always last so they will always override any files from an addon. This actually makes a wonderful place for application specific customization: your addon could provide a good default template, and the application can override by simply placing their own template in the same path.\n\n## Future\n\nMany things are still planned for the \"Addon Story\" in Ember CLI. A few of them below:\n\n* Allow addons to specify preferred ordering (before or after another addon). Similar in concept (and stolen from) the Ember initializer ordering. This is implemented on master and will be included in 0.0.37.\n* Allow addons to provide a `blueprintPaths` function that will return addition paths for blueprints to be looked up. This will allow an addon to override internal blueprints or add their own.\n* Allow more than one preprocessor to be used at once. Currently, it is only possible to have a single preprocessor, but this is a limitation if you want both SCSS and plain CSS (for example).\n* Expose post-processed stages. This will allow for better customization of the final output which things like [autoprefixer](https://github.com/ai/autoprefixer) would be able to take advantage of.\n\n## Call To Arms\n\nThis API is still very fluid and not set in stone. We need as much feedback as possible to truly solidify things.\n"},{"title":"Ember Macros for DRY and Testable Code","tags":["ember","testing","best practices"],"summary":null,"legacy":false,"id":"2014/06/27/ember-macros-for-DRY-and-testable-code","employee":"Lin Reid","date":"2014-06-27T00:00:00","body":"\n\n### Intro\nThis post in going to explore the idea of writing your own Ember macros\nas a strategy for DRYing up and creating more modular Ember code. \nAs you'll see, besides the maintainability and flexibility benefits gained by DRYing\nup and decoupling code, isolated code is significantly easier to test.\nWe'll be using a sample application to illustrate refactoring some code\ninto a macro.\n\n### What is a Computed Property Macro?\nA computed property macro can really be thought of as a function that returns the\ndefinition of a computed property. Essentially, we are creating a function that will\ndefine computed properties for us. They look something like this:\n\n```javascript\n// Defining a computed property macro\nfunction greeting(dependentKey, greeting) {\n  return Ember.computed(dependentKey, function() {\n    return greeting + ', ' + dependentKey;\n  });\n}\n\n// Consuming a computed property macro\nvar Greeter = Ember.Object.extend({\n  user: null,\n  englishGreeting: greeting('user', 'Hello'),\n  spanishGreeting: greeting('user', 'Hola')\n});\n\nvar concierge = Greeter.create({ user: 'Narwin' });\nconcierge.get('englishGreeting') // => 'Hello, Narwin'\nconcierge.get('spanishGreeting') // => 'Hola, Narwin'\n\nconcierge.set('user', 'Boomer');\nconcierge.get('englishGreeting') // => 'Hello, Boomer'\nconcierge.get('spanishGreeting') // => 'Hola, Boomer'\n```\n\nSo, why not just use a standard computed property? Macros give us the\nability to take common chunks of functionality and share them throughout\nour code, allowing us to avoid re-writing the logic every time we need\nit. \n\nEmber provides us with a bunch of useful computed macros\nright out of the box. If you're not familiar with them, you should\ndefinitely [check them out](http://emberjs.com/api/#method_computed).\n\nNow that we've covered our bases, lets move on to the sample app.\n\n### Sample App\nThe goal of our sample application is to track financial transactions\nand to provide an overview of income and expenses for a given time frame.\nOur app has a `Month` model which has many `transactions`. A `Month` also\nhas `incomeTransactions` (transactions with positive amounts) and\n`expenseTransactions` (transactions with negative amounts). Below are\ntests and code for our `Month` and `Transaction` models.\n\n\n`app/models/month.js`\n\n```javascript\nvar hasMany = DS.hasMany;\nvar filter = Ember.computed.filter;\n\nexport default DS.Model.extend({\n  transactions: hasMany('transaction'),\n\n  incomeTransactions: filter('transactions', function(transaction) {\n      // Grab all transactions with a positive amount.\n      return transaction.get('amount') > 0;\n    }\n  ),\n\n  expenseTransactions: filter('transactions', function(transaction) {\n      // Grab all transactions with a negative amount.\n      return transaction.get('amount') < 0;\n    }\n  )\n});\n```\n\n`tests/unit/models/month-test.js`\n\n```javascript\nimport { test, moduleForModel } from 'ember-qunit';\n\nvar store, month, transactions, tran1, tran2, tran3, tran4;\n\nmoduleForModel('month', 'Unit - Month Model', {\n  needs: ['model:transaction'],\n\n  setup: function(container) {\n    store = container.lookup('store:main');\n\n    month = this.subject({\n      name: 'June'\n    });\n\n    Ember.run(function() {\n      tran1 = store.createRecord('transaction', { amount: 100 });\n      tran2 = store.createRecord('transaction', { amount: 200 });\n      tran3 = store.createRecord('transaction', { amount: -300 });\n      tran4 = store.createRecord('transaction', { amount: -400 });\n\n      transactions = [tran1, tran2, tran3, tran4];\n\n      month.get('transactions').addObjects(transactions);\n    });\n  }\n});\n\ntest('incomeTransactions returns positive transactions', function() {\n  expect(1);\n\n  var results = month.get('incomeTransactions');\n\n  deepEqual(results, [tran1, tran2]);\n});\n\ntest('expenseTransactions returns negative transactions', function() {\n  expect(1);\n\n  var results = month.get('expenseTransactions');\n\n  deepEqual(results, [tran3, tran4]);\n});\n```\n\n\n`app/models/transaction.js`\n\n```javascript\nvar attr = DS.attr;\n\nexport default DS.Model.extend({\n  amount: attr('number')\n});\n```\n\n\nThe month controller will handle computing the `incomeTotal` and\n`expenseTotal` for the month.\n\n`app/controllers/month.js`\n\n```javascript\nvar computed = Ember.computed;\n\nexport default Ember.ObjectController.extend({\n  incomeTotal: computed('incomeTransactions.[]', function() {\n    // Get the amount for each transaction in incomeTransactions.\n    var amounts = this.get('incomeTransactions').mapBy('amount');\n\n    // Sum the amounts\n    return amounts.reduce(function(previousValue, currentValue) {\n      return previousValue += currentValue;\n    }, 0);\n  }),\n\n  expenseTotal: computed('expenseTransactions.[]', function() {\n    // Get the amount for each transaction in expenseTransactions.\n    var amounts = this.get('expenseTransactions').mapBy('amount');\n\n    // Sum the amounts\n    return amounts.reduce(function(previousValue, currentValue) {\n      return previousValue += currentValue;\n    }, 0);\n  })\n});\n```\n\n`tests/unit/controllers/month-test.js`\n\n```javascript\nimport { test, moduleFor } from 'ember-qunit';\n\nvar set = Ember.set;\n\nvar monthController, incomeTransactions, expenseTransactions;\n\nmoduleFor('controller:month', 'Unit - Month Controller', {\n  setup: function() {\n    incomeTransactions = [\n      { amount: 100 },\n      { amount: 200 }\n    ];\n\n    expenseTransactions = [\n      { amount: -300 },\n      { amount: -400 }\n    ];\n\n    monthController = this.subject({\n      incomeTransactions: incomeTransactions,\n      expenseTransactions: expenseTransactions\n    });\n  }\n});\n\ntest('incomeTotal returns the total of all incomeTransactions', function() {\n  expect(1);\n\n  var result = monthController.get('incomeTotal');\n\n  equal(result, 300);\n});\n\ntest('incomeTotal recomputes when an incomeTransaction is added', function() {\n  expect(1);\n\n  var newTransaction = { amount: 500 };\n\n  monthController.get('incomeTransactions').addObject(newTransaction);\n\n  var result = monthController.get('incomeTotal');\n\n  equal(result, 800);\n});\n\ntest('expenseTotal returns the total of all expenseTransactions', function() {\n  expect(1);\n\n  var result = monthController.get('expenseTotal');\n\n  equal(result, -700);\n});\n\ntest('expenseTotal recomputes when an expenseTransaction is added', function() {\n  expect(1);\n\n  var newTransaction = { amount: -600 };\n\n  monthController.get('expenseTransactions').addObject(newTransaction);\n\n  var result = monthController.get('expenseTotal');\n\n  equal(result, -1300);\n});\n```\n\n\nIf your spidey senses are tingling, they should be. There is a lot of\nduplication going on in above code. In fact, the only difference between `incomeTotal` and\n`expenseTotal` is which set of transactions they are working with (incomeTransactions\nor expenseTransactions). Similarly, the only difference between `incomeTransactions` and `expenseTransactions`\nis whether the amount is a positive or negative number. Let's write a couple of macros to DRY up this code.\n\n\n### Creating custom Ember Macros\nBoth `incomeTotal` and `expenseTotal` have almost exactly the same\nlogic. The goal of each is to take an array of objects and return the\nsum of a specific property on each object. Let's create a `sumBy` macro\nwith the goal of being able to write something like: `sumBy('array', 'property')`.\n\n`app/utils/sum-by.js`\n\n```javascript\nexport default function(collection, property) {\n  return Ember.reduceComputed(collection, {\n    initialValue: 0.0,\n\n    addedItem: function(accumulatedValue, item){\n      return accumulatedValue + Ember.get(item, property);\n    },\n\n    removedItem: function(accumulatedValue, item){\n      return accumulatedValue - Ember.get(item, property);\n    }\n  });\n}\n```\n\n`tests/utils/sum-by.js`\n\n```javascript\nimport { test } from 'ember-qunit';\nimport sumBy from '../../../utils/sum-by';\n\nvar set = Ember.set;\n\nvar bankAccount, transactions, tran1, tran2, tran3, tran4;\n\nmodule('Unit - SumBy', {\n  setup: function() {\n    tran1 = { amount: 1 };\n    tran2 = { amount: 2 };\n    tran3 = { amount: 3 };\n    tran4 = { amount: -4 };\n\n    transactions = [tran1, tran2, tran3, tran4];\n\n    bankAccount = Ember.Object.extend({\n      transactions: transactions,\n      totalAmount: sumBy('transactions', 'amount')\n    }).create();\n  }\n});\n\ntest('returns the sum of property for all objects in collection', function() {\n  expect(1);\n  var actual = bankAccount.get('totalAmount');\n\n  deepEqual(actual, 2);\n});\n\ntest('recomputes when a new object is added to the collection', function() {\n  expect(2);\n  deepEqual(bankAccount.get('totalAmount'), 2, 'precondition');\n\n  var newTrans = { amount: 10 };\n\n  bankAccount.get('transactions').addObject(newTrans);\n\n  var actual = bankAccount.get('totalAmount');\n\n  deepEqual(actual, 12);\n});\n```\n\n\n`incomeTransactions` and `expenseTransactions` could also use some\nDRYing up. The only difference between the two is whether they are\nfiltering by positive of negative numbers. Let's write a `filterBySign`\nmacro with the goal of being able to write something like: \n`filterBySign('array', 'property', '+')`.\n\n`app/utils/filter-by-sign.js`\n\n```javascript\nvar get = Ember.get;\nvar filter = Ember.computed.filter;\n\nexport default function(collection, property, sign) {\n  return filter(collection, function(object) {\n    return (sign + 1) * get(object, property) > 0;\n  });\n}\n```\n\n`tests/unit/utils/filter-by-sign-test.js`\n\n```javascript\nimport { test } from 'ember-qunit';\nimport filterBySign from '../../../utils/filter-by-sign';\n\nvar bankAccount, transactions, tran1, tran2, tran3, tran4;\n\nmodule('Unit - filterBySign', {\n  setup: function() {\n    tran1 = { amount: 1 };\n    tran2 = { amount: 2 };\n    tran3 = { amount: -3 };\n    tran4 = { amount: -4 };\n\n    transactions = [tran1, tran2, tran3, tran4];\n\n    bankAccount = Ember.Object.extend({\n      transactions: transactions,\n      positiveTransactions: filterBySign('transactions', 'amount', '+'),\n      negativeTransactions: filterBySign('transactions', 'amount', '-')\n    }).create();\n  }\n});\n\ntest(\"'+' returns all objects with positive property values\", function() {\n  expect(1);\n  var actual = bankAccount.get('positiveTransactions');\n  var expected = [tran1, tran2];\n\n  deepEqual(actual, expected);\n});\n\ntest(\"'-' returns all objects with negative property values\", function() {\n  expect(1);\n  var actual = bankAccount.get('negativeTransactions');\n  var expected = [tran3, tran4];\n\n  deepEqual(actual, expected);\n});\n\ntest('recomputes when a new object is added to the dependent array',\nfunction() {\n  expect(2);\n  deepEqual(bankAccount.get('positiveTransactions'), [tran1, tran2]);\n\n  var newTrans = { amount: 1000 };\n  bankAccount.get('transactions').addObject(newTrans);\n\n  var actual = bankAccount.get('positiveTransactions');\n  var expected = [tran1, tran2, newTrans];\n\n  deepEqual(actual, expected);\n});\n```\n\nWhen reading through the tests for `filterBySign`, note how much easier the setup is compared\nto our original tests for the same functionality on the `Month` model. Because\nwe're testing the code in isolation, we're able to use POJOs\nand arrays to test our code. This allows us to avoid having to work\naround the `Month` model's relationships, creating records with the\nstore and wrapping our setup code in an `Ember.run` to handle async\nbehavior. Much nicer!\n\n###Refactoring the Month Model and Controller\nWe can now refactor our month model and controller to use our new\nmacros.\n\n`app/model/month.js`\n\n```javascript\nimport filterBySign from '../utils/filter-by-sign';\n\nvar hasMany = DS.hasMany;\n\nexport default DS.Model.extend({\n  transactions: hasMany('transaction'),\n\n  incomeTransactions: filterBySign('transactions', 'amount', '+'),\n  expenseTransactions: filterBySign('transactions', 'amount', '-')\n});\n```\n\n`app/controllers/month.js`\n\n```javascript\nimport sumBy from '../utils/sum-by';\n\nexport default Ember.ObjectController.extend({\n  incomeTotal: sumBy('incomeTransactions', 'amount'),\n  expenseTotal: sumBy('expenseTransactions', 'amount')\n});\n```\n\nThe refactored model and controller are nice and concise while still\nmaintaining their readability. We can now delete our old unit tests on\nour `Month` model and controller as they now overlap with our macro tests.\nThe net result is trimming down the code we have to maintain by about\nhalf.\n\nIf you're thinking about writing a macro or just want to see what other macros\nare out there, check out [ember-cpm](https://github.com/jamesarosen/ember-cpm). \nIt's a library of non-core macros that you can plug in to you Ember app.\nIf you can't find what you're looking for there, take a shot at writing\nyour own macro and send in a pull request to share it with the\ncommunity!\n"},{"title":"Design as Conversation","tags":["design","design process","design thinking"],"summary":"Invisible systems of the design process.","legacy":false,"illustration_alt":"Forest creatures of the Round Table","illustration":"http://i.imgur.com/sxxEnba.jpg","id":"2014/07/18/design-as-conversation","employee":"Ashley Treni","date":"2014-07-18T00:00:00","body":"\n\n<img class=\"illustration\" src=\"http://i.imgur.com/sxxEnba.jpg\" alt=\"Forest creatures of the Round Table\">\n\nOur understanding of design is perpetually in flux. Over the years design has transitioned from print and typography to web design, communication design to interaction design, user experience design to information design and design thinking. The space of design expands to encapsulate all these areas, while simultaneously formalizing specialized methodologies.\n\nDesign is a process; it no longer refers only to static artifacts or visualizations. Design is a craft as much as it is a way of thinking and interacting.\n\nAt DockYard, the design and development teams work closely together in an open dialogue, problem solving and giving real time feedback. Functionality and usability are built to work with one another, and it is this exchange of ideas, the conversation, that allows for the success of this interdisciplinary collaboration. There is no hierarchy of thought; each person brings personal experience and skill that contributes to a richer shared understanding. Many in the design world have begun to formalize this process - identifying these as environments for “innovation”.\n\nThe success of design, however, doesn’t lie in the adherence of these systems. As much as we may reflect on the process of design - it remains a real time activity. Visual design, UI/UX considerations, and software engineering are all skills that come second to the ability for a team to work together. Through conversation, articulation, and modeling, we design the way in which we confront social complexities and wicked problems that exist as a result of differing perspectives. DockYard’s internal process is sensitive to these considerations, but doesn’t attempt to formalize its methodology, as problem solving is unique to each individual circumstance.\n\nThe static, active, and meta states of design exist simultaneously layered within one another. When we invest in understanding one another, we truly embody what it means to design for experience, interaction, perception, emotion, and cognition. To “design the process of design” is simply to be curious, present and engaged in all that we do.\n\n[Richard Wurman’s](http://www.northeastern.edu/camd/artdesign/people/richard-saul-wurman/) explicit philosophy resonates with me a great deal. His approach to life is a demand to embrace a lack of understanding; a mentality that allows you to ask questions, to start at the beginning. It liberates you to say \"I don't know what you mean\" or \"I don't know much about that\" - something we are unfortunately as a society not encouraged to do - much to the detriment of learning and individual understanding. These fears exist in work environments, classrooms, within relationships - we so often are made to feel inadequate if our understanding doesn't match another's (or our own) expectations.\n\nThe collaborative nature of design reacts against these pressures. We each bring unique understanding, but it is our humility, interest in others and in experience, and the value we place in the exchange of ideas that makes design a powerful thing.\n"},{"title":"Facebook Experiment","tags":["experiments"],"summary":"How I tried to experiment back on Facebook.","legacy":false,"id":"2014/07/18/facebook-experimentation","employee":"Maria Matveeva","date":"2014-07-18T00:00:00","body":"\n\nI just read this [thoughtful and refreshing article](https://medium.com/@scottrob/facebooks-going-to-be-ok-but-science-is-taking-a-hit-fd512b250f3e) about Facebook's now infamous experiment on a large group of users. It outlines the ethical problems in running an experiment on unwilling participants, and how the scandal that followed damages the reputation of scientific research, which has ethical (not just legal) restrictions. It also reminds us that testing different versions of a product on users is nothing new, and we all seem OK with it as long as it stays in the realm of marketing.\n\nThe outrage over users' emotions being manipulated without consent reminds me of my own feeling of insecurity a few years ago, when personalized ads just started appearing on Facebook (somewhere around 2009?). Suddenly this free service, which I use for talking to friends, is listening in and pushing ads on me. Weird. I wanted to push them back.\n\nCan I do anything to these algorithms that determine what ads I see? I wanted to experiment with them - to manipulate the ads by intentionally changing my information and posting fake content from my profile. I didn't keep any screenshots for evidence, so you'll just have to believe that some of it worked well.\n\nAt the time, I had to use Facebook at work quite a lot. As \"the web design person\" for a nonprofit organization, I posted to Facebook regularly and kept track of potentially abusive comments on the official page, so I had to be logged in and therefore exposed to the ads at the same time.\n\nIf you are a female - especially a female of an important purchasing age like me - you'll have many companies fighting for your attention. In your early 20s it's mostly personal purchases like shoes, clothes and makeup. A few years later, you qualify into the coveted \"homemaker\" target market. You supposedly start making decisions for a growing family about which groceries, appliances and brand of house paint to get - and companies really want your attention.\n\nI was getting tired of the keywords and browsing history from my personal life following me around at work with supposedly relevant shopping ads, so I tried to confuse Facebook. \n\nFirst I tried posting fake announcements of a tropical vacation and labeling some of my photos with far-away locations, but the ads didn't change much. I would see the occasional 50% off ad for brand name luggage, but nothing drastic. Many of my Facebook friends were confused, including a few coworkers. (\"A three week vacation? What about my report?\")\n\nNext, I changed my gender to male. I loved the ads that I got in return. Suddenly there were no glitter shoes, no 75% off designer dresses, no engagement rings. Instead I saw \"finish your computer science degree\", high quality leather goods, and website hosting ads. I had not changed anything else about my behavior. The same keywords and likes give a girl and a boy version of me a completely different market persona. I enjoyed the boy version a lot more.\n\nThe third thing I changed was location. Facebook seemed to save different location privacy settings on desktop and in the browser, and defaulted back to showing my location once in a while. I was not happy to reveal my exact location with each post. It just seemed too invasive. On top of that, Facebook started mining my friends' location settings to determine mine whether I wanted to reveal it or not. It seemed easier to claim a false location than to keep fighting for it to remain blank. I set my hometown and current location to North Pole, Alaska.\n\nThe ads felt a bit more brawny on top of my previous change to \"male\". Some offers of rugged hiking boots (I actually buy hiking boots!) and tactical something or other. On the downside, one real life friend later said she was confused by the  North Pole location.\n\nSince I tried those interventions, Facebook algorithms have of course advanced, and the simple gender setting change today might not produce a significant change in ads. But it felt rewarding to kick back at the marketing machine, and to sometimes get results. I am a web designer, so I have to be a user of web things as well as a maker. I do not think I will be quitting Facebook this week, or next. But I enjoy running experiments back on it.\n\nAs a user, I was able to influence my ads. As a designer, I remain skeptical of user declared content. For example, if I had access to the kind of data Facebook has on most users, and wanted to target a person of a specific age and gender, I would consider their behavior instead of relying on one setting. I would look to confirm their gender, relationship status and age settings with specific keywords or themes in their posts and things they reacted to. \n\nWe should make sure our products do not break in \"weird\" cases (for example, when user settings and behavior seemingly contradict each other), and remain aware of the assumptions we make in the design process.\n"},{"title":"Making better repeat patterns","tags":["experiments","design"],"summary":"My favorite technique to avoid the obvious tiled look.","legacy":false,"illustration_alt":"A most zen-like practice","illustration":"http://i.imgur.com/2GWB8Et.jpg","id":"2014/07/23/repeat-patterns","employee":"Maria Matveeva","date":"2014-07-23T00:00:00","body":"\n\n<img class=\"illustration\" src=\"http://i.imgur.com/2GWB8Et.jpg\" alt=\"A most zen-like practice\">\n\nI enjoy the look of hand-drawn things. And I use patterns a lot. But when the two are combined, the results are often disappointing. My least favorite thing is to see a pattern where identical copies of a hand drawn object were repeated without variation. The automatic repetition here is not appropriate to the shaky handmade look of the art.\n\nThe effect reminds me of Office circa 1995 (remember the classic marble and granite patterns?) or the obviously tiled walls in video game environments. In a 3D environment, a small size of the tile that causes this obvious tiled look is a necessity to conserve processing power.\n\nRemember these?\n![bad textures](https://i.imgur.com/jPzIWv8.jpg)\n\nBecause I want to use hand drawn repeat patterns in my work, and it would be impractical to draw a thousand individual pieces to create the pattern, I experimented to determine exactly how many pieces I need to preserve the varied look, while being able to tile.\n\nWhen I intentionally draw similar objects, I found that 15-30 copies will make a decent repeat pattern. I draw more than I need, then squint and get rid of a few that are too dissimilar. Once pieces are arranged on the pattern, there will always be a few that stick out and attract attention to the “seams” between your pattern tiles. To solve this, I leave only a small amount of variation in both shape and placement, and I repeat a few of the shapes several times in a single tile. This distracts from the “edges” of the tiles because repetition happens on two different rhythms.\n\nPattern element 2 is repeated several times within one unit.\n![repeat pieces](https://i.imgur.com/JDXVcVA.png)\n\nTrying to get as far away as I can from the obvious square tiled look, I also experimented with other manners of tiling. Adobe Illustrator offers brick (offset), hexagonal and other options, but I eventually need to go back to a rectangular repeating unit because I want to use my pattern in browsers.\n\nA rectangular repeat unit is used to make hexagonal tiles.\n![repeat hex](https://i.imgur.com/gtEb7sn.png)\n\nHere is one of the patterns I ended up making in this non-repeated style.\n\nOne unit of the repeat pattern.\n![trees](https://i.imgur.com/HGzqiN5.png)\n\nI used this tree, circled, several times inside one repeating unit.\n![more trees](https://i.imgur.com/tjduV4g.png)\n\nThe pieces are aligned to the grid, of course, but they are hand drawn so sizes are slightly off. I intentionally spaced them slightly off the grid as well, but preserved the overall balanced appearance (just squint and fix whatever looks off  - very scientific!)\n![even more trees](https://i.imgur.com/lgAlgpy.png)\n\n## And finally - here are the patterns!\n\n![swatches](https://i.imgur.com/jEK1YAq.png)\n\n[Download the Illustrator file](/images/patterns.ai) and use these patterns in any project. We only ask that you do not resell them. Enjoy!\n\n\n"},{"title":"On Selling UX","tags":["design","design process","design thinking"],"summary":"Getting what you want out of your design process.","legacy":false,"id":"2014/07/25/on-selling-ux","employee":"Steven Trevathan","date":"2014-07-25T00:00:00","body":"\n\n## The Talk\n\nPeople are talking about the difficulties of selling UX process to their boss, their clients, or their prospective clients. They're upset that they don't have the tools to create the caliber of experience others are building and it's all because a few people aren't buying into their process. You might have heard it or said it yourself that those in the way \"just don't get UX\". I know I've said it.\n\nFrom this point of view, we appear to be looking at the problem as a matter of conversion; turning someone who isn't interested in change of process into someone who'll embrace it. It's a hard sell and, if you've ever experienced being hung up on while cold calling someone, you'll know that your chances of failure are much greater than your chance of conversion. But don't let that scare you.\n\nJust like the design process itself, there are many ways to approach this problem. Success in your approach is a matter of understanding perspective and - dare I say - empathy for those in the critical path.\n\n\n## Definitions\n\nWe all have a habit of creating definitions in our minds of what other people do from what we hear around the office (or internet) and they're often pretty far off base. Those definitions become our foundation for what it means to be those other things: a designer, a developer, a product manager, a CEO. Those definitions, baseless or not, are used to judge the value of the things we do.\n\nAn example might be that most people realize they need a software developer to build an application but they may not understand the angles to be considered, the processes for discovering those angles, or the costs involved. It's easily misunderstood and can be a surprise for those outside of your industry.\n\n\n## Shared Values\n\nWe intend to create a great product and we understand there are many variations in process that could bring it to life. As creators, that process can often be poorly preconceived and unnecessarily limited before we get a hand in it. We have a few options from here to deliver our full value, and selling isn't one of them.\n\nAaron Scott from [Leap](http://leap.agency/) gave a talk at [UX Boston Conf](http://www.meetup.com/uxboston/events/136304392/) about doing your best in getting to know those you're working with to help deliver a winning concept to the client. This approach holds true in more ways than just reaching a final design; it will help you gain the buy-in you need to perform at your full potential.\n\nThe stakeholder may understand what you do, need some experience of your process before understanding, or maybe they're not ready for it all. You need to know that they're acting off of their definitions, and it's not always their fault for having an incomplete picture. Just the same, it is equally important for us to understand them and their needs.\n\nIf they're not ready, convincing them otherwise will cause anxiety during the project and potentially cause issues of trust with you or future designers if things don't go well. Use your best judgment and tread lightly.\n\n\n## Collaboration\n\nWhen your work is primarily visual it can be especially difficult to get the buy in you need. Most of the stakeholders will have had vision for their entire lives and trust themselves to judge what they feel is good and bad. They have their own tastes, their own definitions of what you do, and their own expectations of the process.\n\nOur value as designers is best understood when demonstrated and this is your most powerful tool to gain buy in. Make room for them to be part of your design conversation. Problem solve and communicate with them like you might your design team. Let them breath the same air you are and replace your salesmanship with collaboration. Use this method instead of presentations and cold hard salesmanship or politics.\n\nIf you don't believe they're a good fit to collaborate with your design team, you may wish to pass on their project. Consider them a \"client in training\", give them your best advice, and set them free. Of course this isn't as easy when working in-house, where I would hope that if you've come to this conclusion you'd start looking for a more collaborative environment.\n\nSo stop *selling* UX. Look around, listen, ask questions, and help the client in training see further before you put a contract in front of them. Your process of gaining an understanding of the product, users, and their context will sell your expertise all on its own. If they're not ready, which is up to you to decide, set them free.\n\nThey may not always be a returning client, but they will respect you for being honest with them every step of the way - and that's a lifelong trust."},{"title":"Project Carpe Diem - \"Game Plan\"","tags":["project management","planning"],"summary":null,"legacy":false,"illustration_alt":"image","illustration":"http://i.imgur.com/hwZuLsa.jpg","id":"2014/07/29/project-carpe-diem","employee":"Jon Lacks","date":"2014-07-29T00:00:00","body":"\n\nI have been exposed to many different work tracking/planning tools during my time as Project Manager. Early on it was tools like Excel, MS Project, IBM Rational. Later it was Jira, Kanban Boards, GitHub Issue Visualization Tools and physical PostIt Note boards. I would classify the former tools being more aligned with senior management's desire to be “Well Informed” and the latter being more team centric and aligned with Iterative software development. \n\nWorking with both distributed and co-located teams has challenged me to devise appropriate work tracking strategies for these very different team contexts.  However, one thing has remained the same to this day: I have never worked with a team that has determined they do not want to do any level of work tracking either in a high or low fidelity way regardless of the software development methodology being applied.\n\nFor purposes of this article I will be discussing some of the benefits we have seen in using a physical board with a couple of our co-located DockYard project teams. While I do maintain an appreciation of the big picture plan (aka High-Level Plan),  I have come to embrace a concept that is advocated in the field of Exercise Science - something I have been reading up on lately. I am sure this is not the only field of study citing this approach but wanted to mention this one as top of mind. It is the notion of setting smaller objectives to take one (us) closer to a larger goal. In terms of software development a goal would be synonymous with a product feature. By no means is this a new frontier in development planning, it is simply an application of some already acknowledged concepts.  What I believe is the slight twist is the setting of “Daily” objectives  in addition to full Iteration objectives. Consider this Project Carpe Diem!\n\nAt DockYard we are calling this approach “Game-Plan.” It covers the following four dimensions -\n\n1. Features\n2. Time (Days)\n3. Tasks (Hrs)\n4. Role on Team   \n\nAt DockYard we harnesses the power of the daily standup meeting with low tech multi-colored Post-It Notes on a physical board in the office.  During Iteration planning we discuss the next prioritized feature(s), lay out the relevant sub-features in agreeable sequence, define tasks for those sub-features across all the practice areas on our team. We set an estimation guardrail to have tasks be no smaller than half day’s work and no larger than 2 - 3 days.  We discuss dependencies, hand offs, opportunities to parallelize (Optimize) work across different team members.  We start our iteration and reference the following board where we set/track daily team objectives - \n\n![image](http://i.imgur.com/hwZuLsa.jpg)\n\nAt the conclusion of Iteration planning we take these tasks and convert them into GitHub issues aligned with a Milestone (Feature). However, we don’t typically reference GH in our standup meetings but do see this as a very effective means to trace our code to the agreed tasks and enable a logical platform for code review.\n\nOther fringe benefits we are afforded by our “Game-Plan” on a daily basis include the following- \n\n* Clearly show dependencies across the team\n* Helps us focus WIP (Work in Progress)\n* Allows team to understand implications if a task is taking longer than expected - adjust our plan\n* Allows us to suss out blockages that a team member might not reveal on their own \n* If a team member has capacity and someone is over capacity they can see where they can help out \n\nYou will also note we do maintain visibility into the “High-Level Plan” at all times to ensure we continue to be thoughtful of implications to the overall project objectives.\n\nSo Carpe Diem fellow Project Teams - I’d love to hear if any teams out there are up to something similar or has learnings to share!\n"},{"title":"The most difficult position to hire for in tech right now","tags":["opinion","design","engineering","html","css"],"summary":null,"legacy":false,"id":"2014/08/06/the-most-difficult-position-to-hire-for-in-tech-right-now","employee":"Brian Cardarella","date":"2014-08-06T00:00:00","body":"\n\nThe most difficult position to hire for in tech right now is not\nengineering. It isn't design. It is the hybrid position: the UX\ndeveloper. Or the UX designer. Or the implementation developer. Or the\nCSS engineer.\n\nThis is how difficult it is, I have no idea what the \"official\" title of\nthis position is. We seem to go back and forth every few weeks on what\nto call it. But, this role has become incredibly crucial to how we and\nmost web companies operate.\n\nHistorically the responsibility for this position has fallen to\nengineering, or maybe design, depending upon how your team ran things.\nAnd it was the worst work. Cutting HTML, building terrible CSS. But\ntoday process and standards have fallen into place to make this role a\nlegitimate one that people should build a career in.\n\nUnderstanding how to optimize pages rendering, reduce CSS selector\nlookups, organizing stylesheets and markup files. This is just the\nstart. Finding someone that can communicate between design and\nengineering is a challenge and the people I've found to naturally fit\ninto this role excel at this. All of this before we ever start to talk\nabout accessibility, browser compatibility, standards compliance, and\nresponsive design.\n\nHowever, there is barely anyone out there making a career in this role.\nPerhaps because it has been traditionally looked down upon. Or perhaps\nbecause engineering and design get the glory. The UX developer might\nthink of one's self as the red-headed-stepchild.\n\nWe've taken a lot of efforts to bring the same quality we have in\nengineering and design here to our HTML & CSS. We've adopted\n[BEM](http://bem.info/),\n[SMACSS](https://smacss.com/), and we're constantly looking to improve\nour process and the tools we use. Have other companies found similar issues with this\ngrowing field? I'd like to hear from some people.\n\n(btw [we're hiring](mailto:jobs@dockyard.com))\n"},{"title":"Designing an Experience","tags":["design","design thinking","observations"],"summary":"A parallel between live performance and experience design.","legacy":false,"id":"2014/08/22/design-an-experience","employee":"Tim Walsh","date":"2014-08-22T00:00:00","body":"\n\nOver the years I have attended a lot of concerts, probably too many to count. Perhaps enough to make me deaf in the near future. One thing I've realized - I keep going back for the experience.\n\nA good concert is one where I’ve stood witness to the construction of a musical composition, built piece by piece from each member of the band, materializing into a single living, breathing entity; emblematic of those who devoted the time and energy into building something bigger than themselves. \n\nGood design should mirror this experience. It should be collaborative. It should be defiant and intelligent, original but cognisant of the past. It should set expectations for any and all future interactions. It should make the person say, “now that was the best show I’ve ever been to.” \n\nBecause when it comes down to it, who would want the alternative? A bad performance is like something designed in Microsoft Word. It is obvious and unbalanced. It is “too loud” and often “has way too many drunk people.”  \n\nSo control the stage while designing. Give people an experience that not only captures their attention, but gives them a reason to listen."},{"title":"Comics and Big Data","tags":["design","storytelling","information graphics"],"summary":null,"legacy":false,"id":"2014/08/25/design-and-big-data","employee":"Ashley Treni","date":"2014-08-25T00:00:00","body":"\n\nI’ve never been into comics or graphic novels. They’ve always remained in my periphery, but I never took the time to be interested in them. I appreciated good illustration, but rarely watched animations (except for Disney and Pixar of course) and pretty much ruled out that I would never “get” the appeal of a comic book.\n\nI took a data mining class last semester, and we discussed the importance of **visual storytelling**. I jotted down notes and took away a comprehensive understanding of design implications - keep colors relative and consistent, scale, got it, check.\n\n[Dietmar](http://www.northeastern.edu/camd/artdesign/people/dietmar-offenhuber/), my professor, had mentioned a book by Scott McCloud, [Understanding Comics](http://scottmccloud.com/2-print/1-uc/), and suggested looking to comics and film as an important metaphor for data visualization. Though I didn’t pay much attention at the time, this notion stuck with me, and a few weeks ago I invested in that very book.\n\nComics are a brilliant demonstration of visualizations that show multivariate information. Interactions, emotions, time, and space are all present, concurrent, and in flux - using frames and transitions to move the reader from one thought to the next. Comics pay attention to the readability of a story, by piecing together \"juxtaposed images in deliberate sequence.\" (McCloud, *Understanding Comics*) Unlike film, however, the static nature of comics leaves room for creative challenges balancing those variables simultaneously, especially the evolution of time. \n\nA series of information graphics is subject to the same dimensional considerations. Data Visualization is a balance of data analytics, visual representations, and a narration which provides a context for each investigation. Designing complex data to be comprehensive, interactive, and inviting is quite a challenge. While there are tools we can use to inspire visualization methods and techniques, there is much more to consider. There is an entire science behind visual cognition; why humans respond to certain characteristics faster than others (to be elaborated on at another point in time).\n\nTo incorporate storytelling into data visualization is to consider who we design for. Like comics, we must create an environment for the audience to become immersed, and the presentation of ideas shapes the interaction. The visual language we use, the way we sequence through visualizations, directly influences the legibility of the information. When we embrace the humanism of comprehension and perception, we design the experience to promote the success of the reader's ability to understand.\n\nLet's design to agitate curiosity and engagement. How can we utilize visual storytelling to inspire research, critical analysis, and conversation? Harnessing the power of design, we can draw inspiration from comics, and present information in a way that considers how the mind observes and acquires ideas.\n\nAs it were, I’m now devouring comics - making up for lost time. I’ve put my summer reading list on hold - to make time for books shared with me from fellow designers at DockYard, who maybe not so surprisingly, already have a deep appreciation and love for the brilliant medium that is comics.\n"},{"title":"The Fear of Failure","tags":["art","design","design thinking","inspiration","design process"],"summary":null,"legacy":false,"id":"2014/09/11/fear-of-failure","employee":"Logan Faerber","date":"2014-09-11T00:00:00","body":"\n\nWhen confronted with a new task it's natural for someone to feel a sense of anxious hesitation. Sure, it varies between individuals depending on the activity or setting, but entering an unfamiliar scenario can make anyone feel uncomfortable. Often this anxiety leads someone to succumb to their fears of failure, which ultimately results in them not even taking a chance at learning something new.\n\nNo one wants to be a failure - there's a connotation that you should just give up or else be publicly humiliated. Thanks to the recent development of social networks, anyone can declare someone as a failure simply by leaving a comment on a video online or posting blanketed statements on various articles - all the while never having to say it to their face directly or give useful constructive feedback. This mentality comes from a very judgmental and one sided declaration that spurs from people's fear of being a failure themselves. \n\nAlone, the term failure is a simple solution to a more complex problem. It's quick to label the scenario as everything having gone wrong rather than taking the time necessary to provide constructive feedback or to consider steps leading up to the \"failure\". By neglecting to reflect on the the particulars of the situation we are not learning from our mis-steps. \n\nRather than refer to these results as failures, I like to think of them as mistakes, granting more leniency to a lifetime of self-educating. While a failure feels conclusive, a mistake feels like a small part of a whole, which is more representative of how learning a new skill or concept should be. We should always be approaching the chance to learn something new with an optimistic and open mind, and the only way to do that successfully is to embrace the fact that you're bound to make mistakes along the way. Think about it; if a kid messes up, we don't instantly jump to calling them a failure. We let them know that it's okay, they've made a mistake, but then we follow up with an instruction or demonstration on how they could improve next time. This ability to showcase compassion when sharing ideas is how we've come so far as a human race. We tend to be most curious as children because we're unaware of the cultural judgment that comes from not being right all the time. We're still willing to experiment without that fear of failure. The curiosity to learn something new is an exciting one, where we focus on ourselves improving and not the jealousy of what others have accomplished, so why not treat our entire lifetime of learning with a similar level of patience and understanding? \n\nFear can be incredibly influential when learning something new as long as it's used to fuel the fire and not extinguish it - prove it wrong. Instead of focusing on what you have to accomplish and getting overwhelmed, take time to learn at your own pace; as they say, patience is a virtue. The best way to learn is to dive right in without thinking too heavily. By getting directly involved you will be learning through a hands on experience, which helps to reconfirm what works and what doesn't. As with most things, repetition is key to retaining information.  If you're willing to make mistakes along the way, jump right in and get your hands dirty. Not only will you avoid wasting time hesitating, but you're forced to find a solution now that you've already begun. The less you think in these scenarios, the better. \n\nIn order to learn we must be willing to make mistakes. Hundreds if not thousands of them. You'll probably even make some incredible, irreversible messes along the way. But rather than wasting time to criticize yourself or worry about what others think of you, focus on the task at hand. Take time to acknowledge what wasn't working, why it wasn't working, and move on. It's as simple as that. Ultimately our biggest failures lead to our greatest successes. So in order for us to improve and grow as individuals as well as a society we must try to overcome this fear or else we'll never progress, and that's the real failure.\n"},{"title":"Reducing Project Costs: Features As Business Objectives","tags":["design process","business","design thinking","engineering","planning","process"],"summary":null,"legacy":false,"id":"2014/09/12/features-as-business-objectives","employee":"Michael Dupuis","date":"2014-09-12T00:00:00","body":"\n\nThere is a lot of insight a developer can offer when it comes to reducing costs associated with building web applications. While few developers have MBA degrees, we are “in the trenches” when it comes to bringing a project from [ideation](http://www.wikiwand.com/en/Ideation_(idea_generation)) to completion. We see where projects go astray and where in the process complexity gets introduced, timelines get pushed out, and costs rise.\n\nFailed features are a significant cost to any project. I’m defining a failed feature as a feature which gets implemented by the developer correctly, but which was ill-conceived in the planning stages. There’s no 404 error pages, just poor user experiences that don’t serve the application’s aim.\n\nTo mitigate failed features, there is a first principle that I think clients should apply at the outset of any software project: \n\n**Align the application’s features with business goals.**\n\n“Have attainable goals,” is something you hear in a range of industries – from fitness to financial planning. For example, it is common when designing an investment portfolio to come up with a baseline for what you’d like to have saved by the time you retire. Goals help quantify short-term success (meeting monthly savings goals) and bring context to immediate financial decisions (going on an extravagant vacation vs contributing to the 401k).\n\nIn many regards, defining business goals is far harder than designing a feature for an application. Developers can implement an idea, but if the idea is not well grounded or refined enough, the implementation does not matter. Application consumers will not be able to use the feature in a way that translates to success for the business. For all intents and purposes, the feature is “broken” and costs are about to go up because it will need to be fixed.\n\nThis is why coming to a consultancy with a list of features is problematic. Features are not grounded in any sort of reasoning; business objectives are. Enter the planning process with a set of business objectives for the application.\n\nLet’s take a simple case. A client is overhauling their marketing site. They sit down in their first planning meeting with the designers and developers and say “we want a blog.” A blog is a feature – it is not a business objective. What would be more helpful from the designer and developers’ perspectives is to hear: “we want a way to show prospective clients that our firm is transparent.” This a business objective. It informs the designer that there is a target audience to design for (prospective clients). It tells the designer a little bit about the client’s values (transparency). Yes, it may lead to a blog, but what’s important is that it grounds the feature with a purpose.\n\nFeatures must align with business goals, because they create the theoretical framework in which the application operates; the alternative is an aimless application with a lot of code, a lot of options, and a lot of usability problems. Designing a user experience which gets the consumer from point A to point B becomes difficult because there is not a logical consistency to the elements in the application. Features do not have a unique roles, and so the designer cannot delegate responsibility in a predictable manner.\n\nFeatures that are not aligned with business objectives are expensive.\n\nIt goes without saying, but clear design thinking translates into cleaner implementations for the developers building the application. Features can be added, removed, and enhanced without hurting other elements of the application. Code becomes less coupled, is more maintainable, and can be better tested.\n\nFeatures without well-defined roles don’t have a place in the application’s ecosystem, and so they often fail. This is a worst case scenario. It means that users can’t interact with the application in a way that’s meaningful for the business. And since these failed features need to be fixed and re-worked to meet the business objective (which should have been known and communicated at the outset of the project “discovery” process), the client has expended the following resources:\n\n1. the time that went into designing and implementing the failed feature\n1. the cost that went into designing and implementing the failed feature\n1. the time that will go into designing and implementing the correct feature\n1. the cost that will go into designing and implementing the correct feature\n\nThis is to say nothing of the opportunity costs. While one client is figuring all of this out, a competitor who aligned their features with their business objectives and “got it right” on the first attempt is gaining happy, new users. \n\nWhen a businesses hires a software consultancy to develop an application, they’re bringing in skills and expertise from the outside. It’s unlikely that a developer is going to advise a client on how to gain market share, and it’s just as unlikely that a client is going to open a designer/developer’s eyes to a new application feature. Rather than planning an application around a set of features, clients can make the most of a consultancy's resources by coming to the planning stages of a project with well-defined business objectives.\n"},{"title":"Building Quality Into Our Projects","tags":["quality","engineering","planning","process","project management"],"summary":null,"legacy":false,"illustration_alt":"image","illustration":"http://i.imgur.com/DEWme3R.jpg","id":"2014/09/19/building-quality-into-our-projects","employee":"Jon Lacks","date":"2014-09-19T00:00:00","body":"\n\nThis article serves as a continuation of a “Client Targeted” article recently published by our own Michael Dupuis (<a href=\"http://reefpoints.dockyard.com/2014/09/12/features-as-business-objectives.html\">Features As Business Objectives</a>). These posts aim to provide our current and prospective clients insight into how we approach development at DockYard.\n\nBuilding “Quality” software does not happen by accident. It is actually one of the unspoken sides of the “iron triangle” of project constraints (Scope, Cost, Time) - or should we call it a diamond now? Let’s not go there!\n![image](http://i.imgur.com/DEWme3R.jpg)\n\nWhen making an investment in development of an application, the level of desired quality influences project cost and schedule.  Building an appropriate Quality Plan for a project requires time, planning and execution which is the responsibility of DockYard and the clients with whom we engage.  Below I layout the primary types of quality related practices we may consider applying to our (your) projects; always driven by clients’ unique context (See my earlier blog post about context driving practices - <a href=\"http://reefpoints.dockyard.com/2014/06/06/process-paradox.html\">Process Paradox</a>).  This article does not serve to describe these quality practices in depth but will cover the basics in terms of how they could apply to client projects.  Any one of these practices in isolation is not an effective recipe for quality, it is the degree to which these practices are commingled in a logical way that results in positive outcomes.\n\n## Practice #1 - Test-Driven Development / Automated Testing\n\nBefore the Engineer writes a line of code they are investing time in thinking about and writing the appropriate test cases for the code - these tests will serve as a functional quality benchmark which the engineer can code towards. In parallel these efforts build up a library of automated tests that will ensure that the “working” features built early in the project continue to work when new features (code) are introduced later on.  If we don’t have these tests and we have 1000’s of lines of code, testing/debugging overhead raises exponentially which will result in increased risk to project cost and/or desired schedule.  It’s also important to note that this practice is functionally-centric and not visual which is addressed with other practices described below.\n\n***What this means to the client***\n\nThe cost and eventual savings related to this practice manifest themselves as time spent thinking vs. coding vs. testing. When we estimate what it will take to develop a given feature, we consider the time spent thinking about these tests, writing the tests, maintaining the tests in addition to writing the feature code.  However, keep in mind that the time spent testing later on in the project, when the code base has grown exponentially, is reduced due to this upfront investment of time (see figure below) because we have a growing set of automated tests that will ensure we continue to maintain high quality throughout the development cycle.\n\n![image]( http://imgur.com/2HBq9ie.jpg)\n## Practice #2 - Pair Programing / Code Reviews\n\nSometimes (usually) two heads are better than one.  Pair Programming is exactly as it is described. Two engineers team up to work side by side on a single unit of code (or feature.) In a 2013 article published by the Economist a study conducted by Laurie Williams of the University of Utah showed “*...paired programmers are 15% slower than two independent individual programmers, while \"error-free\" code increased from 70% to 85%. Since testing and debugging are often many times more costly than initial programming, this is an impressive result. Pairs typically consider more design alternatives than programmers working alone, and arrive at simpler, more maintainable designs; they also catch design defects early.*”\n\nAdditionally, Code Reviews by a peer or more senior engineer serve to ensure that the code being written meets agreed best practices and that mistakes of the past don’t get reintroduced.\n\n***What this means to the client***\n\nPair programing and Code Reviews are practices DockYard believes yield higher quality code while also establishing a continuous learning culture across our engineering team.  The extent to which we apply these practices is less variable in that it is part of our company DNA - however, like any practice, a client’s project context will dictate the extent to which these apply.  The client will incur the benefit of a well rounded and productive engineering team which can translate to reduced project cost.\n\n## Practice #3 - Manual Testing\n\nIn a literal sense this is the type of testing conducted by a human who seeks to ensure the less common use cases which may not have been exercised by an Automated Test or code review are working as expected. Additionally, this type of testing ensures the visual design of the product has been upheld -  Spacing, pixels, colors, fonts, etc.  Browser compatibility is also something manual testing will verify. This type of testing is usually conducted by members of the project team and the client. They work in collaboration across the feature set, report and classify severity of bugs which are eventually assigned to engineers when appropriate.\n\n***What this means to the client***\n\nThe client should be prepared to be a very active participant in this practice and schedule their time accordingly.  Feature complexity will drive the amount of time required for this type of testing - which might be nil if complexity is low.  A very rich user experience will require more testing and thus manifest itself in terms of increased time/cost.\n\n## Practice #4 - Client Demos (and Acceptance Testing)\n\nFor most projects we work in 1-2 week iterations (sprints) and at the conclusion of this time period we typically demonstrate the progress we have made by sharing working software. These demonstrations serve a dual purpose:\n\n1. gives the client opportunity to verify development is proceeding in the desired direction, and if not, attempt to course correct early on vs. late in the project when course correction can be very costly\n2. allows the team to reflect and continuously improve how they are executing the project.\n\nWhen a feature is ready for prime time, we will usually ask the client to formally accept the feature as complete.  This ensures the team can shift their full focus and attention to building the next features on the backlog. Context switching can be very costly in terms of productivity, therefore we try to call things “Done Done” before moving on.\n\n***What this means to the client***\n\nSimilar to manual testing, client should be prepared to be a very active participant in both demos and conducting acceptance testing within agreed timeframes.  Deviation from established timeframes will result in increased project cost/time.  Therefore, whenever we engage with a client, we request upfront a high level of collaboration and availability to keep things moving along.\n\nHopefully after reading this article, you have gained an appreciation for some of the considerations we make in terms building quality into our projects.  The level of quality a client desires and the pride DockYard has in its deliverables drives the extent to which these practices are utilized.  Therefore, if you are interested in engaging with us, think about the level of quality you expect and we will work together to derive an appropriate quality plan that balances your cost and time constraints.\n"},{"title":"JavaScript Performance For The Win","tags":["javascript","engineering"],"summary":null,"legacy":false,"id":"2014/09/22/javascript-performance-for-the-win","employee":"Alex Navasardyan","date":"2014-09-22T00:00:00","body":"\n\nJavaScript performance is a very hot topic nowadays. There's a lot of information out there on what\nbrowsers do with JavaScript code in order to execute it faster. Let's go over some of the tips that\nwill help you write faster JavaScript code.\n\n## Tooling\n\nThere're are couple of tools that you can use to identify and fix peformance problems. One of the\nthem is Chrome Developer Tools (open Chrome Developer Tools, switch to `Profiles` tab and click `Start`).\nDeveloper Tools will give you a great overview of what actual happens in your application under the hood\n(what functions are called, how much CPU time they consumed, how much memory). That's a great starting\npoint. Now you can start fixing performance where it matters.\n\n## Non-optimizable code\n\n`try-catch` and `try-finally` blocks will not be optimized by the V8 (to be clear, if the function contains\na `try` block, the whole function will not be optimized).\n\n```javascript\n// code\ntry {\n  iMightThrowFunc();\n} catch(exception) {\n  iHandleExceptions(exception);\n}\n// code\n```\n\nA better way of writing the code above, would be to isolate the `try` block into a separate function so `code`\ncan be optimized and only `iMightThrowFunc` would not be optimized:\n\n```javascript\nfunction iMightThrow() {\n  try {\n    // [code]\n  } catch(exception) {\n    iHandleExceptions(exception);\n  }\n}\n\n// code\niMightThrow();\n// code\n```\n\n## Using Local Variables\n\nIf you're using a piece of code many times, it's better to create a local variable for it for a couple of reasons:\n\n1. faster scope look ups (once the variable is local scope, it's faster to retrieve it)\n2. caching (performing an operation once and storing the result will result in less work for the browser)\n\n## Literals\n\nIt might sound very obvious but you should use object literals whenever you can.\n\n```javascript\n// use\nvar array = [];\n// instead of\nvar array = new Array(16);\n```\n\nYou rarely know what the size of the array is going to be in your application. Let V8 manage the growth\nof the array as you add items to it. It will also ensure that the array is in \"fast elements\" mode and\nitem access is always fast. You can read more about V8 object representation [here](http://jayconrod.com/posts/52/a-tour-of-v8-object-representation).\n\n#### \"Dictionary Mode\"\n\nAn object will go into \"dictionary mode\" when you add too many properties dynamically\n(outside constructor), `delete` properties, use properties that cannot be valid identifiers.\n\n```javascript\nfunction forInFunc() {\n  var dictionary = {'+': 5};\n  for (var key in dictionary);\n}\n```\n\nWhen you use an object as if it was a dictionary, it will be turned into a dictionary (hash table).\nPassing such an object to for-in is a no no.\n\n#### Iterating over a regular array\n\n```javascript\nfunction arrayFunc() {\n  var arr = [1, 2, 3];\n  for (var index in arr) {\n\n  }\n}\n```\n\nIterating over an array using `for-in` is slower than a `for` loop and the entire function containing\na `for-in` statement will not be optimized.\n\nUsing `for` loop is almost always a safe bet. Do you need to iterate over object's properties?\n\n```javascript\nvar objKeys = Object.keys(obj);\nvar propertyName;\n\nfor (var i = 0, l = objKeys.length; i < l; i++) {\n  propertyName = objKeys[i];\n  // more code\n}\n\nfor (var propertyName in obj) {\n  if (obj.hasOwnProperty(propertyName)) {\n    // more code\n  }\n}\n```\n\n## For-In\n\n`For-In` statements can prevent the entire function from being optimized in a few cases. It will result\nin \"Not optimized: ForInStatement is not fast case\" bailout.\n\n### `key` has to be a pure local variable\n\nIt cannot be from upper scope or referenced from lower scope.\n\n```javascript\nvar key;\n\nfunction doesNotSeemToBeLocalKey() {\n  var obj = {};\n  for (key in obj);\n}\n```\n\n## Arguments\n\nCareless manipulations with `arguments` might cause the whole function to be non-optimizable. It might result in\none of these \"bailouts\": \"Not optimized: Bad value context for arguments value\" and \"Not optimized: assignment\nto parameter in arguments object\".\n\n### Reassigning `arguments`\n\n```javascript\n// do not re-assign arguments\nfunction argumentsReassign(foo, bar) {\n  if (foo && foo === 5) {\n    bar = 'Barracudas';\n  }\n  // code that uses `bar`\n}\n\n// use local variables instead\nfunction argumentsReassign(foo, bar) {\n  var localBar;\n\n  if (foo && foo === 5) {\n    localBar = 'Beantown Pub';\n  }\n  // code that uses `localBar`\n}\n```\n\n### Leaking `arguments`\n\n```javascript\n// `arguments` is a special object and it is costly to materialize.\nfunction leaksArguments() {\n  var args = [].slice.call(arguments);\n  // code that uses `args`\n}\n\n// does not leak arguments\n// accessing `arguments.length` is just an integer and doesn't materialize\n// `arguments` object\nfunction doesNotLeakArguments() {\n  var args = new Array(arguments.length);\n\n  for (var i = 0; i < args.length; ++i) {\n    // `i` is always valid index in the arguments object\n    // so we merely retrieve the value\n    args[i] = arguments[i];\n  }\n  // code that uses `args`\n}\n```\n\nNote, that in most cases optimizing takes more code. You can probably write a build step for that:\n\n```javascript\nfunction doesNotLeakArguments() {\n  arguments_slice(args, arguments);\n  // code that uses `args`\n}\n```\n\nHappy Coding!\n"},{"title":"Go: UX East's UX Camp","tags":["design","design process","design thinking","conferences","ux east"],"summary":"A weekend of creative thinking and collaboration.","legacy":false,"id":"2014/09/24/announcing-ux-east-camp","employee":"Steven Trevathan","date":"2014-09-24T00:00:00","body":"\n\nWe are pleased to announce [UX East's UX Camp](http://uxeast.org/), a weekend of creative thinking, collaboration, and design in one big house on Nov 14—16th in [Bryant Pond, ME](https://goo.gl/maps/JPqdT).\n\nThis isn't a typical networking event or conference. We'll escape the busy and distracting city environment to focus on our craft alongside others interested in design. It's a project weekend, a getaway, and a mini–conference all rolled into one. You'll work on whatever you like with the option of gaining creative input of others.\n\nThe environment is intimate by design. There will only be 30 people at this event who you'll eat, sleep, and work alongside. On top of all this, there will be a workshop and a few talks available to all who attend.\n\nThere are many more details to come, and I'm excited to share them with you! Follow our [UX East](https://twitter.com/ux_east) twitter account or check back here for updates. If you're interested in taking part in the event in any capacity, please reach out to [steven@dockyard.com](mailTo:steven@dockyard.com).\n\nSee you all in Maine!\n"},{"title":"KSS Your Styleguide Goodbye","tags":["tools","process"],"summary":null,"legacy":false,"illustration_alt":"GitHub Styleguide","illustration":"https://i.imgur.com/nfwgONd.jpg","id":"2014/10/24/kss-your-styleguide","employee":"Christopher Plummer","date":"2014-10-24T00:00:00","body":"\nStyleguides are a place where developers and designers can find authoritative information about how elements are to be styled throughout a project. Contributors can always refer to a styleguide to help them create new pages and elements. Careful attention to a styleguide can prevent a contributor from designing or developing components that don't conform to the designers' vision.\n\nMost styleguides are created by designers and developers prior to development to guide the translation of comps into code. In a perfect world, that styleguide is a living document that is updated as changes are made to the design. This often doesn't happen. As changes are made throughout a project's development cycle, the styleguide is rarely updated. At some point on almost every project, that styleguide is no longer a reliable, authoritative document.\n\nIf only there was a better way...\n\n## Enter KSS\n\n[KSS](http://warpspire.com/kss/) is a methodology and set of tools that will help you create automated, living styleguides. Through the KSS menting syntax and the KSS parser, the guide can be updated automatically throughout the development cycle. All those little adjustments and decisions that happen in conversations outside your documented channels will be reflected in your KSS styleguide. In theory, the styleguide will show the most up-to-date styles. KSS styleguides also render element states like `:hover` as you can see in this [example from GitHub](https://github.com/styleguide/css/):\n\n![GitHub Styleguide](https://i.imgur.com/nfwgONd.jpg)\n\nA KSS styleguide can be designed to reflect the look and layout of your project using existing styles:\n\n![Two KSS Styleguides](https://i.imgur.com/oq4P8vd.jpg)\n\n**KSS isn't magic. It's not going to create the styleguide for you.** You still have to do a lot of custom configuration and coding. Coding the styleguide starts with commenting your CSS. You have been leaving helpful comments for future developers all along, right? KSS [defines a syntax](http://warpspire.com/kss/syntax/) for these comments:\n\n```sass\n// Short description of the element to be documented\n//\n// :hover             - description of this modifier.\n// .disabled          - description of this state class modifier.\n//\n// Styleguide x.x.x. Section Name and/or Number\n.element-to-be-documented {\n  ...\n  &:hover{\n    ...\n  }\n  &.disabled{\n    ...\n  }\n}\n```\n\nA KSS parser like [this one for ruby](https://github.com/kneath/kss) parses the elements of those comments – the description, modifiers, and section – and applies it to a partial like this:\n\n```erb\n<div class=\"styleguide-example\">\n\n  <h3>\n    <%= @section.section %>\n  </h3>\n  <div class=\"styleguide-description markdown-body\">\n    <p><%= markdown h(@section.description) %></p>\n    <% if @section.modifiers.any? %>\n      <ul class=\"styleguide-modifier\">\n        <% modifiers.each do |modifier| %>\n          <li><strong><%= modifier.name %></strong> - <%= modifier.description %></li>\n        <% end %>\n      </ul>\n    <% end %>\n  </div>\n\n  <div class=\"styleguide-element\">\n    <%= @example_html.gsub('$modifier_class', '').html_safe %>\n  </div>\n  <% modifiers.each do |modifier| %>\n    <div class=\"styleguide-element styleguide-modifier\">\n      <span class=\"styleguide-modifier-name\"><%= modifier.name %></span>\n      <%= @example_html.gsub('$modifier_class', \" #{modifier.class_name}\").html_safe %>\n    </div>\n  <% end %>\n\n  <div class=\"styleguide-html\">\n    <%= @example_html %>\n  </div>\n</div>\n```\n\nYou'll also need to create a controller, a template, helpers, and a front-end KSS script to render the styleguide. It's a lot of up-front work, but there are examples and parsers already written for Node.js, Ruby, PHP, Sinatra, Rails, and so on.\n\n## Why use KSS?\n\n**If standards, methodolgies, and tools are your thing, you'll like KSS:**\n\n- The kss.js script can render elements with different states (called modifiers by KSS) directly in the styleguide blocks. For example, buttons with `:hover`, `:focus`, `:active`, states or even modifier classes like `.red`, `.is-active`, or `.disabled` will be automatically added to the styleguide allowing readers to see every possible state at once.\n\n- CSS comments and styleguide documentation are bound together in the stylesheets, not some other styleguide-specific template. UX developers can comment the stylesheets they work in most while they're working in them.\n\n- The styleguide templates can also include markup codeblocks, allowing readers to see the markup elements necessary to generate a component.\n\n## Why not use KSS?\n\n**If you're in the \"tools are bullshit\" crowd, you're going to hate KSS:**\n\n- Styleguides created with KSS are only as reliable as the CSS and markup used to generate them. If an element is changed in a way that no longer conforms to the design comps, the styleguide will no longer reflect the correct way that element is supposed to be styled. For example, a developer might change the border radius of a particular button for a new page and doesn't realize that he or she has just changed the base button style in the styleguide. Now the button entry styleguide is no longer a reliable representation of the styles established in the design comps.\n\n- When elements are taken out of their context it can change how styles are applied. Elements have to be adjusted and changed just to appear correctly in the styleguide. This is work beyond what is strictly required to develop a site.\n\n- Styleguide-only styles and markup might be confusing to developers joining a project. The rules and markup in the styleguide aren't necessarily the same rules or markup used in the site. When creating new elements that follow from a styleguide entry, simply copying the elements as they appear styleguide could cause layout and style problems.\n\n- The KSS documention is spread out over many files. Nothing is centralized. Simply restructuring the styleguide, editing sections, or even adding new items requires sifting through many CSS files and templates. And when styles for elements are duplicated or spread across several pages, where do we put the documentation?\n\n- Deciding what goes in the styleguide and how it is documented becomes another tangle of challenging questions. How do we describe this element? How to we organize the guide? What do we include?\n\n## KSS Is Just Another Thing\n\nThe strength of KSS – automation – is also the source of its weakness – mutable elements. If the styleguide can be updated automatically, it can also be sabotaged accidentally. The styleguide must be QA'ed alongside the site to ensure that it conforms to the design comps and that it accurately illustrates elements as they appear in the actual site pages. Developers must take care to pay attention to styleguide-only rules and markup.\n\nYou could generate a static styleguide in your comping tool of choice as a definitive reference against which to check the living styleguide. But then you're just creating more documents that must be updated. You haven't solved the original problem.\n\nImplementing KSS requires additional UX Development and Design resources (additional QA, more templates, styleguide-only styles, controllers, etc.), but may save resources spent creating and updating a static styleguide.\n\nKSS is not a perfect solution to the problem of maintaining living styleguides. You'll simply have to try it in your workflow to evaluate its utility.\n"},{"title":"Motivation vs Discipline","tags":["opinion"],"summary":null,"legacy":false,"illustration_alt":"Motivate","illustration":"https://i.imgur.com/ChxXPmT.jpg","id":"2014/10/30/motivation-vs-discipline","employee":"Brian Cardarella","date":"2014-10-30T00:00:00","body":"\n\nWe've all seen the **Motivational Posters**:\n\n![Motivate](https://i.imgur.com/ChxXPmT.jpg)\n\nI always hear people talk about\n**motivation**. *What motivates you?* *I'm lacking motivation.* Well I'm\nhere to tell you that motivation is bullshit.\n\nMotivation may get you to take on a task or behavior that you don't\nnormally do but eventually that motivation will either not be there any\nmore or won't be effective. Then you'll slip, and you justify it by\nthinking *\"well I just lacked proper motivation\"*.\n\n*Motivation* as a concept is a cop-out. If you feel that you need\nmotivation to accomplish your goals you will likely fail over the\nlong-term. Instead you should be looking toward discipline.\n\nThere is a saying *\"it takes 3 weeks for a new behavior to become\nhabit\"*. If you haven't heard that before that's OK because it isn't\ntrue. According to research it actually takes [on average 66 days of\ncontinual behavior to form a\nhabit](http://www.huffingtonpost.com/james-clear/forming-new-habits_b_5104807.html).\nSo ask yourself this. Can you use the same motivation for 66 days in a\nrow? If not, do you have that many different forms of motivation to form this\nnew habit over this period of time? I don't think many of us do.\n\nDiscipline on the otherhand is you saying to yourself *\"I will do this\neven if I would prefer to do something else\"*. It's not an easy trait to\nestablish but if you can do so you'll find that making changes happen\nmore easily. I think many of us have a *will* to overcome existing habits and\nform new ones but we lack the *way* to do so. Too many distractions, too\nmany opportunities, too many excuses. Take a look at successful people\naround you. Ask yourself are they successful because of some outside\nmotivation or are they successful because they've made a conscious\ndecision they're going to wade through the muck to get what they want.\n\nFocus on being disciplined instead of waiting to be motivated. \n"},{"title":"Pitch This","tags":["opinion","business","marketing"],"summary":null,"legacy":false,"id":"2014/11/07/pitch-this","employee":"Brian Cardarella","date":"2014-11-07T00:00:00","body":"\n\nHere is something I probably shouldn't be admitting: I can't put\ntogether a sales pitch for my own company.\n\nIt's not that I don't know what we do, I am intimately familiar with\nwhat we do. It's not that I don't believe in us, in fact we\nhave big growth plans for the next 3 years and I am certain we'll meet\nthem. It's just that I find it incredibly difficult to describe to\nothers in an \"elevator pitch\" what a software consultancy can offer\nwithout going down the \"technology\" rabbit hole.\n\nThe exercise is: *if I were introduced to someone at a party, how do I convince them they should \nhire DockYard*? Funny enough, I can't do it. This is a very large\ndeficiency for me/my company right now. To date **all** of our\ncontracts have been from inbound sales. Which is great, but we need to\nbe able to sell our services to companies that don't yet know about us.\n\nSo what does DockYard do? According to our current landing page *We\ncreate web & mobile applications*. Which is 100% true, but if I told\nthis to you I doubt you'd hire us. I asked other DockYard'ers to try\ntheir hand at writing the DY pitch. To illustrate how difficult this is\nhere is what they came up with:\n\n* *DockYard designs and develops applications for people who have an idea and don't know what to do next*\n* *We build web products, and focus on quality.*\n* *We create software that helps people. A client can come to us seeking advice regarding software development practices or looking to implement a product he/she has been thinking about. Our main focus is delivering a solution that a client is happy with by using powerful visual design, best software engineering practices and latest technologies.*\n* *We're a design and development shop specializing in really intuitive, responsive user interfaces. We work primarily with Ember.js, which is a JavaScript framework similar to Angular and Backbone. On the backend, we prefer a Rails backend and transactional database, which is more reliable than the NoSQL databases out there.*\n* *DockYard leads projects from ideas to user-friendly products that are built by cutting edge technologies and methodologies. As a team, we put clients' business goals in the forefront through the collaborative expertise of our designers and developers.*\n* *DockYard helps business owners create web apps with the combined power of Ember and great design.*\n* *We're a team of software designers and engineers deeply invested in producing the best solution to a challenge, rather than just the one that works.*\n* *We do a lot of research before we start designing, so our projects are thought through. Designers have a lot of say in what we actually build, compared to other shops, so it makes the work more meaningful.*\n\nSome of these go beyond the scope of a \"pitch\" but I think the message is clear: this is not an easy assignment. \nThe common theme is the focus on our expertise, which is a good angle. Expertise has been what defines DockYard.\nBut do all companies care about **how** we build? \n\nCurrently nearly all of our clients get in touch with us because\nof our expertise in Ember.js. At that point the sale is\nactually quite easy. There aren't a lot of consultancies right now\nclaiming expertise in Ember. Amongst those firms I believe that\nDockYard is considered one of the top. So by the time the client\ncontacts us they have probably already decided to go with us. This is\ngreat but it paints us into a niche. We're missing out on the other\n99.99% of the opportunities that don't know about us.\n\nSo how do some other software consultancies pitch? I don't know if it is\nfair to use the marketing tagline from their website as their \"pitch\"\nbut I think it is close enough for the purposes of this article. Let's\ntake a look:\n\n* **Thoughtworks** *We provide software delivery, pioneering tools and\n  consulting for organizations with ambitious missions.*\n* **Pivotal Labs** *We transform how the world builds software.*\n* **thoughtbot** *Our clients hire us to design and build their\n  products. We focus on user outcomes and simplicity. We write code for\niOS, Android, and the web.*\n* **37signals** *an elite team of expert web design and usability\n  specialists dedicated to simple, clear, and useable customer-focused\ndesign.*\n\nI don't know if this really helps me or confuses me even more. These are\nall over the place, from general, to technology specific, to downright\nvague. Each of these companies have been very successful. How much of\ntheir success do they owe to their sales pitches? **37signals** (when\nthey were a consultancy) was famous for being a referral based business.\n(or at least advertising themselves as such) I don't know **thoughtbot**\nas well as I used to but I believe they still don't have any internal\nsales team. **Thoughtworks** and **Pivotal** both have sales/biz-dev\nteams. Their marketing lines are very vague, very \"wide-net\". No help\nhere.\n\nIt's sad to say but I am currently at a loss on how to effectively sell my own company. \n"},{"title":"My project for UX Camp","tags":["ux east","ux camp","user experience","design","conferences","design process"],"summary":null,"legacy":false,"illustration_alt":"sketches","illustration":"https://i.imgur.com/K9TBWR9.jpg","id":"2014/11/12/bring-to-ux-east","employee":"Maria Matveeva","date":"2014-11-12T00:00:00","body":"\n\nThis weekend, I am heading to [UX East's camp](http://uxeast.org/) in Maine. It is kind of like a conference, except you also get the opportunity to work on your own project and get feedback from others while there. I am helping organize the event, and a large chunk of my time will be spent taking photos and helping with other random tasks, so I wanted to bring a project that’s small and easy to manage.\n\n![sketches](https://i.imgur.com/K9TBWR9.jpg)\n\nMy project is practicing how to quickly sketch ideas by hand.\n\nWhen I first started as a UX Designer at [DockYard](https://dockyard.com/), I noticed how confident the other designers were at sketching. [Logan](https://dockyard.com/team#logan-faerber) just happens to be a [kickass illustrator](https://dribbble.com/shots/1765074-UX-East-Icons?list=users&offset=3), which helps. But still, I felt like I lacked confidence in comparison. I’ve been trying to improve, but had not tried anything focused on sketching specifically yet.\n\n\n## Why is sketching useful?\nSketching is a great tool not only to produce work deliverable to the client (hand drawn wireframes are often part of the Discovery phase in our work) but also a way to think more clearly. If I can articulate an idea through a drawing, I have a good understanding of it. In the process of drawing something out, I also find the fuzzy areas that need more definition, and I am able to ask better questions as a result.\n\nWriting on a subject is similar to this exploratory sketching. By trying to write on a subject, I find unexplained pieces, and am forced to form my thoughts clearly. But writing only uses one aspect of an idea. Visuals are something else. I want to rely on both verbal (writing) and visual (drawing) thinking in my work.\n\n## How to practice?\nI decided to focus on practicing only the skill to express a single idea through a very simple drawing. As an art supply enthusiast, it is easy for me to get carried away in selecting just the right pen, paper or color for a project. To counter this, I limited my tools: a clipboard, a single medium-weight black marker, and a sizable stack of half-sheets of printer paper.\n\nI further limited possible distractions by deciding not to focus on high quality, thoughtful drawings, and instead produce many simple drawings. For this reason, I will also not look for great reference material, but try to just get the visual idea down on paper quickly instead.\n\nI will also focus on actually drawing, rather than annotating. In the few practice drawings I made so far I resorted to writing the details I could not get into the drawing. It would be great to get away from this.\n\nWhen I finish one of these simple drawings, I will slide it to the bottom of the stack so I’m ready to start another one. I will not focus on judging the results too quickly.\n\nAt camp, I might share the drawings I make, and ask for feedback on how to make them more clear. Will they make sense? With some practice, I hope that they do.\n\nSo, here’s what I am working on. Pretty simple, and should be fun! I also asked a couple of colleagues what they are planning to do — and here it is:\n\n## What Steve is working on\nHe's going to work on a video game idea that originally started as a web-comic at DockYard. In addition to that he's taking a look at some various prototyping tools (as well exploring InVision a little deeper).\n\n## What  Tim is working on\nTim has been working on a typeface that is targeted to be both practical and highly legible. He's hoping to gain some feedback from fellow campers and continue chipping away at the lowercase letterforms.\n"},{"title":"Rubygems.org Redesign","tags":["design","ruby"],"summary":null,"legacy":false,"illustration_alt":"RubyGems Redesign","illustration":"https://i.imgur.com/Wy7zNYB.png","id":"2014/11/18/rubygems-redesign","employee":"Brian Cardarella","date":"2014-11-18T00:00:00","body":"\n\n![RubyGems Redesign](https://i.imgur.com/Wy7zNYB.png)\n\nToday I am very proud to announce that the DockYard-led redesign of\n[rubygems.org](http://rubygems.org) has been launched.\n\n[Ruby Central](http://rubycentral.org) just announced and put into production a redesign of Ruby's\nmost popular community website during the Lightning Talk session at\n[RubyConf 2014](http://rubyconf.org)\n\nThe redesign effort was led by [Logan\nFaerber](https://twitter.com/LoganFaerber) and built out by [Amanda\nCheung](https://twitter.com/acacheung). You can see how happy it has\nmade them.\n\n![Hooray!](https://i.imgur.com/l6jQ1f0.jpg)\n\nWe would have been lost without the guidance from Ruby Central folks [Evan\nPhoenix](https://twitter.com/evanphx),\n[David Radcliffe](https://twitter.com/dwradcliffe), [André Arko](https://twitter.com/indirect). As well as some insight from [Nick Quaranto](http://twitter.com/qrush).\n\nWe were very fortunate to have been selected. We hope that everyone\nenjoys the new look!\n"},{"title":"UX East Camp 2014","tags":["design","design process","design thinking","conferences","ux east"],"summary":null,"legacy":false,"id":"2014/11/18/we-did-it","employee":"Steven Trevathan","date":"2014-11-18T00:00:00","body":"\n\n[We did it.](http://uxeast.org/ \"UX East Camp\") This weekend went far better than we ever could have imagined. We’re grateful and maybe a tad bit emotional, so bear with us.\n\nThe camp was initially intended as somewhat of a proof of concept, but became something much more real than that. Beyond proving that we are all willing to spend 3 days living with complete strangers, we experienced the unique value of the connections, friendships, and mentoring that this style of event facilitated. It turns out that the people who pay good money for and spend a whole weekend on such a unique social and learning environment are exactly the type of people who make it worthwhile. The need to learn, share, and be challenged by their peers is in their blood. This is who they are, and they’re the people we want to bring together.\n\nIt goes without saying: [Michelle](https://twitter.com/michelleyaiser \"Michelle Yaiser\"), [Ed](https://twitter.com/StayingInDroves \"Ed King\"), [JD](https://twitter.com/CalamityJD \"JD Jordan\"), and [Ben](https://twitter.com/benjordan \"Ben Jordan\") did much more than they were asked to and were the core of what made the camp so great. They shared their wisdom, challenged us to solve hilariously weird and unique problems, guided us, and befriended us. They poured their hearts into this and we are proud and humbled to have had them for our first UX East Camp.\n\nThe event was a risk, but the speakers and attendees overwhelming proved to us that it can and should be done. So we’re going to do it again.\n\nSee you next year at UX East Camp, Spring 2015.\n"},{"title":"Ember Wish List","tags":["ember","opinion"],"summary":null,"legacy":false,"id":"2014/11/28/ember-wish-list","employee":"Brian Cardarella","date":"2014-11-28T00:00:00","body":"\n\nIt's getting close to Christmas and I've got a few things on my list for\nTomster Claus this year. All of my wishes are about making my\napplications smaller. One of the constant complaints I see about Ember\nis that it is \"too fat\". You may not know this but this problem is\nsolveable and can actually grow alongside Ember to ensure your assets\nare a slim as they can be. On to the wish list!\n\n### Tree Shaking\n\nAre you familiar with Tree Shaking? The concept is simple, a dependency\ngraph of your application is built. Let's say one of your files requires\n`A`, `B`, and `C`. And `A` requires `D`, and `F`. And `C` required `F`.\nCurrently with Ember CLI all files for all of your dependencies will get\nincluded in the final build. So if there is an `E` file it will be in\nthe final build even if you are not using it in any way, this is wasteful.\nWith ES6 the dependency graph can be built between your files, any files\nthat are not in the graph are not included in the final built. They are\n\"shaken\" out of the build process. This means a smaller footprint for your assets.\n\nThere are two major hurdles to implementing this in Ember CLI right now.\nThe first is that doing a static analysis on the dependency graph may\nresult in false positives of what files to ignore for the build. While\nthere are many files that you are depending upon via the `import`\nstatement:\n\n```javascript\nimport { foo, bar } from 'baz';\n```\n\nThis is very easy to parse. But your application can also import\nresources via the Ember Resolver:\n\n```javascript\ncontainer.lookup('model:foo');\n```\n\nA few levels down a `resolveOther` function is called and `lookup` is\nturned into a `require`:\n\n```javascript\nrequire('my-app/models/foo');\n```\n\nparsing this out is not as simple. We could just assume everything in\nthe app's namespace should be part of the final build, but when other\nlibraries are doing more complex tricks with importing this presents a\nproblem. For example, in the latest version of Ember Validations the\nvalidators themselves live in the `ember-validations` namespace. You can\noverride validators by placing them in your namespace. The lookup is\nsomething like this:\n\n```javascript\nfunction lookupValidator(name) {\n  return container.lookup('validator:'+name) ||\n    container.lookup('ember-validations@validator:'+name);\n}\n```\n\nHow do we properly parse this out to include the correct validators in\nthe dependency graph? One solution might be for library authors to\ndeclare which files should always be included in the final build, but\nthis defeats the purpose of only including what is being used. If the\napplication is using the Presence Validator but not the Inclusion\nValidator why would I want those extra LOCs?\n\nThe other major hurdle is Ember itself. While Ember's source is in ES6\nform the final build that you get is in AMD. Which means it is one file.\nEmber will have to be distributed in the original ES6 form. I am also\nnot a fan of the current package names. If this ever happens I would\nmuch prefer:\n\n```javascript\nimport Component from 'ember/component';\n```\n\nrather than\n\n```javascript\nimport Component from `ember-views/views/component';\n```\n\n### Separate builds\n\nEmber CLI is all or nothing right now. Which means that you have a\nsingle build pipeline for your application assets (`app-name.js`) and a single build\npipeline for 3rd party assets (`vendor.js`). It would be nice to define\nadditional assets that can be built into final files. For example, [this\nrequest for Ember\nAdmin](https://github.com/dockyard/ember-admin/issues/32). Technically\nthis could be done right now but it would require some heavy hacking of\nthe vendor asset pipeline in Ember CLI. Personally I would like to see\nan API for this specifically. Perhaps it could be in the form of isolating a namespace to\nbe ignored in the `vendor.js` final concat but still output in the\n`dist/` directory.\n\n### Async code loading\n\nThis wish dove-tails off the previous one. Now that we have our separate\nassets how do we safely load them into our Ember apps? If we are\nisolating the assets I would think this implies they aren't meant for\nconsumption at application launch. Going back to the Ember Admin\nexample, not all users need those LOCs. Only when an authorized user\nhits the admin functionality should it pull down the Ember Admin assets\nand plug into the app. This would be ideal. The major hurdle here is\nwith how the container currently works. Perhaps something like this\ncould put it on the right track:\n\n```javascript\nresolveOther: function(name) {\n  if (needAsyncLoad(name)) {\n    asyncLoad(name).then(function() {\n      // after this load completes the name\n      // would be removed from the list of\n      // resources requiring async loading\n      resolveOther(name);\n    }\n  } else {\n    return require(name);\n  }\n}\n```\n\nThis would allow even further shrinking of the initial applicaiton\nfootprint. Only include what is necessary, async load other assets. This\ncreates the illusion of speed which is just as good as actual speed. You\nwill have the trade-off of periodic sections of your app with a longer\nthan normal loading state, but that should only happen once per\napplication instance.\n\n### Wishes to reality\n\nFulfilling these wishes should go a long way to negating the \"too fat\" argument for\nEmber. Here's to hoping that 2015 will see a more lean Tomster.\n"},{"title":"HTMLBars: Calling All Testers","tags":["ember","ember-cli","htmlbars"],"summary":null,"legacy":false,"id":"2014/11/30/htmlbars_calling_all_testers","employee":"Robert Jackson","date":"2014-11-30T00:00:00","body":"\n\nHTMLBars support has landed in Ember's canary channel thanks to the tireless work\nof the HTMLBars team. Make sure to chat them up at [EmberConf](http://emberconf.com/) (you\nare going right?!?!) for some war stories.\n\nWe are nearing the end of the 1.9 [beta cycle](http://emberjs.com/builds/#/beta) (aiming for 2014-12-06)\nwhich means we will be making the go / no-go decision on all pending features in Canary when we branch\nfor the next beta cycle. Clearly, we would all love to have 1.10 use HTMLBars.\n\nIn order to enable the HTMLBars feature flag in the 1.10 betas (shipping around 2014-12-09), we need\nhelp confirming that no major issues exist. This is where *you* come in!\n\n### Using Canary Builds with Ember CLI\n\nUpgrading to the canary channel with Ember CLI is very straightforward.\n\n#### Update Bower\n\nRun the following:\n\n```bash\nrm -rf bower_components\nbower install --save handlebars#~2.0.0\nbower install --save ember#canary\nbower install\n```\n\nBower also prompts you to confirm various \"resolutions\" that it is unsure of. Make sure you\npick `ember#canary` and Handlebars 2.0 if prompted.\n\n#### Update NPM Dependencies\n\nRun the following:\n\n```bash\nnpm uninstall --save-dev broccoli-ember-hbs-template-compiler\nnpm install --save-dev ember-cli-htmlbars\n```\n\n#### Summary\n\nNow we have successfully updated to the latest canary builds of Ember. Next up: HTMLBars.\n\n### Using HTMLBars with Ember CLI\n\nEnabling HTMLBars is as simple as adding the following to your `config/environment.js` (under\n`EmberENV.FEATURES` section):\n\n```\nEmberENV: {\n  FEATURES: {\n    'ember-htmlbars': true\n  }\n},\n```\n\nNow restart any running `ember serve` commands you have and you should be running with HTMLBars.\n\n### Report Issues\n\nThis part is critical: Please report any issues [at GitHub](https://github.com/emberjs/ember.js/issues),\nespecially regressions from 1.8 or 1.9-beta. If your business has certain browser requirements (IE8 for example)\ntesting on those edge-case platforms today will help us resolve issues in time for 1.10.\n"},{"title":"The Importance of Process, and Why It Matters","tags":["opinion","process"],"summary":null,"legacy":false,"id":"2014/12/12/importance-of-process","employee":"Paul Webb","date":"2014-12-12T00:00:00","body":"\n\nI joined DockYard in April of this year, after leaving a small startup. Before that, I was at another\nstartup and doing lots of freelance/agency work. In all of these places, there was never an existing\nprocess in place, aside from what was in my head. For better or worse, this was fine and allowed me to\nget work done. What I have learned since joining DockYard however, is that my old method of working is\ndangerous for a bigger company and just does not work.\n\nInitially, I resisted changing my process, like a fool/jerk. Why should I? My process has worked for\nyears, it was inherently superior! *Obviously*, this was not true. I got too comfortable with how I\nhad been coding and ignored requests to learn about [BEM syntax](http://csswizardry.com/2013/01/mindbemding-getting-your-head-round-bem-syntax) and organizing my CSS in a different order. Applying most\nof these new techniques to my own personal projects allowed me to see the usefulness to our UX team's\n(evolving) process. It was then that I realized, process is not about you or I, it is about the team.\n\nIf I am working on a project for six months and spin off to another project, another UX developer can\npick up where I left off and understand the code I have written. If everyone wrote code the way they\nfelt like, there would be so much time lost (and wasted) trying to figure out what the original coder\nmeant when they wrote something. Money would be lost as well because time would not be spent on doing\nactual work.\n\nProcess improves productivity and productivity allows the team to gain a better understanding of what\nis possible for the company as a whole. Which, in the long run, creates better opportunities and\nprojects for all of us.\n\n#### TL;DR\n\nBe open to new ideas about process. If it does not make sense to you, apply it to your own work before\ncompletely dismissing it.\n"},{"title":"Pattern Matching in Elixir for Rubyists","tags":["elixir","ruby"],"summary":null,"legacy":false,"id":"2014/12/26/pattern-matching-in-elixir-for-rubyists","employee":"Brian Cardarella","date":"2014-12-26T00:00:00","body":"\n\nThis is the first in a series of posts for helping Ruby devs understand\nsome of the concepts in Elixir.\n\n## Pattern Matching\n\nPattern Matching is one of my favorite Elixir features. Let's take a\nlook. (using an [Elixir\nMap](http://elixir-lang.org/getting_started/7.html#7.2-maps))\n\n```elixir\n%{foo: bar} = %{foo: \"baz\"}\n```\n\nThe above is matching a pattern. Don't think of `=` as assignment, you\nshould think of `=` as *equality*. The left-hand side of the `=` is\nequal to the right-hand side. Through pattern matching the variable\n`bar` is assigned the value `\"baz\"`. Consider:\n\n```elixir\n[foo, bar] = [1, 2]\n```\n\n`foo` is assigned `1` and `bar` is assigned `2`. Patterns can match to\nany depth:\n\n```elixir\n[foo, bar, [baz]] = [1, 2, [3]]\n```\n\nhere `foo` and `bar` have the same value from the previous example but\n`baz` is now assigned the value of `3`. Alternatively if we had written:\n\n```elixir\n[foo, bar, baz] = [1, 2, [3]]\n```\n\n`baz` is now assigned the value of `[3]`. This would be an example of a\nsemi-greedy matcher. You can expand upon this to greedily match the\nentire statement:\n\n```elixir\nmy_list = [1, 2, [3]]\n```\n\nNow `my_list` greedily matched to the entire right-hand side of the\n`=`. So why is this cool? Let's take a look at a Ruby method that\nhas some conditions:\n\n```ruby\ndef foo(a, b, c)\n  if a == :something\n    ...\n  elsif b == :other\n    ...\n  else\n    ...\n  end\nend\n```\n\nThe above is likely something familar to many Ruby devs. This presents\nsome problems. Any methods with several code paths increases the\ncomplexity of the method. Complex methods can be difficult to test in\nisolation. Let's take a look at how this would be implemented in Elixir:\n\n```elixir\ndef foo(:something, b, c) do\n  ...\nend\n\ndef foo(a, :other, c) do\n  ...\nend\n\ndef foo(a, b, c) do\n  ...\nend\n```\n\nThe first question Ruby devs have is *why are there three functions of the same\nname?* In Elixir you can define multiple functions of the same name as\nlong as the function signatures are unique. Functions are matched\nagainst the values passed in. So `foo(:something, 2, 3)` would match the\nfirst `foo` defined. `foo(1, :other, 3)` matches the second. `foo(1, 2,\n3)` matches the third. Match priority is the order in which the\nfunctions are defined.\n\nNow our functions are concise, and focused on the very specific\nbehavior. The conditional is obfuscated through the pattern matching but\nthis is a common design pattern in Elixir so it should be embraced.\n\nThe pattern matching can be more complex:\n\n```elixir\ndef foo(%{foo: bar}, \"baz\") do\n  ...\nend\n```\n\nThe above will match: `foo(%{foo: \"zeb\"}, \"baz\")` but would not match\n`foo(%{foo: \"zeb\"}, \"bar\")` because the second argument does not match.\n\nTake a look at the [Elixir Pattern Matching\nGuide](http://elixir-lang.org/getting_started/4.html) for more\ninformation.\n"},{"title":"Lessons Learned - Three years of running a software consultancy","tags":["opinion","business"],"summary":null,"legacy":false,"id":"2014/12/28/lessons-learned-three-years-running-a-software-consultancy","employee":"Brian Cardarella","date":"2014-12-28T00:00:00","body":"\n\nThis year's story is one of how we nearly went out of business *twice* yet\nstill managed to pull off our most successful year yet.\n\n## People\n\nIn 2013, we ended the year with 11 employees. We made a key hire at the start of the year with [Robert\nJackson](http://twitter.com/rwjblue) joining us. I had met Robert a few\nmonths prior at [Burlington Ruby\nConf](http://burlingtonrubyconference.com/). Robert had been\ncontributing to a few of our Ember libraries, as well as making a name\nfor himself by quickly moving up the contributors list in Ember.js\nitself. Less than four months after we hired Robert he was welcomed onto\nthe Ember.js Core Team. I'm extremely proud of him accomplishing\nthat.\n\nWe added depth to our design team in Q1 2014 with [Maria Matveeva](http://twitter.com/rgbcolor)\nand [Tim Walsh](http://twitter.com/imakemusic). Tim and Maria have been\ninvaluable for us, their dedication and ability allows you to easily\nforget how young they are. I'm looking forward to seeing how they\ncontinue to grow in 2015.\n\nEarly in 2014, we hired our first Project Manager, [Jon\nLacks](https://twitter.com/jon_lacks). Jon and I went to college\ntogether, and historically I have not had a good run of\nworking with friends. That has been my fault, I think I was more\ninterested in working with people I was friends with than establishing\nwhat their responsibilities would be. Jon and I agreed that any and all\npotential issues that may arise that could conflict with our prior\nrelationship should be aired out immediately. Jon joined\nDockYard in February and spent the first month or so observing our team\nmore than taking complete ownership of our process. I gradually handed\noff some of what I was managing to Jon (running standups, getting involved with\nsome client meetings, helping with estimations). All this to say that\nadding a dedicated PM was one of the highest impact decisions I made in\n2014. I suspect that many companies don't need one until they're around\n10 people in size but once you do hire one you'll be thankful.\n\n[Romina Vargas](https://twitter.com/i_am_romina) and [Lin Reid](https://twitter.com/Linstula) were two engineers that went through our\nintern program and we upgraded them to full-time as soon as we could.\nBoth Lin & Romina have been important members of some of our larger\nclients projects in 2014.\n\nMarin Abernethy, a former engineering intern, came back for her third (and final)\ninternship with us after her graduation from college.\nIn the Fall we hired her as a full-time engineer.\n\n[Paul Webb](https://twitter.com/netopwibby) interviewed with us in early 2014 but we had some projects\nfall through and things got very tight for us (more on this later) so we\nhad to pass. But as soon as we had the bandwidth we brought Paul onboard\nto our UX Development team.\n\nHeading into the Summer, we started to get spread a little thin on the\nengineering team. I had come off of client work completely to focus on\nthe business so we needed another Senior level engineer. I reached out\nto [Estelle DeBlois](https://twitter.com/edeblois), who had come to our\n[Wicked Good Ember](http://wickedgoodember.com) conference in June.\nShe's been lead developer for one of our larger clients over the past\nfew months.\n\nOur final hire starts full-time with us in January. [Ashley\nTreni](https://twitter.com/ashleytreni) was actually tending bar at\n[Highball Lounge](http://www.highballboston.com/) right next door to our\noffice (they can see us, we can see them). She asked what we did and it\nturns out that she is an amazing designer who was completing her Masters\nin Information Design and Visualization at Northeastern. She did a summer internship with us and\naccepted our offer for full-time employment just recently.\n\n### Hiring is hard\n\nHiring continues to be hard. We have had success by focusing on\ntechnology niches, but we may have tapped that out. Going into 2015, we\nwill have to consider how do we reach out and attract top talent,\n*and* how do we improve the existing talent we have. Promoting from within\nis something I've talked a big game about but have done little with.\nThis will change in 2015.\n\nI began 2014 with the same trend I had in the previous two years: I\nwould hire good people even if we didn't have projects to put them on.\nComing out of Q1 2014, I had to stop this immediately. While we had built\nup a great team, the weight of that payroll and our lack of cashflow at\nthe time was at a breaking point where I could no longer cover the\ndifference by taking myself off salary. Since then I have been very\nconservative with hiring. Unfortunately we actually missed out on some\ngreat people because of this, and I regret that as I was perhaps *too*\nconservative in our hiring at the time. Heading into 2015, this will\nprobably continue to be an aspect of the company I will continue to\nimprove.\n\n### Firing still sucks\n\nI had to fire two employees in 2014. Firing always sucks and I don't\nthink I'll ever get used to it. There is a guilt that is attached that\nat some point is out-weighed by whatever you're not getting from said\nemployee. So how does one mitigate the guilt? [Netflix has a great\npolicy when it comes to firing\nemployees](http://www.slideshare.net/reed2001/culture-1798664?ref=https://gigaom.com/2013/01/29/netflix-company-culture/).\nThe document outlines their full cultural philosophy but the gist of how\nthey fire is that they give a very generous severance package. So\nmanagers don't concern themselves with the guilt what will happen to\nthis employee without their job. I think this is a great idea, but not\nalways practical for all companies. If we had Netflix money then I would\ndefinitely align our severance package with theirs.\n\n### Culture\n\nWe've done a lot of work to define what the culture of DockYard actually\nis. Until Q4 2014 our culture was never written in stone. So we took\nsome time to put it into words:\n\n* strong problem solvers, with attention to detail\n* coachable learners and willing mentors\n* professional, kind and respectful\n* collaborative team players\n* disciplined\n* reputation\n* diverse\n* fun\n\nI'm sure you're looking at this list and thinking \"yeah this is pretty much what every company will say\".\nThat could be true, but these are going to be our hiring and retention criteria. We will be building a team around \nthese principles and expect everyone at DockYard to live up to them.\n\n### Heading into next year\n\nWe have a goal of expanding our team to over 25 by the end of 2015. I\nwould actually prefer to be closer to 30. Our hiring will be focused on\nSenior Level talent for engineering, design, and UX. We're always interested\nin [hearing from great people, get in touch if you're\ninterested](mailto:jobs@dockyard.com).\n\n## Estimations\n\nOur problems with maintaining our estimations were not significantly\nimproving in early 2014. We had to eat a lot of money on contracts that\nwas due either to bad estimations or our inability to properly manage our\nclients. If we ever expected to build a real company, this had to be\nfixed. This is where Jon came in as our first Project Managing hire. It\ntook a few months but we've gone from being consistently late to being\nconsistently early. Our estimations are currently one of the more\nreliable aspects of our business. This has not just helped relationships\nwith existing clients but being able to reliably sell our services to\nnew clients is incredibly powerful.\n\n### Heading into the next year\n\nI suspect we will continue to hone our ability to estimate. We will also\nbe looking to hire an additional Project Manager as we decided we don't\never want to spread a PM over more than three projects.\n\n## Financials\n\nIn 2013 we ended the year with $1.7m in revenue with about 20% profit\nmargin. This year we improved that to $3.1 in revenue with 33% profit\nmargin. This is a significant jump, in many ways I'm incredibly proud of\nwhat we were able to accomplish this year. However, I also know that we\n(as a company) underperformed. If we had been as productive in the first\nhalf of the year as we were in the second half we should have been\ncloser to a $4m+ company with >50% profit margin.\n\n### What went wrong\n\nWe were getting contracts coming in through the year, but nothing with\nthe challenge or scope that I was hoping for. Small $50k contracts here\nand there. I like working on small projects but from a business\nperspective we were burning too much time negotiating contracts,\nbalancing people on and off between contracts. I was butting heads with\nour business developer. He and I had different ideas on how to run the\ncompany. The funny thing is that neither of us were wrong. He wanted to\nreduce price due to lack of the demand we had at the time. I didn't want\nto do that. I was willing to pass on contracts that we could have\ngotten if we cut our rate 25%. This eventually put us in a position of\nbringing in 0% of billings for more than 50% of the company rather than\n75% of billings. Which would you rather have?\n\nI'm sure there are people reading this was a deeper background in\nrunning a business than saying it was stupid not to take the 75%. Here\nis my problem: at that amount we weren't making any profit and our\npeople were tied up on projects. I was tired of living hand to mouth, I\nhad taken myself off of payroll consistently for the past few years. I\nwas living off my wife's salary.\n\nAt the end of Q1 I was looking down the barrel of DockYard and not\nliking what I was seeing. Then we got a whale of a contract come our\nway. This was a contract that could right the ship. Or so I thought.\n\nI was not heading up the contract negotiations. The only criteria I gave\nwas what I thought our rate should be for this contract. When it came to\nit our business developer was not confident that we could get that rate.\nI was distraught. I was not willing to lock DockYard into a long-term\ncontract at cost. I told my wife at dinner I was going to start looking\nfor a \"real job\" and that DockYard was finished.\n\nI didn't sleep. I stayed up and kept mulling over the contract, was this\nit? I came to several conclusions:\n\n1. The client could afford our rate.\n2. We were worth the rate.\n3. Our business developer did not believe in #2\n4. I should be handling contract negotiations for DockYard\n\nI came into work that morning. Within a span of 15 minutes I fired our\nbusiness developer and landed the client at the rate we felt we\ndeserved.\n\nI realize the above might seem indifferent to letting someone go. He and\nI actually got along very well on a personal level. But as I mentioned\npreviously when it came to how to run DockYard we didn't see eye to eye.\nI was stressing out over this constantly and in the event I was not able\nto land this client on my own at the very least I could say that I went\nout my way. Egotistical? Yes, of course. But it is something I needed to\ndo. If we had slowly died over the rest of 2014 due to no real profit\nmargin I would have quit.\n\nThis was the first of two near-deaths for DockYard this year. The second\nwould come just two months later.\n\nThe large client came with a large legal team, one that I was unprepared\nfor handling properly. We have an excellent lawyer we're working with\nbut I am accustomed to contract negotiation taking maybe a week. This\ntook months to complete.\n\nThe problem with dealing with Enterprise companies is that they can\noutlast you. It isn't their intent to do so, it is in their best\ninterest that their vendors are able to work on what they need to the\nbest of the vendor's ability. It doesn't help either party if the vendor\ncan't make payroll. However, because of how many Enterprise companies\nare structured, and who has to sign off on what, an unprepared small\nvendor can be put into a position of agreeing to some things that are not\nin its best interest so it can start getting paid ASAP.\n\nI was perhaps too  risky in this regard. I held out on the contract, I\nput it through multiple rounds of negotionation. There was some legit\nscary stuff in it that I was not willing to agree to. We had started\nwork with the client before the contract was completed. At the time I\ndidn't consider this to be a big risk.\n\nWhat happened was that there was little to no incentive to speed up the\ncontract signing for our client. We were working, doing what they\nwanted, and they had no obligation to pay us. I realize some of you are\nreading this and thinking \"Rookie Move!\" but consider the context.\nStarting work with large clients prior to contracts being completed is\nactually a common practice in the Enterprise. I hear some of you\nscreaming \"no it isn't!\". Yes, it is.\n\nWe ran out of money. We had a payroll that we were $25k short for. I had\na very difficult conversation with the client and made the tough\ndecision to stop work until the contract was signed and our existing\ninvoices were immediately covered. I made a personal loan to DockYard to\ncover payroll. (as a side-note, banks never loan you money when you need\nit) Thankfully the client saw the situation for what it was and we were\nable to move forward. This was in June.\n\nPutting the brakes on the project and getting the contract done and\ngetting paid was the turning point for DockYard. We went from invoicing\non average $30k/week to over $100k/week. With no contract longer than\nNet-30 by August we had all of our debts paid off and were in a position\nto hire again. By November we had gone from a 1% profit margin for the\nyear in June to over 25%.\n\nIt is actually strange writing about this now, and I'm not entirely\ncertain I should have written all of this. In some ways it was one of\nthe most stressful times in my life, and looking back it feels surreal.\n\nI hope there are some nuggets of knowledge in here to help others avoid\na similar situation.\n\n### Heading into next year\n\nWe have ambitious financial goals. We aim for a $5m+ business in 2015. A\n$10m+ business in 2016, each year with >25% margin. If we can maintain our current momentum we\nshould easily meet 2015's goal.\n\n## Technology\n\n### Ember.js\n\nWe bet very heavily on [Ember.js](http://emberjs.com) in 2013. That bet\nhas paid off very well for us in 2014. The client mentioned above hired\nus for our expertise in Ember.js. We landed another great client in the\nSummer because of Ember.js. We are seeing a steady flow of work come in\nbecause of Ember.js but I don't think we can meet our $5m goal by\nrelying on inbound leads from Ember.js.\n\nOne thing we've never dealt with is selling our services into another\ncompany. We've got most work by companies making a technology decision then\nfinding who is good at working with said technology. How do you convince\na company unfamiliar with Ember.js that it is what they should use to\nbuild their product with? What if this person is not technology savvy?\n\nI came to the conclusion that you cannot sell Ember.js directly. I\nneeded help with building a sales pipeline and sales pitch. A friend put\nme in touch with [Lorne\nCooper](https://www.linkedin.com/pub/lorne-cooper/0/9a6/811) who I have\nbeen working with over the past two months. Lorne convinced me that I\nhad sales backwards. We need to start with Marketing. (he also convinced\nme that I couldn't sell Ember.js)\n\nSo what we built was the DockYard marketing funnel. Working backwards\nfrom Ember.js, we broadened the funnel. If the answer is: **Ember.js**\nthen the question should be **What is the best Single Page App\nframework?** (let's save tech debates for another time). I didn't feel\nthat selling SPAs was any better than selling Ember.js. Again, the\nanswer is **Single Page Apps** so the question should be **How do you\nprovide a modern user experience on the web?**. Now were had something.\nSelling UX as a solution to companies was tangible. If we could market\nthat UX improvements was the way to solve common problems in modern web\napps then we could hook companies on the idea that Single Page Apps was\nthe best way to deliver modern UX. If we could convince companies on\nSPAs then we have the chance to convince them that Ember.js is the best\nframework for building out SPAs. At this point we have to make a case\nthat DockYard is the best company as building Ember.js applications. We\nnow had our marketing funnel. We plan on putting this funnel to the test\nin early 2015, but don't expect any significant number of qualified\nleads to be produced until late 2015, more likely early 2016.\n\n### Elixir\n\nWhile we are not currently writing any [Elixir](http://elixir-lang.org) apps I think \nit will be part of our offerings around Q3 2015. Specifically because of\nthe [Phoenix Framework](http://www.phoenixframework.org/) being very\nsimilar to [Ruby on Rails](http://rubyonrails.org) I think we should be\nable to ramp upon it quickly.\n\nThe other choices I considered looking into were\n[Go](http://golang.org) and [Rust](http://www.rust-lang.org/). Elixir\nfeels like the best of the three to me. It is far less popular than the\nother two but considering it is backed by Erlang and boasts the most\napproachable syntax, has meta-programming, concurrency, and is built for\nfault tolerance I feel of those three language Elixir is the best suited\nfor the future. Of course, this is a gamble and time will tell.\n\n### Ruby on Rails\n\nOur involvement with Ruby on Rails will never go away completely but I\ndon't see Ruby or Rails being a serious part of our technology identity\nin the future. I would like to think that we were out with a bang\nthough, in early 2014 we were selected to redesign\n[RubyGems](http://rubygems.org). We launched the redesign at\n[RubyConf](http://rubyconf.org) and it was a nice way to say \"thank-you\"\nto a community that we've benefited from for so long.\n\n### Heading into next year\n\nI always want DockYard to be a company that does not stagnate on\ntechnology. I enjoy working with and exploring new technology and I\nalways want to push our engineering team to do that same. In the near\nfuture I think Ember.js and Elixir will be important for us, of course\nwe must be open-minded enough about new technology on the horizon.\n\n## Design\n\nDesign has become so essential to our process I don't understand how we\ngo by in the early years without a dedicated design team. We rely upon\ndesign to manage our Discovery Phase, build and inform our estimations.\nDesign has more impact on us converting a client out of Discovery to a\nfull client than engineering does.\n\n### UX East\n\nThis year we ran our first Design conference, [UX East](http://uxeast.org/).\nIt was structured as a design camp with two talks and one workshop.  The conference was organized by our Creative Director Steven Trevathan\nand Maria Matveeva we believe we were hugely successful.\n\nWe're already beginning plans for next year's UX East (you can sign up for\nupdates, including call for proposals, [here](http://eepurl.com/_NCUL)).\n\n### Team Structure\n\nEvery project is now assigned at least two designers. This is partially\nbecause the projects are big enough to merit the team, but it's also a huge\nqualitative add to the final delivery. Pairing designers is really helpful for \"leveling up\" as well. Matching\ndesigners by their different strengths they'll help each other grow. The\nconcept is very similar to pair programming, however the designers go\nthrough many rounds of critiques instead of using the same computer for an\nextended period.\n\nWhile we hadn't previously done this, and it looks like a fairly obvious\nimprovement to make, the result has been surprisingly positive and our most\nrecent projects are seeing a huge benefit from it.\n\n### Setting Goals & Sticking To Them\n\nOne thing we're very good at is coming up with ideas. Lot's of them. There is\nno shortage there, however there is a real challenge in effectively using down\ntime and DockYard Fridays to commit to delivering on those ideas. I believe\nthis is due to not having specific departmental goals that directly fit into\ncompany annual or quarterly objectives.\n\nAn example of this challenge is [Tools of the Trade](http://toolsofthetrade.dockyard.com/).\nIn the beginning of 2014 we put effort into creating small and novel icon packs\nand distrubuting them as free to use. It generated some interest, and we had\nfun with our icons, but we dropped the ball and lost momentum on it. Not because\nwe didn't enjoy making them or that it didn't benefit our designers by the\nchallenge, but because it didn't fit cleanly into any company objective.\n\nWe've set a Q1 2015 goal to create a program and agenda for design experimentation\nwith a focus on single page web applications. By that objective we'll be aiming\nto provide more practical design tools, design and interaction patterns, and free\nassets for other designers in creating single page web applications. By commiting\nto this goal and using Tools of the Trade as vehicle, we should be able to promote\nourselves, \"level up\" our designers, and effectively utilizing downtime.\n\n## Business\n\nOn the business side of things we've begun to add more structure to DockYard. We hired a CEO coach \nto take us through an OGSM (Objectives, Goals, Strategies and Measures)\nplanning session for 2015. It was a tiring two days of time that helped\nus discover what type of company we want to be. The management team has\nall decided that DockYard should aim big and that is what we're going to\ndo.\n\n### Office Space\n\nIn Q2 2015 we'll be moving into a new office space. Our current space\nhas served us well but it has its problems. The new space will be\nmodern and have plenty of space for us (we're upgrading from 2,800 sq/ft to\n7,800 sq/ft). I'm excited to share those plans in the upcoming months.\n\n## Wrapping Up\n\nI hope this year's reflection has been useful for you in some way. Each\nyear's summary has felt different and I'm sure next year's will too. As\na company DockYard has taken some knocks this year but we came out\nstronger for it with more focus and an actual gameplan. I'd love to hear\nother's experiences as well in the comments.\n"},{"title":"Tips on Mental Models","tags":["design","design process","design thinking"],"summary":"A few things to keep in mind.","legacy":false,"illustration_alt":"A very frustrating projector remote","illustration":"https://i.imgur.com/ybHKog9.jpg","id":"2014/12/30/modeling-mental-models","employee":"Steven Trevathan","date":"2014-12-30T00:00:00","body":"\n\nJust as a single color can have conflicting associations between different cultures, mental models can vary widely between users. If you haven’t heard of [mental models](http://en.wikipedia.org/wiki/Mental_model), they are a beholder’s mental image of a designed object and how it may be interfaced with.\n\nUnderstanding the mental models your users have created of your product (or similar product experiences) is important. It will help you improve either by adjusting the product to better fit their mental model or by changing the users’ mental model to better fit your product. Neither are simple.\n\nTo give you a sense of how a mental model is constructed or applied to a product, let's imagine looking at a new object in extreme slow motion:\n\nThe object is placed before you. The first thing you notice is its size and shape. It’s small enough to fit in the palm of your hand, thin, and rectangular in shape. Its color is off-white. In this first glance you might make some general assumptions about the object’s nature and function, but given that there are countless objects that could share these qualities, your observation continues.\n\nOn the grey rectangle you can clearly see a small red button, a small green button, a large square button, and a series of small grey buttons in a familiar 3x3 grid. Given that the device is small enough to fit in your hand, has multiple buttons, and lacks a screen, you might conclude that it’s a remote of some kind. And you might stop there, unless you actually have to use the remote.\n\nWhile making these observations, your brain was building a mental model of how to interact with it by referencing past experiences with similar objects. Taking the path of least resistance, your brain wants to reapply these models wherever and whenever it can. You won’t need to re-teach yourself how to use something you’ve consistently used over the years unless something significantly breaks the pattern. With each connection you make with familiar and unfamiliar qualities of the object, either consciously or not, you pave ways to interpret the purpose, value, and effectiveness of the object.\n\nThe speed with which we identify these things correlates to how similar the object is in form to other objects we’re familiar with. The models you create as a user aren’t originating solely with the object in front you; instead they are created from all the objects you’ve ever interacted with. This is where understanding and employing mental models gains value in design. We can use them to manipulate, speed up, or slow down interpretation of our products.\n\nThe information and interpretations from that first glance are all gleaned with relatively low effort, almost instantaneous, and you’re not always aware that you are making these evaluations. However, a unique object often takes a conscious effort to understand. If the object wasn’t very well designed to reveal its own function you may instead have exhausted yourself with a seemingly uninterpretable thing and given up.\n\n\n## Borrowing\nWe sometimes borrow mental models from unrelated or contextually irrelevant experiences because some aspect of what we are interacting with may have unconsciously reminded us of previous experiences. A thing isn’t always what we think it is.\n\nBecause we are all somewhat responsible for building our own mental models from our experiences with the designed world, our interpretations of an object’s purpose or quality of performance can vary greatly. I think this is part of the reason why reviews of products are so polarized. People’s expectations and preferences are different, and sometimes they just aren’t able to build a fitting mental model of the product. So they’ll borrow it.\n\nIf the object is truly unique, layers of mystery may remain for a broad user base. Thus, there may be limits to how they have evaluated the object’s purpose. As designers, we don’t need to hold ourselves responsible for explaining everything, but it is important to get a user to as complete an understanding as possible using the object’s form alone. No language, no manuals, no tutorials. No automatically playing videos after they log in for the first time.\n\n## Against the grain\nGoing against the grain of a mental model is generally a bad idea, but it can be valuable. It should be by design, of course, and might provide some comparative market value and interest. An example of this working was the introduction of the iPod and its very unique interface (the wheel) while competitors had basically indistinguishable and boring (by comparison) arrow key pads. The iPod might have been a little more difficult to use, but the innovative design wasn’t enough of a challenge to stop people from using it. Instead the change helped Apple greatly differentiate their product from other MP3 players.\n\nWhat happens when you go against the grain for no good reason? Lots of avoidable and silly mistakes, that’s what. Take this remote for our projector as an example.\n![A very frustrating projector remote](https://i.imgur.com/ybHKog9.jpg)\n*For emphasis, I’ve erased the small labels generally ignored by users when turning the projector on or off.*\n\nWe know it’s a remote at first glance because we’ve used them before. The shape seems to suggest both purpose and a direction for use. Which end of the remote would you point toward the projector?\n\nIf you said you’d point it with the slanted side forward and the red button in the upper right, you would have found on your first (and second, and third) attempt that this remote’s form does not align with your mental model. With this particular design, you are expected to hold the remote with the red button positioned on the bottom left. \n\nIn other words, the mental model I have for remotes is not matched to the device because the manufacturer ignored a common design pattern without apparent reason, adding only momentary confusion, rather than enhanced functionality, to my experience.\n\n# Last words on defining (and refining) your models\nWhen designing your product, be aware of your users’ mental models and recognize that your own will be very different from theirs. This is an overwhelmingly common mistake.\n\nYou should also be aware of user and market contexts to judge what aspects of their models you may break and which you should keep. Don’t break the model just to be different if the difference provides no value or delightful experience for a user.\n\nLastly, designers must understand that users will have wildly varying points of reference, so presumed models need to be tested with multiple different users before the direction of the product design is settled upon. Failure to do this will put the success of the product at risk.\n"},{"title":"BEM Tips: Avoid Chaining Modifiers","tags":["css"],"summary":null,"legacy":false,"id":"2015/01/05/avoid-chaining-modifiers","employee":"Amanda Cheung","date":"2015-01-05T00:00:00","body":"\n\nAt DockYard, we use the BEM methodology for naming our CSS classes. BEM\nstands for Block, Element, Modifier and is a front-end development\ntechnique that suggests a class naming convention for your HTML elements. If\nyou aren&rsquo;t already familiar with BEM, it would be helpful to take a look at\n[Harry Robert&rsquo;s MindBEMding blog post](http://csswizardry.com/2013/01/mindbemding-getting-your-head-round-bem-syntax/)\nand the [BEM website](https://bem.info/) first.\n\nWhen I started looking into using BEM, I thought it would definitely work well\nfor large web applications. The more rules we could put in place\nregarding naming conventions, the better. What I didn&rsquo;t understand\nwas what to do when an element could be considered an element of a block *or* a\nmodifier. If I had a button that was in the footer and it was styled differently\nthan other buttons in the website, should it be named `.footer__button`\nor `.button--footer`? Arguments could be made for both sides, so is one better\nthan the other?\n\nAfter trying out both ways, `.footer__button` proved more scalable because\nthis rule could be consistently applied in more situations. Could there\nbe more types of buttons in the footer?\nIf there are also social buttons in the footer, our choices now become\n`.footer__button--social` or `.button--footer--social`. In the second one, is social modifying\nfooter and footer modifying button? Or is social modifying button as\nwell? To avoid confusion, I would call it `.footer__button--social`\nand not chain my modifiers. This doesn&rsquo;t mean we\nshouldn&rsquo;t use multiple modifiers in a class name at all.\n`.person--female__hand--right` is still fair game. It&rsquo;s clear that female\nis modifying person and right is modifying hand.\n\n## TL;DR\nIf I had an element that could potentially be either an element of a\nblock or modifying an element, the latter is better because\nchaining modifiers can be confusing.\n"},{"title":"Complex Search Pages Feel Better in Ember","tags":["ember"],"summary":"Creating a better search experience with Ember","legacy":false,"id":"2015/01/07/complex-search-pages-feel-better-in-ember","employee":"Dan McClain","date":"2015-01-07T00:00:00","body":"\n\nWith many server rendered search pages, a change to your search parameters\ntypically renders a new page. The use of some JavaScript can alter the\nsearch results, as seen below. Note that both refreshes and JavaScript results\nswapping happens.\n\n<iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/pstevGCOUHs\" frameborder=\"0\" allowfullscreen></iframe>\n\nWhenever the results are altered, it feels (and is) slow. The times that\nrefresh the whole page feel the slowest, but even when a partial\nchange happens, it's obvious and slow. It feels clunky\n\nWith Ember, we can provide a better experience. The video below is a similiar\nstyle search page on a site we built for [Learnivore](http://learnivore.com) with Ember.\n\n<iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/7F2F1iGOw4s\" frameborder=\"0\" allowfullscreen></iframe>\n\nNotice that the page never refreshes completely. The search box always stays on\nthe page. And when we switch categories, only the relevant options are swapped\nout, we don't have to redraw the whole page. And when we select an additional\nfilter on the left, only the search results are swapped out. **This page performs\nbetter because it performs less work.** It feels better because you are constantly\nseeing parts of the page reloaded without being changed. The filters on the left\nonly change when they need to.\n\nIt will also perform better on low bandwith connections; it only requests the\ndata necessary to render the page.  This will require fewer bytes to be sent\ncompared to the server rendered page.  When you render the page on the server,\nyou have to include every tag necessary to render that content. When you are\nusing a single page application architecture like Ember, it will only need the\ndata that makes up that result.\n\nWhat a representation of the server rendered page looks like coming across the\nweb to your device:\n\n```html\n<html>\n  <head>\n    <title>Your search results</title>\n    <!-- Several to tens of lines for stylesheets and javascript -->\n  </head>\n  <body>\n    <header>\n      <h1>Search results!</h1>\n      <p>This can be tens of lines, hundreds of characters to establish content\n      and look</p>\n    </header>\n    <div>\n      <a href=\"somepage\">Here is one of the search results</a>\n      <p>Some description of your search result</p>\n      <img src=\"SomeImage>\n    </div>\n    <!--Repeat the result 10/20/50 times -->\n    <footer>\n      <a href=\"about>About us</a>\n      <p>Hundreds more characters to provide links, style, etc</p>\n    </footer>\n  </body>\n<html>\n```\n\nSince the page needs to be completely reloaded, we need to display not only\nthe contents, but any header and footer content. This simplified example also\nlacks any type of filters or inputs to alter your results, which would make the\namount of data sent to your device larger to view the page. This needs to happen\nwhenever the page is updated.\n\nCompare the above to what Ember requires to update the page:\n\n```json\n{\n  searchResults: [\n    {\n      title: 'Here is one of the search results', url: 'somepage',\n      description: 'Some description of your search result', image: 'SomeImage'\n    },\n    Repeated 10/20/50 times\n  ]\n}\n```\n\nBytes are wasted sending down the markup to render the page; it's already\nthere, along with the header and footer. This payload is much smaller, and\nprovides a friendlier experience to those on a slow connection.\n\nWe can provide better interactions with Ember because the user will not see unnecessary\nrerendering of the same content. The requests to update the content will be\nsmaller, so new results will arrive faster. The difference in speed of these two\napproaches is increased as the user's bandwidth shrinks. Faster pages help with\nconversions, and Ember can provide a faster, more intuitive experience.\n"},{"title":"Why is Google ignoring over 400,000 backlinks to DockYard?","tags":["opinion","business"],"summary":null,"legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/tpcgGpK.png","id":"2015/01/11/why-is-google-ignoring-over-400000-backlinks","employee":"Brian Cardarella","date":"2015-01-11T00:00:00","body":"\n\nImagine our enthusiasm when the opportunity to add hundreds of thousands\nof backlinks from one of the web's most popular library hosting websites\nback to our domain came our way. And imagine our surprise when Google\ndecided they meant nothing.\n\nBack in [November we launched the redesign of\nRubyGems.org](http://reefpoints.dockyard.com/2014/11/18/rubygems-redesign.html). We were contacted by\n[RubyCentral](http://rubycentral.org) about 9 months prior. I was\ninterested in this opportunity for three reasons:\n\n* It gave DockYard the opportunity to give back to the Ruby community,\n  one that has been so pivotal to our growth early on (and one that has\nbeen pivotal to my growth as a professional engineer for nearly 10\nyears)\n* DockYard can show off its design talents to the community\n* DockYard would get a *\"Designed By\"* sponsor link at the bottom of\n  every page.\n\nThis blog post is going to explore the third reason and the result of\nthis over the past two months.\n\nAt the time of launch RubyGems.org had over 90,000 gems published. This\nmeant a sponsor link at the bottom of every page that was backlinking\nto [DockYard.com](https://dockyard.com). In addition to the landing page\nand the other static pages. This was an appealing value to gain from a\nre-design effort. According to Google's own backlink search DockYard had\nonly 65 pages linking back. This struck me as odd considering this blog\nitself links back to DockYard.com and there were more than 65 posts. But\nsurely after the redesign this number should go up. Our estimated\nPageRank was `5`.\n\nAfter the redesign we saw the expected spike in traffic\n\n![](http://i.imgur.com/tpcgGpK.png)\n\nChecking in on the referrals we can see that to date we have received\nover 600 referrals from RubyGems.org. I'm OK with these numbers as I\nnever expected everyone to be clicking on those links.\n\n![](http://i.imgur.com/cM66gW5.png)\n\nHowever, what did shock me was that none of these backlinks were being\ncounted by Google.\n\n![](http://i.imgur.com/fTyXVzV.png)\n\nThe sponsor link does not have a `nofollow` attribute. And I admit that\nSEO is not something I've very good at. But if I were to look at another\nbacklink source such as\n[ahrefs](https://ahrefs.com/site-explorer/overview/subdomains/?target=dockyard.com)\n\n![ahrefs](http://i.imgur.com/tlHt3sK.png)\n\nYou can clearly see the spike in referring pages. A **huge** jump from\nnearly nothing to over 400,000. The bottom graph shows that these are\nprimarly *DoFollow* links.\n\nSo these backlinks aren't being counted by Google? Does Google only count\none domain per backlink? Color me confused. I suspect we're doing\nsomething wrong on our end to not get any credit. Could it be that such\na huge spike in backlinks are flagged as suspicious by Google? I'd\nappreciate any thoughts in the comments.\n"},{"title":"Book design and the web","tags":["design","observations"],"summary":"Really understand your content, then select its format.","legacy":false,"illustration_alt":"Barents Lessons","illustration":"https://i.imgur.com/t0md8VR.jpg","id":"2015/01/13/book-design-and-the-web","employee":"Maria Matveeva","date":"2015-01-13T00:00:00","body":"\n\nI recently attended a presentation by a [Swiss book designer Ludovic Balland](http://www.ludovic-balland.ch) where he described the process behind his beautiful and sophisticated books. His studio has done many architecture monographs, because the format lends itself well to carefully considered custom design. (Architects with lots of work to show also tend to have the budget for and interest in such things.)\n\n## Formats in print\n\nA key concept in his book design process is the selection of an appropriate medium, or format, for each type of content. He explained that with enough analysis, the materials from which a book is to be made can clearly be separated by type of content. For example, photographs of completed buildings are one type, and architectural drawings of incomplete or conceptual projects — another. Once the separation is made, the next logical step is to select the best format for each type of content, with sensitivity to its beautiful representation. Type of paper, ink, printing methods, folding and binding possibilities all become variables in an equation, which can have a logical and aesthetic solution.\n\n*Barents Lessons* is a book based on a trip that a group of students took to the Barents Sea.\n(All images via [ludovic-balland.ch](http://www.ludovic-balland.ch/))\n![Barents Lessons](https://i.imgur.com/t0md8VR.jpg)\n\nThis book consists of three sections, with three distinct formats. The first — Analysis — is text, meant for long form reading.\n![Analysis](https://i.imgur.com/F1edPyY.jpg)\n\nIt is followed by a section of detailed maps. Colors were individually selected to take advantage of the cartographic detail. For this and other projects, Ludovic’s studio often completely re-draws graphics like this all in a consistent style for the book, which they then can print at the highest quality.\n![Maps](https://i.imgur.com/FDgyvQH.jpg)\n\nThe final section holds student photographs. They are shown in an order determined by the value of the photo: from dark to light, avoiding forced storylines between photographs that do not necessarily relate to each other. The paper selection has changed once again, and the photos are given full prominence with minimal captions.\n![Photographs](https://i.imgur.com/xZFCVHw.jpg)\n\nI find this book to be a great example of logical and thoughtful design: content is well supported and enhanced through the technology of book production. Everything, from the binding, to the paper, to the colors and page layouts, supports the content of the book. I also think it’s a strong parallel to the use of technology to support users, and the things they want to do, when we build products on the web.\n\n## Formats on the web\n\nWhile technology allows us to make things respond in a specific manner to an action, to show only the necessary things to the right person, or to add delightful and playful details to already common tasks, it is the thoughtful and often economical selection of the “formats” we use on the web that makes for a strong, impactful project.\n\nFor example, using Ember.js - [a technology that allows us to change portions of a web page without reloading the entire thing](http://reefpoints.dockyard.com/2015/01/07/complex-search-pages-feel-better-in-ember.html) - allows us to enhance a search page very effectively. We could use the same technology to enhance a gallery type page (whose primary purpose is to show static content) but the improvement would be marginal and not cost effective. The [Inexhibit platform](http://www.indexhibit.org/what-who-why-how/) focuses on *“a community of users who place emphasis on content over complicated website design”* and offers a minimal tool for artists to create a gallery and show their work.\n\nWe can always add technology to marginally improve the experience. We could also print newspapers on higher quality paper, but the format would conflict with the nature of a newspaper as a frequently updated disposable item.\n\nOur ability to select the appropriate format, or technology, for a task reflects our deep understanding of the content and the problem we are solving. The rejection of unnecessary improvements is an important decision. It makes our work efficient and focused.\n"},{"title":"Masking private information from the owner","tags":["design","observations","privacy"],"summary":"Are we allowing users to walk right into identity theft?","legacy":false,"id":"2015/01/13/should-we-consider","employee":"Steven Trevathan","date":"2015-01-13T00:00:00","body":"\n\n## Should we consider allowing the display of all private or risky information to the owner strictly through a prompt?\n\n**This could include:**\n\n* username\n* password\n* e-mail\n* birth date\n* social security number\n* credit card info (maybe never show it)\n* account numbers\n* you get it by now\n\n## Why?\nWell, one little bit of information that someone tweets about themselves in a screenshot could mean they’re sharing a useful piece of data to a DOXX operation by some douchebag on the internet. That’s the theory, but as I know very little about DOXXing it may not make sense.\n\n## Why am I thinking this?\nI just tweeted a photo and I realized after the fact I might have put some sensitive information in it. Not like credit cards or actionable items to any normal viewer, but the kind of information that could add up to something a technically sophisticated malicious person might like. Turns out it was just my name, which seems ok to me.\n\n## Because users don’t really know better and they never will\nI’ve spent a lot of time resisting the “our users don’t know” mantra in certain scenarios, and I can tell you why sometimes still resist it, but I digress. When it comes to security, our brains aren’t very good at remembering the pieces of information we’ve shared. I have 4k+ tweets and I know a lot of people are at that or beyond. How can we be sure we haven’t shared too much information? I don’t think we can.\n\nIt could certainly be a pain in the designer's ass to worry about protecting the user from doing something harmful to themselves (on purpose yet without being aware) in addition to everything else our daunting jobs require us to, but maybe this really warrants consideration by designers. Maybe it’s part of the job."},{"title":"Check your expectations (at the bathroom door)","tags":["design","observations"],"summary":"Your normal is not always their normal.","legacy":false,"illustration_alt":"Person with gas mask","illustration":"https://i.imgur.com/8pbNwei.jpg","id":"2015/01/14/check-your-expectations","employee":"Maria Matveeva","date":"2015-01-14T00:00:00","body":"\n\n![Person with gas mask](https://i.imgur.com/8pbNwei.jpg)\n*This is what we walked through one Friday evening as we were leaving work.*\n\nThe building we work in is under construction. There are many small and large annoyances that come with a live construction site nearby. One thing has been particularly awkward: access to our restrooms.\n\nAs you might suspect, most if not all construction workers are men. There is active pipe work going on in the building, so they often need to do work directly inside the women's restroom at random times throughout the day. We would discover that a man is working on a ceiling duct in a space we expected to be for women only, and it has caused a considerable amount of tension.\n\nWhile there may be many alternatives to doing construction work like this without warning, with less disruption of our work day, I had also started to question why this behavior felt like such an intrusion. After all, there are covered stalls with doors that go down close to the ground, so there's still a significant amount of privacy.\n\nThe reason seems to be not the exposure itself, but the fact that a certain space (e.g. beyond the door that says \"WOMEN\") has been designated for a specific use, and is limited to one gender. This situation is not default - in fact, there are a few alternatives:\n\nOften located in smaller restaurants or coffee shops, a single-user bathroom normally does not have a gender restriction. One would simply wait for it to be vacant, and use it without a second thought.\n\nA \"family\" bathroom (explicitly marked as such) is for one or many users. It is roomier than the \"regular\" bathrooms next to it, and normally utilized by a parent with children, or someone using a wheelchair. Few eyebrows would be raised when several people at once, regardless of gender, walk out.\n\nAt MOMA PS1 there is an explicitly declared unisex shared restroom. It has three stalls (with doors) and a urinal facing the back wall. It is a bit unsettling to use for the first time, but the explicit declaration makes it feel like a shared awkward experience, rather than a disadvantage of one group of people or another.\n\nIn summary - our expectations always determine what we consider to be unacceptable. The example of bathrooms in our office building clearly shows that a construction worker's expectation (\"this is my work site\") and my female co-workers' expectation (\"this is a space for women only\") did not line up. More importantly, both parties were \"right\" in their own way.\n\nTo me as a designer, this awkward situation clearly illustrates how important it is to understand a client's or a colleague's expectations in any given situation. It is entirely possible – especially when working with a client in an industry I am not familiar with – to commit terrible missteps without even knowing they happened.\n\nTo avoid the kind of toxic misunderstanding, it is important to communicate assumptions (even the \"duh!\" kind) early on in a project. It may feel awkward to have to say out loud the things that you consider to be understood by everyone involved. Get over it. When you find and defuse that one thing you did not agree was a given, it will all be worth it.\n"},{"title":"Job: Senior UI & Visual Designer","tags":["design","job"],"summary":"Work at DockYard designing highly interactive web applications!","legacy":false,"id":"2015/01/14/sr-ui-designer","employee":"Steven Trevathan","date":"2015-01-14T00:00:00","body":"\n\nWe are looking for the next addition to our design team.\n\nThe ideal candidate is someone who can demonstrate a strong user-centric approach to their work, cares deeply about how their work will ultimately function, has been part of the user research process in the past, and shows strength in typography, color, and information layout.\n\nWe’re a design-driven software consultancy with design projects typically lasting 2-4 months. If you’re sick of working on the same product for years at a time, this may be a welcome change for you. Many of our client projects are “greenfield”, so you’ll have the opportunity to define the core concepts that will permeate throughout the application and be built upon as the product grows.\n\nWe are also heavily involved in the Boston design community. We very successfully ran our first UX East Camp last Nov, we host and coorganize UX Boston, run UX Happy Hour, speak at industry conferences and meetups, and blog about our experience (blog traffic is around 300 hits per day). If you’re publishing your work and articles through DockYard they will get traction.\n\nYou will be expected to take part in your community and we will give you tools to do so. We run weekly internal talks on a rotating schedule, run company wide peer-reviews of blog posts, and will fly you to one industry conference a year.\n\nDockYard also has a full engineering team on staff (actually much larger than the design team by about 2-to-1). They are experts in both front and back end technologies. The implementation of your work will be on-point and very well engineered.\n\nWe offer better than market rates. Full health and dental coverage (no matter what your coverage requirements are). We also have 6 weeks of vacation time per year. 4 of those are mandatory vacation.\n\nThis is an on-site position in Boston, MA.\n\nIf this type of working environment interests you, then we’d love to hear from you. [E-mail us](mailto:jobs@dockyard.com) (we do not work with recruiters) to get in touch."},{"title":"Joining DockYard","tags":["job","culture","team"],"summary":"Reflections on the past few months of being employed at DockYard","legacy":false,"id":"2015/01/16/joining-dockyard","employee":"Estelle DeBlois","date":"2015-01-16T00:00:00","body":"\n\nSix months ago today, I signed the letter officially accepting the offer\nto join DockYard as a Senior Developer. It was the best decision I could have made.\n\nWhen I announced my resignation to my previous employer, he jokingly said that if\nthey had known choosing Ember as a new client-side framework would\neventually make me want to pursue a new Ember-focused opportunity, they would\nhave chosen Angular.\n\nI first started dipping my toes into Ember in late Spring 2013, some time after\nEmber 1.0 RC3 was released. The Ember.js community was undeniably very active and\nvibrant. That following June, I attended my first Boston Ember meetup,\nwhere [Dan Gebhardt](https://twitter.com/dgeb) shared tips on testing Ember apps,\nand [Alex Navasardyan](https://twitter.com/twokul) gave an introduction to Ember Data.\nThat's how I came to know of DockYard.\n\nSoon, some names started to emerge as familiar names within the\ncommunity. [Brian Cardarella](https://twitter.com/bcardarella) became\nknown within our dev team as the one who wrote\n[ember-validations](https://github.com/dockyard/ember-validations),\nwhich we were using in our application. [Robert\nJackson](https://twitter.com/rwjblue) was another name that kept popping\nup on my Twitter and GitHub feeds. Call me a nerd if you will, but I was\nas excited to have The Robert Jackson accept a fix that I submitted to\n[ember-dev](https://github.com/emberjs/ember-dev) later that year to make builds\npass on Windows (with Rake at the time) as I would have been meeting a film celebrity.\n\nDockYard further reinforced its reputation by organizing the Wicked Good Ember\nconference in Boston, in June of 2014, which I of course attended.\n\nNeedless to say, when Brian reached out to me last July about joining the team, I\nsaw it as an opportunity that was really hard to pass on. Logistically,\nI may have been better off staying where I was. I had a 40 min commute.\nJoining DockYard would have doubled my commuting time. I was also\ncomfortable with the position I was holding, building out cool D3.js\ncharts with Ember, leading the development of new products, and getting\nmyself involved in all kinds of engineering team growth efforts. But\nthen there was DockYard. I went with my gut feeling instead and left\nthe warm and comfortable seat to face the exciting, though new and scary thing that was\nDockYard.\n\nScary? Yes. From everything DockYard had done for the Boston community\nto the talent behind its wheel, I was absolutely terrified of not\nfitting in, that it was too elite for me. I checked out the team page on\nthe website and read everyone's biography a number of times,\ntrying to picture what kind of co-workers I would be interacting with\ndaily. No matter how great the projects can be, culture is a big thing.\nTo my delight, the culture at DockYard is one that resonates the\nmost with me in my 10 years of professional career.\n\nDockYard has a well-balanced team of young, bright minds and more\nseasoned developers, and I embrace that. There is none of that \"I am\nbetter than you\" bullshit. Those I once viewed as Ember Gods and would\nhave been intimidated to talk to have been incredibly supportive and encouraging.\nIn the past, whenever I was involved in the hiring process for\nEngineering, I had always wondered where all the great developers were.\nWell, they're here, happily employed at places like DockYard. If there\nis one thing I can say about the company, it's that it's doing something\nright to attract an amazingly talented and diverse crew. I've been\nparticularly impressed with our designers. It's nice as a developer to\nwork on such nifty UIs!\n\nDoing consultancy work was new to me, and I had been warned about what I was\nthrowing myself into, that I'd end up losing focus on quality and just\nhack solutions together quickly to meet client deadlines. I don't doubt\nthat those kinds of situations can creep up, but so far, I've found\nquite the opposite in the two projects that I've been involved in.\nPeople care deeply about delivering clean, maintainable,\nand well-tested code, and they've been especially adept at maintaining those\nprinciples throughout the life of a project.\n\nIt's also refreshing to be able to work on a diverse portfolio of\nprojects. In the first few months since joining DockYard, I worked on a Rails and Ember app\nthat incorporated some really cool geolocation functionality. I am now\nworking on something that is unlike any other app I have ever developed.\nThe project includes Arduino code, Ember.js, and Node WebKit\n([NW.js](http://nwjs.io/)).\n\nThe best, of course, is DockYard's mindset towards open source. I always\nlook forward to our \"DockYard days\" on Fridays to hack on code, blog\n(this is my first one!), contribute back to the community in some ways,\nor just to level up our craftsmanship.\n\nAnd as much as everyone works really hard, we also know when to have\nfun, be it through Risk game tournaments, friendly games of Carcassonne\n(or, as some would say, \"Casserole\"), or world exploring and building on\nMinecraft.\n\nFinding a job that you'll love can be hard. Finding a team that you'll\nlove working with can be twice as hard. And sometimes, it's okay\nto leave behind what is comfortable and secure, in light of\nsomething promising, yet unknown. You may be pleasantly surprised.\n"},{"title":"Is your homepage as good as your door sign?","tags":["design","observations","user experience"],"summary":"Ask good questions to solve for real user goals","legacy":false,"illustration_alt":"","illustration":"http://imgur.com/ebDk2UJ.jpg","id":"2015/01/20/is-your-homepage-as-good-as-your-door-sign","employee":"Maria Matveeva","date":"2015-01-20T00:00:00","body":"\n\nToday is a federal holiday, and a day off for us at DockYard. On days like these, when I do not travel, I often go to the local library.\n\nToday gave me the perfect opportunity to see how easy it would be to find a specific bit of information (*is the library open today?*) on a library website.\n\nLike many government and community organizations, libraries are easy targets for ridicule when it comes to web design. Look at the outdated styles their site uses! How crowded it is! The HTML tables used for layout! The multi-colored announcements “designed” in Word! \n\nWhat I am looking for today is something else: I want to judge the achievability of a specific task regardless of the presentation. Presentation (layout, hierarchy, and just plain good design) affects a user’s ability to achieve her goals, no doubt. I just want to start with the goals, and a specific measurement, rather than starting with the common pitfall of visual designers like myself: noticing the surface details that seem broken rather than the process behind them.\n\nSo, here’s my experiment:\n\n## Find out if the library is open today.\n\n*With a few considerations.*\n\nIt may be **self evident** that a library is closed on a government holiday. It was not to me. I assume that most casual users have a vague suspicion that it may be closed, and would seek confirmation via the website.\n\nI narrowed my search to just the homepage for this exercise, expecting to find the equivalent of a physical “Sorry, closed today!” door sign. And while many libraries provided the same information on Twitter or Facebook, it would be prohibitive to compare all these resources for this quick study.\n\nI saw most of these homepages for the first time today. A regular user of the local library may notice things differently than a new user, so for example the “CLOSED” text announcement that replaces a daily schedule of events, might stand out more for them.\n\nI looked for three things:\n\n-  was the holiday at all on the homepage,  \n- was it clear, and \n- was it obvious?\n\nI got about halfway down the alphabetized list of Minuteman Library Network locations, and consider this to be a useful and fair sample for my purpose.\n\nLet’s roll:\n\n### 1. Acton \n##3/3! \n\n![](http://imgur.com/ebDk2UJ.jpg)\n\nThe site is visually appealing and clear at the same time. I immediately got an answer to my question. Success!\n\n###2. Arlington (Robbins Library)\n##0/3 \n\n![](http://imgur.com/CpqOqdR.jpg)\n\nHours are clearly listed, but the holiday is not. Based on this page, I would assume it is open today — in fact, the clear listing of hours reinforces my wrong assumption. To see the holiday announcement, I would need to know to visit the Calendar. A shame, because the site looks quite polished to me and was likely re-designed fairly recently (guessing 2013, from its footer). An investment in a bit of user testing and research would have likely fixed this.\n\n###3. Ashland \n##Huh? 0.5/3 \n\n![](http://imgur.com/yQ2dOww.jpg)\n\nWhile there is no indication of library closure today, the Townhall is clearly  closed. As a local, I might know what that means for my library trip, so I gave 0.5 points for at least mentioning the holiday exists.\n\n###4. Bedford \n##0/3 \n\n![](http://imgur.com/XhAfaNt.jpg)\n\nToday’s closure is not mentioned anywhere. Neither are the regular hours. I would look  either in About Us, or (eventually) see a link for Hours & Directions close to the top right.\n\n###5. Belmont \n##3/3! \n\n![](http://imgur.com/inJbhUs.jpg)\n\nThe site doesn’t look like much, but it accomplishes my goal today perfectly. The library is clearly closed.\n\n###6. Brookline \n##3/3 \n\n![](http://imgur.com/jpBCY9k.jpg)\n\nThis library goes beyond my expectations by clearly listing not only today’s closure, but the entire holiday weekend for all three of its locations. The “Closed” notice is clear and immediately jumps to my attention. While there is no “closed TODAY” notice, I found this more detailed listing works just as well.\n\n###7. Cambridge \n##0/3 \n\n![](http://imgur.com/QVg8HQO.jpg)\n\nThis library was a particular disappointment, because I have used it many times and the collection and its building are delightful. I am assuming it is one of the better funded libraries, given its location in direct proximity to Harvard. While the amount of content this page needs to show may be far greater than what a smaller local library deals with, this is no excuse for making things difficult to find. I get the feeling that the structure of the site is based on internal objectives, rather than user goals. \n\nHere’s where today’s closure information is, in fact, located:\n\n![](http://imgur.com/W4eopoE.jpg)\n\nI would have to do this:\n- “find library hours” on the homepage\n- select “holidays” among eleven listings\n- see on the list that today, January 19th, is a holiday\n\n###8. Concord \n##0/3 \n\n![](http://imgur.com/zH7HVUy.jpg)\n\nNo indication of whether it is open today. The latest news seems to be the New Year’s.\n\n###9. Dedham \n##3/3 \n\n![](http://imgur.com/8qHlEVH.jpg)\n\nIt is immediately clear that the library is closed today.\n\n###10. Dover \n##2/3 \n\n![](http://imgur.com/ZmLY9lq.jpg)\n\nThere is a clear indication that the library is closed today. I had to scan the page for a while and read a few things before I noticed it, so it was not obvious.\n\n###11. Framingham \n##2.5/3 \n\n![](http://imgur.com/3j83pAP.jpg)\n\nIt was almost obvious that “all libraries will be closed” today — even on this crowded page. I was distracted by the email sign-up notice, but the next thing I read was the closure notice. Not pretty, but close to functional.\n\n###12. Franklin \n##0/3 \n\n![](http://imgur.com/9CnV6Uv.jpg)\n\nThe public library website seems to be just a layer of content on top of the Franklin local government site. Very confusing. No indication of closure.\n\n###13. Holliston \n##2.5/3 \n\n![](http://imgur.com/UNEAehM.jpg)\n\nI found the closure information quickly, but it did not stand out enough (for my taste) from other news.\n\n###14. Lexington \n##3.5/3 \n\n![](http://imgur.com/n6IeQHX.jpg)\n\nThe first indication of the library closure for MLK is in the featured image. It eventually changes to another feature, but there is a second indicator (Today’s hours: CLOSED) that makes the situation obvious. This fall-back “closed” notice got this site an extra .5 points on my scale.\n\n##What did I miss?\n\nOf course, this is a very small test for a very specific user need. The sites that did well on my scale for “closing hours” may fail miserably at providing an answer to “what’s the street address?” or “can I renew my book online?”.\n\nThis test reiterated for me the importance of research and real-life user testing. Knowing what problems people might try to solve by going to a website, and where the site fails them, is necessary for most any meaningful improvement. \n\n##How not to miss things:\n\nAs a designer, I am often excited by a problem I see, and can jump to a solution I consider to be self-evident. (*The page is too crowded. Let’s change the typeface and layout!*) But to make my solutions truly useful to other people, I must know what they need.\n\nIn this example, I am a user with a specific need. Designers do not often start working on a project with solid knowledge of user needs. To bridge this gap, we test the current product (if it exists), create personas and scenarios, and ask lots of questions.\n\nResearch could have prevented the “is the library closed?” problem. If there was one question I could ask people,  it would be “What was the most frustrating thing about this library?” Out of many responses, I would imagine at least one would mention showing up at the library to find it closed. Asking these types of general questions, not *“how satisfied are you with the library website? (on a scale from one to ten)”*, will eventually lead us to meaningful design.\n\nOr, at least, save us the frustration of showing up to a closed library.\n\n"},{"title":"Bubbling actions through components","tags":["ember"],"summary":"Let your actions be handled in your controllers and routes","legacy":false,"id":"2015/01/28/bubbling-actions-through-components","employee":"Dan McClain","date":"2015-01-28T00:00:00","body":"\n\nIf you're building components for re-use, you're likely to run into the\nfollowing problem. Say you built a form component, and you also built some type\nof custom button component. You want the action triggered by the button to be\nhandled in your controller or route. If you try to bind the action of that\ninner button, it will be captured by the component, not the controller. The\nissue is that components swallow actions that are triggered within them; they\nwill not escape the component unless we punch a hole for them to bubble up.\n\nYou need to capture the action of the inner components and fire off new actions\nfrom the parent component. In the example below, the button is in a component\nthat is inside of another component. The controller has an action to increment\nthe counter.\n\n<a class=\"jsbin-embed\" href=\"http://jsbin.com/suvat/4/embed?output\">Ember Starter Kit</a><script src=\"http://static.jsbin.com/js/embed.js\"></script>\n\nOur components' templates are super simple:\n\n```hbs\n{{! index.hbs}}\n  {{pressCount}} Button presses\n  {{button-wrapper action=\"buttonClick\"}}\n\n{{! components/button-wrapper.hbs}}\n  <h2>Button Wrapper</h2>\n  {{press-button action=\"buttonClick\"}}\n\n{{! components/press-button.hbs}}\n  <button {{action \"buttonClick\"}}>My Button</button>\n```\n\nNotice we bind to the action of the `press-button` component in our\n`button-wrapper` component, and in our `index` template, we bind to the action\nof the `button-wrapper`. This alone doesn't work; we need to send actions from\neach component when they receive actions from the underlying component.\n\nIn our `press-button` component, we send an action when the button is clicked:\n\n```js\nApp.PressButtonComponent = Ember.Component.extend({\n  classNames: 'press-button',\n  actions: {\n    buttonClick: function() {\n      this.sendAction();\n    }\n  }\n});\n```\n\nOur `button-wrapper` receives the action from the `press-button` component and\nfires its own action:\n\n```js\nApp.ButtonWrapperComponent = Ember.Component.extend({\n  classNames: 'button-wrapper',\n  actions: {\n    buttonClick: function() {\n      this.sendAction();\n    }\n  }\n});\n```\n\nAnd our index controller receives that action from `button-wrapper` and\nincrements the `pressCount`:\n\n```js\nApp.IndexController = Ember.Controller.extend({\n  pressCount: 0,\n\n  actions: {\n    buttonClick: function() {\n      this.incrementProperty('pressCount');\n    }\n  }\n});\n```\n\n## Wrapping up\n\nIt's pretty easy, yet tedious to wire up an action from a component within a\ncomponent. You can trigger actions multiple levels above your initial action,\nand even mutate the action's arguments on the way up. Maybe the model that\ntriggered the initial action should be put into some type of intermediate\nstate. Maybe you want to normalize several different actions that are bubbling\nup through certain components. Since you need to manually bubble these\nactions up, we can manipulate them at each level that the bubbling occurs. It's\nsomewhat trivial to handle, you just have to be aware of the work needed to\ntie all your pieces together.\n"},{"title":"Estimation Buyers Guide","tags":["project management"],"summary":"Buyer beware of estimates without understanding how it was derived","legacy":false,"id":"2015/01/28/estimation-buyers-guide","employee":"Jon Lacks","date":"2015-01-28T00:00:00","body":"\n\nAs a Project Manager, I have seen estimates in all forms - points, days, months, hours, mario coins, etc. Many say estimates in Software development are garbage and significant margin of error should be the expected norm. I believe this perspective to be true if estimation is conducted in a vacuum vs. as a means to have a conversation with prospective clients about what it is going to take to achieve their vision.\n\nWhile estimation provides financial insight into a project, it also provides the project team with a point of reference when it comes to establishing schedules and conducting impact analysis when something needs to change (which is inevitable). As a project manager, a solid process by which we establish an estimate allows me to best serve the client and team.\n\nI would question any firm who claims to offer a high confidence estimate to a prospective client without spending time mapping out the direction an application/product may take on paper. I am not talking about writing a 50 page requirements document (which I once did on a project 10 years before I knew any better).  I am talking about getting the “supporting\" cast the context they need to provide an informed perspective on the complexity associated with building the application.  This complexity spans design, engineering, quality and any other overhead associated with a project. \n\nLet me paint this picture for you. Client X wants to build out a new application. The team to build said application provides client X with an estimate based off of a couple pre-sales meetings. Cost is negotiated until everyone around the table is happy with the economics and then the project is handed over to the project team and they are told to build “this” application in “this” amount of time. Client X is doomed regardless of whether or not that application is handed over in the agreed amount of time. Here’s why:\n\n* The team has no context - Therefore, they are going to spend the first weeks of development getting up to speed as opposed to delivering working features putting the schedule behind right out of the gate\n* The team does not \"own\" the estimate -  Someone else provided it on their behalf (who wants to be responsible for something they don’t own?)\n* Unexpected risks and complexity will (not “may”) put schedule at risk\n* Quality will (not “may\") suffer because the team will attempt to meet the date commitment at the expense of quality\n\nTo avoid this at DockYard, we use a tool called Discovery. This is an intensive time-boxed exploration of a client’s business objectives, market and user needs, as well as technological possibilities. These inputs translate into wireframes and those wireframes translate into an estimable breakdown of deliverables that provides a platform to discuss scope, schedule and cost with our client. Our Discovery phase is cross-functional where we have designers and developers working hand in hand to understand the direction a client wants to go. We iterate on design concepts, we discuss technical direction and potential complexities, we map out scope in a way that allows clients to make decisions which may adjust cost and schedule up or down.   While this Discovery phase might feel like a tough nut to crack, it typically results in lower overall project cost, higher quality and better probability of staying on budget/schedule.\n\nA recent post by our own Mike Dupuis speaks to the value engineers can add to the “Discovery” phase of a project resulting in savings later in the project lifecycle-  [Features as Business Objectives](http://reefpoints.dockyard.com/2014/09/12/features-as-business-objectives.html)\n\nWhether you love them or hate them, estimates are here to stay in a client services context.  Therefore, instead of grumbling about them - make sure you're using estimation as more than just a number but a means to have a conversation. Buyer beware of anyone who slaps an estimate on the table without providing you an explanation of how that estimate was derived.  \n\n“Luck is what happens when preparation meets opportunity” - Well said by someone much more insightful than I!\n"},{"title":"Empowering through Design","tags":["design","interaction","user experience","native web"],"summary":"The UX benefits of Single Page Web Apps","legacy":false,"id":"2015/01/30/empowering-through-design","employee":"Ashley Treni","date":"2015-01-30T00:00:00","body":"\n\nThere has been some debate in the development community between the [\"tradeoffs in server side and client side rendering.\"] (https://medium.com/@cramforce/tradeoffs-in-server-side-and-client-side-rendering-14dad8d4ff8b) As a UX designer working at an Ember shop that focuses on rich client experiences, I've observed the benefits of single page web applications, from a design perspective.\n\nThe best kind of user interface is one where the system remains transparent, and moves the user fluently through relevant prompts to accomplish the task at hand. That experience can only be as good as the tools we have to shape and elevate that participation. At DockYard, we design and develop single page web apps using Ember as our client-side framework, because it allows for greater clarity of interaction, while keeping the technology transparent.\n\nA single page web app is a webpage that can update contents within the page without refreshing the entire browser window. Because the server doesn't dictate the display, the \"client,\" or browser, determines how to represent it. Only the data associated with the selection is changed to reflect the action. \n\nYou can imagine how beneficial that real time feedback is on the user side of the experience. Whether aware of it or not, this creates a more immersive experience, and enables the user to better grasp the information by directing attention to content. There is more opportunity to nest information which alleviates information overload, and animation simplifies complexity while still engaging the user. \n\nTo do this well, good information architecture and content organization are imperative. Functionality and interaction must be part of the architecture, but not interrupt the flow and navigation. The visual design and communication must be clear and directive. The design supports self directed navigation and the process is not disrupted by the reload of a page. Creating this kind of real time response in the browser is the result of better, faster performance, bringing us closer to a native feel from the web.\n\n<iframe src=\"//player.vimeo.com/video/118249906\" width=\"500\" height=\"452\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n\n[Learnivore] (https://learnivore.com/) is a website that connects teachers and students searching for instruction across many disciplines. The search page is one of the largest hubs in the Learnivore experience. This [\"complex search\"] (http://reefpoints.dockyard.com/2015/01/07/complex-search-pages-feel-better-in-ember.html) filters by type of instruction, location, rate, price, qualifications, and more. The results change dynamically, reflecting the filter selection, as demonstrated in the video above.\n\nGood design empowers the user to make the choices they need to accomplish their goals. It promotes communication and supports informed decision making through real time response. The single page web app model and the technologies to create and innovate with it are at the forefront of mobile and web design and development. It is a technology that not only provides opportunities for creativity and innovation for designers and developers alike, it constructs a more informative and cooperative experience for our users.\n"},{"title":"Why I'm disappointed in React Native","tags":["opinion","javascript"],"summary":null,"legacy":false,"id":"2015/01/30/why-i-am-disappointed-in-react-native","employee":"Brian Cardarella","date":"2015-01-30T00:00:00","body":"\n\nThis week at React.js Conf 2015 React Native was introduced. You can see\nthe two most important videos here:\n\n<iframe width=\"560\" height=\"315\"\nsrc=\"https://www.youtube.com/embed/KVZ-P-ZI6W4\" frameborder=\"0\"\nallowfullscreen></iframe>\n\n<iframe width=\"560\" height=\"315\"\nsrc=\"https://www.youtube.com/embed/7rDsRXj9-cU\" frameborder=\"0\"\nallowfullscreen></iframe>\n\nThe TLDR is that Facebook has developed a view layer for React that can\nbe used within native mobile apps. Within this context React's templates\ncan call native components (and views) as if you were referring to normal\nHTML elements. Furthermore a JavaScript layer has been introduced to the\nnative layer that runs the React applications, this means that you can\ndebug your React Native applications in Chrome Web Tools while it runs\non an iOS device.\n\nThis is *amazing* technology and I don't think anyone was expecting\nthis. As an Ember developer I'm jealous. After some reflection I\nrealized I was also incredibly disappointed in Facebook for heading in\nthis direction.\n\n### We are (supposed to be) all in this together\n\nThe web development Holy Grail right now is to compete directly with (perhaps\nsomeday replace) native mobile applications. With React Native the web\nhas lost a huge partner in Facebook for helping make this a reality.\nWhat incentive does Facebook have for pushing forward mobile web now\nthat they can just produce native applications with web technology? What\nincentive do the existing React developers (and the large number of\ndevelopers that will move to React in the near future) have for building\nand proving out mobile web use-cases with React Native? **None**.\n\n### We are getting close\n\nThis year saw significant improvements in mobile web. We are so close.\nCheck out this video from Google showing off the potential of mobile\nweb:\n\n<iframe width=\"560\" height=\"315\"\nsrc=\"https://www.youtube.com/embed/v0xRTEf-ytE\" frameborder=\"0\"\nallowfullscreen></iframe>\n\nNo longer is mobile web a matter of *if* but a matter of *when*.\nHowever, with Facebook effectively taking themselves out of the\nconversation we've lost one of the best use-cases and the largest voices\nwith one of the most popular JavaScript frameworks.\n\nMobile web is a point of friction currently, and that friction existing\nis good because it will drive people and companies to pursue solutions\nto the problem. React Native is a work-around for mobile web. Some will\nthink of it as a \"best of both worlds\" and perhaps they are correct. But\nthe problem of mobile web will continue to exist.\n\n### Business needs trump ideological ones\n\nOf course Facebook should do what is in its own best interest. [In 2012\nMark Zuckerberg said that Facebook bet too heavily on\nHTML5](http://techcrunch.com/2012/09/11/mark-zuckerberg-our-biggest-mistake-with-mobile-was-betting-too-much-on-html5/).\nHe was correct then and he is correct now: mobile web feels like shit\nwhen compared to native. The User Experience is the primary concern for\nany product company. This, however, should not stop us from persuing\nmobile web and pushing the technology forward. I just hope that React\nNative doesn't impede that progress in any way.\n"},{"title":"Debugging a Broccoli Tree","tags":["broccoli"],"summary":null,"legacy":false,"id":"2015/02/02/debugging-a-broccoli-tree","employee":"Robert Jackson","date":"2015-02-02T00:00:00","body":"\n\n[Broccoli](https://github.com/broccolijs/broccoli) is a great tool for building up assets gradually through a list of changing steps. Unfortunately, when things go wrong in one of your steps it is often very difficult to figure out what is happening at each stage.\n\nHere is where [broccoli-stew](https://github.com/stefanpenner/broccoli-stew) comes in, it is a Broccoli utility library that contains a number of super useful plugins with a [posix](https://en.wikipedia.org/wiki/POSIX) flair to them. Tools like `mv`, `rename`, `find`, `map`, `rm`, `log`, and `debug` make it much easier to reason about your Broccoli build.\n\nAnd thanks to the `debug` and `log` plugins it has become **massively** easier to log the contents of each tree, or get an extra copy to poke at manually.\n\n### Initial Brocfile.js\n\nLets assume you have the following `Brocfile.js`:\n\n```javascript\n// Brocfile.js\nvar Funnel = require('broccoli-funnel');\nvar ES2015 = require('broccoli-es6modules');\nvar log = require('broccoli-stew').log;\n\nvar app = new Funnel('app', {\n  destDir: 'my-app-name',\n});\n\nvar transpiledTree = new ES2015(app);\n\nmodule.exports = transpiledTree;\n```\n\nThe goal of the Brocfile.js listed above is:\n\n1. Grab all files in `app/` and its subdirectories\n2. \"move\" those files to `my-app-name/`\n3. transpile those files from [ES2015](http://webreflection.blogspot.co.uk/2015/01/javascript-and-living-ecmascript.html).\n\nSo far this seems pretty easy, but what if your resulting output didn't contain the files you expected?  How would you track that down?\n\n\n### Log Tree\n\nYou can log the files in a tree using `broccoli-stew`'s `log`:\n\n```javascript\n// Brocfile.js\nvar Funnel = require('broccoli-funnel');\nvar ES2015 = require('broccoli-es6modules');\nvar log = require('broccoli-stew').log;\n\nvar app = new Funnel('app', {\n  destDir: 'my-app-name'\n});\n\nvar loggedApp = log(app, { output: 'tree', label: 'my-app-name tree' });\n\nvar transpiledTree = new ES2015(loggedApp);\n\nmodule.exports = transpiledTree;\n```\n\nUsing `log` like this will list out the files that are present just after the `Funnel` step.  It might output something like the following:\n\n```\nmy-app-name tree\n└── my-app-name/\n   ├── my-app-name/cat.js\n   └── my-app-name/dog.js\n```\n\nThis is super helpful to see that the right files are selected, but what if you are seeing the right files but the contents were not right?\n\n### Debug Tree\n\nUsing `broccoli-stew`'s `debug` you can have a duplicate copy of the tree generated into the root of the project so you can inspect it later (it will not get cleaned up at the end of the build like the temp folders do).\n\n\n```javascript\n// Brocfile.js\nvar Funnel = require('broccoli-funnel');\nvar ES2015 = require('broccoli-es6modules');\nvar debug = require('broccoli-stew').debug;\n\nvar app = new Funnel('app', {\n  destDir: 'my-app-name'\n});\n\nvar debugApp = debug(app, { name: 'my-app-name' });\n\nvar transpiledTree = new ES2015(debugApp);\n\nmodule.exports = transpiledTree;\n```\n\nThe `debug` plugin as used above will create a folder on disk at `DEBUG-my-app-name` in the root of your project with the full contents of the `app` tree when it was called. You can review this folder's contents at your leisure without worrying about the Broccoli server calling cleanup and deleting the directory.\n\n### Conclusion\n\nUsing `broccoli-stew` to debug a Broccoli pipeline is absolutely awesome, and makes getting a project using Broccoli much easier.  Thanks to [@stefanpenner](https://twitter.com/stefanpenner) and [@chadhietala](https://twitter.com/chadhietala) for pushing things forward!\n\nIf you'd like to checkout and play with the `Brocfile.js` above, you can do the normal `git clone` and `npm install` song and dance with [https://github.com/rwjblue/debugging-broccoli](https://github.com/rwjblue/debugging-broccoli).\n"},{"title":"Vim: Jump, Jump, Jump!","tags":["vim","workflow"],"summary":"Kris Kross' favorite Vim feature","legacy":false,"illustration_alt":"","illustration":"https://i.imgur.com/mFc1cHz.png","id":"2015/02/04/vim-jump-jump-jump","employee":"Doug Yun","date":"2015-02-04T00:00:00","body":"\n\n# <a href=\"https://www.youtube.com/watch?v=010KyIQjkTk\" target=\"_blank\">Jump, Jump, Jump!</a>\n\nIn the last Vim-related post, we\n[discussed **mark** motion](http://reefpoints.dockyard.com/2014/04/10/vim-on-your-mark.html),\nand today, we're going to cover another type of navigation: **jump** motion.\n\nThe main benefit of jump motion is its speed; it allows us to quickly traverse through the current file\nopen or previously visited files.\n\nLet's briefly cover some of the most familiar ones.\n\n## File Jumps\n\n*File jumps* will navigate you to a location within the current file, regardless if that\nlocation is seen or not seen within the window.\n\n### <a href=\"https://www.youtube.com/watch?v=Xz-UvQYAmbg\" target=\"_blank\">Ain't no Mountain high enough, ain't no valley low enough...</a>\n\n**gg**\n\n* Will take you to the *top* of the file.\n\n**G**\n\n* Will take you to the *bottom* of the file.\n\n### Sentences and Paragraphs\n\n**(**\n\n* Move a *sentence backwards*, can take a prefix argument.\n  * **5(** - Navigates you 5 sentences backwards.\n\n**)**\n\ne Move a *sentence forward*, can take a prefix argument.\n  * **10)** - Navigates you 10 sentences forwards.\n\n**{**\n\n* Move a *paragraph backward*, can take a prefix argument.\n  * **5{** - Navigates you 5 paragraphs backwards.\n\n**}**\n\n* Move a *paragraph forward*, can take a prefix argument.\n  * **5}** - Navigates you 5 paragraphs forwards.\n\n### <a href=\"https://www.youtube.com/watch?v=EDNzQ3CXspU\" target=\"_blank\">Search and Destroy</a>\n\n**/**\n\n* Allows you to search *forwards* for a desired pattern within the file.\n  * **/fishsticks** - Searches for all occurences of `fishsticks` ahead of your current cursor.\n\n**?**\n\n* Allows you to search *backwards* for a desired pattern within the file.\n  * **?catdog** - Searches for all occurences of `catdog` behind your current cursor.\n\n**n**\n\n* Repeats the last **/** or **?** search.\n\n**N**\n\n* Repeats the last **/** or **?** search in the *opposite* direction.\n\n## Window Jumps\n\n*Window* jumps allow you to move within the current scope of the window or viewport.\n\n### <a href=\"https://www.youtube.com/watch?v=JECF2EB3LXU\" target=\"_blank\">High, Middle, and Low</a>\n\n**H**\n\n* Jumps your cursor to the **highest** line of the window.\n\n**M**\n\n* Jumps your cursor to the **middle** line of the window.\n\n**L**\n\n* Jumps your cursor to the **lowest** line of the window.\n\n## System Wide Jumps\n\n*System* jumps are special; they have the ability to take us to any previously visited file,\nregardless if those files are or are not within the same directory.\n\nThis is where jump motion really shines!\n\n### <a href=\"https://www.youtube.com/watch?v=KZaz7OqyTHQ\" target=\"_blank\">Jump Around</a>\n\nGive these next commands a try:\n\n**CTRL-O**\n\n* Jump to our previous position.\n\n**CTRL-I**\n\n* Jump to our next postion.\n\nBy pressing these commands repeatedly, you'll see that you are traversing through\nyour recently visited files.\n\n### Jump list\n\nOur recent jumps are stored on our *jump* list. We can view all the jumps through Vim's\ncommand-line mode. There are three ways to open up the jump list.\n\n**:jumps**\n\n**:jump**\n\n**:ju**\n\n* Opens up the jump list\n\n![](https://i.imgur.com/mFc1cHz.png)\n\nAbove is an example of a jump list. There are four columns: *jump*, *line*, *col* and *file/text*.\nThe numbers underneath the *jump* column are used to prefix our jump command, **CTRL-O** and **CTRL-I**.\nWe are also given the position of our cursor from the  *line* and *col*umn columns. Lastly, the\n*file/text* column, gives us either the file path or, if the jump is located in our currently opened file,\nthe line of text.\n\nUsing our example jump list, if we want to jump to the `4`th jump, located within `~/dir2/file.md`, we'd\nprefix our previous jump command with the number **4**, i.e. **4CTRL-O**.\n\nNext if we want to get back to our previous position, the line\n`This is another sentence!` we can cycle back to it with a couple of **CTRL-I**s. Cool!\n\nI find that *jump* motion complements *mark* motion really well. By setting multiple marks in the current file,\nand flying to different files with jumps, my workflow has greatly improved.\n\nHope you give *jump* motion a try!\n"},{"title":"Ember QUnit 0.2.x","tags":["ember-cli","testing","ember"],"summary":null,"legacy":false,"id":"2015/02/06/ember-qunit-0-2","employee":"Robert Jackson","date":"2015-02-06T00:00:00","body":"\n\n[Ember QUnit](https://github.com/rwjblue/ember-qunit) 0.2.x has been released. It brings a whole bunch of bug fixes and some much needed cleanup, but there are a couple breaking changes also.\n\n## History of the changes\n\nEmber QUnit started as a self contained library to make unit testing of Ember applications significantly easier. Ember QUnit proved that unit testing an Ember application could be very simple, and users of other testing frameworks wanted to join in the unit testing fun.  Unfortunately, the early code was fairly coupled to [QUnit](http://qunitjs.com) (the testing framework being used) so reusing the Ember unit testing helpers separate from QUnit was not possible.\n\nEmber QUnit 0.2.x is a complete organizational refactor to remove the Ember unit testing helpers (into the appropriately named [ember-test-helpers](https://github.com/switchfly/ember-test-helpers)) and keep the QUnit specific parts in Ember QUnit. The majority of this refactoring effort was done by [Dan Gebhardt](https://twitter.com/dgeb) and sponsored by the good folks at [SwitchFly](http://www.switchfly.com) (you can read their write-up of the work [here](http://blog.switchfly.com/2014/11/Refactoring-Ember-Testing-for-Mocha)). Out of this effort we have been able to create [Ember Mocha](https://github.com/switchfly/ember-mocha) which now has feature parity with Ember QUnit and is a truly first class Ember unit testing solution. Due to the usage of a general purpose underlying ember-test-helpers library, it should now be possible to create a nice wrapper around nearly any JS testing framework.\n\n## Notable Changes\n\n### setup and teardown Deprecation\n\n`setup` and `teardown` are deprecated in favor of `beforeEach` / `afterEach`. This update was made to allow closer conformance to [QUnit 2.x](http://qunitjs.com/upgrade-guide-2.x/) concepts.\n\n```javascript\n// Refactor from (under 0.1.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce', 'AwesomeSauceComponent', {\n  setup: function() { },\n\n  teardown: function() { }\n});\n\n// To (under 0.2.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce', 'AwesomeSauceComponent', {\n  beforeEach: function() { },\n\n  afterEach: function() { }\n});\n```\n\n### Global Assertion Deprecation\n\nUsage of global assertions are deprecated and should be replaced with the `Assert` argument to your test callbacks. This update was made to allow closer conformance to [QUnit 2.x](http://qunitjs.com/upgrade-guide-2.x/) concepts.\n\n\n```javascript\n// Refactor from (under 0.1.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce');\n\ntest('implements awesomeness', function() {\n  equal(....);\n  ok(....);\n});\n\n// To (under 0.2.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce');\n\ntest('implements awesomeness', function(assert) {\n  assert.equal(....);\n  assert.ok(....);\n});\n```\n\n### Arguments to setup / teardown / beforeEach / afterEach\n\nIn prior versions of Ember QUnit, the `setup` and `teardown` hooks were called with a single argument: the container. In Ember QUnit 0.2 this argument is no longer present.\n\nNote: usage of `setup` and `teardown` are deprecated, you should use `beforeEach` and `afterEach`.\n\n\n```javascript\n// Refactor from (under 0.1.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce', 'AwesomeSauceComponent', {\n  setup: function(container) {\n    /* do stuff */\n  },\n\n  teardown: function(container) {\n    /* do stuff */\n  }\n});\n\n// To (under 0.2.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce', {\n  beforeEach: function() {\n    var container = this.container;\n\n    /* do stuff */\n  },\n\n  afterEach: function() {\n    var container = this.container;\n\n    /* do stuff */\n  }\n});\n```\n\n### Deprecated this.append in Component tests\n\nIn a component test you would previously call `this.append()` to append your component into the DOM.  This was somewhat confusing, and took some explaining when teaching to newcomers, so it has been replaced with `this.render()` which fits much better in our Ember mindset.\n\n\n```javascript\n// Refactor from (under 0.1.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce');\n\ntest('implements awesomeness', function() {\n  var component = this.subject();\n\n  this.append();\n\n  equal(component.$().text(), 'WHOAA!! AWESOME!!!');\n});\n\n// To (under 0.2.x):\nimport { test, moduleForComponent } from 'ember-qunit';\n\nmoduleForComponent('awesome-sauce');\n\ntest('implements awesomeness', function(assert) {\n  var component = this.subject();\n\n  this.render();\n\n  assert.equal(component.$().text(), 'WHOAA!! AWESOME!!!');\n});\n```\n\n### Ordering of afterEach / teardown Callback\n\nIn Ember QUnit 0.1.x, the `teardown` callback was called *after* all internal cleanup was finished (like clearing the container, removing any views from the DOM, etc).  In Ember QUnit 0.2.x `afterEach` / `teardown` is called before the internal hooks.\n\n### Build Changes\n\nThere are a few build related changes with Ember QUnit 0.2.x:\n\n* Build output is removed from the main repo, and now is maintained at [ember-qunit-builds](https://github.com/rwjblue/ember-qunit-builds).\n* The output file locations are no longer nested in `dist/`.\n* CJS and AMD output is no longer generated.\n\n### [ember-cli-qunit](https://github.com/ember-cli/ember-cli-qunit) Version\n\nIf you are using Ember CLI, you should update to [ember-cli-qunit](https://github.com/ember-cli/ember-cli-qunit) version 0.3.7.\n\n## Summary\n\nPlease file issues [ember-qunit issues](https://github.com/rwjblue/ember-qunit/issues) if you come across anything that isn't listed here.\n"},{"title":"Manage the conversation","tags":["ux design","research","discovery"],"summary":"Learning to conduct user tests and interviews","legacy":false,"id":"2015/02/11/managing-the-conversation","employee":"Maria Matveeva","date":"2015-02-11T00:00:00","body":"\n\n\nOne of my core UX design skills is finding information through user testing and interviews. What we gather will help us decide what to build, and how. This makes our ability to source qualitative information very important to the success of a product.\n\nA user interview is, at its essence, a closely managed conversation. It is my responsibility, as the designer, to manage it. The level of control required of the UX designer in this situation is unfamiliar, and can be stressful in the beginning. I think the reason for this initial discomfort is that we have little context for this managed type of conversation in our everyday life. We’re used to conversations in which both parties share control over the direction and tone. Owning the conversation completely can feel rough and undemocratic. It takes skill and experience to do it while making the other party feel at ease.\n\nI want to share what I learned while conducting interviews and user tests at DockYard. I hope this will take some of the edge off the initial difficulty for others also learning this skill, and make it a more pleasant and productive time for all.\n\n##Lessons learned\n\n###1. Prepare well\n\nThere is a lot of prep work involved, before the conversations can even start. Taking the time to do these steps properly allows me to get the most out of the time I spend with the interviewee.\n\n- Schedule the interviews. You may need to find suitable users yourself. Or, the client may help by putting you in touch with some preselected users to interview. Try not to schedule interviews back-to-back in case one takes a bit longer than expected.\n- Arrange for the legal details. This could include notifying the interviewee of privacy arrangements, having them sign an NDA, or otherwise vetting the situation. Basically, you want to protect yourself, the person you’re interviewing, and the client by specifying how information is going to be used.\n- Draft a sequence of questions that cover your desired information.\n- Edit until questions sound polished and neutral (more on this to follow, in a separate post)\n- Prepare a notebook, pen and a laptop.\n- Print the questions so I can write notes in context and check off completed ones.\n- Prepare backups and extra copies of any materials I’m planning to use.\n- Grab water and a snack! You don’t want to take focus away from the interview by being too thirsty or hungry.\n- If needed, also grab a timer and a sound recorder (your needs may vary)\n- Triple-check the list of interviewees and their basic information. For example, phone interviews can happen over different time zones. It’s nice to verify you're not calling the person who kindly offered up their time at 6am.\n\n###2. Establish context\n\nYour interviewee should theoretically know who you are and what you’re talking about. After all, they agreed to the interview. However, it is always a good idea to confirm your assumptions. A brief introduction won’t hurt. For example, you could start with *“Hi \\_\\_\\_\\_, thank you for taking time to do this! My name is \\_\\_\\_\\_, and my company was hired by \\_\\_\\_\\_ to improve their product. How familiar are you with the product?”*\n\n###3. Direct the conversation\n\nFor a UX designer starting out, it may seem rude to redirect the conversation. Especially so if your interviewee is describing, with passion and detail, a subject they are an expert in. But don't be afraid to redirect the conversation. You need to get to the specific questions you want answered (but of course be nice about it!). For example, to get back on track, you might say *“Great - this extra information is very helpful, but I’d like to get back to the original reason you started using \\_\\_\\_\\_?”*  This acknowledges the value of their insight, then nudges them to answer your original question.\n\n###4. Go with the flow\n\nAt the start of the interview, there is a prepared, logical sequence of questions to ask. But in a conversation, one thing may lead naturally to another. If it makes sense to ask things out of order, it’s totally acceptable to do so. This is where a printed list of questions helps. Check them off as you go to make sure none remain unanswered.\n\n###5. Use teamwork\n\nIt is definitely easier to have a team of two handling the interview. This way, one person asks questions while the other focuses on capturing notes. Some notes may be of things like body language, expression, and movement - all important indicators of how a user may feel about the questions in addition to what they actually say. An experienced interviewer could probably handle both tasks with grace. As a beginner, it's almost impossible. Try to do both at once, and you'll either get awkward pauses as you write notes, or you'll fail to record some of the valuable details.\n\n###6. Don’t be afraid to clarify\n\nSome interviews happen over the phone. The challenge here is that we lose most of the added information of body language and facial expression. This could be remedied with extra questions. For example, if I think the interviewee is referring to their laptop to answer something, I would literally ask that: *“I’m guessing you’re looking at the laptop screen for reference - is that correct?”*  It is also important to be  attentive to the tone of voice so you can hear emotion, like hesitation.\n\nAnother possible challenge in phone interviews is sound quality. Users may be on a shaky cell phone connection, or calling us via Skype. This can make their (and potentially your own) voice difficult to understand. It is tempting to dismiss the poor quality of sound and just omit details you can’t quite hear. Make sure to always ask the interviewee to repeat or speak louder if you do not understand what’s being said.\n\n##In conclusion\n\nConducting interviews caused me to cringe quite a few times. Am I doing it right? What does the interviewee think of me? Do I sound professional? Looking back, I can see how I and my colleagues got over our fears, and made significant improvements with just a few rounds of practice.\n\nRemember, both you and the interviewee are there because you want to improve some aspect of people’s lives through your work and their experience. You’re on the same side, and you share this interest in the thing you’re discussing. Make the most of this interviewing situation, and you will see improved results each time.\n"},{"title":"Automating Reefpoints","tags":["automation"],"summary":"We used Travis-CI to automatically publish this blog","legacy":false,"id":"2015/02/12/automating-reefpoints","employee":"Dan McClain","date":"2015-02-12T00:00:00","body":"\n\nWe have a healthy mix of developers and designers, plus a project manager and\noffice manager. This results in a group of people with varying degress of command line expertise.\nTo make it easier to write blog posts, [I added instructions to create a blog\npost using only GitHub](https://github.com/dockyard/reefpoints#the-github-web-interface-way).\n\nThis made it super easy for anyone to create a new blog post, have people\nreview it, but one piece was missing: making it easy for people to publish\ntheir article once it was reviewed. Well, I solved that problem today with\n[Travis-CI](http://travis-ci.org) and a little bit of bash script.\n\nThe first step required was to script the publishing of our blog. We already\nuse [`middleman-gh-pages`](https://github.com/neo/middleman-gh-pages), which makes publishing as easy as `rake publish`.\nI created the following [`travis_deploy.sh`](https://github.com/dockyard/reefpoints/blob/master/travis_deploy.sh) script:\n\n```sh\n#!/usr/bin/env bash\n\nset -e\n\ngit config --global user.email \"socko@dockyard.com\"\ngit config --global user.name \"sockothesock\"\n\n\n# This specifies the user who is associated to the GH_TOKEN\nUSER=\"sockothesock\"\n\n# sending output to /dev/null to prevent GH_TOKEN leak on error\ngit remote rm origin\ngit remote add origin https://${USER}:${GHTOKEN}@github.com/dockyard/reefpoints.git &> /dev/null\n\nbundle exec rake publish\n\necho -e \"Done\\n\"\n```\n\n`middleman-gh-pages` is smart in that it figures out your GitHub remote based\non the origin, so what we did is update the origin to use a GitHUb OAuth token\nthat allows writing to public repos. We store the OAuth token in the\nenvironment variable `GHTOKEN`, which we encrypt in our [`travis.yml`](https://github.com/dockyard/reefpoints/blob/master/.travis.yml):\n\n```yml\nlanguage: ruby\nsudo: false\ncache: bundler\nrvm:\n- 2.0.0\nbranches:\n  only:\n  - master\nscript: \"./travis_deploy.sh &> /dev/null\"\nenv:\n  secure: eAyjmkDKLbXnGvC75KRNVLoAr6WE7ldT6JGOzOKOfQ9WxhEFgzAXoKZVO4mX4DfDfJbZbCyFmxKqALXGXjaBKwU2eQKeq1g4svBnxGPHmOKFMfVjkSCFag0bppE2JK9VXn70lVYFh8kJHavHgQ2pRYlSb78WfmUKbbB9PSH/rSE=\nnotifications:\n  slack:\n    secure: o2ksyDNq6Ea2oHUbUpgICYHAUdZ0QgHSQNqgn/gginNyPYAd2MtS2h7iXVrzSgeXDSNi6WpAvAeOcUnzpA6h6oBkl0YvUTaXJs50IepWfAE4UZPwX9ZFfV8YiwnOCU9ByUTU2L9qeq83W3LuDYY7j6xZJjP5KMLC78TqTKy5pd8=\n```\n\nI also added a Slack notification so that people can see when new blog posts\nget published. The last thing I did was go into the Travis-CI setting and\nturned off the option to build Pull Requests, as that would publish articles\nbefore they were merged.  I accidentally leaked the OAuth Token in the Travis\nlogs (that's why the `script` step is redirecting output to `/dev/null`).\n\nIn the end, it was really simple to automate the publication of our blog. It\nhas the added bonus of publishing corrections to the blog when anyone's pull\nrequest is merged.\n"},{"title":"Rubyist's Guide to Executing JavaScript","tags":["ruby","javascript"],"summary":"A high-level look at how your Ruby and JavaScript code gets executed.","legacy":false,"illustration_alt":"Ruby execution diagram","illustration":"http://i.imgur.com/Sa1qURz.png","id":"2015/02/24/rubyists-guide-to-executing-javascript","employee":"Michael Dupuis","date":"2015-02-24T00:00:00","body":"\n\nJavaScript is introduced to developers as a programming language that runs client-side, in the browser. This is convenient as a jumping off point for aspiring programmers, who can simply open up Chrome’s Web Inspector and start alerting “Hello, World!”, but it’s a concept that isn’t easy to unpack. Soon enough, the developer will likely find herself in contact with JavaScript outside of the browser – Node.js being the most prominent example of this. At this point, the notion of JavaScript being a language for the browser is no longer helpful; it obfuscates what is happening when a developer executes a line of code.\n\nThis post is a high level primer on what is happening “under the hood” with our code. It will lend some insight into what terminology like “tokenizing,” “interpreting,” “compiling,” and a host of other terms mean. You'll gain a better sense of what the concept of a virtual machine encapsulates. And hopefully you'll leave with a better understanding of what your script is doing before it hits your computer's processor.\n\nI feel this article will be well-suited for Rubyists who find themselves increasingly working in the realm of JavaScript, as I’ll be comparing how code executes between the two languages.\n\nRather than explaining how a line of Ruby or JavaScript code gets processed and run, I’d like to work our way backwards, beginning with machine code. When you write a line of Ruby, it doesn’t simply go to the processor when you run the script. It goes through a number of translations before being turned into machine code that the processor can execute. We’ll look at how Ruby gets processed and then touch on how JavaScript differs.\n\n## Ruby\n![Ruby execution diagram](http://i.imgur.com/Sa1qURz.png)\n\n### Machine code\nMachine code is binary that is executed directly by your computer’s CPU. The bit patterns correspond directly to the architecture design of the processor.\n\nBefore a statement in a scripted language becomes machine code, it gets compiled into machine code by a compiler.\n\n### Virtual Machine\n[LLVM](http://www.aosabook.org/en/llvm.html) compiles code on most\nUnix-based machines. It generates the machine code for the processor\nduring compilation, which is just the process of translating one language to another.\n\nThe virtual machine executes your code. It's written in C and is known as the [YARV](http://en.wikipedia.org/wiki/YARV) interpreter. It is at the heart of a scripting languages \"implementation,\" as it executes the source code via whatever language the scripting language is built upon ([C](http://en.wikipedia.org/wiki/C_(programming_language)) in the case of [Ruby MRI](http://en.wikipedia.org/wiki/Ruby_MRI)).\n\nYARV doesn’t receive the Ruby statement as you typed it. It goes through an abstraction of your code known as an [Abstract Syntax Tree (AST)](http://en.wikipedia.org/wiki/Abstract_syntax_tree), which get compiled to YARV byte code and run.\n\nThis \"tree\" is made up of nodes assembled by something called the parser.\n\n### Parser\nYou can think of a node on the Abstract Syntax Tree as an atomic representation of a Ruby grammar rule. The reason that Ruby knows to print “Hello, World” when it sees `print 'Hello, World'` is because the parser knows that `print` is a method and the string `'Hello, World'` is its argument. These syntax rules are located inside of a language’s grammar rule file.\n\nAgain, the parser creates the Abstract Syntax Tree that the virtual machine compiles and interprets.\n\n### Tokenizer/Lexer\nIf you’re wondering how Ruby knows that `print` is a separate element in the language from `'Hello, World'`, then you’re understanding the function of the Lexer or Tokenizer. The Tokenizer scans your line of Ruby code, character-by-character and determines where the \"words\" of the language begin and end. The Tokenizer can tell the difference between a space separating words and a space separating a method name from its arguments.\n\nAnd that’s the 10,000 foot lifecycle of a Ruby statement, as it goes from Tokenization to becoming machine code. If you’re looking for the microscopic explanation, I’d recommend [Ruby Under a Microscope](http://www.nostarch.com/rum).\n\n## JavaScript\n### Client-side\nMost browsers implement [Just-In-Time (JIT) compiling](http://en.wikipedia.org/wiki/Just-in-time_compilation). This means that the JavaScript code you write is compiled right before it gets executed by the virtual machine; though, in JavaScript, the interpreter is not referred to as a virtual machine, but as a JavaScript engine.\n\nV8 is the engine that interprets and executes JavaScript in the Chrome browser, Nitro is the engine for Safari, SpiderMonkey for Firefox, and Chakra on Internet Explorer. The efficiency with which a browser interprets JavaScript accounts for a substantial portion of its performance these days, especially as JavaScript-heavy, Single Page Applications become increasingly important.\n\n### Server-side\nNode.js is the predominant framework for running JavaScript server-side. It is built on top of Google’s V8 engine, which is a little confusing if you’ve just read that V8 interprets JavaScript in the browser. In general terms, the JavaScript interpreter is extracted from Chrome, compiled on the server, and utilized by Node.js, allowing you to execute JavaScript outside of the browser.\n\n## Conclusion\nUpon researching how a line of Ruby or JavaScript gets executed, you'll quickly find that you can go down a rabbit hole. There are so many different implementations of Ruby, so many advancements in how code gets processed, and so much ambiguity in the terminology we use, that it can be quite challenging to form a mental model of what's going on under the hood. That being said, a little patience goes a long way, and if you're looking to dive into any one of the topics described above, I think you'll be surprised at how readable much of the technical documentation is out there.\n"},{"title":"EmberConf 2015 Day 1","tags":["ember"],"summary":"Live blog of EmberConf 2015","legacy":false,"id":"2015/03/03/ember-conf","employee":"Marin Abernethy","date":"2015-03-03T00:00:00","body":"\n\n# Opening Keynote: Tom Dale and Yehuda Katz\n\n* To kick off the conference Tomster joined Tom Dale and Yehuda Katz on stage!\n* [@mixonic](https://github.com/mixonic) [@ef4](https://github.com/ef4) [@mmun](https://github.com/mmunm) were welcomed as new members to the Ember Core Team\n* Big thanks to Robert Jackson [@rwjblue](https://github.com/rwjblue)!!!! [Get rwjblue a beer!](http://getrwjblueabeer.com)\n\n## Ember 2014 in Review\n\n* Rapid Release worked great! 6 week release cycle to get new features into everyone's hands.\n\n### HTMLBars\n\n```hbs\n<a href={{url}}>\n```\n\ninstead of\n\n```hbs\n<a {{bindAttr href=\"url\"}}> \n```\n\n* Block parameters, faster and lower memory, validation for templates\n* Killed metamorphs!\n* Improvements to Ember Inspector including Ember Data and promises pane, render performance tab, multiple `<iframe>`s, and redesigned UI, to name a few.\n\n### Ember CLI\n\n* Single install command for Addons, test support, massive performance improvements, and API stubbing, and server proxy (the list goes on!).\n\n### Testing Ecosystem\n\n* handles asynchrony \n\n### Ember Data\n\n* Relationship syncing, async relationships - built with async loading in mind.\n* Adapter Ecosystem\n\n## That was last year, what's next?\n\n* [Versioned Guides](http://guides.emberjs.com) -- live today!\n* Next Version of Ember CLI (as of last night)\n* Engines\n* List View\n* <angle-bracket> Components (already in Canary)\n* Liquid Fire\n* Async and Routable Components\n* Ember Data: JSON API support out of the box\n* Pagination and Filtering\n* Shipping Ember Data 1.0\n* 6/12 release date for Ember 2.0, Ember Inspector, Ember CLI, LiquidFire, etc.\n\n\n# Ember.js Performance by Stefan Penner \n[@stefanpenner](https://github.com/stefanpenner)\n\n* Important choices to make, how to make the right choices?\n* Time vs. Space\n* Things that are costly in space: closures, objects, non-optimized code, compiled code, excess shape allocations\n* In Ember.js, need to do less work, align with primitives\n\n## Mis-alignment #1\n\nProblem: Ember does too much work.\n\nSolution: do less\n\n* Actions up, bindings down, no two-way bindings, explicit data flow\n* RIP singleton controllers, explicit lifecycle\n\n## Mis-alignment #2\n\nProblem: `init` and `super` are hard to learn and mis-aligned with ES2015\n\nSolution: Embrace super\n\n* Explicit defaults in super\n* Don't set properties until super\n* When to call `_super()`: When overwriting a framework method before touching `this`\n\n## Mis-alignment #3\n\nProblem: Ember.Object.reopen, buggy, complex internals, massive allocations & shapes\n\nSolution: Limit reopen to before first instantiation\n\n* Meta is a good thing. Every class has a meta, every instance has a meta. Metas for instances are what kill us. Meta is \"live\" inheriting. If can limit reopen, can make all metas one shape.\n* meta.listeners is crazier\n* Solution: work with V8 to make things better\n\n\n# Designing for Ember Apps by Steve Trevathan\n[@strevat](https://twitter.com/strevat)\n\n* Mental models: Understand where the user is coming from and what kinds of interactions they deal with\n    * \"What I think the thing is\"\n    * Influenced by experiences from the past\n    * Not always solid: can be updated and changed. (improvements)\n* 2 types of mental models\n    * Macro: what I think it is from a distance.\n    * Micro: how I think each individual interaction works; the specific feature.\n* Build a framework of understanding\n    * Some apps are just too complicated\n    * Use explicitly if they apply\n    * Break mental models if it improves the experience\n\n\n## Design Patterns\n\n### #1 Gradual Engagement\n\n* Core value given for free. Eventually you may be asked to sign up.\n\n### #2 Skeleton UI \n\n* ex. Google maps: grid becomes fully rendered map.\n\n### #3 Carry Context\n\n* ex. rdio: music played on laptop is reflected on iPad (or other devices). \n\n### #4 Reuse Core Interactions\n\n* ex. Browsing Pinterest: provides click and follow tangent.\n* Micro becomes Macro; core interactions become a symbol of your app.\n* \"When I go home and think of your app, I think of the experience, the micro features more than the macro ones.\"\n\n### #5 Offline Mode\n\n* ex. Google Docs: “trying connect” message and can’t interact with document. Incredibly Frustrating.\n\n## Tools of the Trade\n\n * A free design pattern library for Ember apps. [Sign up!!](http://toolsofthetrade.dockyard.com)\n\n\n# Hijaking Hacker News with Ember.js by Godfrey Chan\n[@chancancode](https://github.com/chancancode)\n\n* Being a canadian is awesome\n\n## [Hijacking Hacker News App](https://github.com/chancancode/hn-reader)\n\n* Browser extension that transforms old site design to new, more usable app\n* Runs in hacker news domain\n\n### Getting the Data\n\n* `$.get(\"/news').then()`: request html page, extract data, then manipulate\n* Hacker News HTML Scrapper: need adapter to help talk to Ember Data store; customize adapter and serializer.\n\n### Fixing the URLs\n\n* Hacker News urls are not ideal for building an Ember app.\n* HN urls (serialized App States) to Ember Router (Actual App States)\n   * trick Ember into seeing URLs that are different from what is in the address bar\n* Router location types: `Ember.HistoryLocation` vs. `Ember.HashLocation`\n   * Can use same mechanism to make a custom Ember.Location: `App.HackerNewsLocation = Ember.Location.extend()`\n\n### Preferences\n\n* Changing preferences in one place and can see changes reflected in other\n\t* Use observer pattern\n\n### The Possibilities\n\n* What if your ideas do not line up with the framework's choices?\n* If the frameworks is doing it's job, than the possibilities should be endless!\n\n\n# The Art of Ember App Deployment by Luke Melia\n[@lukemelia](https://github.com/lukemelia)\n\n* Need to adjust deployment techniques from \"server app\" days\n* When traffic starts routing to the new app, finger-printed assets can no longer be accessed\n\t* Need to keep old and new finger printed assets for a few minutes after a deploy.\n\n## Versioning\n\n* Learn from native apps - phones run different versions of an app\n* Keep API working for older clients through API versioning\n\n## Deployment & serving strategy\n\n* HTML page should be managed and deployed as part of static asset deployment process\n* HTML page should be served by the API server\n* Preview before activating\n* A/B Testing\n\t* Setting global flags based on A/B buckets\n\t* Serving up wholly different HTML based on A/B bucket\n* Notify connected clients\n\n## The New [`ember-cli-deploy`](github.com/ember-cli/ember-cli-deploy)\n\n* Merged these three projects: `ember-deploy`, `front-end-builds`, `ember-cli-deploy`\n* Now, one project with 6 maintainers (and growing!)\n\n### Roadmap\n\n* Release 0.4.0 by the end of this week!\n* Reelease 0.5.0 \n\t* New pipeline hooks and plugins architecture\n\t* Includes post-deploy hook\n\t* Documentation for plugin developers\n\t* `ember-cli-front-end-builds` becomes a plugin\n\t* USAGE: `ember deploy staging`\n* Beyond 0.5.0: deployment to named buckets, support A/B tests, beta testing, etc.\n\n\n# Ambitious UX for Ambitious Apps by Lauren Tan\n[@poteto](https://github.com/poteto)\n\nGood Design is:\n\n\t* how it works\n\t* reactive\n\t* playful\n\t* informative\n\t\n* Designing the product vs. designing the experience\n* You are not the same as your website users\n\n## Good Design is Reactive\n\n * Instant feeback\n * Flow of data and maintaining relationships between that data\n * Ember allows reactivity through the observer pattern\n \n### The Observer Pattern\n\n* Computed properties transform properties and keep relationships in sync\n* Computed Property Macros to keep things DRY.\n\t* Ember ships with a bunch of these out of the box (map, mapBy, concat, etc)\n* Observers synchronously invoked when dependent properties change\n\n## Good design is playful\n\n* Has personality\n* Ex. Slack when you open app (fun messages)\n\n## Good Design is Informative\n\n* Visibility of System Status\n\t* Jakob Nielson - 10 heuristics for User Interface Design\n* Ex. Flash messages\n\t* [`ember-cli-flash`](https://github.com/poteto/ember-cli-flash)\n\n## Good Design is Intuitive\n\n* Drag and drop (trello, Google Calendar, etc...)\n* Ember handles drag and drop events out of the box\n\t* add `draggable=true` to any html element to make it draggable\n\n\n# Bring Sanity to Frontend Infastructure with Ember by Sam Selikoff\n[@samselikoff](https://github.com/samselikoff)\n\n## How Ember Can Help Today:\n\n* Ember and Ember CLI helps infastructure by reducing boilerplate\n* Similar directory structure and architecture\n* Conventions: eliminate trivial differences that hold us back\n* Writing add-ons for shareable code. Allows us to build structure.\n* Use `ember deploy` to deploy apps. Auth and backend config work into separate deploy server.\n* Testing in Ember using `ember test`. QUnit provides helpers.\n* Identify redundancies and abstractions\n\n## How Ember Can Help Tomorrow:\n\n* Semantic versioning and CLI conventions\n* Flexibility\n* New standards and best practices\n\t* generally, shared solutions/frameworks help identify and discover ways of improving applications\n\t* Ember always keeps up to date with these best practices\n* “Ember is not just a framework, it’s a philosophy” of how to create and improve software\n\t* First, give real developers the tools to tinker\n\t* Then, deliberately fold in shared solutions\n\nIn summary, innovate & share!\n\n\n# Dynamic Graphic Composition In Ember by Chris Henn\n[@chnn](https://github.com/chnn)\n\n## Spliting a Statistical Graphic into Parts\n\n* Splitting a problem allows us to change one feature of the graphic at a time\n* Suggests the aspects of a plot that are possible to change\n* Encourages custom visualizations for every data situation\n* Demo: [Scatterplot example](https://github.com/chnn/composing-graphics)\n\t*  Adds multiple regression lines (in example, based on # of cylinders of each car)\n\n    \t```hbs\n    \t{{#each subset as |subset|}}\n          // component\n      \t{{/each}}\n      \t```\n     * Each point in the graph is an svg circle\n\n### Grammer of Graphics by Hadley Wickham\n(Book of guidlines to follow)\n\n* Data to Aesthetic Mappings\n* Scales: one per Asthetic mapping\n\t* Each data to aesthetic mapping has some mapping function\n\t* he has chosen to represent these as points in scatterplot example\n* Layers: geom, stat, optional data to aesthetic mapping\n* Coordinate System\n* Faceting\n\n### What does this look like using Ember?\n\n* Data to Aesthetics = outer layer component which takes in the data as params\n* Scales = computed properties (using computer property macros)\n* Layers = looks like top level component, but must pass the scales\n\n### Further Considerations\n\n* Interactivity\n* Animations and transitions\n\t* performance (updating graphic many times per second)\n\n\n# Test-Driven Development By Example by Toran Billups\n[@toranb](https://github.com/toranbn)\n\nLive coding!!\n\n * Red, green, refactor\n \t* You get a lot of feedback from red (so it can be red, red, red, green, refactor)\n * Incorrect selector in template to make sure you’re doing it correctly (aka. test should fail)\n * Test should not be very layout dependent\n \t* Should be more general and not break whenever you make template changes that do not change app functionality.\n * Test names should be descriptive\n * Testing computed properties is recommended because of how caching works with them. Failing test will let you know which properties should be observed in order to break the cache.\n * Design proof testing\n"},{"title":"EmberConf 2015 Day 2","tags":["ember"],"summary":"Live blog of EmberConf 2015","legacy":false,"id":"2015/03/04/ember-conf","employee":"Marin Abernethy","date":"2015-03-04T00:00:00","body":"\n\n# Fault Tolerant UX by Dan Gebhardt\n[@dgeb](https://github.com/dgeb)\n\n* Users should be shielded from any application issues that are encountered\n\n## Transaction UX\n\n* Atomic: all or nothing\n  * Ex. if a user fills out a form your app should save all the data, not just some.\n* Consistent: move between different states\n* Isolated: allows concurrent changes\n* Durable: changes are persisted\n\n### Apps MUST NOT violate the rules of transactional UX or you are violating the users trust\n\n## Forgiving User Experience\n\n* Fault Tolerant UX --> Forgiving UX\n* Transitional experience: to persist data that has not yet be saved, but in the process of being edited\n* Undo/redo\n* Offline support\n* Asynchronous interface (non-blocking)\n  * user can make changes as quickly as possible (changes can be queued up and synced at your apps convenience)\n\n## Engineering Fault Tolerant UX\n\n* Ember provides simple elgant patterns for building a consistent UX\n* Similarly, ember data provides durable UX\n* Ember data requires customization (extra code) to provide atomic and isolated code\n\n## [Orbit](https://github.com/orbitjs)\n\n### Orbit application patterns\n\n* Client first development\n* Pluggable sources\n* Data synchronization\n* Editing contexts\n* Undo/redo\n\n### [ember-orbit](https://github.com/orbitjs/ember-orbit)\n\n* Provides a store with synchronous and asynchronous methods\n\n\n# Aligning Ember with Web Standards by Matthew Beale\n[@mixonic](https://github.com/mixonic)\n\n## Standards\n\n* The JS standardization process is about to change: ES5, ES6, ES2015!\n* Standards Process\n    * 5 stages - strawman, proposal(polyfills), draft(experimental), candidate(compliant), finished(shipping)\n    * [Polyfill](https://remysharp.com/2010/10/08/what-is-a-polyfill): A polyfill is a piece of code (or plugin) that provides the technology that you expect the browser to provide natively. \n* 2 major standards groups:\n    * WHATWG + W3C (html / dom related)\n    * TC39 + Ecma International (promises, classes, for loops, etc)\n* Aligning with standards is not a one time event. It is ongoing!\n\n## Why Standards?\n\n* The goal is productivity\n* Standards are portable, reflect best preactices, and endure \n* Participants win\n\n### ES5 -> ES2015\n\n * New API for maps\n * Promises\n * Proxies\n\n### Babel\n\n* Babel will turn your ES6+ code into ES5 friendly code\n    * Enables new syntax (fat arrow, let) , APIs (map, set), not everything\n\n### Aligning Ember's Object Model\n\n*  is this feature: stable? a good pattern? implemented correctly? implemented performantly?\n\n### ES Classes\n\n* Three new tools: class, extend, super\n* More gotchas: \n  * setUnknownProperty \n  * Transpiler output\n  * New syntax\n  * Changes in way that super behaves\n  * Mixins\n\nRemember: standards are a two-way street!\n\n[Ember Community Survey](http://www.201-created.com/ember-community-survey-2015)\n\n\n# Growing Ember One Tomster at a Time by Jamie White\n[@jgwhite](https://github.com/jgwhite)\n\nHow did a tech community come to be so vibrant? How can we continue?\n\n## 1. The Tomster\n\n* Representation of productivity and friendliness\n* Tomster wore different hats\n  * Custom tomsters\n* Good defaults\n  * Having a friendly mascot makes things easier.\n  * “Ambition” and “friendliness” is hard to juxtapose\n* Composing concepts\n\n## 2. Language\n\n* Tomster is a tool. Productivity and friendliness implicitly part of conversation\n  * Words stick; the right words enable conversations\n  * “hack” is not a good vocabulary word - negative connotation \n\n## 3. User Interface\n\n* Programming language and documentation with good user interface\n\n## 4. Hackability\n\n* Parts have to be accesible - has to feel hackable.\n  * Tomster was not overly done.\n\n## 5. Roles\n\n* Many specialisms in Ember Community: documenteer, student, mentor, critic, explorer, and many more!\n\n\nCommunity building is a design and engineering challenge\n\n\n# Interaction Design with Ember 2.0 and Polymer by Bryan Langslet\n[@blangslet](https://github.com/blangslet)\n\n* The web browser is the largest app runtime in the world, and will continue to grow\n* Every device has to be connected to the web\n* Web frameworks and toolkits are getting closer to native performance everyday \n\n\"How can I - one person with a laptop - leverage my time as powerfully as I possibly can, every minute I work?\"\n\n## Ember-Flow\n\n* A paradigm shift for web interaction design\n* The goal: to blur the lines between native and web applications\n\n### Web Components\n\n* Extends the browser itself\n  * Polymer components extend a base component\n* Encapsulation\n* Declarative\n* True reusability/portability\n\n## Ember vs. Polymer Use Cases:\n\n* Ember: developer productivity, conventions\n* Ember: community\n* Ember: World-class routing and state management\n* Polymer: constantly pushing the web forward\n\n### Web Animations API\n\n* Has the best of both CSS and javascript animations\n* Web animations run outside of the main thread and can be accelerated on the GPU\n\n### [Treasure Hunt Demo Application](https://github.com/blangslet/treasure-hunt)\n\n* \"Demonstrates an experimental integration between ember.js routing and Polymer's core-animated-pages component to create beautiful inter-state animated transitions\"\n\n\n# Building Applications for Custom Environments with Ember CLI by Brittany Storoz\n[@brittanystoroz](https://github.com/brittanystoroz)\n\n### Ember CLI\n\n* Everyones favorite command line tool\n* Build organized ember apps quickly\n* Fills huge void in toolset for JS devs\n\n### Ember CLI Addons\n\n* Extend ember-cli beyond core fucntionality\n* Follow standard npm conventions\n* Easy to create & install:\n\n`ember addon name-of-your-addon`\n\n`ember install:addon name-of-your-addon`\n\n## Firefox OS\n\n* Requirements that Ember CLI could not provide\n    1. Generate and validate a manifest file (same concept as package.json)\n    2. UI components that mimic OS interface\n    3. Publish to Firefox marketplace\n* Ember CLI Addon was born to fill those requirements.\n\n### 1st Requirement: Generating The Manifest\n\n* Creating Blueprints\n  * rules for generating common code and file structures:\n\n`ember generate blueprint name-of-blueprint`\n\n### 2nd Requirement: FirefoxOS UI ([Gaia](https://github.com/gaia-components/gaia-tabs))\n\n* Building components\n`bower install gaia-components/gaia-stubs`\n* 2 responsibilities:\n  * including dependencies and creating the addon\n  * making both available to the consuming application\n\n## Components Review\n\n* Dependencies:\n  * bower install within addon\n  * bower install withing consuming logic\n* Component logic\n  * create component\n  * export components to consuming aplication\n  * define component template\n* Validation & Publishing\n  * creating commands for control over when these things happen\n  * `includedCommands` hook: returns object of commands which are found inside `lb/commands`\n  * `ember help` lists out information about available add-on commands. And lots more useful info.\n\n\n# Building Real-time Applications with Ember by Steve Kinney\n[@stevekinney](https://github.com/stevekinney)\n\n* Integrating browser functionality and third party code into our applications. In this case, WebSockets.\n* What is a WebSocket Used for? \n  * Collaboration, analytics dashboards, prompting user to upgrade application\n* Can I actually use WebSockets? \n  * For the most part, yes (some earlier version of IE not supported)\n* Socket.io -> library for Node\n* Faye  -> simple pub/sub messaging\n\n### Approach #1: Use Standalone Controller\n\n* Somewhat limited because it only works between controllers\n\n### Approach #2: Dependency Injection with Services\n\n* `ember generate service websocket`\n* Declare where you want to inject it inside the Initializer\n* Inside controller: `websocket: Ember.inject.service()`\n\n### Approach #3 Using Socket.io\n\n  * Socket.io is both a server and client side library\n\n[What is your favorite thing about JavaScript?](bit.ly/js-poll)\n\n\n# Minitalks!\n\n## 1. Measuring Performance with User Timing API by Bill Heaton\n[@pixelhandler](https://github.com/pixelhandler)\n\n* Measuring the differences in template rendering speeds between Ember.js v1.8.1 w/Handlebars v1.3 and Ember.js v1.10.0 w/HTMLBars\n* Check out his findings on [blog!](http://pixelhandler.com/posts/measuring-performance-with-user-timing-api-in-an-ember-application)\n\n## 2. `ember-islands` by Mitch Lloyd \n[@mitchlloyd](https://github.com/mitchlloyd)\n\n* [`ember-islands`](https://github.com/mitchlloyd/ember-islands)\n* Render Ember components UJS-style to achieve \"Islands of Richness\". You can arbitrarily render Ember components in the body of the page and they will all be connected to the same Ember app.\n\n## 3. Ember Testing with Chemistry Dog by Liz Bailey \n[@lizzerdrix](https://github.com/lizzerdrix)\n\n* Migration from Rails to Ember\n* Ember does not provide as much documentation on testing\n* Would love to help make Ember more approachable to beginners\n\n## 4. Running C++ in ember-cli with Emscripten by Michael Nutt\n[@mnutt](https://github.com/mnutt)\n\n * [`ember-cli-emscripten`](https://github.com/movableink/ember-cli-emscripten)\n * Allows you to add C or C++ to your ember app, then require the exposed functions and classes.\n * Fibonacci sequence demo!\n\n## 5. Ember Observer by Kate Gengler\n[@kategengler](https://github.com/kategengler)\n\n* [Ember Observer](https://github.com/emberobserver/client)\n* Gives addons a score out of 10\n* pulls hourly from npm and Github\n\n## 6. CSS is Hard by Erik Bryn\n[@ebryn](https://github.com/ebryn)\n\n* [`ember-component-css`](https://github.com/ebryn/ember-component-css)\n* namespaces our component styles automatically!\n\n\n# Physical Design by Edward Faulkner\n[@ef4](https://github.com/ef4)\n\n* Computers are so abstract. Possibilities are endless, only hindered by your imagination.\n* Constrained by physics\n* Googles material design spec\n  * does not break rules of physics\n  * animations and motion appeal to us because they fit into our idea of how it should physically work.\n* [Liquid Fire](https://github.com/ef4/liquid-fire) live demo!\n  *  `npm install —save-dev liquid-fire` for Ember 1.11+\n* [Ember Paper](http://miguelcobain.github.io/ember-paper)\n\n\n# Closing Keynote: Chris Eppstein\n[@chriseppstein](https://github.com/chriseppstein)\n\n## Announcing: Eyeglass\n\n* Distribute SASS extensions as NPM modules for [LIBSASS](https://github.com/sass/libsass)\n* Will be able to integrate with a number of different build systems, including Ember CLI\n* Major performance improvements\n* The best parts of SASS and Compass, working with the best tools JS has to offer\n\n## A Selection of Chris' Inspirational Messages\n\n* \"Don't be a Sasshole\"\n* \"People come to a community for the tech, but stay for the love!\"\n* \"Sass didn't lose when I started ignoring the haters\"\n* \"If you use a framework you love, you'll never work a day in your life\"\n* \"Secret to a vibrant community: be excellent to eachother\"\n"},{"title":"DockYard is now accepting staff augmentation Ember.js contracts","tags":["javascript","ember"],"summary":null,"legacy":false,"id":"2015/03/09/dockyard-is-now-accepting-staff-augmentation-ember-js-contracts","employee":"Brian Cardarella","date":"2015-03-09T00:00:00","body":"\n\nOver the past three years DockYard has primarily taken on \"greenfield\"\nprojects, where we are responsible for building applications from\nscratch through design, development, and launch. Starting today we're\nadding Ember.js Staff Augmentation to the services we provide to our\nclients.\n\nIf you are looking to add an Ember.js expert to help your team you\nshould contact us. Our entire engineering team is extremely experienced\nin Ember.js application development, Ember.js best practices, and Ember.js Test Driven\nDevelopment. We can help your team finish existing features, guide\nyour team on how to properly build an Ember.js application, and help you\nhit your delivery deadline.\n\n<a href=\"https://dockyard.com/contact\">Visit our contact page and choose\n\"Staff Augmentation\" for the Budget</a>\n"},{"title":"Ask good questions","tags":["design","observations","quality","workflow"],"summary":"The only way to get real answers in user interviews for UX design","legacy":false,"id":"2015/03/11/ask-good-questions","employee":"Maria Matveeva","date":"2015-03-11T00:00:00","body":"\n\nIn an [earlier post](http://reefpoints.dockyard.com/2015/02/11/managing-the-conversation.html), I focused on the challenges of leading a good user interview. Today, I’d like to focus on one rule about asking questions to get reliable results.\n\n##Ask open-ended questions.\nOtherwise, the responses you get will be either biased or useless. \n\n##Let's look at some interview questions (from worst to best)\n\nThey appear in order: from least useful to most useful in getting you good responses. For context, imagine you’re doing some user research and you're in the middle of a project to design some widgets.\n\n - **“You like this widget in green, right? We picked green because it’s calming.”**\nThis question is so bad it's grotesque, but it may still happen to novice interviewers. Not only does the question suggest a specific answer (you like it!), but it also gives reasons why that answer might be the right one (green is calming!) The interviewee is not likely to share a genuine opinion with this much pressure to say “yes, I love it in green!”.\n\n - **“How do you feel about this widget? Do you like its color?”** Slightly better, but still of limited use. By suggesting a response and allowing the user to narrow it down to a binary yes/no, we’re getting a very limited amount of information back. In addition, likes and dislikes move the conversation into a potentially awkward area. Some people may not be comfortable telling you they don’t like something you made.\n\n - **“How do you feel about this widget? What do you think it does?”** Now, this is better. We are opening up to qualitative responses with lots of detail. By not suggesting options for what an answer might be, we are more likely to get unexpected, valuable results.\n\n - **“Talk me through what you see here.”** A super open-ended question, useful in the beginning of an interview. Do they even see the widget?\n\n - **“How would you normally approach (widget-related task)?”** This seems to be the best opening question for a user interview. While not appropriate for all circumstances, it is great at opening up areas you may not have considered to be in the scope of the project. This question can help reframe the problem you are working to solve.\n\n - **“How did you last (widget-related task)?”** Past behavior is a more reliable indicator than a behavior people might describe as their normal. So, this re-phrasing can encourage more honest answers. \n\nYou may notice that it takes more  time to ask open-ended questions. You may trigger your interviewee to share a lot of extra information, not just a concise answer to the question you asked. You may have to follow up with more questions to get to the “why” behind a certain behavior. But with the increased effort comes a better result. The responses are real. They are not influenced by your opinion about the thing you’re asking, because you’ve kept that opinion outside the questions. These responses present a more nuanced picture of your users’ needs and environment.\n\nI condensed this principle from conference talks, books and workshops I attended over the past few years. Two sources in particular: \n\n - [Michelle Yaiser's](https://twitter.com/michelleyaiser) talk on user research at [UX Camp](http://uxeast.org/)\n\n - [Sound reporting : the NPR guide to audio journalism and production](http://shop.npr.org/sound-reporting). This book is outside of the usual UX Design reading list, but it's useful for interviewing skills. It shows how much  effort and consideration it takes a journalist to gather information in a neutral, ethical way.\n\nIt's almost always a better investment of your time to conduct a few in-depth, “difficult” and neutral interviews, than to rush many interviewees through surface-level questions. This is especially true at the beginning of a project, when more design options are open. Your effort to keep the process unbiased will yield quality results, and quality wins.\n"},{"title":"Thriving in a New Work Environment","tags":["opinion","job","team"],"summary":"Learn how to go beyond expectations at your new job","legacy":false,"id":"2015/03/16/thriving-in-a-new-work-environment","employee":"Cory Tanner","date":"2015-03-16T00:00:00","body":"\n\n## My Background\nIf you asked me a month and a half ago when I was living and working near Philadelphia as a Director of digital communications, “Cory what are the chances that you will be in Boston working for a new company?”. I would have said you were crazy and I couldn’t see myself leaving the Philly area unless a company blew me away with their culture and work environment. How would I watch my Sixers, Eagles, and Phillies games if I left the Philly area?\n\nThen in a week and a half frenzy I was moving up to Boston after it had just snowed another two feet in Boston. A day after that I had moved in to my new apartment and it was my first day at DockYard as a Junior UX Developer!\n\nFast forward a week and I had met 16 new DockYard co-workers (who, yes, are crazy smart) and was introduced to a new coding/project management environment. I was then challeneged to learn how to  structure my SCSS with the\n[BEM]\n(https://github.com/dockyard/styleguides/blob/master/uxd/class-naming-conventions.md)\nclass naming conventions and rules for Scalable and Modular Architecture for CSS\n([SMACSS]\n(https://github.com/dockyard/styleguides/blob/master/uxd/beginning-a-project.md)), all of this  was a tidal wave of new information and personally a different way of thinking.\n\n## It’s Not All About You\nI would love to say that the sole reason that I’ve been able to handle all the new information is that I am purely that awesome. But in reality I could not have gotten through any of this without the work environment DockYard has implemented.\n\n[Estelle]\n(http://reefpoints.dockyard.com/2015/01/16/joining-dockyard.html) and\n[Marin]\n(http://reefpoints.dockyard.com/office/2013/07/09/first-month-at-dockyard.html) explain how “Wicked Good” the DockYard team is and do so better than I can, but from my experience after a month of working here it is clear that everyone wants to help each other (new guy included). If you need help and you’re not approaching other team members with questions, you might find yourself out of place.\n\nThis type of atmosphere is exactly what you need for soaking in all the information you receive at a new job. You will always have questions and uncertainties in a new environment like:\n\n* Am I meeting their expectations\n* Am I messing this up\n* Will I look stupid if I ask this question\n* What will they think if...\n\nIt is inevitable to have these questions when you are in a new work place and you should have them, don't be afraid to solve those concerns by asking productive questions! The new company you just joined would rather be asked a stupid question then see you running in circles not willing to interact with the team.\n\nI have asked many questions in my first month here and not once has someone:\n\n* Said no\n* Told me there was no point to my question\n* Looked down on me for not knowing something\n\nThat is a testament to DockYard but also should be how any team should be run, especially web development teams.\n\n## Success Is Ultimately Decided By You\nNow it’s not all up to the team you are joining to make you successful, you have to be willing to do the following:\n\n* Put time into reading about things you did not understand\n* Research tools/techniques that you see yourself using in the future\n* Be open minded with new development techniques and a new project management process\n\nIf you are successful with goals/projects your boss gives you, then you are meeting your employers standards. In the web development line of work in order to thrive in an environment you should be going above what is expected of you.\n\nWhen coworkers look at your work they should be impressed and surprised with:\n\n* The product you are presenting\n* How quick and thorough you are when learning new things\n* Contributions you make to current projects\n\nWhen you are getting those type of reactions to the list above you are thriving in the new work environment.\n\n**\"Thriving in a new work environment comes from working harder and more efficiently than expected\"**\n\nBe willing to be one of the first people at the office and leave later than most, you want to soak in as much information as you can. When you are given new things to learn tackle them immediately.\n\nDuring all the chaos of starting a new job stay organized and keep notes of things you are learning, you will probably not remember that Git command after one or two uses.\n\nIf you find yourself in a new work environment and feel overwhelmed just remember to ask as many questions as you can and work hard to understand the solutions your team provides you.\n"},{"title":"The Doldrums of Consulting","tags":["business","opinion"],"summary":null,"legacy":false,"illustration_alt":"http://i.imgur.com/X6DGygm.jpg","illustration":"http://i.imgur.com/X6DGygm.jpg","id":"2015/03/18/the-doldrums-of-consulting","employee":"Brian Cardarella","date":"2015-03-18T00:00:00","body":"\n\n![http://i.imgur.com/X6DGygm.jpg](http://i.imgur.com/X6DGygm.jpg)\n\n*The Doldrums* is a sailing term. It means when you're stuck on the\nwater with no wind. Your only option is to wait for the wind to pick up\nso you can continue on your way.\n\nDockYard is currently in the doldrums.\n\nMaybe this isn't something that a consultancy should publicly admit,\nbut we've seen client engagement significantly dry up for us in the past\nmonth and a half. Where we were selling and turning clients away a few\nmonths ago, we are struggling to close a single deal right now. This is\nthe ebb and flow of consulting, it happens. Our only option is to wait\nfor the wind to pick up so we can continue on our way.\n\nI was speaking with a few other software (Ember) consultancies recently\nand they voiced similar stories. I am not certain why Ember has seen\nsuch a steep drop off in interest. One theory is that Ember is currently\nin the *Trough of Sorrow*\n\n![http://i.imgur.com/hkzpuBa.png](http://i.imgur.com/hkzpuBa.png)\n\nDoes a framework follow similar trends to a startup? Perhaps. In any\nevent, we're now trying to diversify our offerings. I announced last\nweek that DockYard is now offering Staff Augmentation services. This has\npiqued some interest but we're seeing a lot of inquiries for starting a\nfew months from now.\n\nIt is funny because I know in a month or two we'll be fine. We just have\nto survive the thin times, which is always stressful. How we weather\nthis will speak a lot about DockYard as a company. It is said the only\nway to survive the *Trough of Sorrow* is going to be company culture. If\nthis is true then I'm quite confident in us.\n\nI also realize that we're towards the end of a financial quarter.\nCompanies tend to reach out after the start of a quarter, but if I were\nthem I wouldn't wait. If companies were to [contact\nus](https://dockyard.com/contact) now they would find us in a position that\nwould be easy to negotiate with.\n\nI'd be interested in hearing from other shops: have you experienced The\nDoldrums? What pulled you through? What strategies have you put in place\nto avoid them in the future?\n"},{"title":"The Lean Project","tags":["project management","lean","agile"],"summary":"The right recipe of team, process, communication, work environment and pride","legacy":false,"id":"2015/03/19/lean-project-management","employee":"Jon Lacks","date":"2015-03-19T00:00:00","body":"\n\nI am a firm believer in Lean processes aimed to maximize value while minimizing waste. When it comes to running projects in a Lean way, this goes far beyond the role of the Project Manager (or Scrum-master) thus requiring the right recipe of team, process, communication, work environment and pride. Often I am asked what are the typical practices I apply to projects which fall in the mobile/desktop application development context- this is my attempt to answer the question.  **Important disclaimer** - this is not a prescription for how to run a project, nor does it guarantee success. The secret sauce is always the people NOT the process.\n\n## The Raw Materials\n\n If any of these seem unreasonable, you need to take a hard look at your team and work environment. Any concessions made here will reduce team effectiveness.\n\n* A team well-balanced in terms of seniority - Experience is contagious!\n* Dedicated team members - not split across multiple projects\n* Co-located team members\n* Smaller teams (no more than 5-7) — Once you breach this team size communication complexity increases exponentially.\n* Conduct retrospectives with full participation - Always seek to get better\n* A knowledge management strategy ensures team members know where to store/post directional artifacts that other team members require to do their job (e.g. Wireframes, PSDs, Test Cases, Context Diagrams )\n* Use of Information Radiators — Physical views into plans (e.g. Post-Its on a whiteboards) that may supplement a digital plan view\n\n## 1) Breakdown the work\n\nDecomposition of capabilities/features is a necessary and somewhat painful evil. However, you do not need to go to a painful level of detail to create this artifact. The importance is breadth not necessarily depth. The depth only needs to go as far as necessary for the team to directionally understand where a feature needs to go. If a team member is able to provide some form of time estimate (best and worst case) for one of those lower level items, you're low level enough. If estimates are coming out to less than 1 day you have likely gone too far. Get the full team involved, apply the 80/20 rule in terms of completeness and time-box the activity.\n\n## 2) Define a Path\n\nOnce you have step 1 in place, work with the team to derive a chronological execution of the work driven by perceived value and/or risk/complexity of a given feature. Front loading your risk/complexity (as long as it is somewhat high value) is a very acceptable and smart approach because impact of course correction early on is much less invasive than the alternative. Ensure a basic architecture for the overall solution is derived and communicated. This ensures that the team has a solid foundation to build upon.\n\n## 3) Respect the [Pyramid of constraint](http://en.wikipedia.org/wiki/Project_management_triangle)\n\nScope, Time and Cost — Fundamental variables applicable to any project context. Visibility and active monitoring of these variables is essential to ensure project success. First and foremost, ensure that a baseline is established for each of these variables before a team even start the project. Understand how your stakeholders rate the relative importance of each of these variables and uphold the \"Rule\" that trade-offs are the only way these baselines can/will adjust. Deferring this activity to after a project gets going can result in scope creep and cost/time over runs.\n\n## 4) Hold up the mirror\n\nAs a PM, it’s your responsibility to hold up a mirror in front of your team that shows the good, the bad, and the ugly.  This allows the team to maintain appreciation for the big picture while they do their best to work through the small one.   I am huge advocate of a plan view that I have written about in the past ([High and Mid-Level Plans](http://reefpoints.dockyard.com/2014/07/29/project-carpe-diem.html)) — which shows time, features, tasks, distribution of work across team capability areas (Design, Backend, UXD, etc.), progress made, unplanned work and deferred work that will come in later releases.  If you have this and revisit it often, consider your team informed and that those Triangle of Constraint variables are being monitored (for the most part.)\n\n## 5) Create an environment of ownership and accountability\n\nEveryone is a player. PM’s should be servant leaders, therefore any plan created needs to be the team's plan not the PM’s (or Sr. Mgmt.)  This way the team has accountability and ownership rights over whatever happens to the plan. If something is not going as planned the team can understand the implications of this and course correct and work to reveal why something may not be working out. Constant readjustment and calibration is required to keep things moving along. The project manager helps ensure these conversations happen.\n\nNo team member can slip into the shadows. To be successful every contributor needs to have a voice. A PM needs to put their “Facilitation” hats on and ensure they proactively encourage all to participate and chime in on team affairs. That’s the beauty of teams. They succeed together, not as individuals.\n\n## 6) Demonstrate Progress\n\nDemos encourage quality, because no one wants to demo something that works and looks subpar. Stakeholders  can rest assured they did not buy snake oil and value is being delivered in some regular interval. Demonstrations affirm you're heading in the right direction.  Last but not least, demos allow the team to celebrate success in short bursts - It feels great to get something done especially when the road ahead is a long one!\n\nGive it a go and let me know if this works for your team.\n"},{"title":"Tips for writing Ember Addons","tags":["ember","javascript"],"summary":null,"legacy":false,"id":"2015/03/22/tips-for-writing-ember-addons","employee":"Brian Cardarella","date":"2015-03-22T00:00:00","body":"\n\nAfter having published many Ember addons I have started to develop my\nown sense of \"Best Practices\" and I'd like to share those with you:\n\n## 1. Keep it minimal, don't include stylesheets\n\nI see quite a few addons out there that include their own look & feel by\nincluding sytlesheets. I actually think this is a bad idea. *Keep in\nmind, every line of code you put into your addon will end up in the\nfinal footprint of the apps consuming it*. This means if you are\nincluding stylesheets those will end up in `vendor.css`. The odds are\nthat whatever styles you decide look good, someone else might not.\nThey'll waste even more space by including their own overrides. This is\nwasteful.\n\nInstead, you should *keep it minimal*. See\n[ember-admin](https://github.com/dockyard/ember-admin). I intentionally\ndid not style the addon so it is left as minimal as possible. If you\nwant to show off a styled version of the addon, you can either include\nstyles in the dummy app's styles for the addon's test dummy. Allow\npeople to run the addon's server locally and view what could be. Or, you\ncan include an addon wrapper library that depends upon your addon. This\nwrapper can include default styles that consumers may choose not to\nalter. For example,\n[ember-admin-bootstrap](https://github.com/dockyard/ember-admin-bootstrap)\nstyles ember-admin with Twitter Bootstrap. If this is good enough for\nyou then you just install this library and it pulls in ember-admin but\ngives you some nice styling that you don't have to spend time doing.\n\n## 2. Allow for overrides\n\nI believe strongly in composable addons. A consumer should have the\nability to easily extend your addon to do whatever they want. This means\norganizing your code a certain way. To provide this you should put all\nof your business logic into `addon/` and then include wrapper classes in\n`app/` that just `import` then `export` the extended class. For example:\n\n```javascript\n// addon/components/foo-bar.js\nimport Ember from 'ember';\nexport default Ember.Component.extend({\n  // business logic\n});\n\n// app/components/foo-bar.js\nimport FooBar from 'my-addon/components/foo-bar';\nexport default FooBar;\n```\n\nThese light wrapper classes **should not** include any business logic.\nAgain, they simply `import` then `export` the extended class. This gives\nconsumers the option of overriding this in their own\n`app/components/foo-bar.js` file to extend and add customization.\n\n## 3. Turn off Prototype Extensions\n\nCurrently ember-cli will not generate an addon project with Prototype\nExtensions turn off. However, [I have requested this be the\ndefault](https://github.com/ember-cli/ember-cli/issues/3443). Turning\noff Prototype Extensions will cause the following syntax to fail in\nyour addon's test suite:\n\n```javascript\nfoo: function() {\n  // whatever\n}.property('bar')\n```\n\nThere are several syntax shortcuts that Ember injects into the base\nTypes. Arrays have quite a bit. Turning off Prototype Extensions will\nforce you to write the above code as:\n\n```javascript\nfoo: Ember.computed('bar', function() {\n  // whatever\n})\n```\n\nAnd this will play nice with consumer applications that must run with\nthe Prototype Extensions turned off.\n\n[It should be noted that Ember 1.10 has a bug where turning off Prototype\nExtensions causes Ember itself to\nfail](https://github.com/emberjs/ember.js/issues/10590). This should be\nfixed in 1.11 (**Update: This has been addressed in [Ember](https://github.com/emberjs/ember.js/pull/10697).**).\n\nAvoiding Prototype Extensions can be difficult. I plan on writing a\nfuture blog post to outline certain strategies to duplicate the behavior\nthat you miss out on without Prototype Extensions.\n\nTo turn off Prototype Extensions you'll need to install the `ember-disable-prototype-extensions`:\n\n```\nnpm install --save-dev ember-disable-prototype-extensions\n```\n\nSee\n[ember-validations](https://github.com/dockyard/ember-validations/pull/270)\nfor an example.\n\n## 4. Test your addon\n\nThis one should go without saying but I have seen *way* too many addons\nout there that are untested (the generated tests don't count). Please\nkeep in mind that there are people building products that might consume\nyour work. Untested code is just one more thing that could go wrong in\nsomeone's app. If unit testing the code is too difficult, at the very\nleast write integration tests against the dummy application to ensure\nthe happy paths.\n\n## 5. Depend on other addons\n\nYou may not know this but addons can depend upon addons. Rather than\nrecreating behavior per-addon it would be best to extract out common\nbehavior to its own dependency. For example,\n[ember-data-route](https://github.com/dockyard/ember-data-route) and\n[ember-cli-async-button](https://github.com/dockyard/ember-cli-async-button)\nare both being used in\n[ember-admin](https://github.com/dockyard/ember-admin/blob/master/package.json#L21-L23).\n\nTo use an addon as a dependency it *must* be put into the `dependencies`\nobject in `package.json`, **not** `devDependencies`. You may need to\nadd this keyword to your `package.json` as it is not part of the\nauto-generated file.\n\nEmber's addon eco-system is getting better every day, and as a community\nwe are learning as we grow how best to build and maintain addons. I'm\nhoping you find these tips helpful. Please feel free to share your own\nin the comments below. \n"},{"title":"Beginner’s mentality","tags":["design","observations"],"summary":"A fresh perspective can help an expert find and address their blind spots.","legacy":false,"illustration_alt":"An old map showing a campus as an island surrounded by unknown waters","illustration":"http://imgur.com/Aulbb3t.jpg","id":"2015/03/23/beginner-mentality","employee":"Maria Matveeva","date":"2015-03-23T00:00:00","body":"\n\nMany people consider us UX or Web experts, and experts are clearly the best people for the job. But we know we have a significant blind spot - our extensive knowledge of the system makes us less likely to see the potential problems a novice might encounter. Anyone who is very familiar with a system, a discipline, or a product has put some distance between them and their beginning level challenges that cause them to develop an [expert blind spot](http://c4ed.lib.kmutt.ac.th/sites/default/files/HowLearningWorks-Ambrose.pdf).\n\nI am sure you are familiar with this situation: you’re invited (or invite yourself) to an event at a university campus. You arrive a bit earlier than you needed, so you can orient yourself in the unfamiliar space. The map on your phone is only accurate to the nearest block, so you get a campus map and try to find room 41-B in the Humanities building named after someone important. You feel stupid.\n\nThis is what campus maps often look like:\n![An old map showing a campus as an island surrounded by unknown waters](http://imgur.com/Aulbb3t.jpg)\n\nThe reason most outsiders find campus maps confusing and difficult to use is the shift in the frame of reference.\n\nFor someone who lives or works on campus, the frame of reference is relative to the borders and shape of the universe that is the university (or corporate, or hospital) campus. They might consider their office to be “in the far North corner” relative to the outline of the campus on a map. Or, they might think of themselves as “right in the middle of the Art Department”. The Art Department here is amorphous: it’s something that may either span two city blocks, or half of a floor in a physical building.\n\nFor an outsider, the frame of reference is still the surrounding landscape. They may not know precisely when they entered the school campus (there is no painted border on the ground) or that they are in its top left corner. The “you are here” marker on the campus map helps, but it still takes a while to adjust to the landmarks differentiated by department, not by road or city block. To find a building, they are forced to adapt to a new system of coordinates.\n\n\n## Work with an outsider\n\nI often see this situation reflected in the websites of large institutions. When someone very close to an institution thinks of how their web presence may be organized or used, they inevitably do so with the influence of all the expertise they have. They can’t help it - they “live” inside the campus, and they are good at what they do.\n\nThere are many examples of this kind of insider thinking: organizing content by internal structure (instead of user need), breaking up a university website into Athletics, Academics, and Arts (which one contains the event I want to attend?) or assuming that a typical user has even a basic understanding of specialized terminology and concepts.\n\nThis is by no means a treaty against specialized knowledge and perspective. The insider knowledge of an industry expert makes a product good, their know-how makes it work. But the outside perspective of a novice-expert truly helps make a product findable and usable.\n\nTo attract new customers or visitors, a product needs to make sense to someone unfamiliar with it in their own broader frame of reference. To ask the right questions, to establish user goals and needs, and to judge the effectiveness and clarity of a product, we need both the insider and the outsider perspective.\n"},{"title":"Rubyists Guide to Ember.js Dependencies","tags":["ruby","ember"],"summary":"A dependency management primer for Rubysist living in a Gemfile-less, Ember.js world.","legacy":false,"id":"2015/03/24/rubyists-guide-to-ember-dependencies","employee":"Michael Dupuis","date":"2015-03-24T00:00:00","body":"\n\nAt DockYard, we have a lot of Ruby on Rails experts who have adopted Ember on the frontend. One of the early hurdles a Ruby developer faces when working on an Ember.js application is dependency management. A popular mechanism for managing a Ruby application’s dependencies is the [Gemfile](http://bundler.io/gemfile.html) provided by [Bundler](http://bundler.io/ ). Including a library is as easy as declaring it in the Gemfile and running `bundle install`:\n\n```ruby\n# Gemfile\nsource 'https://rubygems.org'\ngem 'rails', '~> 4.2.0'\n```\n\nFor better or worse, there is no dominant, single package manager in JavaScript. Ember applications, and more specifically, those running [Ember-CLI](http://www.ember-cli.com/), rely on two package managers: [Bower](http://bower.io/) for client-side libraries and [npm](https://www.npmjs.com/) for server-side libraries.\n\nIn this post, I'll provide a basic dependency management primer for\nthose moving from Ruby to JavaScript.\n\n## npm\nEmber-CLI uses npm to manage internal dependencies. npm resembles RubyGems, in so far as it allows you to install and manage third-party libraries, which in this case, are Node.js programs.\n\n### package.json\nLibraries for npm are referred to as “packages.” Each package has a `package.json` file which lists the dependencies of the library itself. In this regard, the `package.json` is analogous to a RubyGem’s `gemspec` file.\n\n### .npmrc\nYou can configure how node packages get installed via the\n[.npmrc file](https://docs.npmjs.com/files/npmrc). You may have one\nglobally, per user (`~/.npmrc`), or per project.\n\n### Installing dependencies\nTo install an npm package, run `npm install [package-name]` from the\ncommand line.\n\nThis will either install the library and it's dependencies\ninto your current working directory or in one of its parent directories. Here's how it works: if there is a `node_modules/` or `package.json` in any directory above the current working directory, packages will be installed into that directory. Otherwise, calling `npm install [package-name]` creates a `node_modules/` directory in your current working directory and installs the packages there.\n\nThis is a slightly different mental model for Rubyists who are not used to installing gems on a per project basis; gems are generally installed into version-specific Ruby directories with the more popular version managers like [rbenv](https://github.com/sstephenson/rbenv) or [RVM](https://rvm.io/).\n\nIt’s also possible to install packages globally using the `--global` flag when installing. This installs the package in your `usr/local/lib/` directory by default. These packages typically contain executable files and are used via the command line (such as Ember-CLI).\n\nYour dependencies will likely have dependencies. These get installed within a `node_modules/` directory in the given package. It's a little strange the first time you navigate into a `node_modules/package-name/` only to find another `node_modules/` directory, but that's what that is. You’ll notice a `node_modules/` directory for dependencies of global packages as well if you look in the `usr/local/lib/` directory where global packages live.\n\nOne last thing to note regarding npm installations: npm caches the\nlibraries you pull down to prevent you from having to download\nlibraries that are already on your system. You'll find that cache:\n`~/.npm/`.\n\n## Bower\nWhile you'll use npm to manage your server-side Node.js dependencies, you’ll use Bower for managing front-end assets, such as JavaScript, HTML, CSS, image, and font files.\n\n### .bowerrc\nBower itself is an npm package. Its libraries are referred to as “components” and the end user can configure their installations via a `.bowerrc` file. This file specifies where dependent components will be installed, the URL where the component will be registered (its registry), and the JSON file used to define the component (`bower.json` by default) among other things.\n\n### bower.json\nThe [`bower.json`](http://bower.io/docs/creating-packages/#bowerjson) file resembles the [gemspec](http://guides.rubygems.org/specification-reference/) file you find in Ruby gems. It contains the library metadata, such as the name, version, dependencies, and development dependencies for the library.\n\nAs we mentioned, components can be searched for via registries. The registry matches the name of a component with the endpoint at which it’s hosted. [Bower.io/search](http://bower.io/search/) closely resembles [rubygems.org](https://rubygems.org/gems) in this way.\n\n### Installing dependencies\nWhen you install a Bower component via `bower install [component_name]`, the repository will be cached locally to expedite any future installations of the component. In case you’re curious, the bower cache location is: `~/.cache/bower/`.\n\nUnlike npm, Bower components are installed \"flat\" as opposed to in a hierarchical manner; all of your project's components (and their dependencies) will be installed into `bower_components/` directory, by default. For example, if one of your components is dependent on the `underscore.js` library, both will sit side-by-side in the `bower_components/` directory (remember, with npm, dependencies of dependencies are continually nested in their parent's directory within a `node_modules/` directory).\n\n## Conclusion\nHere's a quick wrap-up of the analogous files between Ruby and the JS\npackage managers we discussed:\n\n| Description  | Ruby | JS (npm, server-side) | JS (Bower, client-side) |\n| ---- | ---- | ---- | ---- |\n| Term for external library | \"Gem\" | \"Package\" | \"Component\" |\n| End-user configuration file | `.gemrc` | `.npmrc` | `.bowerrc` |\n| Per-library configuration file | `*.gemspec` | `package.json` | `bower.json` |\n| Cache directory | `~/.gem/` | `~/.npm/` | `~/.cache/bower/` |\n\nAs ES2015 (formerly known as \"ES6\") becomes more prevalent and JavaScript code becomes more\nmodular and better for passing around, dependency management grows in\nimportance. Hopefully this quick primer will clear up some\nconfusion Rubysists have as they transition from working with the\nGemfile to working with the package managers JavaScript offers.\n"},{"title":"Testing when your frontend and backend are separated","tags":["ember","testing"],"summary":"How can you run full integration tests when using separate repos?","legacy":false,"id":"2015/03/25/testing-when-your-frontend-and-backend-are-separated","employee":"Dan McClain","date":"2015-03-25T00:00:00","body":"\n\nThe last project I worked on was an Ember app that had a Rails backend that was\ndeployed on Heroku. We had this application as a single repository, where there\nwere two folders at the root, `frontend` and `backend`. This was somewhat easy\nto test on Travis-CI; it would check out the one repository, run the Rails\ntests, start the Rails server, then run the ember tests that hit the Rails\nserver. This ended up being a pain to deploy, as when you changed the Rails app,\nyou were going to redeploy the Ember app, and vice-versa.  It also presented an\nissue when deploying to Heroku, as [we had to utilize `git subtree` to push\nthe backend](https://www.youtube.com/watch?v=ceFNLdswFxs&t=4103), which\ncontained the production assets.\n\nWith the latest project I started, I'm keeping the backend and the Ember app\nseparate.  Since the apps are separate, they can be deployed independant of\neach other. This made it a little bit harder to run integration tests against\nthe backend.\n\n**Side note:** while you can mock/stub your API in your Ember tests, it is\nimportant to run integration tests against your backend regularly. When you\nmock your API, it ends up giving you this false sense of security when it comes\nto your Ember app being compatible. Your models may line up perfectly with your\nmocks, but your mocks can fall out of date. To prevent this, at least when\nrunning on your continuous integration (CI) server, you should have your Ember\napp hit the backend server.\n\nTo run end-to-end integration tests on Travis-CI, I added tasks to the\n`.travis.yml` file to clone the backend repository, install dependencies, and\nrun the server:\n\n```yml\nlanguage: node_js\nnode_js:\n  - \"0.12\"\n\nsudo: false\ncache:\n  directories:\n    - node_modules\n    - backend\n    - vendor/bundle\n\nbefore_install:\n  - npm config set spin false\n  - npm install -g npm@^2\n  # Select the RVM version\n  - rvm use 2.2.1 --install --binary --fuzzy\n  # Clone the repository if isn't cloned\n  - \"[ -d backend/.git ] || git clone git@github.com:<backend-repo> backend\"\n  - \"cd backend\"\n  # Reset the repo so we can have a conflict-less pull\n  - \"git reset --hard\"\n  - \"git clean -f\"\n  - \"git pull\"\n  # Install dependencies\n  - \"bundle install --path=../vendor/bundle --jobs=3 --retry=3 --deployment\"\n  # Run the server\n  - \"RAILS_ENV=test ./bin/rails s &\"\n  # Wait for the Rails app to start\n  - \"sleep 5\"\n  - \"cd ..\"\n\ninstall:\n  - npm install -g bower\n  - npm install\n  - bower install\n\nscript:\n  - npm test\n```\n\nNote that I cached both the backend and bundle directories to speed up the time\nit takes to get the backend running. Since the backend is cached, we only have\nto pull the new code.\n\nIn this example, we have a Rails app with no database, but it would be pretty\neasy to add one. The only other required step was to add an SSH private key to\nthe Travis settings, since you would have two separate deploy keys. That would\nprevent you from cloning the backend repository from the frontend test.  There\nshould be nothing holding you back from performing end to end tests when you\nhave separate repositories!\n"},{"title":"Bringing Ember to the Desktop with NW.js","tags":["ember"],"summary":null,"legacy":false,"illustration_alt":"screenshot","illustration":"https://cloud.githubusercontent.com/assets/1691398/6768192/536a6fde-d033-11e4-9375-e2f506c1c8c7.png","id":"2015/03/26/bringing-ember-to-the-desktop-part","employee":"Estelle DeBlois","date":"2015-03-26T00:00:00","body":"\n\nOne of our recent client projects at DockYard had us go in a totally new\ndirection in terms of technology stack. We needed to build a desktop\napplication that could communicate with some Arduino devices via\n[WebSockets](https://developer.mozilla.org/en-US/docs/WebSockets).\n\nLet me first put this out there: I love building for the web. The mere\nthought of developing native desktop applications always makes me cringe\na little, though I admit, I haven't done much in that arena since those\n[Java Swing](http://en.wikipedia.org/wiki/Swing_%28Java%29) days from forever ago.\nNevertheless, you may find yourself at some point needing to build for the desktop.\nThankfully, you don't have to put your fuzzy little Tomster away.\n\n[NW.js](https://github.com/nwjs/nw.js), formerly known as Node WebKit, is a runtime\nbuilt on top of Chromium and Node/IO.js that lets you develop native applications\nusing the web technologies that you love. You can essentially build an Ember app, and\nalso invoke Node modules all within the browser, then package it up as\na Mac OS X application or Windows `exe` file when you're ready to distribute.\n\n## Demo\n\nHere's a screenshot from a NW.js app built with Ember for demonstration\npurposes:\n\n![screenshot](https://cloud.githubusercontent.com/assets/1691398/6768192/536a6fde-d033-11e4-9375-e2f506c1c8c7.png)\n\nIt's a simple GitHub-flavored Markdown Editor that lets you create and preview\nMarkdown documents, and save them to disk.\n\nYou can try it for yourself. Just download the application from the\nfollowing links for your platform, unzip, then double-click on `Markdown\nEditor.app` (Mac) or `Markdown Editor.exe` (Windows).\n\n* Mac OS X: [markdown-editor-osx64](https://s3.amazonaws.com/dockyard-general/ember-nw-demo/markdown-editor-osx64.zip)\n* Windows:\n[markdown-editor-win64](https://s3.amazonaws.com/dockyard-general/ember-nw-demo/markdown-editor-win64.zip)\n* [Source code](https://github.com/brzpegasus/ember-nw-markdown)\n\nFor a touch of user friendliness, the app even ships with your favorite\nmascot:\n\n_Mac:_\n<img alt=\"Mac Icon\" src=\"https://cloud.githubusercontent.com/assets/1691398/6853610/9ee8c52c-d3c2-11e4-971a-3472bfd35609.png\">\n\n<em style=\"display: block;\">Windows:</em>\n<img alt=\"Windows Icon\" src=\"https://cloud.githubusercontent.com/assets/1691398/6853614/a32becc2-d3c2-11e4-9ed4-83d645825f4b.png\">\n\n## Getting Started\n\nThe main entry point to a NW.js application is an HTML page that you\nspecify in your project's `package.json`:\n\n```json\n{\n  \"name\": \"my-app\",\n  \"main\": \"dist/index.html\"\n}\n```\n\nOn startup, NW.js will launch a new Chromium browser window,\nthen set the location to that starting page:\n`file:///Users/brzpegasus/projects/my-app/dist/index.html#/`.\n\nThis does require that you set your `Ember.Router`\n[location type](http://emberjs.com/api/classes/Ember.Location.html) to `hash`. In Ember CLI,\nthis is a simple tweak to your `config/environment.js` file:\n\n```javascript\n// config/environment.js\nmodules.exports = function(environment) {\n  var ENV = {\n    locationType: 'hash', // Change this from 'auto' to 'hash'\n    // ...\n  };\n};\n```\n\nFrom there on, you should feel quite at home and ready to develop your Ember app.\n\nOr maybe not quite yet.\n\n## A Bit About NW.js\n\nNW.js tweaks Chromium and Node in order to\n[integrate](https://github.com/nwjs/nw.js/wiki/How-node.js-is-integrated-with-chromium)\nthe two worlds and make it possible for you to call Node modules from the client:\n\n```javascript\nconsole.log(location.href);   // Yup, we're in browser land\n\nvar fs = require('fs');       // Call core Node modules\nvar async = require('async'); // Or even third-party modules!\n```\n\nIf you're used to Node and CommonJS, this `require` function should look very\nfamiliar, but it isn't exactly the same. Here's what it does:\n\n```javascript\nfunction require(name) {\n  if (name == 'nw.gui')\n    return nwDispatcher.requireNwGui();\n  return global.require(name);\n}\n```\n\nSo if you were to call `require('nw.gui')`, you would get access to the\n[Native UI Library](https://github.com/nwjs/nw.js/wiki/Native-UI-API-Manual)\nto do things like manipulating the window frame, adding menus, keyboard shortcuts, etc.\nOtherwise, the function ends up calling `global.require` to import Node modules.\n\n`global` is Node's global namespace object. You can use it to retrieve\nother global objects besides `require`, such as `global.process`.\nHowever, many of them are made available directly on the `window` object, so you can\nreference them without prefix, just as you would in Node:\n\n```javascript\nconsole.log(window.process === global.process) // => true\nconsole.log(process.env.USER) // \"brzpegasus\"\nconsole.log(process.platform) // \"darwin\"\n```\n\n## Naming Conflicts\n\nModules written with ES2015 ([previously, ES6](https://esdiscuss.org/topic/javascript-2015#content-3))\nsyntax in your Ember app get transpiled into\nAMD for today's browsers. This is problematic because AMD also specifies a\n`require` function for loading modules. In Ember CLI, this is implemented via\n[ember-cli/loader.js](https://github.com/ember-cli/loader.js).\n\nBy the time the app is done loading, any functionality that depends on\nthe native UI library or Node modules will break as the `require`\nfunction would have been redefined.\n\nYou can get around this by saving a reference to Node's `require` before loading\nany script. Once all scripts are loaded and executed, redefine `require`\nto work with both module systems. This is necessary as certain operations\nwill not work with the alias:\n\n```javascript\n// Before loading any script\nwindow.requireNode = require;\n\n// After all scripts are loaded\nvar requireAMD = require;\n\nwindow.require = function() {\n  try {\n    return requireAMD.apply(null, arguments);\n  } catch (error) {\n    return requireNode.apply(null, arguments);\n  }\n};\n```\n\n## An Addon For All Your NW.js Needs\n\nI've recently released an Ember CLI addon to help make this process\neasier. Simply install [ember-cli-node-webkit](https://github.com/brzpegasus/ember-cli-node-webkit),\nthen start coding right away. All the configuration will be taken care\nof for you, so no need to worry about `require` naming conflicts.\n\nThe addon can build your project, watch for changes, and reload the page in NW.js\nduring development. And when you're ready to distribute, packaging is just\none command away. The packaging is a wrapper around the excellent\n[node-webkit-builder](https://github.com/mllrsohn/node-webkit-builder)\nbut the configuration is done automatically based on the addon's\nunderstanding of your app structure.\n\nI will not spend time talking about the addon in this blog post, but I\ninvite you to check out the [README](https://github.com/brzpegasus/ember-cli-node-webkit/blob/master/README.md)\nto get familiar with all the options that are at your disposal.\n\n## Conclusion\n\nWhen we first set out to build a desktop app for a client project,\ndocumentation on how to integrate NW.js with Ember was scarce. Even more\nscarce was documentation on how to integrate it with Ember CLI. I hope\nthis post and this addon will provide some guidance to others down the\nroad.\n\nI'd love to share some code samples and discuss patterns you can adopt\nto make your NW.js app more manageable and testable, but they'd be too\ndense for this introductory blog post. However, you'll be hearing more from me\non this topic in the future!\n"},{"title":"Pluralize Your Word(s) With ember-pluralize","tags":["ember","addon","javascript"],"summary":"Introducing a pluralizing addon based on a given count.","legacy":false,"id":"2015/03/27/pluralize-your-words-with-ember-pluralize","employee":"Romina Vargas","date":"2015-03-27T00:00:00","body":"\n\nDo you ever find yourself repeating identical pieces of code throughout\ndifferent projects? If so, that's the perfect indicator for an addon\nopportunity. Ember Addons allow you to quickly integrate sharable code\ninto different projects, without copy and pasting, via one simple command:\n\n```bash\n  ember install:addon addon-name\n```\n\nOn some of our most recent projects, we kept finding the need to\npluralize words based on _how many_ of each item we had. Also, since\nour data is dynamic and constantly changing, the pluralization of a\nword should remain in sync with our fluctuating data. And so\n[`ember-pluralize`](https://github.com/rsocci/ember-pluralize) was born.\n\nAfter a quick `ember install:addon ember-pluralize`, using the addon\nis a piece of cake.\n\nLet's suppose we have a model like so:\n\n```javascript\nexport default Ember.Route.extend({\n  model: function() {\n    return Ember.A([\n      Ember.Object.create({ name: 'Cartman', cheesyPoofs: 20 }),\n      Ember.Object.create({ name: 'Stan', cheesyPoofs: 5 }),\n      Ember.Object.create({ name: 'Kyle', cheesyPoofs: 1 }),\n      Ember.Object.create({ name: 'Kenny', cheesyPoofs: 0 })\n    ]);\n  }\n});\n```\n\nNow we want to output how many Cheesy Poofs each person has. This addon\nprovides a helper that allows us to do the following in our template:\n\n```hbs\n{{#each model as |person|}}\n  {{person.name}} has {{h-pluralize person.cheesyPoofs \"Cheesy Poof\"}}\n{{/each}}\n```\n\nwhich will output\n\n```hbs\n// Cartman has 20 Cheesy Poofs\n// Stan has 5 Cheesy Poofs\n// Kyle has 1 Cheesy Poof\n// Kenny has 0 Cheesy Poofs\n```\n\nAnd now, as they each start throwing back some Cheesy Poofs, the counts\nwill start to update, as well as the word \"Cheesy Poof\", according to\nhow many are remaining. Alternatively, if you don't need to display the\nactual number, passing in `omitCount=true` as the third parameter will\nexclude it from the output:\n\n```hbs\n{{#each model as |person|}}\n  {{person.name}}'s {{h-pluralize person.cheesyPoofs \"Cheesy Poof\" omitCount=true}}\n{{/each}}\n```\n\n```hbs\n// Cartman's Cheesy Poofs\n// Stan's Cheesy Poofs\n// Kyle's Cheesy Poof\n// Kenny's Cheesy Poofs\n```\n\nNote: If you're using Ember Data, you will be provided with a built in pluralize\nhelper through the [Ember Inflector](https://github.com/stefanpenner/ember-inflector)\nlibrary. The helper is registered for availability in the template; the\nfunctionality is similar, but given that it takes up to two arguments\n(the count and the word), you're not able to solely display the pluralized\nword based on a given a count.\n\nIf you'd like to see more on the addon, it can be found on\n[GitHub](https://github.com/rsocci/ember-pluralize)!\n"},{"title":"Helping Our Engineers","tags":["html"],"summary":"Writing Pseudo-Code as UX Developers","legacy":false,"illustration_alt":"Has no followers","illustration":"https://dl.dropboxusercontent.com/u/38675407/followers--no-followers.png","id":"2015/03/31/helping-our-engineers","employee":"Amanda Cheung","date":"2015-03-31T00:00:00","body":"\n\n## Writing Pseudo-Code as UX Developers\n\nAs a team, we are always trying to improve our process at DockYard to\nmake things easier for one another. I’m part of the UX development team, which\ntakes care of the HTML and CSS/Sass for our projects.\nOne thing we have found to be helpful to our Ember/back-end engineers is pseudo-coding\nwhere loops and conditionals should go in our templates. It only takes a basic understanding of\n[flow control]\n(https://pine.fm/LearnToProgram/chap_06.html).\n\nWhen we are in the development phase of a project, UX development usually tries to\ncomplete HTML first. That way UX dev and engineering can work in\nparallel without completion times depending on each other. What can we\ndo to make this process smoother? Below are two code examples of what an engineer may see given these mockups.\n<img alt=\"Has no followers\"\nsrc=\"https://dl.dropboxusercontent.com/u/38675407/followers--no-followers.png\">\n<img alt=\"Followers shows interests\"\nsrc=\"https://dl.dropboxusercontent.com/u/38675407/followers--with-interests.png\">\n\nUnorganized comments:\n\n```handlebars\n{{! at the beginning the user will not have any followers so show this}}\n<div class=\"follows-wrap\">\n  <h2 class=\"follows--is-empty\">You don’t have any followers.</h2>\n</div>\n\n{{! when a user has followers show this block and not the block above}}\n<div class=\"follows-wrap\">\n  <div class=\"follows\">\n    <div class=\"follow\">\n      <img src=\"\" class=\"follow__image\">\n      <h2 class=\"follow__name\">Alfred H.</h2>\n      <h3 class=\"follow__interests__heading\">Follows for:</h3>\n      {{! must be following for at least one interest to have a follower. when the follower is only following for one interest will not have the part that says 2 others or span below that}}\n      <p class=\"follow__interest\">Tennis &amp; Racquet Sports,\n        <a href=\"#\" class=\"follow__interest--other\">2 others</a>\n        <span class=\"follow__modal__interests\">\n          <span class=\"follow__modal__interest\">Photography</span>\n          <span class=\"follow__modal__interest\">Soccer</span>\n        </span>\n      </p>\n    </div>\n  </div>\n</div>\n```\n\nPseudo-code comments:\n\n```handlebars\n<div class=\"follows-wrap\">\n  {{! if user has followers}}\n    <div class=\"follows\">\n      {{! each follower / following}}\n        <div class=\"follow\">\n          <img src=\"\" class=\"follow__image\">\n          <h2 class=\"follow__name\">Alfred H.</h2>\n          <h3 class=\"follow__interests__heading\">Follows for:</h3>\n          <p class=\"follow__interest\">\n            Tennis &amp; Racquet Sports\n            {{! if following for more than one interest}}\n              ,\n              <a href=\"#\" class=\"follow__interest--other\">2 others</a>\n              <span class=\"follow__modal__interests\">\n                <span class=\"follow__modal__interest\">Photography</span>\n                <span class=\"follow__modal__interest\">Soccer</span>\n              </span>\n            {{!end if}}\n          </p>\n        </div>\n      {{! end each}}\n    </div>\n  {{! else}}\n    <h2 class=\"follows--is-empty\">You don’t have any followers.</h2>\n  {{! end if}}\n</div>\n```\n\nThe unorganized way can get out of hand with complex applications. The\npseudo-code method turns out to be slightly more work for UX developers,\nbut it saves our engineers a lot of time and confusion. Being able to break\nthings down into simple if/else statements or each loops has been much more efficient.\nNo more reading paragraphs of what’s supposed to go where and when, or\nre-organizing the template!\n"},{"title":"Elixir: Come for the syntax, stay for everything else","tags":["elixir"],"summary":null,"legacy":false,"id":"2015/04/08/elixir-come-for-the-syntax-stay-for-everything-else","employee":"Brian Cardarella","date":"2015-04-08T00:00:00","body":"\n\nI have been programming for over 20 years now. I started with Basic,\nfound my way to C++, and spent two years writing Assembly (MASM). Then I\nfound Ruby. Ruby completely changed everything for me. I loved Ruby. I\nloved Ruby for a reason that many \"elite\" programmers tend to dismiss:\nthe syntax.\n\nYou see, syntax is very important to me. Call it what you will,\nbikeshedding, OCD, stupidity. I care about syntax. It matters to me, and\nwith Ruby I found a community that shared my thoughts.\n\nWhen Go and Rust came along I was disappointed. Clearly these two\nlanguages were superior in performance (and in many other areas) but were a syntactic step back\nfrom Ruby. What was their reason? Clearly Ruby, and even Python, have\nproven that the masses are attracted by clear and readable syntax. New\nlanguages should take the best of what is currently available and\nimprove upon them. Go seems to target the C/C++ audience, whereas Rust\nseems to attract JavaScript developers. So I guess this becomes a matter\nof perspective and opinion.\n\nElixir is different. I put Elixir up there with Go and Rust as part of\nthe three new languages that will define the next decade of backend\nsoftware development. With Elixir I found a language that embraced\nRuby-like syntax, but also gave me much more.\n\nThe syntax is only skin deep, but this is part of allure of Elixir. It\nis my foot in the door. When I first saw Elixir code I thought to myself\n\"OK, this is something I can wrap my head around\".\n\nI think a lot of Ruby developers will find their way to Elixir. It seems\nthat many were attracted to Go but I suspect when they start to explore\nwhat the Elixir language has to offer they'll see the benefits.\n\nBut a language needs more than just a hook, there has to be a compelling\nreason to stay. For me that was Functional Programming.\n\nIt seems that Functional Programming is making a come back. Every day\nthere is a new blog article on why you should start writing Functional\ncode. Let's break this down into a few points:\n\n## 1. Scalability\n\nThis is an Erlang trait. Elixir apps will attempt to make the best use\nof all the cores in your CPU as possible. Compared to Ruby this is a big\ndeal. We don't have to write anything special, the Erlang VM (BEAM) just\nhandles this for us automatically. This means we are efficiently using\nour hardware. This type of approach didn't make a lot of sense a few\nyears ago, multi-core CPUs were expensive. Now they're cheap and Elixir\nbenefits.\n\n## 2. Memory\n\nElixir programs are meant to be broken into many different processes.\nThe garbage collection strategy being used isn't revolutionary but\nbecause we are dealing with **many** runtimes instead of just one the\nimpact on GC is negligible. In addition, you can picture how short-lived\nprocesses might be the equivalent of objects in an OOP lanuage. We pass\nmessages into the process and get back a value. Each process manages its\nown memory, if the process is short-lived enough GC is never even run\nand the process is destroyed after it has completed its job. As opposed\nto Ruby where everything lives in one world and if you stop using the\nobject it will get GC'd eventually impacting performance.\n\n## 3. Immutability\n\nImmutability got a bad rap when memory was expensive. Why would we write\napplications in such a way so as to waste memory by having variables\nwhose values couldn't be mutated? Memory is now super cheap, and this is\nnot much of a concern. With this in mind we can evaluate immutability\nwithin the context it was originally meant: to ensure state. When we\ntalk about parallel processing the state of a process becomes very\nimportant. If we are expecting `X` to always be a specific value but we\nare writing in a language where `X` can change this can lead to\nproblems.\n\n## 4. Fault Tolerance\n\nThis one really impressed me when I started to dig into it. You may have\nheard that Erlang was invented for telephony. How often do you get a\nmessage from your phone company saying \"we're updating our systems so\nyou won't get a call for a while\". This is the level of uptime that is\nachievable with Elixir. Hot code swapping is another very cool feature.\nThink **real** Zero Downtime Deploys.\n\n## 5. Community\n\nThis one is more personal to me. I'm attracted to technology that is not\ncentralized into one company. Go and Rust are very much just Google and\nMozilla technologies. Those languages will always be at the whim of\ntheir corporate masters, wheras a language like Elixir that is not tied\nto any one company feels like it has a more democratic process behind\nits development. Let many companies develop use-cases and improve the\nlanguage. (I realize that Erlang falls into this category, but Erlang is\npretty much set in stone at this point)\n\nThe community around Elixir also feels very much like the Ruby community\ndid early on. I said the same thing about the Ember.js community. I\nguess I'm just chasing that Ruby dragon, trying to catch that high\nagain.\n\n\n### Conclusion\n\nWe've been exploring Elixir heavily over the past few months. The more I\ndig into the language the more I love it. We're going to bet pretty\nheavily on Elixir and if you are a Ruby developer looking for a change\nin pace I highly suggest you check it out. The best place to start is\nwith [Dave Thomas'\nBook](https://pragprog.com/book/elixir/programming-elixir).\n"},{"title":"The Importance of Being Experience First","tags":["design","engineering","user experience","opinion"],"summary":"Why being Experience First is more critical than ever – will the rise of website builders threaten the future of software consulting?","legacy":false,"id":"2015/04/09/the-importance-of-being-experience-first","employee":"Lauren Tan","date":"2015-04-09T00:00:00","body":"\n\nWe're in the middle of a digital renaissance that has software eating the world.\nLike the industrial revolution, the digital revolution might see us eventually\nbecoming obsolete, but that's okay because that's what progress looks like. To\nstay relevant, we need to place the Experience First.\n\n## The architects of the digital world\nThe modern architect has her roots in ancient and medieval history. They\noriginated as artisans; master craftsmen such as stone masons and carpenters.\nIn ancient times, there was no clear separation between the role of the\narchitect and the engineer – they were seen as one and the same.\n\nIn some ways, the architects of the digital world are similar to those of the\nphysical. There are many parallels between the two, although it's important to\nbe aware of leaky abstractions, and that they are only *similar*, not exactly\nthe same.\n\n## The craftsmens' renaissance\nWe're currently living in an age of digital renaissance.\n[Software is eating the world](http://www.wsj.com/articles/SB10001424053111903480904576512250915629460),\nand some of us believe that we're right in the middle of a great technological\nrevolution – the software revolution.\n\n> It's no longer enough to build a good product or service. The world demands\n> excellence, because good is the new average.\n\nI believe it's partly a symptom of how efficient manufacturing has become, that\nwe're experiencing wide scale [commoditization](http://www.rushkoff.com/blog/2005/9/4/commodified-vs-commoditized.html)\nof goods and services that were historically considered luxuries. Because of\nthis, we're also at the start of a new renaissance – one in which there is a\nresurgence of an appreciation for [well designed experiences](http://www.launch.co/blog/the-age-of-excellence.html/).\n\nIn my [EmberConf talk](http://confreaks.tv/videos/emberconf2015-ambitious-ux-for-ambitious-apps),\nI defined design to mean more than aesthetics; design is how\nthings work, and encompasses the *entire experience* across different mediums.\nAirbnb calls this being [Experience First](http://www.wired.com/2015/01/airbnbs-new-head-design-believes-design-led-companies-dont-work/),\nas opposed to Design First, which suggests that anyone who isn't a designer has\ntheir contributions take a backseat.\n\n> \"That experience is essentially a story, a narrative which ultimately enjoins\n> us to a brand.\" – [Om Malik, Gigaom](https://gigaom.com/2013/10/22/square-airbnb-and-why-experience-really-is-design/)\n\nIn other words, it’s obvious that we place value on things that fulfill both\nform and function. The popularity of beautiful user experiences, both online and\noffline, are the expression of a digital renaissance that is only going to\ncontinue growing.\n\n## The rise of website builders and what it means for us\nUnlike classical portrait painters, bowling alley pinsetters and other\njobs that have become redundant, the digital creator seems to be relatively\nsafe.\n\nWith the rise of website builders like [Wix](https://thegrid.io/),\n[Squarespace](http://www.squarespace.com/), [The Grid](https://thegrid.io) and\nportfolio/shop builders like [Shopify](http://www.shopify.com/),\n[BigCommerce](https://www.bigcommerce.com/) and [Virb](http://virb.com/) though,\nit's easier than ever for an individual or business to get a beautiful looking\nwebsite created at a fraction of the cost.\n\nThe beauty of the web is that once an asset has been made, it effectively costs\nnothing to clone. A designer with a copy of Sketch or Photoshop can very quickly\ndesign a 'theme', have it converted into HTML/CSS by a \"PSD to HTML\" service\n(as they're commonly known), and then sell it on one of these site builders.\nYou could very easily get a beautiful looking website setup and live on the web\non Squarespace for less than $10 a month.\n\n## Why you need to place the Experience First\nOne thing I've learned from my time in Business School, is that humans\n[suck at predicting things](http://freakonomics.com/2011/06/30/the-folly-of-prediction-full-transcript/).\nMaybe we're all going to be made redundant, but the ones that design the\nbest experiences will continue to be more relevant than ever.\n\nIf creating a website or app is commoditized, so be it. After all, who's going\nto design and build the website builder? The fact is, designing a beautiful\nexperience across different mediums will never be automated, not until we\nhave the technology to build incredibly intelligent Sentient AIs. But by then,\nwe'd all [be in trouble](http://www.imdb.com/title/tt2209764/), so I wouldn't\nworry about it just yet.\n\nBecause it's easier than ever to build a website or app, the experience matters\nmore than ever as the way to differentiate your product or service from the\naverage. When you look to hire a developer or consultancy today, I think it's\nimportant that you seek out the ones that have honed the balance between design\nand engineering, and have spent time thinking about designing truly delightful\nonline (and offline) experiences.\n\n## Lauren is a DockYarder\nI've had a very diverse and varied experience with the web – I went to design\nschool, did a finance degree, and started a [company](http://www.thepricegeek.com).\nRecently, I made the exhausting move from halfway across the world in Australia\nto join DockYard, because we truly care about the entire experience. I'm very\nproud to be able to call DY my new home.\n\nThis is my first post on Reefpoints – I hope you've enjoyed reading! If you'd\nlike to read more of my writing, you can find more on my\n[Medium](http://www.medium.com/@sugarpirate).\n\nSpecial mention to [@nfFrenchie](https://twitter.com/nffrenchie) and everyone\nelse who helped review this post.\n"},{"title":"The Beginner's Fallacy","tags":["opinion"],"summary":null,"legacy":false,"id":"2015/04/10/the-beginners-fallacy","employee":"Brian Cardarella","date":"2015-04-10T00:00:00","body":"\n\nHelping onboard beginners is a hot topic right now in software\ndevelopment. It is very good that this is important to people as we need\nnew software developers. However, I have noticed that many of these\ndevelopers are finding it difficult advancing beyond beginner. This\nis especially evident when they are taken out of their current\ndevelopment environment.\n\nBeginners require guidance and a set of rules to follow. This has been\nshown time over time to be an effective strategy for learning. The\nrules/principles/laws, whatever you want to call them, are based upon\nthe experience of more advanced developers that essentially boil down to \n\"here is what you want to do *most* of the time\". They are a great\nsubstitute for experience. They also fit in very nicely with the notion\nof **Convention Over Configuration**. But unless you are stepping\noutside of your framework the advantage of COC may turn into a career\nhindering disadvantage.\n\nI am a big fan of Convention Over Configuration. I was first exposed to\nit with Ruby on Rails and I like that Ember.js has been\nfollowing this path as well. However, I also believe that it can become\na crutch for beginners. The rules that they are following coupled with\nthe low friction environment of COC leads to a developer experience that\ndoes not present too many obstacles to be overcome. Learning requires\nchallenge. You meet a challenge, you learn how to overcome that\nchallenge, you move on and now that experience is a tool you can wield in\nthe future.\n\nThe market being flooded with beginners along with COC frameworks should\nproduce an environment that is heavily favored towards employers. (buyer's market) \nIn most cases these developers will be\nable to accomplish most of what a very experienced developer can\naccomplish. This is great for the company's bottom line but not so good\nfor the individual developer's own career growth.\n\nInstead, if you are interested in advancing beyond being a beginner,\nyou must get out of your comfort zone. This is going to require you to\nput more time into your craft than your job necessarily allows. Try new\nsoftware languages, try old software languages. Go read\n[SICP](https://mitpress.mit.edu/sicp/). Attend meetups, [read\npapers](https://github.com/papers-we-love/papers-we-love),\ncontribute to open source. *Contribute to open source even if you think\nyour PR won't be accepted*. All of these things will take you out of the\ncomfort zone that your daily work gives you, but you'll grow and become\na better (and more in demand) developer for it.\n"},{"title":"Detecting Ember.js Components Entering or Leaving the Viewport","tags":["ember","addon","javascript"],"summary":"I wrote a post last year about how I made an Ember Mixin that would let Ember Components or Views know if their DOM element had entered or left the viewport. This time, I want to talk about how I improved the original Mixin to use the requestAnimationFrame API for improved performance at close to 60FPS.","legacy":false,"illustration_alt":"Featuring Brian","illustration":"https://d262ilb51hltx0.cloudfront.net/max/1600/1*9WZqJfpL4daIEBJiufTolQ.png","id":"2015/04/20/ember-in-viewport","employee":"Lauren Tan","date":"2015-04-20T00:00:00","body":"\n\n*This concise version originally appears on [Medium in longform](https://medium.com/delightful-ui-for-ember-apps/creating-an-ember-cli-addon-detecting-ember-js-components-entering-or-leaving-the-viewport-7d95ceb4f5ed).*\n\nI [wrote a post](https://medium.com/delightful-ui-for-ember-apps/ember-js-detecting-if-a-dom-element-is-in-the-viewport-eafcc77a6f86)\nlast year about how I made an Ember Mixin that would let Ember Components or\nViews know if their DOM element had entered or left the viewport. If you're\nunfamiliar with the [`getBoundingClientRect`](https://developer.mozilla.org/en-US/docs/Web/API/Element/getBoundingClientRect)\nAPI or the approach in general (for determining if an element is in the\nviewport), please have a read of that post first!\n\nThis time, I want to talk about how I improved the original Mixin to use the\n[`requestAnimationFrame`](https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame)\nAPI for improved performance at close to 60FPS. Because\n[certain browsers](http://caniuse.com/#search=requestAnimationFrame) (mainly IE)\ndon't support `rAF`, we'll also setup an automatic fallback to using the Ember\nrun loop method I used in my previous post.\n\n## Demo\n![Featuring Brian](https://d262ilb51hltx0.cloudfront.net/max/1600/1*9WZqJfpL4daIEBJiufTolQ.png)\n\nI made a simple [demo app](http://development.ember-in-viewport-demo.divshot.io/)\nto demonstrate how you might use the Mixin. The goal for this addon was to allow\nyou to easily style or do something with Components/Views when they enter or\nleave the viewport. For example, you could easily use this Mixin to build a\nlazy loader for images, or even for triggering animations. Using this Mixin,\nyou won't need to use a jQuery plugin and can instead rely on a highly\nperformant ember-cli addon.\n\n## Installing the addon\nIf you're using ember-cli and want to use the addon, you can install it with:\n\n```shell\n$ ember install ember-in-viewport\n```\n\nThe source for the addon is available at [dockyard/ember-in-viewport](https://github.com/dockyard/ember-in-viewport).\n\n## Rewriting the In Viewport Mixin\nThe Mixin still uses the [same method](https://medium.com/delightful-ui-for-ember-apps/ember-js-detecting-if-a-dom-element-is-in-the-viewport-eafcc77a6f86)\nfor determining if a DOM element is in the viewport, using\n`getBoundingClientRect` and the window's `innerHeight` and `innerWidth`.\n\n### Updating the Is In Viewport logic\nThe method for calculating whether or not a DOM element is in the viewport\nremains mostly unchanged, except with the addition of a new `viewportTolerance`\nargument.\n\n```js\nimport Ember from 'ember';\n\nconst { merge } = Ember;\n\nconst defaultTolerance = {\n  top    : 0,\n  left   : 0,\n  bottom : 0,\n  right  : 0\n};\n\nexport default function isInViewport(boundingClientRect={}, height=0, width=0, tolerance=defaultTolerance) {\n  const { top, left, bottom, right } = boundingClientRect;\n  const tolerances = merge(defaultTolerance, tolerance);\n  let {\n    top    : topTolerance,\n    left   : leftTolerance,\n    bottom : bottomTolerance,\n    right  : rightTolerance\n  } = tolerances;\n\n  return (\n    (top + topTolerance)       >= 0 &&\n    (left + leftTolerance)     >= 0 &&\n    (bottom - bottomTolerance) <= height &&\n    (right - rightTolerance)   <= width\n  );\n}\n```\n\nWith the addition of the `viewportTolerance` option, addon users can relax how\nprecise the check is. When set to `0`, the Mixin only considers an element\ninside the viewport when it is completely visible inside of the viewport.\n\n### Setting up the Class variables\n```js\nconst {\n  get,\n  set,\n  setProperties,\n  computed,\n  run,\n  on,\n  $,\n} = Ember;\n\nconst {\n  scheduleOnce,\n  debounce,\n  bind,\n  next\n} = run;\n\nconst { not }     = computed;\nconst { forEach } = Ember.EnumerableUtils;\n\nconst listeners = [\n  { context: window,   event: 'scroll.scrollable' },\n  { context: window,   event: 'resize.resizable' },\n  { context: document, event: 'touchmove.scrollable' }\n];\n\nlet rAFIDS = {};\n```\n\nIf you haven't had the chance to use [ES2015 features](https://babeljs.io/docs/learn-es6/),\nnow's a good time to learn, since `ember-cli-babel` has been shipped with\nember-cli by default for a while now. Here, we're destructuring certain methods\nfrom Ember, as well as setting up an array of listeners we want to register. I\nalso declare a mutable variable `rAFIDS` with `let` — I'll be using this object\nto store the ID that's returned by `requestAnimationFrame` so that we can cancel\nit later.\n\nSomething interesting to note is that these variables are actually shared by all\ninstances of the Mixin. This means if we stored the ID in that variable, it would\nbe overwritten by other instances of the Components that are being watched by\nthe Mixin. So instead, we'll store each ID as a key (the element ID for the\nComponent) inside of an object. More on that later.\n\n### Initial state\n```js\n_setInitialState: on('init', function() {\n  setProperties(this, {\n    $viewportCachedEl   : undefined,\n    viewportUseRAF      : canUseRAF(),\n    viewportEntered     : false,\n    viewportSpy         : false,\n    viewportRefreshRate : 100,\n    viewportTolerance   : {\n      top    : 0,\n      left   : 0,\n      bottom : 0,\n      right  : 0\n    },\n  });\n})\n```\n\nWe'll need to setup some initial values for our Mixin's state. We do this when\nthe Object the Mixin is mixed into is instantiated, by setting some properties\non `init`. This is because [Mixins extend a constructor's prototype](http://emberjs.com/api/classes/Ember.Mixin.html),\nso certain properties will be shared amongst objects that implement the Mixin — \nand in our case, we want these to be unique to each instance.\n\nHere, we're also going to make use of our utility function [`canUseRAF`](https://github.com/dockyard/ember-in-viewport/blob/0.2.1/addon/utils/can-use-raf.js)\nto let the Mixin know whether to use `requestAnimationFrame` or fallback to the\nEmber run loop.\n\n### Setting up the DOM element rendered by the component\nWhen the DOM element is inserted, we'll need to do a few things:\n\n1. The initial check on render to see if the element is immediately in view\n2. Setting up an observer to unbind listeners if we're not spying on the element\n3. Calling the recursive `requestAnimationFrame` method\n4. Setting up event listeners if we are spying on the element\n\n```js\n_setupElement: on('didInsertElement', function() {\n  if (!canUseDOM) { return; }\n\n  const viewportUseRAF = get(this, 'viewportUseRAF');\n\n  this._setInitialViewport(window);\n  this._addObserverIfNotSpying();\n  this._setViewportEntered(window);\n\n  if (!viewportUseRAF) {\n    forEach(listeners, (listener) => {\n      const { context, event } = listener;\n      this._bindListeners(context, event);\n    });\n  }\n})\n```\n\n### Checking if the DOM element is immediately in view\nAfter the element has been rendered into the DOM, we want to immediately check\nif it's visible. This calls the `_setViewportEntered` method in the\n`afterRender` queue of the Ember run loop, which ensures that the DOM element\nis actually already inserted and available for us.\n\n```js\n_setInitialViewport(context=null) {\n  Ember.assert('You must pass a valid context to _setInitialViewport', context);\n\n  return scheduleOnce('afterRender', this, () => {\n    this._setViewportEntered(context);\n  });\n}\n```\n\n### Unbinding listeners after entering the viewport\nIt makes sense in certain use cases to stop watching the element after it has\nentered the viewport *at least once*. For example, in an image lazy loader, we\nonly want to load the image once, after which it makes sense to clean up\nlisteners to reduce the load on the app. We do that with the `viewportSpy`\noption.\n\nHere, we programatically add an observer on the `viewportEntered` prop if\n`viewportSpy` has been set to `false` by our addon user. The observer itself\ndoesn't do much — it unbinds listeners and then removes itself.\n\n```js\n_addObserverIfNotSpying() {\n  const viewportSpy = get(this, 'viewportSpy');\n\n  if (!viewportSpy) {\n    this.addObserver('viewportEntered', this, this._viewportDidEnter);\n  }\n},\n\n_viewportDidEnter() {\n  const viewportEntered = get(this, 'viewportEntered');\n  const viewportSpy     = get(this, 'viewportSpy');\n\n  if (!viewportSpy && viewportEntered) {\n    this._unbindListeners();\n    this.removeObserver('viewportEntered', this, this._viewportDidEnter);\n  }\n}\n```\n\n### Setting up event listeners\nLet's look at binding our event listeners before we take a look at\n`_setViewportEntered`, the main method for the mixin. We'll be using the array\nof listeners we declared earlier at the top of the file, and binding the event\nto the appropriate context (`window` or `document`), like so:\n\n```js\n_bindListeners(context=null, event=null) {\n  Ember.assert('You must pass a valid context to _bindListeners', context);\n  Ember.assert('You must pass a valid event to _bindListeners', event);\n\n  const elementId = get(this, 'elementId');\n\n  Ember.warn('No elementId was found on this Object, `viewportSpy` will' +\n    'not work as expected', elementId);\n\n  $(context).on(`${event}#${elementId}`, () => {\n    this._scrollHandler(context);\n  });\n}\n```\n\nNote that we can actually pass the Component's [`elementId`](http://emberjs.com/api/classes/Ember.View.html#property_elementId)\n(the `id` attribute that is rendered into the DOM) to the event, which will\nallow us to only unbind the listener for that particular element. If we didn't\ndo this, all listeners would have been unbound when the first DOM element enters\nthe viewport, which isn't what we'd want.\n\n### Handling the event\nNow, we can handle the event by debouncing the main method with the\n`viewportRefreshRate` set by the addon user.\n\n```js\n_scrollHandler(context=null) {\n  Ember.assert('You must pass a valid context to _scrollHandler', context);\n\n  const viewportRefreshRate = get(this, 'viewportRefreshRate');\n\n  debounce(this, function() {\n    this._setViewportEntered(context);\n  }, viewportRefreshRate);\n}\n```\n\n### Unbinding listeners\nWhen we eventually destroy the Component, we want to make sure we also cleanup\nafter ourselves. We'll have to remove both event listeners and the recursive\n`requestAnimationFrame` call:\n\n```js\n_unbindListeners() {\n  const elementId      = get(this, 'elementId');\n  const viewportUseRAF = get(this, 'viewportUseRAF');\n\n  Ember.warn('No elementId was found on this Object, `viewportSpy` will' +\n    'not work as expected', elementId);\n\n  if (viewportUseRAF) {\n    next(this, () => {\n      window.cancelAnimationFrame(rAFIDS[elementId]);\n      rAFIDS[elementId] = null;\n    });\n  }\n\n  forEach(listeners, (listener) => {\n    const { context, event } = listener;\n    $(context).off(`${event}#${elementId}`);\n  });\n}\n```\n\n```js\n_teardown: on('willDestroyElement', function() {\n  this._unbindListeners();\n})\n```\n\nIf you recall, the `requestAnimationFrame` function returns an ID that uniquely\nidentifies the entry in the callback list. We can pass this on to\n`cancelAnimationFrame` in order to cancel the infinitely recursive call to the\nmain method. Because we register the Component's DOM `elementId` as a key in the\n`rAFIDS` object, we can remove the specific rAF call for that single Component.\nI've wrapped the cAF call in an `Ember.run.next` to avoid a race condition that\nhappens occasionally.\n\n### Updating the viewportEntered property\nLet's take a look at the main method responsible for setting the\n`viewportEntered` property. This method does two main things:\n\n1. Set `viewportEntered` to `true` or `false`\n2. Fire off the next `requestAnimationFrame` step\n\n```js\n_setViewportEntered(context=null) {\n  Ember.assert('You must pass a valid context to _setViewportEntered', context);\n\n  const $viewportCachedEl = get(this, '$viewportCachedEl');\n  const viewportUseRAF    = get(this, 'viewportUseRAF');\n  const elementId         = get(this, 'elementId');\n  const tolerance         = get(this, 'viewportTolerance');\n  const height            = $(context) ? $(context).height() : 0;\n  const width             = $(context) ? $(context).width()  : 0;\n\n  let boundingClientRect;\n\n  if ($viewportCachedEl) {\n    boundingClientRect = $viewportCachedEl[0].getBoundingClientRect();\n  } else {\n    boundingClientRect = set(this, '$viewportCachedEl', this.$())[0].getBoundingClientRect();\n  }\n\n  const viewportEntered = isInViewport(boundingClientRect, height, width, tolerance);\n\n  set(this, 'viewportEntered', viewportEntered);\n\n  if ($viewportCachedEl && viewportUseRAF) {\n    rAFIDS[elementId] = window.requestAnimationFrame(\n      bind(this, this._setViewportEntered, context)\n    );\n  }\n}\n```\n\nAs a simple optimization, we can cache the selected DOM element inside the\nObject as `$viewportCachedEl` so we don't have call the expensive DOM node\nselector method every time. Then, we pass the Component's element properties to\nthe utility we defined earlier, and set the `viewportEntered` property.\n\nIf `requestAnimationFrame` is enabled, we call the method again inside of the\nrAF method, after binding it to the correct context. Like\n`Function.prototype.bind`, this creates a new function, that when called, has\nits `this` keyword set to the correct value (along with any arguments). With\nthat first call after the element is inserted into the DOM, this fires off an\ninfinitely recursive loop that will only end when we cancel it.\n\nHence, we don't have to setup event listeners when rAF is enabled. And that's it\nfor the Mixin!\n"},{"title":"The New DockYard.com","tags":["business","announcement"],"summary":null,"legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/D3KeY1b.jpg","id":"2015/05/20/the-new-dockyard-dot-com","employee":"Brian Cardarella","date":"2015-05-20T00:00:00","body":"\n\nI'm proud to announce the new [DockYard.com](https://dockyard.com)\n\n![](http://i.imgur.com/D3KeY1b.jpg)\n\nWith this relaunch of our website we are also changing our direction as\na company. We've always been considered an *engineering* company but we\nare now considering ourselves a **User Experience** company. All of\nour design and engineering decisions go into delivering a modern user\nexperience on the web for our clients.\n\nThis new website is also built how we believe modern web applications\nshould be built: with [Ember.js](http://emberjs.com) on the front-end\nand [Phoenix](http://phoenixframework.org) on the back-end. \n\nOver the next few weeks we're going to share the story of how our team rebuilt\nDockYard.com. You'll hear from our Creative Director [Steven Trevathan](http://twitter.com/strevat) on\nwhat went into the Discovery of our new website, the design decisions\nmade, as well as a view of some early mockups and how we came to the\nfinal design. [Dan McClain](http://twitter.com/_danmcclain), the head of our Engineering team will discuss\nhow we built our Ember application the \"DockYard Way\" which meant we\nhad to make contributions back to Ember itself, as well as\nseveral other libraries, in order to get the experience just right.\n[Amanda Cheung](http://twitter.com/acacheung), our Lead UX Developer, will share what efforts went into the implementation of\nthe design; how we build modern responsive markup. Finally you'll hear\nfrom [Jon Lacks](http://twitter.com/jon_lacks), our Project Manager, who will show how we managed the rebuild\nof our own website using the exact same processes we use on our client\nprojects.\n\nAlong with these stories we'll not just tell you how we did things, we\nplan to show you. We'll be open sourcing all of the code for the Ember\nfront-end as well as the Phoenix back-end in the coming weeks. There are\nalso many libraries that we plan to extract from the application to\nshare with everyone.\n\nI'm extremely proud of the team for delivering this rebuild. It is the\nbest example of the quality and integrity of our design and technical\ncapabilities to date.\n"},{"title":"Sign Up For The DockYard Newsletter","tags":["business","announcement"],"summary":null,"legacy":false,"id":"2015/05/21/sign-up-for-the-dockyard-newsletter","employee":"Brian Cardarella","date":"2015-05-21T00:00:00","body":"\n\nWe are now running a monthly newsletter, we'll send currated design and\nengineering content directly to your Inbox. The best articles from our\nblog as well as exclusive content that we'll only publish in the monthly\nnewsletter.\n\nYou can sign up at the bottom of this page!\n"},{"title":"Begin with Benchmarking","tags":["benchmarking"],"summary":"Utilizing design research strategies","legacy":false,"id":"2015/05/22/begin-with-benchmarking","employee":"Ashley Treni","date":"2015-05-22T00:00:00","body":"\n\nDesign research is critical to the beginning stage of every design project. Research orients us in the world in which we intend to build and the audience we intend to build for. It is helpful to begin by identifying other services that already exist in that space, to observe the current market offerings. Building a research catalog for reference and critique is what we refer to as \"benchmarking.\"\n\nHere are three major benefits to benchmarking:\n\n1. It helps you better understand and articulate how your product or service is different\n2. It is a tool for learning about topics you might not be familiar with (especially for client projects)\n3. It allows you to observe strengths and weaknesses of existing experiences to inform your own design decisions\n\nAt DockYard, we always begin with benchmarking. Benchmarking helps us define a scope based on realistic expectations, and identify opportunities and core values for the project. It is a way to learn through exploration. In this practice and analysis we deconstruct existing complex systems, identify the minimum viable product and core interactions, and pinpoint the major actions that support user goals. \n\nThese exercises give us a better understanding of the space we intend to support, and the expectations for building a system of our own. It sets a focus and direction for ideation and user interviews, and aligns our understanding with the client's, which supports conversation.\n\nThere are several different layers to observe in a given case study from structural to aesthetic: content organization, accessibility, systems architecture, user experience methods, interface design, to visual design. It can be challenging to observe all these different layers and identify what about them creates a quality online experience.\n\n1. Start broad. Identify the overall goal of the service that brings you from A to B. Is that process transparent and supportive? Were you able to easily use the product and accomplish the task at hand? Is the information accessible? How is it organized and delivered?\n\n2. Look at the usability and interactions. Do the interactions make sense in context? Is the structure intuitive, clear, and easy to use? Are design patterns present: experiential, cognitive, tangible ways that help users interact with the interface? Identifying these patterns in context helps us understand where they can be used to support user interactions.\n\n3. Consider the visual design and experience. What is the quality of the experience, and does it reflect the overall goal of the service? Is it delightful? confusing? distracting? Does the visual language and style support understanding?\n\n\nBenchmarking isn't about taking someone else's solution and using it as your own. Every project has different content, different goals, different challenges. Deconstructing existing design solutions is key to identifying structural and experiential decisions, and reflecting on why those decisions were made to support the task at hand. This kind of critical thinking allows us to be discerning, to ask questions about how others have solved problems in similar spaces, so that we can anticipate and identify the major goals for the system we intend to build.\n\nThrough intentionally observing systems and strategies, we adopt a perpetually observant and critical mindset. The benchmarking mentality encourages us to pay attention to and appreciate the complexity of data driven web experiences, and to see how the challenges of vision, architecture, and experience were met and resolved.\n"},{"title":"Announcing Voorhees","tags":["elixir","testing","phoenix"],"summary":"Voorhees is a library for testing Phoenix JSON APIs","legacy":false,"id":"2015/05/29/announcing-voorhees","employee":"Dan McClain","date":"2015-05-29T00:00:00","body":"\n\nI've been building JSON APIs in [Phoenix](http://www.phoenixframework.org) for\na few Ember apps I've been working on. I wanted to ensure that the JSON\nresponse didn't include extra information in the form of attributes that\nshould be kept server side, and returned the correct payload. We can break\nthese two concerns into separate tests, the first making sure that our JSON\nresponse conforms to a specific \"schema\", the other making sure that the\nattributes that we care about are correct.\n[Voorhees](https://github.com/danmcclain/voorhees), named after [JSON...I mean\nJason Voorhees](http://www.imdb.com/media/rm4040136960/ch0002146#), provides\nfunctions for both of these concerns.\n\n## `Voorhees.matches_schema?`\n\n`Voorhees.matches_schema?(payload, expected_keys)` makes sure that a payload\nconforms to a certain format. You pass in a string that is the API response and\na list of keys to check it against. If that payload has extra keys, or the\npayload is missing keys, the function returns `false`, causing it to fail the\n`assert` in your test.\n\n### Examples\n\nValidating simple objects\n\n    iex> payload = ~S[{ \"foo\": 1, \"bar\": \"baz\" }]\n    iex> Voorhees.matches_schema?(payload, [:foo, \"bar\"]) # Property names can be strings or atoms\n    true\n\n    # Extra keys\n    iex> payload = ~S[{ \"foo\": 1, \"bar\": \"baz\", \"boo\": 3 }]\n    iex> Voorhees.matches_schema?(payload, [:foo, \"bar\"])\n    false\n\n    # Missing keys\n    iex> payload = ~S[{ \"foo\": 1 }]\n    iex> Voorhees.matches_schema?(payload, [:foo, \"bar\"])\n    false\n\nValidating lists of objects\n\n    iex> payload = ~S/[{ \"foo\": 1, \"bar\": \"baz\" },{ \"foo\": 2, \"bar\": \"baz\" }]/\n    iex> Voorhees.matches_schema?(payload, [:foo, \"bar\"])\n    true\n\n\nValidating nested lists of objects\n\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": [{ \"baz\": 2 }]}/\n    iex> Voorhees.matches_schema?(payload, [:foo, bar: [:baz]])\n    true\n\nValidating that a property is a list of scalar values\n\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": [\"baz\", 2]}/\n    iex> Voorhees.matches_schema?(payload, [:foo, bar: []])\n    true\n\n## `Voorhees.matches_payload?`\n\n`Voorhees.matches_payload?(payload, expected_payload)` makes sure that a payload\ncontains the right values. It should be used in conjuction with\n`Voorhees.matches_schema?/2`. `Voorhees.matches_payloads?` ignores values that\nare present in the `payload` but not in the `expected_payload`; this allows you\nto ignore server generated values, like `id` and `created_at` timestamps. You\nmay not necessarily care about the values of these server generated attributes.\nIt will return `false` when a value in `expected_payload` is missing from the\n`payload`, or when the values in the `payload` differ from the `expected_payload`.\n\n### Examples\n\nExpected payload keys can be either strings or atoms\n\n    iex> payload = ~S[{ \"foo\": 1, \"bar\": \"baz\" }]\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => \"baz\" })\n    true\n\nExtra key/value pairs in payload are ignored\n\n    iex> payload = ~S[{ \"foo\": 1, \"bar\": \"baz\", \"boo\": 3 }]\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => \"baz\" })\n    true\n\nExtra key/value pairs in expected payload cause the validation to fail\n\n    iex> payload = ~S[{ \"foo\": 1, \"bar\": \"baz\"}]\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => \"baz\", :boo => 3 })\n    false\n\nValidates scalar lists\n\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": [\"baz\"]}/\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => [\"baz\"] })\n    true\n\n    # Order is respected\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": [1, \"baz\"]}/\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => [\"baz\", 1] })\n    false\n\nValidates lists of objects\n\n    iex> payload = ~S/[{ \"foo\": 1, \"bar\": { \"baz\": 2 }}]/\n    iex> Voorhees.matches_payload?(payload, [%{ :foo => 1, \"bar\" => %{ \"baz\" => 2 } }])\n    true\n\nValidates nested objects\n\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": { \"baz\": 2 }}/\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => %{ \"baz\" => 2 } })\n    true\n\nValidates nested lists of objects\n\n    iex> payload = ~S/{ \"foo\": 1, \"bar\": [{ \"baz\": 2 }]}/\n    iex> Voorhees.matches_payload?(payload, %{ :foo => 1, \"bar\" => [%{ \"baz\" => 2 }] })\n    true\n\n## Take a machete to your API responses\n\nMake sure your API responses are what you expect, or cut them down at the knees when your tests fail!\n"},{"title":"Declarative Breadcrumb Navigation in Ember.js","tags":["ember","addon","javascript"],"summary":"ember-crubmly is a simple Component that is placed once in your application, and then generates a dynamic breadcrumb by looking up the current route hierarchy. The addon has a simple declarative API, which makes integration with your app super easy.","legacy":false,"illustration_alt":"ember-crumbly-demo","illustration":"https://i.imgur.com/Sutk1UQ.png","id":"2015/06/02/ember-crumbly","employee":"Lauren Tan","date":"2015-06-02T00:00:00","body":"\n\nBreadcrumb navigation isn't a new concept, in fact, it's usefulness has been endlessly debated about by UX designers all over. Today, I won't get into the nitty gritty on whether or not your app should include one, but I'd like to share an addon I built for a project I'm working on that required it.\n\nThis is a simple Component that is placed once in your application, and then generates a dynamic breadcrumb by looking up the current route hierarchy. The addon has a simple declarative API, which makes integration with your app super easy.\n\nLet's dive in!\n\n## Demo & Source\n\n![ember-crumbly-demo](https://i.imgur.com/Sutk1UQ.png)\n\nYou can take a look at the [demo app](http://development.ember-crumbly-demo.divshot.io/) to see ember-crumbly in action. What's cool about it is how little code it takes to add dynamic breadcrumbs to your app, and how declarative it is. The [source is on GitHub](https://github.com/poteto/ember-crumbly), as always.\n\n## The idea\nWe work on many Ember apps at DockYard, and one particular client's project I was working on called for a very dynamic breadcrumb type UI that would respond to changes in the route and model. Before I started actually implementing it, I sketched my plan on paper to see if I could make it nice and declarative instead of manually setting the breadcrumb on each of those route templates.\n\n### The Ember Container and currentRouteName\nThe Component relies mainly on Ember's container and the current route name. On a high level, the Component is injected with the Application Controller's `currentRouteName` prop, then looks up the appropriate route in the Container to check if it has a `breadCrumb` prop defined. If it does, we display whatever the POJO is, or else we show its route name in the Component.\n\n## Intended usage\nThe goal was to have an API as declarative as the following:\n\n```hbs\n{{bread-crumbs linkable=true outputStyle=\"foundation\"}}\n```\n\nAnd the route:\n\n```js\n// foo/route.js\nexport default Ember.Route.extend({\n  breadCrumb: {\n    title: 'Animals'\n  }\n});\n```\n\nWe also wanted to be able to pass in our own template block too:\n\n```hbs\n{{#bread-crumbs linkable=true as |component route|}}\n  {{#if route.title}}\n    {{route.title}}\n  {{else}}\n    {{route.foo}} ({{route.bar}}) ... {{route.baz}}\n  {{/if}}\n{{/bread-crumbs}}\n```\n\nLet's see how we can write a component that does just that using some of Ember's new features.\n\n## Injecting the Application Controller\nI've explained how we inject things in other posts, so I won't go into detail for the initializer. Ember adds the [currentRouteName and currentPath to the Application Controller](http://guides.emberjs.com/v1.10.0/understanding-ember/debugging/#toc_get-current-route-name-path), so we'll inject it into our Component so we can extract it.\n\n```js\nexport function initialize(container, application) {\n  application.inject('component:bread-crumbs', 'applicationController', 'controller:application');\n}\n\nexport default {\n  name: 'crumbly',\n  initialize\n};\n```\n\n## Declaring your variables\nWe typically declare our variables and functions used at the top of each file, to make code easier to read and refactor in the future. For ember-crumbly's `bread-crumbs` component, we're using the usual suspects:\n\n```js\nimport Ember from 'ember';\nimport layout from '../templates/components/bread-crumbs';\n\nconst get = Ember.get;\nconst {\n  A: emberArray,\n  EnumerableUtils,\n  Component,\n  Logger,\n  computed,\n  getWithDefault,\n  assert,\n  typeOf,\n  setProperties\n} = Ember;\n\nconst {\n  classify\n} = Ember.String;\n\nconst {\n  map,\n  filter\n} = EnumerableUtils;\n\nconst {\n  warn\n} = Logger;\n```\n\nYou might be wondering why we declare `const get = Ember.get;` by itself on L4 — currently there are issues with destructuring `{ get }` and [bugs in Esprima](https://github.com/dockyard/ember-suave/issues/5), so we do it by itself as temporary workaround.\n\n## Component props\nHere we set a bunch of default props for the component.\n\n```js\nexport default Component.extend({\n  layout,\n  tagName: 'ol',\n  linkable: true,\n  reverse: false,\n  classNameBindings: [ 'breadCrumbClass' ],\n  hasBlock: computed.bool('template').readOnly(),\n  currentRouteName: computed.readOnly('applicationController.currentRouteName')\n```\n\nWe've injected the Application Controller into the component in our initializer, so getting the current route's name is as simple as setting a computed property macro. We make it [`readOnly`](http://emberjs.com/api/classes/Ember.ComputedProperty.html#method_readOnly) so we don't set it by accident.\n\n## Computing the route hierarchy\nEmber's `currentRouteName` prop returns the current route hierarchy separated by periods. For example, if you were on `/foo/bar/baz`, your route would probably be something like `foo.bar.baz.index`. Knowing this, the goal would be to split the string by the period, and then working out the route name for each of its parts. With the correct route name, we can then lookup the route on the container and extract the `breadCrumb` POJO we need for our bread-crumb.\n\n```js\nrouteHierarchy: computed('currentRouteName', 'reverse', {\n  get() {\n    const currentRouteName = getWithDefault(this, 'currentRouteName', false);\n\n    assert('[ember-crumbly] Could not find a curent route', currentRouteName);\n\n    const routeNames = this._splitCurrentRouteName(currentRouteName);\n    const filteredRouteNames = this._filterIndexRoutes(routeNames);\n\n    const crumbs = this._lookupBreadCrumb(routeNames, filteredRouteNames);\n    return this.get('reverse') ? crumbs.reverse() : crumbs;\n  },\n\n  set() {\n    warn('[ember-crumbly] `routeHierarchy` is read only');\n  }\n})\n```\n\nYou'll notice straight away that we're using new Ember computed property syntax here. The new syntax allows you to set both getters and setters on your CP, instead of checking argument length like you used to have to do.\n\n## Figuring out the route name\nFirst, we split the `currentRouteName` string into an array, and then filter out any `index` routes. This is because the string splits into an array with all the parts, so `foo/bar/baz` would yield `[ 'foo', 'bar', 'baz', 'index' ]`, while we only want the first 3.\n\n```js\n_splitCurrentRouteName(currentRouteName) {\n  return currentRouteName.split('.');\n},\n\n_filterIndexRoutes(routeNames) {\n  return filter(routeNames, (name) => {\n    return name !== 'index';\n  });\n}\n```\n\nNow with the array of parts, we need to piece them together again bit by bit to reconstruct their constituent routes.\n\n## Looking up the route on the container\nIn here, we:\n\n1. Map over the filtered route names individually\n2. Reconstruct the route name by slicing the original array of route names with the [right `end` argument](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice)\n3. Look the reconstructed route name up on the container\n4. Retrieve the breadCrumb POJO, add props to it, and return an Ember Array that our component can iterate over in its template\n\n```js\n_lookupBreadCrumb(routeNames, filteredRouteNames) {\n  const defaultLinkable = get(this, 'linkable');\n  const breadCrumbs = map(filteredRouteNames, (name, index) => {\n    const path = this._guessRoutePath(routeNames, name, index);\n    let breadCrumb = this._lookupRoute(path).getWithDefault('breadCrumb', undefined);\n    const breadCrumbType = typeOf(breadCrumb);\n\n    if (breadCrumbType === 'undefined') {\n      breadCrumb = {\n        path,\n        linkable: defaultLinkable,\n        title: classify(name)\n      };\n    } else if (breadCrumbType === 'null') {\n      return;\n    } else {\n      setProperties(breadCrumb, {\n        path,\n        linkable: breadCrumb.hasOwnProperty('linkable') ? breadCrumb.linkable : defaultLinkable\n      });\n    }\n\n    return breadCrumb;\n  });\n\n  return emberArray(filter(breadCrumbs, (breadCrumb) => {\n    return typeOf(breadCrumb) !== 'undefined';\n  }));\n}\n```\n\n### Reconstructing the route name\nEach time map runs in the previous method, we get a single piece of the route name, e.g. `bar`. We know that its correct route name is `foo.bar`, so we can slice the original array with the [map's `index` argument](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map#Syntax) to piece those bits together. When we start with the first piece (`foo`), we know that we need to look up `foo.index` so that we can generate the correct link-to, so we check for that.\n\n```js\n_guessRoutePath(routeNames, name, index) {\n  const routes = routeNames.slice(0, index + 1);\n\n  if (routes.length === 1) {\n    return `${name}.index`;\n  } else {\n    return routes.join('.');\n  }\n}\n```\n\nNow that we have the correct route name for each path, we can look up the actual route object on the Container while we map over the filtered route names.\n\n### Looking up the route on the Container\nThe Ember Container (basically how Ember keeps track of all its different objects) isn't well documented because it is originally intended to be private API. However, many addons and apps make use of it to do certain things, and this one is no exception. There is an [RFC on the table](https://github.com/emberjs/rfcs/pull/46) with reforming the Registry and Container, so this might have to be changed in the future. For now, we can still get the Container from the Component, and then use its `lookup('type:name')` method to find the route.\n\n```js\n_lookupRoute(routeName) {\n  const container = get(this, 'container');\n  const route = container.lookup(`route:${routeName}`);\n  assert(`[ember-crumbly] \\`route:${routeName}\\` was not found`, route);\n\n  return route;\n}\n```\n\n### Extracting the breadCrumb POJO\nWith the route object in hand, we can then easily extract the `breadCrumb` POJO we define on our routes.\n\n```js\nlet breadCrumb = this._lookupRoute(path).getWithDefault('breadCrumb', undefined);\nconst breadCrumbType = typeOf(breadCrumb);\n\nif (breadCrumbType === 'undefined') {\n  breadCrumb = {\n    path,\n    linkable: defaultLinkable,\n    title: classify(name)\n  };\n} else if (breadCrumbType === 'null') {\n  return;\n} else {\n  setProperties(breadCrumb, {\n    path,\n    linkable: breadCrumb.hasOwnProperty('linkable') ? breadCrumb.linkable : defaultLinkable\n  });\n}\n\nreturn breadCrumb;\n```\n\nIn certain scenarios, you might want to opt-out of displaying a specific route in the breadcrumb. We allow that by setting `breadCrumb: null` inside of that route. If no breadCrumb POJO is found, we set the title to be the route's capitalized name by default, and if we do find one, we simply add the path and linkable keys to it.\n\nFinally, we return an [Ember Array](http://emberjs.com/api/classes/Ember.html#method_A) so that the resulting array is iterable in the template, and filter out any undefined breadcrumbs.\n\n```js\nreturn emberArray(filter(breadCrumbs, (breadCrumb) => {\n  return typeOf(breadCrumb) !== 'undefined';\n}));\n```\n\nWith the logic done, let's look at our somewhat complicated template to handle all the different uses!\n\n### Template logic\nBecause we want to handle both the inline and block form of the Component, as well as the ability to make each route linkable, the template does get a little complicated:\n\n```hbs\n{{#each routeHierarchy as |route|}}\n  <li class={{crumbClass}}>\n    {{#if hasBlock}}\n      {{#if route.linkable}}\n        {{#link-to route.path}}\n          {{yield this route}}\n        {{/link-to}}\n      {{else}}\n        {{yield this route}}\n      {{/if}}\n    {{else}}\n      {{#if route.linkable}}\n        {{#link-to route.path}}\n          {{route.title}}\n        {{/link-to}}\n      {{else}}\n        {{route.title}}\n      {{/if}}\n    {{/if}}\n  </li>\n{{/each}}\n```\n\nAnd that's done!\n\n*This post also appears on [Medium in longform](https://medium.com/delightful-ui-for-ember-apps/declarative-breadcrumb-navigation-in-ember-js-5908a92a5de3).*\n"},{"title":"A clean pattern for modal dialogs","tags":["ember","components"],"summary":"The project you are working on has a number of modal dialogs, and the component helper can help","legacy":false,"id":"2015/06/08/a-clean-pattern-for-modal-dialogs","employee":"Dan McClain","date":"2015-06-08T00:00:00","body":"\n\nRecently, I was working on a project which had a number of different modals. I\ndiscovered a really clean pattern for implementing modals via actions and\n[`ember-modal-dialog`](https://github.com/yapplabs/ember-modal-dialog).\n\nWe implemented each of the different modals as separate components, and\nrendered `ember-modal-dialog` in the `application` template the following\nway:\n\n```hbs\n{{#if isModalVisible}}\n  {{#modal-dialog}}\n    {{component modalDialogName modalContext=modalContext closeAction=\"closeModal\"}}\n  {{/modal-dialog}}\n{{/if}}\n```\n\nThe component helper allows us to dynamically choose which modal we'd like to\nsee. We call the modal via the following action in the application route;\n\n```js\nconst { setProperties, set } = Ember;\n\nactions: {\n  showModal(modalDialogName, modalContext) {\n    const applicationController = this.controller;\n\n    setProperties(applicationController, {\n      modalDialogName,\n      modalContext,\n      isModalVisible: true\n    });\n  },\n\n  closeModal() {\n    const applicationController = this.controller;\n\n    set(applicationController, 'isModalVisible', false);\n  }\n}\n```\n\nWe invoke the modal via a normal action call:\n\n```hbs\n<button {{action \"showModal\" \"my-component-name\" contextForModal}}>Show the modal!</button>\n```\n\nThe `modalContext` could be as simple as a string, or as complex as an\nEmber-Data model. It gets passed to the component as the `modalContext`\nattribute, so you'll need to remember to retrieve your properties from within\nthere if you are trying to do something a bit more complex.\n\nThe component helper is really what enables this pattern, otherwise you'd need\nto either have a series of `if`s to display the correct modal. I may extract\nthis pattern into a separate addon, as I see it as one I'll reuse frequently\nwhenever we have multiple modal dialogs.\n"},{"title":"Go: UX Camp 2015","tags":["design","design process","design thinking","conferences","ux camp","ux east"],"summary":"A weekend away for design collaboration and learning.","legacy":false,"id":"2015/06/09/ux-camp-2015","employee":"Steven Trevathan","date":"2015-06-09T00:00:00","body":"\nLet’s go back to camp.\n\nThis July 18-20 we’re heading back up to Maine, and to a really cool (remote) location. We have four cabins on the lake in Caratunk, ME, and I invite you to join us!\n\nJust like last year, it’s a UX design focused project weekend with intermittent design talks, workshops, games, and music. This year we’re going to have the incredible (Boston based) band [The Grownup Noise](https://www.youtube.com/watch?v=w6ytkBYaIU4) performing for us around the camp fire.\n\nAnd for those of you who are musicians, I implore you to bring some instruments. There will be musical improvisation, led by The Grownup Noise, and we’d love for you to play along with us.\n\nIf you have questions or are interested in sponsorship, please e-mail me at [steven@dockyard.com](mailTo:steven@dockyard.com).\n\nSee you there!\n"},{"title":"Maintaining a session in Phoenix integration tests","tags":["elixir","phoenix","testing"],"summary":"Your server has authentication, and you want to be authenticated in your tests","legacy":false,"id":"2015/06/12/maintaining-session-in-phoenix-integration-tests","employee":"Dan McClain","date":"2015-06-12T00:00:00","body":"\n\nI'm using [Phoenix](http://www.phoenixframework.org) to power the backends for a couple of Ember projects I am\nwriting. For those applications, I've been using OAuth2 + cookie-based sessions\nto authenticate my users. When testing the authentication flow, I wanted\nto make sure that I was properly retrieving my session from the cookie I\npreviously set.\n\n## The hard way (pre Phoenix v0.13)\n\nThe following maintains a session across multiple requests:\n\n```elixir\ntest \"Creating a session with a GitHub code\" do\n  use_cassette \"successful_sign_in\" do\n    response = conn(:post, \"/api/v1/session\", %{ \"authorizationCode\" => \"dan\", \"format\" => \"json\", \"provider\" => \"github-oauth2\" })\n    |> DoorApi.Endpoint.call([])\n\n    assert response.status == 201\n\n    current_session_request = conn(:get,  \"/api/v1/session\")\n\n    current_session_response = response.cookies\n    |> Enum.reduce(current_session_request, fn ({key, value}, conn) -> put_req_cookie(conn, key, value) end)\n    |> DoorApi.Endpoint.call([])\n\n    assert current_session_response.status == 200\n  end\nend\n```\n\nThe above code copies the cookies from the first (completed) request, and\nappends them to the second request. This allows you to retrieve information\nfrom the session returned in the first request.\n\n\n## But wait! There is a better way\n\nWith the release of Phoenix v0.12, new test helpers debuted that allow for the\nconcept of connection recycling.  TL;DR: the new helpers create a new\nconnection with the details of the old, completed connection. We can update our\nfirst example to use the new helpers:\n\n```elixir\ntest \"Creating a session with a GitHub code\" do\n  use_cassette \"successful_sign_in\" do\n    # We call the conn function to get us an initial connection.\n    # From then on, we just pass the result of the last request to the helpers\n    conn = post(conn(), \"/api/v1/session\", %{ \"authorizationCode\" => \"dan\", \"format\" => \"json\", \"provider\" => \"github-oauth2\" })\n\n    assert conn.status == 201\n\n    conn = get(conn, \"/api/v1/session\")\n\n    assert conn.status == 200\n  end\nend\n```\n\nThe helpers remove the need to call our endpoint, and make the code much more concise. This is a huge improvement to testing in Phoenix.\n[You can see a bit more about the helpers in the `Phoenix.ConnTest` documentation](http://hexdocs.pm/phoenix/Phoenix.ConnTest.html)\n"},{"title":"Copy to Clipboard Without Using Flash!","tags":["javascript"],"summary":"\"document.execCommand()\" has now added support for \"copy\" in some browsers","legacy":false,"id":"2015/06/19/copy-to-clipboard-without-using-flash","employee":"Marin Abernethy","date":"2015-06-19T00:00:00","body":"\n\nFor a long time we've had to rely on Flash plugins like [ZeroClipboard](https://github.com/zeroclipboard/zeroclipboard) \nto copy text to the clipboard. While Flash still remains the only cross-browser solution for copying to a user’s clipboard, \nsome browsers have recently added the ability to trigger `cut` and `copy` using `document.execCommand()`! Specifically, \n[IE10+, Chrome 43+, and Opera29+](http://caniuse.com/#search=clipboard%20API). Firefox seems to have some\n[options](http://kb.mozillazine.org/Granting_JavaScript_access_to_the_clipboard) that allow users to grant permissions \nto certain sites to access the clipboard, but I haven't tried it out myself.\n\nFor those of you not familiar with `execCommand()`, it is  more than just `cut` and `copy`! It is one of the core methods\nof rich-text editing in browsers. You can manipulate the contents of the current document, current selection, or a \nspecified range through various commands. Some other common commands include: `bold`, `delete`,  `createLink`, and \n`indent`.\n\n**`execCommand(commandName [, showUI [, value]])`**\n\n  * `commandName` (String): the property that you are validating.\n  * `showUI` (Boolean) *optional*: Display a user interface if the command supports one. Defaults to false.\n  * `value` (DOMString) *optional*: Specifies the string, number, or other value to assign. Possible values\ndepend on the command. Pass an argument of null if no argument is needed.\n\n**Note:** You must set `document.designMode = \"on\"`, or set `contenteditable=\"true\"` on the element that you wish to use `execCommand()` on. \n\nHowever, like `cut` and `copy`, not all commands are enabled across all browsers. I created \nan [Ember JSBin](http://emberjs.jsbin.com/hagupu/5/edit?html,js,output) with a simple WYSIWYG\nto demonstrate some of what `execCommand()` can do. Feel free to play around! \n\nNow to demonstrate how `execCommand` paired with the Selection API can easily copy to a user's clipboard. \nBelow is our HTMLBars with a promo code string that we want to copy.\n\n```hbs\n<p>Promo code: <span class=\"promo-code\">SALE123</span></p>\n<p><button {{action \"copyToClip\"}}>Copy</button></p>\n```\n\nWhen the `Copy` button is clicked, the following action will be called:\n\n```js\ncopyToClip: function() {\n  const promoCode = document.querySelector('.promo-code');\n  const range = document.createRange();  \n  range.selectNode(promoCode);  \n  window.getSelection().addRange(range);\n  document.execCommand('copy'); \n  window.getSelection().removeAllRanges();\n}\n```\n\nIn this action we create a range of the document and add our promo code text as a node of that range. We then \nuse the Selection API method `window.getSelection().addRange()` to add the part of the document we want to copy\nto the user's `selection`. `document.execCommand('copy')` then copies that selection to the clipboard. \nAnd finally, we remove the selection by calling `window.getSelection().removeAllRanges()` so that the user \nnever sees the highlighting.\n\nAnd that's it! If you wanted to confirm everything worked as expected you can examine the response of \n`document.execCommand()`; it returns `false` if the command is not supported or enabled.\n\nYou can check this example out in this [Ember JSBin](http://emberjs.jsbin.com/faqixa/3/edit?html,js,output).\n"},{"title":"Use of color through art history","tags":["user experience","ux design","design","color","art"],"summary":"Part 1 of 4 in the UX color series","legacy":false,"illustration_alt":"Photoshop gradient color picker","illustration":"http://i.imgur.com/C6BX139.jpg","id":"2015/06/25/color-1-art-history","employee":"Maria Matveeva","date":"2015-06-25T00:00:00","body":"\n\n*This post is based on a talk I presented at [UX Burlington](http://uxburlington.com/)*\n\nColor is one of the basic tools for UX design. It is very powerful: it affects us psychologically, physiologically, and, of course, aesthetically. But color selection can be intimidating: with millions of options, designers often feel lost because all the options look equally valid.\n\nIn this series, I will show where color is complex, and then suggest a step—by-step process to make color selection less intimidating.\n\n## Color was not always a thing.\nPeople’s understanding of what color *is* has changed over time. Today, we think of it as a continuous spectrum, consisting of millions of options.\n\n![Photoshop gradient color picker](http://i.imgur.com/C6BX139.jpg)\n\nOur ability to digitally manipulate color contributes to our understanding of it as an infinite space of millions of options.\n\n## Medieval color: paint-by-number\n\nThis was not alway the case. In Medieval Europe, people thought of color as *colors* – separate pigments that are made of different physical materials. Where we might think of two blues as related shades of a single color, medieval artists considered Ultramarine blue and Indigo two separate colors, and never mixed these pigments. In fact, ultramarine - a rare imported pigment - was more expensive than gold. Because of this, colors were rarely mixed (giving a distinct “paint by number” look to illuminated manuscripts) and the expensive pigments were reserved to paint nobility, royalty or holy figures.\n\n![Medieval art can look like paint-by-number](http://i.imgur.com/ZYTgqHn.jpg)\n\n## Vermeer’s color: under contract\n\nIn the 1600s, we start seeing the use of color loosen up a bit. Pigments are no longer reserved for specific use. In this example, the milkmaid by Vermeer, is not royalty. But her dress has the precious ultramarine - and it is mixed and glazed over other color to produce a color effect we would call realistic today. However, the pigment was still very expensive, and the amount of ultramarine to be used in the painting was specified precisely in a contract.\n\n![The Milk Maid by Vermeer](http://i.imgur.com/dqFFYj7.jpg)\n\n\n## Industrial revolution: OMG COLORS!\n\nThe Industrial revolution brought two important innovations to art: synthetic pigments and tube paints. Synthetic pigments started making vibrant colors more available and affordable for artists, and tubes made paint portable for the first time.\n\n![William Perkin’s synthetic mauve color](http://i.imgur.com/UWmb9pz.jpg)\n\nWilliam Perkin’s Mauve was the first synthetic pigment. It allowed a vibrant shade of purple-fuchsia to be applied in a stable manner to fabric and of course to paint. Other pigments followed, and soon there was enough to make art a bit too colorful for some tastes.\n\n![All colorful art in a single graph](http://i.imgur.com/I1VUkov.jpg)\n\nThe invention of paint tubes by Windsor and Newton allowed artists to bring painting outside. So, where before we saw the sky, the trees and the hay their respective “proper” colors, modulated by dark shadows and bright highlights, impressionists started painting from observation and added all kinds of wild atmospheric colors to their hay.\n\n![The HayStacks](http://i.imgur.com/ET5v2Zz.jpg)\n\nAfter impressionism came expressionism. Here, Van Gogh does not show his impression of the way the room looked by using these vibrant, almost “acidic” colors. Instead, he expresses his emotions through how he treats the appearance of the room. By this time, the use of color moves away from realism and towards expressing artistic goals.\n\n![The Red Room - Van Gogh](http://i.imgur.com/FIFalds.jpg)\n\n## 1950s: color is the message\n\nEven farther from references to reality - this 1950s piece by Yves Klein uses color by itself as the message. In fact, the artist patented the chemical process to make this pigment (very similar to a synthetic ultramarine) and made the pigment itself a central part of his artwork for the remainder of his career.\n\n![IK Blue as a monumental art piece](http://i.imgur.com/bGYDuTJ.jpg)\n\n## 1960s: any color you want!\n\nBy the time we get to pop art, the technology behind making pigments has become so advanced that we as consumers became used to expecting any mass produced product to be able to be any color we want. This is why, in pop art, we see the color variations of Warhol’s Marilyn and they seem equally valid. Any color selection, as long as it is intentional, can be as good as any other.\n\n![Warhol’s Marilyn prints](http://i.imgur.com/Jd5v3Le.jpg)\n\n## Where are we now?\n\nIn summary - we went from color being an inseparable, intrinsic part of the material something is made of, to color being a changeable, almost arbitrary attribute of a thing. With seemingly all the possible (digital) colors at our fingertips, it is no wonder we are lost for choice. It is understandable to feel a overwhelmed by the selection.\n\nIn the next post, I will explore the meaning different cultures can give to color.\n"},{"title":"My project for UX Camp summer 2015","tags":["design","pattern","repeat pattern","ux camp","ux east"],"summary":"I'm making repeat patterns. How about you?","legacy":false,"illustration_alt":"My clipboard from UX Camp last year","illustration":"https://i.imgur.com/K9TBWR9.jpg","id":"2015/07/08/my-project-for-ux-camp-2015","employee":"Maria Matveeva","date":"2015-07-08T00:00:00","body":"\n\nI’m super excited to attend (and help organize) this summer’s [UX Camp](http://uxeast.org/). Last fall we had an inspiring, productive weekend and this year I expect even more.\n\nThe camp is a project based weekend, meaning that in addition to talks and workshops, we can all bring a project we want to focus on. Today, I want to share what I tried last fall, how it turned out, and what I’m bringing with me this year.\n\n\n## What I got last year\n\nLast year, I focused on improving my visual thought process through quick sketching. I brought a clipboard, a felt tip marker and a stack of paper, and practiced quickly and roughly sketching out any ideas or notes that I wanted to capture throughout the event. My set-up (clipboard, paper and one pen) was intentionally minimal because I wanted to be able to pick up the project in the breaks between helping run and document the event, and listening to lectures and workshops.\n\n![My clipboard from UX Camp last year](https://i.imgur.com/K9TBWR9.jpg)\n\nThe result was encouraging: I was able to fill about 25 sheets with rough drawings, and got a bit more comfortable capturing my ideas in drawing form, rather than as a list or a paragraph of text.\n\n## What I’m doing this year\n\nThis year, I am hoping to try a slightly more involved project: repeat patterns. It will require a few extra tools, and a bit more space than last year’s.\n\n### The inspiration\n\nI was inspired by Matisse - his paintings and even more, his creative process. He sourced colors and textures for his work from an extensive collection of textiles, artifacts and clothing. I want to create repeat patterns for use online ([an existing interest of mine](https://dockyard.com/blog/2014/07/23/repeat-patterns)) by sourcing color and texture inspiration from Matisse.\n\n![Matisse and his patterns](https://i.imgur.com/PyK5h0F.jpg)\n\n### The tools\n\nTo sketch the patterns, I will bring:\n- Markers in a few colors\n- Sheer marker paper\n- Masking tape (to display my results on a window)\n- A ruler and a pencil\n- Scissors and clear tape to re-combine shapes\n\n### The process\n\nI plan to start with a grid and play with layering patterns on sheer paper to arrive at different solutions. The initial drawings will likely be very messy, but I  expect that the clarity will improve as I work on the same idea a few times.\n\n### The goal\n\nI plan to iterate in public so I can take advantage of the camp setting. While a specific result (pattern) may look good and useful to me, others may offer an unexpected opinion. By showing my work early and getting feedback - even if feedback is anecdotal, like - “*yeah, I might use something like that for a web project*” - I will have the advantage of many people’s perspectives.\n\nSo, here! I’ve shared my plans for camp! My colleagues at DockYard are getting ready as well.\n\n**Tim** is planning to either focus on a typeface he’s been crafting this year, or begin conceptualizing an idea for a live music website.\n\n**Steve** is still undecided about what he’ll focus on in addition to running the camp. (Perhaps, you can [tweet an idea for him](https://twitter.com/uxeast) to work on!)\n\n**Patrick** might finally tackle an infographic he’s been planning to make for [a pumpkin beer review site](http://bumpinpumpkinbeer.com/) he runs, so that he can release it in the fall.\n\n**Amanda** will be working on a future conference talk and learning about animating SVGs.\n\nWhat are you excited to work on? [Share your ideas](https://twitter.com/uxeast) with us!\n"},{"title":"Changing your environment will change your work","tags":["design","creativity","ux camp"],"summary":"Look at expectations, people, and surroundings to help you accomplish that dream project","legacy":false,"id":"2015/07/13/changing-your-environment-post","employee":"Maria Matveeva","date":"2015-07-13T00:00:00","body":"\n\n\n## Environment is key to the way we learn and work\n\nWe often hear stories of genius artists and designers working hard and defying their odds. And while this is certainly an option, I want to talk about the opposite: we have the power to intentionally move into an environment that supports our creative process.\n\nWe often think of “environment” as a physical space, but people and expectations can determine our mental work space regardless of physical location.\n\n## 1. Physical location\n\nIt seems obvious, but the physical location – the room, the set-up, the potential distractions and the familiarity of the space – play an important role. Many creatives choose to work in coffee shops, hotels or other “anonymous” spaces because leaving their home office helps focus on the task at hand. It can be easier to focus against an unfamiliar environment, rather than to focus against an intimately familiar space of your own house – full of potentially distracting things you could do.\n\nIn addition to focus, we can gain inspiration and a fresh perspective from traveling to a new place. These will reflect in the content, as well as the quality of work.\n\n\n## 2. Momentum\n\nStudies show that [people eat more when they have the momentum of eating in a group](https://books.google.com/books?id=RsMNiobZojIC&lpg=PA291&ots=FGHqyv4MMT&dq=people%20eat%20more%20in%20groups%20than%20alone%20study&pg=PA291#v=onepage&q&f=false). For work, too, the momentum of a group doing a similar thing at once can be powerful. Imagine trying to study in a loud dorm room, or focusing on a project while everyone else in your house is doing the normal weekend activities: preparing for a barbecue, watching a favorite TV show or just socializing. Normally, we try to improve our working conditions simply by removing the distractions: getting a quiet place to concentrate, where no TV show is competing for our attention. \n\nWhy not go a step farther? Purposefully placing yourself into an environment where the momentum points toward producing creative work tips the balance in your favor.\n\n\n## 3. Expectations\n\nAnd while we’re on the subject of momentum – just being in an environment where people expect that you’ve showed up to do creative work can support your process. Normally, the first step is to start – to make the decision to work on a creative project right here and right now. In a dedicated time and space, when you have intentionally decided to set aside a weekend for creative work, and made the effort to show up, you are now removing the choice of whether to start on that project or not. The expectations of everyone around you will nudge you forward.\n\nThis is true for many types of environments: dedicated “project work” time in a college class, an art studio where you might attend life drawing sessions, a co-working office space, or even a very supportive office environment when creative projects are encouraged on set-aside time. However, we stumble across fewer and fewer of these environments as our careers progress (when’s the last time you took a college class?), so it is important to purposefully place ourselves in them.\n\n## 4. Feedback\n\nAnother important aspect of a working environment is giving and receiving feedback. It can help you when you feel stuck on a project, but more importantly, it can help you realize things you have not seen from your perspective. Basically, find out that you were stuck without even knowing it.\n\nCreative feedback is a two-way process: in order to receive it, we have to be prepared to give it as well. Investing time to learn about others’ process and goals may feel like a setback when you are eager to make progress on your own ideas, but, aside from being a fair exchange, it’s also beneficial to broaden your frame of reference.\n\nGiving and receiving feedback openly has another advantage. When you expect to share your work in a supportive environment, you’re mentally preparing to explain your project to someone who is unfamiliar with it. Just the effort of translating your thoughts into a clear outline for others to understand can expose potential improvements in the process, and make your work better before you even begin to share it. In a common scenario, you could start explaining a complex bug you’ve been dealing with, then stop halfway with an “aha!” because the explanation caused you to solve the problem yourself.\n\n\n## 5. The nudge\n\nSharing your work, even with a small group of like-minded creative people, can also nudge you to wrap up any loose pieces and present it well. It is often easier to complete some portion of a project, even in draft form, instead of explaining over and over again what you imagine that component to be in the future. \n\nI had this “nudge” happen to me recently, as I was presenting a short talk here at DockYard about an idea I had been working on. I mentioned the domain name I had registered for it, but at the time of the talk, the website was still in draft mode. Brian called me out on that – “there’s nothing there yet!” – and I quickly proceeded to publish the site to be able to support my words when I mention the project again.\n\n\n## In summary\n\nAs we prepare for [UX Camp](http://uxcamp.com/), I realize more and more that the environment we are building is special exactly because it embodies all of the qualities of a supportive working environment. And the type of people who will go out of their way to rural Maine for a project-based learning weekend are exactly the type of people I want to be around.\n"},{"title":"Color and culture","tags":["user experience","ux design","design","color","art"],"summary":"Part 2 of 4 in the UX color series","legacy":false,"illustration_alt":"yellow and blue painted fence","illustration":"https://i.imgur.com/MTiklTJ.jpg","id":"2015/07/15/color-and-culture","employee":"Maria Matveeva","date":"2015-07-15T00:00:00","body":"\n\n*This post is based on a talk I will be presenting at [UX Camp](http://uxcamp.com/) July 18–20, 2015.*\n\nFour posts in this series:\n- [Part 1: Color use in art history](https://dockyard.com/blog/2015/06/25/color-1-art-history)\n- **Part 2: Color in culture - understand your own assumptions** *(you’re reading it!)*\n- *Part 3: A quick intro to color theory (coming soon)*\n- *Part 4: A three-step approach to selecting color for UX design (coming soon)*\n\n## A dangerous color combination\n![yellow and blue painted fence](https://i.imgur.com/MTiklTJ.jpg)\n\nThis was a fence painted blue and yellow. It stood around a kindergarten building in Moscow, Russia early last year. The color of the fence almost caused the kindergarten to be shut down. Because, at about the same time, there was political turmoil between Russia and Ukraine and the fence colors just happened to be a cheery combination of blue and yellow that matched the Ukrainian flag.\n\nAfter the brief scare, the kindergarten was not shut down or burned to the ground. Instead, they simply had to repaint the fence.\n\nThis shows we can’t use colors without understanding their cultural context. Let’s look at some other curious examples of what colors could mean to audiences of differing cultures.\n\n## Did Ancient Greeks care about color?\n![Dark maroon sea photo](https://i.imgur.com/FyimJwL.jpg)\n[Source](https://www.flickr.com/photos/xeubix/2544387679/in/photostream/)\n\nThere are [dozens of references](http://www.nytimes.com/1983/12/20/science/homer-s-sea-wine-dark.html) to a “wine-dark sea” in the Iliad and the Odyssey. But did Homer actually mean that the sea was the same, deep red, color as wine?\n\n![Primary colors arranged from light yellow to dark blue with red in the middle](https://i.imgur.com/Eg5k2Kp.jpg)\n\nNot necessarily. It is still a mystery to historians how exactly color was perceived in ancient Greece. My favorite explanation is that color, meaning hue, did not matter as much as how dark or light an object appeared.\n\n![Umberto Eco color diagram](https://i.imgur.com/ciUZFQG.jpg)\n\nColor systems in Greek, Latin and other languages do not map neatly to the rainbow. Umberto Eco compares the [color terms in the Hanunó'o language](https://books.google.com/books?id=DRd1DZ-5MX0C&lpg=PA168&dq=color%20umberto%20eco%20Hanunoo&pg=PA170#v=onepage&q&f=false) to the ones we use today. Instead of hue, tint and shade, they describe objects as light and dark, but also fresh vs. dry and edible vs. inedible.\n\n## Color is poetry\n![Japanese kimono with layers of colored silk on a print](https://i.imgur.com/JGdn7kd.jpg)\n\nJapan in the Heian period is the opposite of Homer’s Greece. People at court really care about colors. By looking at the arrangement of the layers of silk in someone’s sleeve, you could judge their social status, sophistication, and knowledge of the arts.\n\n## How do you read a color?\n\n### Green\n![Islam, recycling, yes symbols collage](https://i.imgur.com/PaS1pum.jpg)\n\nThe color green is most often used to mean money. It just happens that one of the richest countries in the world prints “greenbacks”. Our green currency is partially due to the plentiful and stable ink that was available at the time, but also related to an earlier Dutch reference: the cloth on bankers’ money counting tables used to be a deep emerald green. Regardless of the source - other countries with much more varied color currencies simply had to adjust to how the US reads “green”.\n\nIn predominantly Muslim countries, a stronger cultural reference for the color green is the religion of Islam.\n\nWhen  we’re talking about natural things, or, say, sourcing construction materials - green stands for ecology and recycling.\n\nAnd, of course, the meaning of green in user interfaces is similar to a traffic light: green is “success”.\n\nLet’s keep going.\n\n### Blue\n![Mary and Krishna and accessible and hyperlink collage](https://i.imgur.com/FPsiodw.jpg)\n\nThe same blue can refer symbolically to Mary’s clothing (the “reserved” color of Ultramarine blue), or the skin of Krishna, and in modern days - to accessibility or web links.\n\n### Red\n![Communism and traditional bride and stop sign](https://i.imgur.com/Jdpj3uv.jpg)\n\nRed is used consistently in traditional bridal-wear, in combination with gold. Politically, red often refers to Communism. In interfaces, the most common use of red is to show an error or a warning (like a stop sign) but I find that in Chinese interfaces, red has much less connection to “error” and is used more freely as an additional brand color.\n\n### Yellow\n![buddhist monks and alert message and school sign](https://i.imgur.com/Ib8Gxgp.jpg)\n\nJust a few examples of “obvious” meanings of yellow: Buddhist monks, alert messages, a school bus, and sunshine.\n\n\n## It’s a mess. Where do we go from here?\n\nSo we’ve seen examples of color meaning that contradict each other (which one to pick?) There are many more. We took time to look at them so that we can be sufficiently scared of misunderstanding our users. This way, we’ll actually do our research.\n\nThe formula is this: add together politics, cultural context, language differences, and how important color is to the audience. This is how you know where to check for mistakes in selecting UI and brand colors. Always check your defaults and assumptions, and you’ll reduce the risk of a cultural #facepalm.\n"},{"title":"Using bare arguments with Ember components","tags":["ember"],"summary":"Positional parameters help you create cleaner APIs for your components","legacy":false,"id":"2015/07/24/using-bare-arguments-with-ember-components","employee":"Dan McClain","date":"2015-07-24T00:00:00","body":"\n\n[`ember-cli-async-button`](https://github.com/dockyard/ember-cli-async-button)\nprovides you with a button that changes state\nbased on a promise in an action. We received a request a while back to allow\nusers to pass parameters to the action the `async-button` calls. We provided\nthe following API for doing so:\n\n```hbs\n{{async-button model action=\"save\" default=\"Save\" pending=\"Saving...\"}}\n```\n\nThe `async-button` calls the following `save` action:\n\n```js\nexport default Ember.Component.extend({\n  actions: {\n    save(callback, model) {\n      callback(model.save());\n    }\n  }\n});\n```\n\nNotice that the callback function is still your first argument, but you get the\nmodel as the second argument now. Prior to Ember 1.13, you had to create a\nhelper which looked through the parameters passed in, and instantiate the\ncomponent, and pass the parameters down. And you had to worry about bindings\nand streams, so this was a bit complicated.\n\n## Positional Parameters\n\n[With the release of Ember\n1.13](http://emberjs.com/blog/2015/06/12/ember-1-13-0-released.html),\ncomponents have a special property called `positionalParams`, which can be an\narray of strings that would translate parameters in the component instantiation\ninto properties on the component.\n\n\n```hbs\n{{x-foo \"Dan\" \"McClain\"}}\n```\n\n```js\n// x-foo component\n\nexport default Ember.Component.extend({\n  positionalParams: ['firstName', 'lastName']\n});\n\n// Retrieving the values\nEmber.get(this, 'firstName'); // => \"Dan\"\nEmber.get(this, 'lastName');  // => \"McClain\"\n```\n\n`\"Dan\"` and `\"McClain\"` would be set as `firstName` and `lastName`,\nrespectively, on the component. You may ask \"What if we want to have an\narbitrary number of parameters passed to our component?\" Well, that's handled\nfor you too! If `positionalParams` is a string, instead of an array, the\nparameters passed to your component will be an array set to that property.\n\n```hbs\n{{x-foo \"Dan\" \"McClain\"}}\n```\n\n```js\n// x-foo component\n\nexport default Ember.Component.extend({\n  positionalParams: 'nameParts'\n});\n\n// Retrieving the values\nEmber.get(this, 'nameParts'); // => [\"Dan\", \"McClain\"]\n```\n\n## Cleaning up `ember-cli-async-button`\n\nWe no longer have to make a helper to clean up our API for `async-button`, and\n[here is the commit where I did\nso](https://github.com/dockyard/ember-cli-async-button/commit/79ce87f01e3244f0e0fa8aff9b4e76f18a5eeed8).\n[I set the `positionalParams`\nhere](https://github.com/dockyard/ember-cli-async-button/commit/79ce87f01e3244f0e0fa8aff9b4e76f18a5eeed8#diff-d6ef0b16dc1a1a16373acd916a9f56f8R9).\n[Note that I removed the helper that we had previously used to provide the same\nAPI](https://github.com/dockyard/ember-cli-async-button/commit/79ce87f01e3244f0e0fa8aff9b4e76f18a5eeed8#diff-e5b0699b77066e62a7221d9735d743c4L1).\nWhen you are creating a component and you want a way to pass parameters\nthat are not explicitly bound to properties, you can now use\n`positionalParams`, and not muck around with helpers and streams just to pass\ninfo into your component!\n"},{"title":"An Existential Redesign","tags":["design","design process","design thinking","business","user experience"],"summary":"Reflections on the experience of creating the new DockYard","legacy":false,"illustration_alt":"The visual evolution","illustration":"https://i.imgur.com/m6qxC6g.jpg","id":"2015/07/27/an-existential-redesign","employee":"Steven Trevathan","date":"2015-07-27T00:00:00","body":"\n![The visual evolution](https://i.imgur.com/m6qxC6g.jpg)\n\n**tl;dr** Particularly in branding oriented design, designing for yourself *really is* much harder than designing for others. Iteration is important, but ensuring you’re iterating in the direction you actually want to be heading is equally (if not more) important.\n\nWhen we started our company repositioning, we knew we had a great, passionate team of designers and engineers together in one office space. We knew that our focus on collaboration would allow us to create something larger than ourselves. The unique story wasn’t that we collaborate, but is more about who we are and why we’re here together. What we’ve come to realize is that everyone, whether they’re a designer, developer, or project manager, is here to deliver the most impactful and delightful user experience they can. Period. Full stop.\n\nCommunicating those goals to everyone outside the walls of the business is the real challenge, however. Boiling down those huge goals that are important to us (the reasons we exist) into something that is consumable and effective for the business is a struggle. Most of the writing felt inaccurate, fluffy, or just purely missed the mark. The same was true for visual communication of that language.\n\nWe’re in the client services industry and that means the messaging is not really about us, our story, or our work. It’s about how we solve problems for the businesses we serve in a way that is long lasting, thorough, and exceedingly performant. This is what our team is able to do, and this is what matters to both our clients and to us. This is where our objectives clearly align with our clients. This is where we found our focus.\n\nI’m very happy with the release of our site and company direction, and I hope you’ll benefit from the detail on the challenges and personal growth we experienced in the process.\n\n## The sawing in the garage\nIt started small, quiet, with hardly any expectation to grow into a project. We were experimenting to see what something more representative of our design process and skill might look like. And what a very big project that became.\n\n![Early sketches in the design process](https://i.imgur.com/BoA1Q9Z.jpg)\n\nInitially, we were in unbound exploration mode using our 20% time (we reserve Fridays for improving craft / professional development) to freely experiment with the design vision for DockYard. Undoubtedly a valuable use of time as it stirred up the realization of our need for a full repositioning, but the actual scope of the project crept up on us fast.\n\nWhen the project became more serious we did not formalize our process as we would have with any of our client projects. This sucked. We wanted it to be perfect and decided we’d spend whatever time we needed to make it so. But, as many of you know, this can become (and was) the enemy of production. We suffered for it, for a period, but the experimentation did lead to something very good. Once we discovered and felt the pains of not running through our own processes, we ate our own dog food and pushed onward with everything we had learned from the experiments.\n\n## Sit down, stand up\nWe followed many paths. Many were really not optimal, even though at times quite beautiful. Only a few actually made any business sense.\n\n- **Illustrate darn near everything**\nThis is one of those reactions to your own work where you feel a little crammed in a box and just want to “do you”. After a couple days of self reflection on this we had to tell ourselves the obvious: we’re designing a site for a product design and development services company, not a game or event promotional site. This served the latter much better than the former, and we moved on after a few iterations that included degrees of illustration use. While beautiful, unique, and fun to experiment with, they didn’t meet our own business goals. It was part of what we do, not **all** we do.\n![Illustrated city over a world of water that contained the rest of the page content](https://i.imgur.com/J9tpLl9.jpg)\n\n- **Patterns**\nSome pattern work was considered for masthead imagery, but ultimately it never communicated anything, so we killed that as well. Perhaps we’ll bring back some patterns in the future, but it’s going to depend on the content of the page. In these cases they felt like mere decoration without reason.\n![An animated grid pattern concept](https://i.imgur.com/SaCLphO.jpg)\n\n- **Photography**\n We relied upon photography pretty heavily for our last site, and perhaps subconsciously we decided we would avoid it for the new site. Because we did, and for a long time. We used some silly photographs here and there that we found as placeholder, but didn’t take the approach seriously until iteration began on the site design you see today.\n![A very silly placeholder photography of an astronaut on fire](https://i.imgur.com/y0eZm7r.jpg)\n\n## Content is hard, people!\nWe knew it wasn’t going to be easy, of course, but then we tried hiring an outside editor to help us improve the content we had created according to our messaging goals. They made a lot of promises, and we framed our project timeline around them. After several disappearances and  excuses, then later finding out that they never made movement on the work, we moved on. We went back to the process we use for every blog post: one owner of the content, and team review on Github or Google Docs.\n\nAside from that, we had created a lot of content over the years, but had deemed it all out of date with our current thinking. So we wrote it all over again. In the process of writing we discovered better branding positioning and a better content strategy.\n\n## Continuous integration\nEmbracing the concept of iteration on a marketing site is actually pretty strange in practice. I’m very used to the experience within application product design and development, but much less so with a site that is supposed to communicate a well formed brand message and is typically considered very static.\n\nBut that message will never be perfect, will it? Putting up a site like ours and planning on iterating on the messaging feels a bit like sending an extremely important e-mail before you had a chance to read over what you had just written. But our site really isn’t that one-and-done static marketing site anymore: it’s to constantly evolve with us and our thinking.\n\nWe treat our releases now like we would any client project. We experiment, collaborate, create timelines, do reviews, and dedicate people to the project full time. This is how we’re able to deliver on client projects, and it’s how we’ll continue to deliver on the DockYard website, events, and other projects.\n\n![An evolution of our logomark](https://i.imgur.com/PtDC6HB.gif)\n\nThe site and brand are a significant improvement over what we’ve had in the past, and they’re a great base for continuous iteration. Content, photography, illustration, and even branding will evolve with much greater ease here, and that makes me very excited for what’s to come."},{"title":"Taking Advantage of Time Limitations In Design","tags":["design","design process","design thinking","user experience"],"summary":"Three simple practices for designing in a limited amount of time","legacy":false,"id":"2015/07/31/taking-advantage-of-time-limitations-in-design","employee":"Patrick Branigan","date":"2015-07-31T00:00:00","body":"\n\nThere may not be a larger, more persistent constraint in design than the notion of time. Time haunts us with its impact on our projects. There exists a constant struggle to come to terms with the fact that time is never going to be on our side. How often do we find ourselves saying, “If only I had more time…”? \n\nOne of the primary effects of time on design is its ability to force a result. The limiting nature of time forces us to be persistent and show progress. Yet persistence and progress are important parts of creating meaningful work. Designers need to focus on how to best use time we’re allotted because we don’t seem to notice just how beneficial time can be when it’s limited.\n\nThe following three practices can always help in delivering a successful design. They add clarity to your work but are especially valuable in the sense that they don’t require a massive amount of time in the design process.\n\n## The grid\nA grid can be constructed promptly and is very flexible in solving our visual design goals. Grids allow us to control the proximity of elements, therefore providing balance, arrangement and other visual suggestion to users. For a user, this can make a design attractive. How attractive something is, regardless of its usability, will inevitably leave a positive impression on users. This is loosely derived from a principle known as the aesthetic-usability effect. Content is an important driver in design but the grid assists in providing clarity and consistency in digesting content. \n\n## Design patterns\nThe ability to dictate color, shape, size and behavior of elements means we can create design patterns that are easy to repeat, and assist the user in interacting with and understanding a design. Our ability to quickly reuse patterns saves us time in the design process. Remember that users are humans – they’re creatures of habit. Patterns allow users to become easily acclimated to a design. Patterns will also allow users to manufacture habits of interaction and recognition. \n\n## Consistency\nReuse core interactions in a design’s micro experiences. This will build consistency in a design and can increase users’ engagement and comfort. Where patterns allow for habitual experiences, consistency allows for predictability, smoothness and comfort in experiences. Consistency will not only keep your users happy but will often encourage them to represent your experience to others in a positive light.\n\nThe next time you find your time is limited, play to the advantage of the user by focusing on practices like these that help maintain quality and focus and directly impact your users’ experiences. Your end result will be more likely to satisfy the goals you’ve set within the limited time you have.\n"},{"title":"Paving Desire Paths","tags":["design","design thinking","user experience","observations"],"summary":"Recognizing preferred interactions of users","legacy":false,"illustration_alt":"A desire path","illustration":"https://i.imgur.com/HCN4mDr.jpg?1","id":"2015/08/03/paving-desire-paths","employee":"Tim Walsh","date":"2015-08-03T00:00:00","body":"\n\n![A desire path](https://i.imgur.com/HCN4mDr.jpg?1)\n\n<a href=\"https://flic.kr/p/5kDxUt\">Desire path</a> by <a href=\"https://flic.kr/ps/2gcpv7\">wetwebwork </a> is licensed under <a href=\"http://creativecommons.org/licenses/by/2.0/\">CC BY 2.0</a>\n\nI recently came across the term Desire Paths while reading <a href=\"http://amzn.com/1592535879\">The Universal Principles of Design</a>. Desire Paths are signs of use or wear indicating a preferred method of interaction. Most often they can be seen as shortcuts or diversions from the expected route. Some have clear intentions, like the picture shown above. This one in particular provides a direct route to the other side of the park. \n\nDesire paths are helpful in understanding users. They provide unbiased, concrete evidence into users’ preferred activity. But they also serve as a reminder about how we may have assumed their activity incorrectly. \n\nLet’s consider this scenario. You are a park planner. Your job involves figuring out where the trees, benches, and other park related objects go. Your goal is to have people use and interact with the park. Adding paths seems like a direct means to accomplish this objective. “I add paths, and people will use them to get where they need to go.” This follows a sort of “build it and they will come” logic.\n\nHowever this is not the best practice. What the park planner lacks in this scenario is any insight from users. Are the paths they're designing really the best, most efficient routes through the park? Is that what users are even after? Maybe users simply want to meander and walk leisurely. Or maybe they use it for running. In any case, the park planner likely forgot to holistically consider the user base.\n\nImagine instead they had planted grass and trees and waited a year or so for users to interact with the park. The result would be a network of natural paths created and defined by users. At this point, the park planner could then pave all the paths, feeling confident that the decisions were justified. This method of design is not only efficient, it is also affordable. A little bit of research can save on both time and money, all while creating a better experience.  \n\nDesire paths are a design principle that can be applicable to any industry. Let’s take a look at Twitter. During its humble beginnings Twitter was a pretty basic service, offering not much besides a stream of updates from your friends. Over time, Twitter noticed some unexpected trends appearing in their service. People who wanted to reply to someone else would simply direct it at them with an @ symbol and then enter the user's name. (i.e. @Bill). As more people began doing this, Twitter began to take notice, eventually integrating it into the service. The same thing happened with hashtags and group discussions. \n\nWhat Twitter did correctly was first come up with a solid concept and deploy it, paying close attention to their user base. They provided the infrastructure, then sat back and watched as people used it to their liking. From this, natural trends began to emerge, paths became visible, and soon features were being defined - not by the service, but by the users.\n\nThis is precisely the value of desire paths. They can reveal better solutions for users. Ones that weren’t even considered in the first place. So take note of desire paths, learn from them, and build on top of them. It’s your users talking, time to listen. \n"},{"title":"Building json-api endpoints with Phoenix","tags":["elixir","phoenix","ember"],"summary":null,"legacy":false,"id":"2015/08/05/building-json-api-endpoints-with-phoenix","employee":"Brian Cardarella","date":"2015-08-05T00:00:00","body":"\n\nI'm currently building a [Phoenix](http://www.phoenixframework.org/) backend API that is being consumed by\n[Ember Data\n1.13](http://emberjs.com/blog/2015/06/18/ember-data-1-13-released.html) which uses [JSON API](http://jsonapi.org/). Here is how I \nhooked everything up.\n\n## Configuration\n\nYou first need to tell Phoenix that it should accept `json-api` format.\nI created a new\n[`pipeline/2`](http://hexdocs.pm/phoenix/Phoenix.Router.html#pipeline/2)\nfor the API:\n\n```elixir\n# web/router.ex\n\npipeline :api do\n  plug :accepts, [\"json-api\"]\nend\n```\n\nWe next need to add the corresponding MIME type:\n\n```\n# config/config.exs\n\nconfig :plug, :mimes, %{\n  \"application/vnd.api+json\" => [\"json-api\"]\n}\n```\n\nNow we have to force Plug to recompile. To do this we have to `touch` a\nfile in the dependency. This may seem a little odd but the [documentation\nrecommends this](https://github.com/elixir-lang/plug/blob/0118337b990aa2109a7b9152ea1e244a37c7dd07/lib/plug/mime.ex#L5-L16).\n\n`> touch deps/plug/mix.exs`\n\n`> mix deps.compile plug`\n\nI like to namespace my APIs so I created a scope and piped it through my\n`api` pipeline:\n\n```elixir\n# web/router.ex\n\nscope \"api/v1\", MyApp do\n  pipe_through :api\nend\n```\n\nI declare all of my API routes in that scope.\n\n## Emitting\n\nTo emit json-api responses I am currently using\n[ja\\_serializer](https://github.com/AgilionApps/ja_serializer). The\nauthor has indicated that some big changes are likely to better align\nwith Phoenix conventions but for now this is the only serializer I am\naware of. The README explains how to serialize, it is pretty simple. For\nexample, to serialize a collection form an `index` action:\n\n```elixir\ndef index(conn, _) do\n  foos = Repo.all(Foo)\n  |> MyApp.FooSerializer.format(conn)\n\n  json(conn, foos)\nend\n```\n\nYou may wish to use Views but I've opted not to.\n\nThe serializer itself would look like:\n\n```\n# serializers/foo_serializer.ex\n\ndefmodule MyApp.FooSerializer do\n  use JaSerializer\n\n  serialize \"foo\" do\n    attributes [\n      \"name\",\n      \"description\"\n    ]\n  end\nend \n```\n\nYou can embed relationships as well, check out the project for more\ndeatils.\n\n## Consuming\n\nEmber Data not only expects to get JSON API format but also sends JSON\nAPI format back to the server when you are creating or updating. The\nattributes keys come in hyphenated and everythig is nested under `\"data\" =>\n\"attributes\"`. Here is how I made life easier for mmyself.\n\nI first wrote a new plug that deserializes all params that are coming in\nby forcing hyphenated keys to underscore format. It works recursively on\nall keys and produces a new params object that is Phoenix friendly. Here\nis the code:\n\n```elixir\n# web/plugs/deserialize.ex\n\ndefmodule MyApp.DeserializePlug do\n  def init(options) do\n    options\n  end\n\n  def call(%Plug.Conn{params: %{\"format\" => \"json-api\"}, method: \"POST\"}=conn, _opts) do\n    result = _deserialize(conn)\n  end\n\n  def call(%Plug.Conn{params: %{\"format\" => \"json-api\"}, method: \"PUT\"}=conn, _opts) do\n    _deserialize(conn)\n  end\n\n  def call(%Plug.Conn{params: %{\"format\" => \"json-api\"}, method: \"PATCH\"}=conn, _opts) do\n    _deserialize(conn)\n  end\n\n  def call(conn, _opts), do: conn\n\n  defp _deserialize(%Plug.Conn{}=conn) do\n    Map.put(conn, :params, _deserialize(conn.params))\n  end\n\n  defp _deserialize(%{}=params) do\n    Enum.into(params, %{}, fn({key, value}) -> { _underscore(key), _deserialize(value) } end)\n  end\n\n  defp _deserialize(value), do: value\n  defp _underscore(key), do: String.replace(key, \"-\", \"_\")\nend\n```\n\nI then added this custom plug to my `api` pipeline:\n\n```elixir\n# web/router.ex\n\npipeline :api do\n  plug :accepts, [\"json-api\"]\n  plug MyApp.DeserializePlug\nend\n```\n\nNext, JSON API's schema is verbose and I didn't want to have to deal with this in my actions,\nElixir's pattern matching is perfect for this. I capture all the\nattributes into `params`:\n\n```elixir\ndef create(conn, %{\"data\" => %{\"attributes\" => params}, \"type\" => \"json-api\"}) do\n  # create action now has\n  # a \"params\" object with all the\n  # attribute date from the client request\nend\n```\n\nWe can even guard the action for JSON API specific types.\n\n## Conclusion\n\nGetting JSON API working with Phoenix takes a few hoops to jump through, but\nhopefully this helps you get up and running.\n"},{"title":"Suave Up Your Code","tags":["ember","javascript","addon"],"summary":null,"legacy":false,"illustration_alt":"code quality","illustration":"http://imgs.xkcd.com/comics/code_quality.png","id":"2015/08/07/suave-up-your-code","employee":"Estelle DeBlois","date":"2015-08-07T00:00:00","body":"\n\n> /swäv/\n> \"Smooth in texture, performance, or style\"\n\nYou may have heard of this thing called [`ember-suave`](https://github.com/dockyard/ember-suave). It's a handy Ember CLI addon that [Robert Jackson](https://twitter.com/rwjblue) and I put together a few months ago to enforce code style consistency across teams and projects. _If you're wondering how the addon got its name, just ask Rob. He was feeling inspired that day._\n\n`ember-suave` uses [JSCS](http://jscs.info/) to ensure that your code conforms to a set of code style rules, and fails your tests if it doesn't.\n\nUnlike [JSHint](http://jshint.com/), which aims to detect errors and potential problems in your JavaScript code, JSCS is a code style linter. In other words, it is the tool you need to make sure all those hearty debates on tabs vs. spaces don't go to waste, and that whatever style guide you managed to settle on within your team can be enforced and maintained.\n\n![code quality](http://imgs.xkcd.com/comics/code_quality.png)\n\n## The first rule of `ember-suave` is to install `ember-suave`\n\nWith JSCS, you control which rules to enable within a project by specifying the rule names and options in a `.jscsrc` file, which may look something like this:\n\n```json\n{\n  \"esnext\": true,\n  \"disallowSpacesInsideParentheses\": true,\n  \"disallowTrailingComma\": true,\n  \"requireBlocksOnNewline\": true,\n  \"validateIndentation\": 2\n}\n```\n\nAssuming you're adhering to a single style guide for all your projects, the configuration would be the same everywhere. `ember-suave` exists so you don't have to recreate and maintain that file in every project. The addon comes bundled with a default configuration file that's nicely tucked away within the addon itself so you don't have to muck with it.\n\nUsing the addon consists simply of running `ember install ember-suave`, then monitoring your console for error messages during development.\n\n`ember-suave` also creates a test for each file it finds in your project, so that you can enforce the code style rules as part of your continuous integration flow, and fail any builds that don't comply.\n\n## You don't rule `ember-suave`. `ember-suave` rules you.\n\nActually, that's not exactly true. The addon was made to be quite configurable.\n\nYou can use it as is, or you can tweak which rules to enable or disable. To configure `ember-suave`, simply create a `.jscsrc` file at the root of your project, listing just those rules that you want to modify. The addon will take care of merging your custom configuration with its own. For example, the following `.jscsrc` file would set a different indentation style from the default of 2 spaces. It would also disable the `requireSpaceBetweenArguments` rule and instruct JSCS to ignore all the files in the `fixtures` folder:\n\n```json\n{\n  \"validateIndentation\": 4,\n  \"requireSpaceBetweenArguments\": null,\n  \"excludeFiles\": [\"fixtures/**\"]\n}\n```\n\n## Need more suaveness?\n\nIf you have a particular code style need but no rule exists in JSCS yet, you can easily roll your own. In fact, `ember-suave` ships with a few [custom rules](https://github.com/dockyard/ember-suave/tree/master/lib/rules) already. Let's take a look at the rule that disallows the use of `var`, preferring `const` and `let` instead:\n\n```js\n// lib/rules/disallow-var.js\nvar assert = require('assert');\n\nmodule.exports = function() {};\n\nmodule.exports.prototype = {\n  configure: function(option) {\n    assert(option === true, this.getOptionName() + ' requires a true value');\n  },\n\n  getOptionName: function() {\n    return 'disallowVar';\n  },\n\n  check: function(file, errors) {\n    file.iterateNodesByType('VariableDeclaration', function(node) {\n      node.declarations.forEach(function(declaration) {\n        if (declaration.parentNode.kind === 'var') {\n          errors.add('Variable declarations should use `let` or `const` not `var`', node.loc.start);\n        }\n      });\n    });\n  }\n};\n```\n\nA rule will always have these three methods: `configure`, `getOptionName`, and `check`.\n\n* `getOptionName` is self-explanatory.\n\n* `configure` is where you assert that a rule has been configured properly in a given `.jscsrc` file. For example, this would not pass the assert, since the value has to be `true`:\n\n```json\n{\n  \"disallowVar\": \"Feeling suave today!\"\n}\n```\n\n* `check` is where all the magic happens. Any given file would first get parsed by JSCS into an AST (Abstract Syntax Tree) before you can analyze its content. You can use the `file` object that is passed into the `check` function to iterate over specific nodes of the tree. For this custom rule, we are looking for any variables that were declared using `var`. If such a declaration is found, we add to the errors object, passing in an error message and the position of the offending code. This is what you would see in the console if you tried using `var`:\n\n```\ndisallowVar: Variable declarations should use `let` or `const` not `var` at router.js :\n     2 |import config from './config/environment';\n     3 |\n     4 |var Router = Ember.Router.extend({\n--------^\n     5 |  location: config.locationType\n     6 |});\n```\n\nConfused about the node types and what to look for? It's actually not very complicated. You can navigate over to [Esprima](http://esprima.org/demo/parse.html), the parser used by JSCS, enter a code snippet into the [Online Parsing Tool](http://esprima.org/demo/parse.html), and see what the corresponding tree looks like.\n\nFor instance, `var color = 'blue';` will generate the following syntax tree:\n\n```json\n{\n  \"type\": \"Program\",\n  \"body\": [\n    {\n      \"type\": \"VariableDeclaration\",\n      \"declarations\": [\n        {\n          \"type\": \"VariableDeclarator\",\n          \"id\": {\n            \"type\": \"Identifier\",\n            \"name\": \"color\"\n          },\n          \"init\": {\n            \"type\": \"Literal\",\n            \"value\": \"blue\",\n            \"raw\": \"'blue'\"\n          }\n        }\n      ],\n      \"kind\": \"var\"\n    }\n  ]\n}\n```\n\nNow you can see why we were checking for nodes of type `VariableDeclaration`, and why we checked whether they were declared with `var` using `declaration.parentNode.kind === 'var'`.\n\nYou can also refer to the many [rules](https://github.com/jscs-dev/node-jscs/tree/master/lib/rules) that already exist in JSCS as you write your own.\n\n## Conclusion\n\n`ember-suave` started as an internal need at DockYard to enforce our [style guide](https://github.com/dockyard/styleguides/blob/master/javascript.md) in a painless, automatable way.\n\nThat said, the addon was built such that anyone can take advantage of the tool. If you start a new Ember CLI project, I recommend you check it out. And if you're thinking of dropping it into an existing project, but fear that the sheer amount of potential error messages would be too time-consuming to address all at once, you can always start by disabling all the rules, then re-enable them one rule at a time. Or you could exclude specific folders; whatever helps bring more suaveness to your code.\n"},{"title":"Polymorphic URLs in Ember","tags":["ember","javascript"],"summary":null,"legacy":false,"id":"2015/08/08/polymorphic-urls-in-ember","employee":"Brian Cardarella","date":"2015-08-08T00:00:00","body":"\n\nEmber makes it easy to consume polymorphic records, assuming you have\nthe following data retrieved from your server:\n\n```json\n{\n  \"data\": [\n    {\n      \"id\": 1,\n      \"type\": \"hooman\",\n      \"relationships\": {\n        \"pet\": {\n          \"data\": {\n            \"type\": \"cat\",\n            \"id\": 1\n          }\n        }\n      }\n    }, {\n      \"id\": 2,\n      \"type\": \"hooman\",\n      \"relationships\": {\n        \"pet\": {\n          \"data\": {\n            \"type\": \"dog\",\n            \"id\": 3\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\nLet's put aside my contrived data model for a minute, the point is that\nin this set the `pet` relationship for the `hooman` can be of type\n`cat` or `dog`. We can handle this in Ember Data by first\ncreating a `pet` model:\n\n```js\nimport DS from 'ember-data';\n\nconst {\n  attr,\n  belongsTo,\n  Model\n} = DS;\n\nexport default Model.extend({\n  name: attr('string'),\n  hooman: belongsTo('hooman') \n});\n```\n\nThen in the `hooman` model:\n\n```js\nimport DS from 'ember-data';\n\nconst {\n  attr,\n  belongsTo,\n  Model\n} = DS;\n\nexport default Model.extend({\n  pet: belongsTo('pet', { polymorphic: true })\n});\n```\n\nThis will instruct the relationship to look at the `type` property to\ndetermine the model type. You can then access through the `pet`\nproperty:\n\n`get(hooman, 'pet') // <cat-model>`\n\nOk, this was probably review for some people. I recently ran into an\nissue where I needed to do a `link-to` for a polymorphic relationship. Using\nour same example, I would have done:\n\n```hbs\n{{link-to hooman.pet.name 'pet' hooman.pet}}\n```\n\nThe router would be setup as:\n\n```js\n// you should make this one of the last routes\nthis.route('pet', { path: '/:pet_type/:pet_id' });\n```\n\nWhen we are using `link-to` there really isn't an issue as Ember will\njust use the model passed in as the model. But we want a nicely\nformatted URL. Ideally if we are passing in a `cat` pet we would\nend up with the url: `/cats/2` and if we are passing in a `dog`\npet we'd get `/dogs/5` and both would be processed by the `pet`\nroute and template (of course we'd have to make sure they both respond\nto the same properties).\n\nTo get this we can override the\n[`serialize`](http://emberjs.com/api/classes/Ember.Route.html#method_serialize) function in our `pet`\nroute. `serialize` is used to parse information out of your model to\nrender the URL associated. It is simple enough to do what we want:\n\n```js\nimport Ember from 'ember';\n\nconst {\n  get,\n  Route\n} = Ember;\n\nexport default Route.extend({\n  serialize(model) {\n    return {\n      pet_type: model.constructor.modelName,\n      pet_id: get(model, 'id')\n    };\n  }\n});\n```\n\nNow the `link-to` will render how we'd expect. Well, mostly. With this\nwe end up with singular route names: `/dog/5` instead of `/dogs/5` for\nexample. We need to pluralize.\n\nBecause we're using Ember Data the\n[ember-inflector](https://github.com/stefanpenner/ember-inflector) library is pulled\nin automatically. Let's use that:\n\n```js\nimport Ember from 'ember';\n\nconst {\n  get,\n  Route,\n  String: { pluralize }\n} = Ember;\n\nexport default Route.extend({\n  serialize(model) {\n    return {\n      pet_type: pluralize(model.constructor.modelName),\n      pet_id: get(model, 'id')\n    };\n  }\n});\n```\n\nNow we get `/dogs/5`. If you are using a different type that does not\npluralize nicely (for example `person` => `persons` instead of `people`)\nthen check out the [ember-inflector README for details on how to add the\npluralized types you\nneed](https://github.com/stefanpenner/ember-inflector).\n\nThis is great, except if someone visits the URL directly instead of\nclicking on a link. Let's add support for that.\n\n```js\nimport Ember from 'ember';\n\nconst {\n  get,\n  Route,\n  String: { pluralize, singularize }\n} = Ember;\n\nexport default Route.extend({\n  model(params) {\n    return this.store.find(singularize(params.pet_type), params.pet_id);\n  },\n  serialize(model) {\n    return {\n      pet_type: pluralize(model.constructor.modelName),\n      pet_id: get(model, 'id')\n    };\n  }\n});\n```\n\nThere we go! Because the URL segment was pluralized we used\n`singularize` to force the type back to what the `store` expects. I hope\nthis helps you.\n"},{"title":"Applying the Adapter Pattern for Analytics","tags":["ember","addon","javascript"],"summary":"Send data to multiple analytics integrations without re-implementing new API.","legacy":false,"illustration_alt":"I heard you like adapters","illustration":"http://i.imgur.com/VpAAHrw.jpg","id":"2015/08/10/ember-metrics","employee":"Lauren Tan","date":"2015-08-10T00:00:00","body":"\n\nAt DockYard, most (if not all) Ember apps we build for our clients require analytics in some form or other. For many of these apps, simply including the Google Analytics tracking script is sufficient. However, we're noticing an increased interest in other analytics services such as Mixpanel or Kissmetrics for the more data minded clients.\n\nIncluding multiple services (typically we see about 3–5 different analytics in use) with different APIs leads to a lot of code duplication, which is less than ideal, and is generally a maintenance nightmare. I don't know about you, but deleting repetitive code is one of my favorite things to do — so [Michael](https://twitter.com/michaeldupuisjr) and I set out to build an Ember addon that would apply the adapter pattern to analytics.\n\nIn this post, we'll explore what the adapter pattern gives us, and demonstrate how to implement it in an easily extensible Ember addon so we can use one API to orchestrate multiple analytics services.\n\n## Introducing the ember-metrics addon\n\nTo install the addon:\n\n```sh\n$ ember install ember-metrics\n```\n\nYou can also find the [source on GitHub](https://github.com/poteto/ember-metrics).\n\nThe ember-metrics addon adds a simple metrics service and customized `LinkComponent` to your app that makes it simple to send data to multiple analytics services without having to implement a new API each time.\n\nUsing this addon, you can easily use bundled adapters for various analytics services, and one API to track events, page views, and more. When you decide to add another analytics service to your stack, all you need to do is add it to your configuration, and that's it.\n\nWith this addon, we wanted to make it super simple to write your own adapters for other analytics services too, so we set out to make it extensible and easily tested.\n\n## What is the Adapter Pattern?\n\n![I heard you like adapters](http://i.imgur.com/VpAAHrw.jpg)\n\nIn a broad sense, the adapter pattern is about adapting between class and objects. Like its real world counterpart, the adapter is used as an interface, or bridge, between two objects.\n\nIn the case of analytics, this is an excellent pattern for us to implement, because these services all have different APIs, but very similar intent. For example, to send an event to Google Analytics, you would use the analytics.js library like so:\n\n```js\n/** \n * Where:\n * button is the category\n * click is the action\n * nav buttons is the label\n * 4 is the value\n*/\nga('send', 'event', 'button', 'click', 'nav buttons', 4);\n```\n\nWhile in Mixpanel, you would track the same event like this:\n\n```js\nmixpanel.track('Clicked Nav Button', { value: 4 });\n```\n\nAnd with Kissmetrics:\n\n```js\n_kmq.push(['record', 'Clicked Nav Button', { value: 4 }]);\n```\n\nAs you can probably tell, this gets repetitive really quickly, and becomes hard to maintain when your boss or client wants to update something as simple as the event name across these services.\n\n## Applying the Adapter Pattern\n\n![Diagram from https://sourcemaking.com/design_patterns/adapter](http://i.imgur.com/azNt3ri.png)\n\nWe generally have a few players in the adapter pattern: the client, the adapter (or wrapper), and the adaptee.\n\nFor ember-metrics, the client is our `Ember.Service`, the adapter is the adapter created for each analytics service, and the adaptee is the analytics library's API.\n\nEach analytics service has its own adapter that implements a standard contract to impedance match the analytics library's API to the `Ember.Service` that is responsible for conducting all of the analytics in unison.\n\n## Using ember-metrics\n\nThe addon is first setup by configuring it in `config/environment`, then injected into any Object registered in the container that you wish to track.\n\n```js\nmodule.exports = function(environment) {\n  var ENV = {\n    metricsAdapters: [\n      { name: 'GoogleAnalytics', config: { id: 'UA-XXXX-Y' } },\n      { name: 'Mixpanel', config: { token: 'xxx' } }\n    ]\n  }\n}\n```\n\nThen, you can call a `trackPage` event across all your analytics services like so, using the `metrics` service:\n\n```js\nimport Ember from 'ember';\n\nexport default Ember.Route.extend({\n  metrics: Ember.inject.service(),\n\n  activate() {\n    this._trackPage();\n  },\n\n  _trackPage() {\n    Ember.run.scheduleOnce('afterRender', this, () => {\n      const page = document.location.href;\n      const title = this.routeName;\n\n      get(this, 'metrics').trackPage({ page, title });\n    });\n  }\n});\n```\n\nIf you wish to only call a single service, just specify its name as the first argument:\n\n```js\n// only invokes the `trackPage` method on the `GoogleAnalyticsAdapter`\nmetrics.trackPage('GoogleAnalytics', { title: 'My Awesome App' });\n```\n\nThis is clearly a much cleaner implementation, as we can now use one API to invoke across all services we want to use in our app.\n\n## Implementing the Adapter Pattern in ember-metrics\nThe service `metrics` is the heart of the addon, and is responsible for orchestrating event tracking across all analytics that have been activated.\n\n### Setting up addon configuration\nA simple pattern for passing configuration from the consuming app's `config/environment` to the addon is through an initializer:\n\n```js\nimport config from '../config/environment';\n\nexport function initialize(_container, application) {\n  const { metricsAdapters = {} } = config;\n\n  application.register('config:metrics', metricsAdapters, { instantiate: false });\n  application.inject('service:metrics', 'metricsAdapters', 'config:metrics');\n}\n\nexport default {\n  name: 'metrics',\n  initialize\n};\n```\n\nThis lets us access the configuration POJO from within the metrics service by retrieving the `metricsAdapter` property when the service is created.\n\n```js\nimport Ember from 'ember';\n\nexport default Ember.Service.extend({\n  _adapters: {},\n\n  init() {\n    const adapters = Ember.getWithDefault(this, 'metricsAdapters', Ember.A([]));\n    this._super(...arguments);\n    this.activateAdapters(adapters);\n  },\n\n  activateAdapters(adapterOptions = []) {\n    const cachedAdapters = Ember.get(this, '_adapters');\n    const activatedAdapters = {};\n\n    adapterOptions.forEach((adapterOption) => {\n      const { name } = adapterOption;\n      let adapter;\n\n      if (cachedAdapters[name]) {\n        warn(`[ember-metrics] Metrics adapter ${name} has already been activated.`);\n        adapter = cachedAdapters[name];\n      } else {\n        adapter = this._activateAdapter(adapterOption);\n      }\n\n      Ember.set(activatedAdapters, name, adapter);\n    });\n\n    return Ember.set(this, '_adapters', activatedAdapters);\n  }\n});\n```\n\nWith the retrieved configuration, we then call the service's `activateAdapters` method in order to retrieve the adapter(s) from the addon or locally, then caching them in the service so they can be looked up later easily.\n\nActivating an adapter simply calls `create` on the looked up adapter (which inherits from `Ember.Object`) and passes along any analytics specific configuration such as API keys.\n\n```js\n_activateAdapter(adapterOption = {}) {\n  const metrics = this;\n  const { name, config } = adapterOption;\n\n  const Adapter = this._lookupAdapter(name);\n  assert(`[ember-metrics] Could not find metrics adapter ${name}.`, Adapter);\n\n  return Adapter.create({ metrics, config });\n}\n```\n\nBecause we've also implemented caching, we can safely call `activateAdapters` without having to re-instantiate already activated adapters, which allows us to defer the initialization of these analytics if (for example) we need to dynamically retrieve a property from one of our models:\n\n```js\nimport Ember from 'ember';\n\nexport default Ember.Route.extend({\n  metrics: Ember.inject.service(),\n  afterModel(model) {\n    const metrics = Ember.get(this, 'metrics');\n    const id = Ember.get(model, 'googleAnalyticsKey');\n\n    metrics.activateAdapters([\n      { name: 'GoogleAnalytics', config: { id } }\n    ]);\n  }\n});\n```\n\n### Leveraging the container and resolver\nThen, leveraging the Ember container and conventions around the [ember-resolver](https://github.com/ember-cli/ember-resolver), we can lookup adapters from the addon first, and then fallback to locally created adapters.\n\n```js\n_lookupAdapter(adapterName = '') {\n  const container = get(this, 'container');\n\n  if (isNone(container)) {\n    return;\n  }\n\n  const dasherizedAdapterName = dasherize(adapterName);\n  const availableAdapter = container.lookupFactory(`ember-metrics@metrics-adapter:${dasherizedAdapterName}`);\n  const localAdapter = container.lookupFactory(`metrics-adapter:${dasherizedAdapterName}`);\n  const adapter = availableAdapter ? availableAdapter : localAdapter;\n\n  return adapter;\n}\n```\n\n### Invoking adapter methods from the service\nNow that our service can access both local and addon adapters, we can invoke methods across activated adapters like so:\n\n```js\nidentify(...args) {\n  this.invoke('identify', ...args);\n},\n\nalias(...args) {\n  this.invoke('alias', ...args);\n},\n\ntrackEvent(...args) {\n  this.invoke('trackEvent', ...args);\n},\n\ntrackPage(...args) {\n  this.invoke('trackPage', ...args);\n},\n\ninvoke(methodName, ...args) {\n  const adaptersObj = get(this, '_adapters');\n  const adapterNames = Object.keys(adaptersObj);\n\n  const adapters = adapterNames.map((adapterName) => {\n    return get(adaptersObj, adapterName);\n  });\n\n  if (args.length > 1) {\n    let [ adapterName, options ] = args;\n    const adapter = get(adaptersObj, adapterName);\n\n    adapter[methodName](options);\n  } else {\n    adapters.forEach((adapter) => {\n      adapter[methodName](...args);\n    });\n  }\n}\n```\n\n## Creating Adapters for the Addon\nWith the service implemented, we can now create a [base adapter class](https://github.com/poteto/ember-metrics/blob/0.1.2/addon/metrics-adapters/base.js) that all adapters extend from. This is mainly so we can assert that the adapter's `init` and `willDestroy` hooks are implemented, and to give it a nicer output in the console through overriding the `toString` function.\n\nIf you're not already familiar with the Ember Object model, the `init` method is called whenever an `Ember.Object` is instantiated through `Ember.Object.create()`.\n\nWe can thus rely on this knowledge that `init` will always be called on object instantiation to pass in configuration to the analytics, and to call its setup. Typically, an analytics service will create a script tag through JavaScript, and asynchronously load its library from some CDN.\n\nFor example, here's the [Google Analytics adapter](https://github.com/poteto/ember-metrics/blob/0.1.2/addon%2Fmetrics-adapters%2Fgoogle-analytics.js) that's bundled with the addon.\n\n### Enhancing the developer experience with blueprints\nOne of my favorite parts of ember-cli are its generators. Using blueprints, we can easily extend the cli commands to generate new metrics adapters using:\n\n```sh\n$ ember generate metrics-adapter foo-bar\n```\n\nThis creates `app/metrics-adapters/foo-bar.js` and a unit test at `tests/unit/metrics-adapters/foo-bar-test.js`. You can take a closer look at these blueprints [here](https://github.com/poteto/ember-metrics/tree/0.1.2/blueprints).\n\nWith these conventions in place, it's now trivial for consuming app developers to add new adapters to work alongside bundled adapters. And when they feel that an adapter they've built is ready to be shared with the community, they only need open a pull request to have that adapter included in the addon.\n\nAt some point in the future, it would make sense for each adapter to have its own repo and npm module, but to keep things simple, we've placed them within the addon.\n\nNow we can easily send data to multiple analytics integrations through one API, DRYing up our code and making it more maintainable.\n\n*This post also appears on [Medium in longform](https://medium.com/the-ember-way/applying-the-adapter-pattern-for-analytics-in-ember-js-apps-29448cbcedf3).*\n"},{"title":"Design sprints: what are they for?","tags":["business","design","design process","discovery","planning","process","workflow"],"summary":"Comparing how Design Sprints and Design Discovery can benefit your business","legacy":false,"illustration_alt":"A design sprint is like shining a focused flashlight","illustration":"https://i.imgur.com/weKPZFU.jpg","id":"2015/08/17/design-sprints-what-are-they-for","employee":"Maria Matveeva","date":"2015-08-17T00:00:00","body":"\n\nDesign sprints at DockYard are based on the [Google Ventures model](http://www.gv.com/sprint/), but with a shorter four-day duration. Design Discovery (the research and strategy phase that enables us test and plan out the entire application before proceeding with Visual Design and Engineering) lasts several weeks, and has a greater scope.\n\nWhile each process has its individual benefits, there are many that they share. In both cases, of Design Sprints and Discovery, we share work with the client early and often. This quick turnaround requires close attention and abstract thinking from the client (for example, evaluating an idea in sketch form rather than fully resolved designs). The benefit is that we course-correct quickly and eliminate alternatives early on.\n\nThe difference is in the scope, end objective, and the deliverables. A design sprint can encompass a specific aspect of a product. It's a highly collaborative and budget friendly way to spike on an idea. Design discovery is a holistic approach to goals and strategy for a product.\n\n\n## What sprints are good for\nThe purpose of a sprint is not to deliver a whole product, but a realistic model of a product experience. In a few cases a product experience may be small and focused enough to be encompassed entirely in the sprint. More likely, a design sprint focuses on a specific aspect of an application, and a single user story. \n\nA sprint might address a question like “how would a new user sign up for your service on a mobile phone?” or “In what ways could an existing customer use the web service you’re building in the course of their day?” A sprint is a rapid way to model and test specific situations, so that the product can be refined. In order to run a sprint, we make reasonable assumptions about a situation around your product, and then isolate, model, and test a them.\n\n## What a sprint looks like\n\nHere’s what a design sprint might look like at DockYard. Let’s imagine a product that helps customers know when a farm share they purchased would be delivered. \n\n- For the sprint, we would be focusing on sending and receiving messages between a delivery driver and a customer.\n- We would only focus on the mobile view of this interaction (with an informed assumption that it’s the most convenient context for checking up on a delivery)\n\n\n### Monday: analyze the context\nWe kick off the sprint by analyzing the situation around the delivery. Who are our users? What problems do they encounter, and which ones can we help them solve? \n\nBy the end of the day, we expect to diagram the portion of a customer’s experience receiving a delivery, and any actions they might take along the way.\n\n### Tuesday: sketch and define\nOn day two we take the workflow we already defined and turn it into a series of hand-sketched wireframes. In this process, additional details become clear and we move toward a standardized approach to similar screens. We define a series of messages between the customer and the delivery driver as the key interaction.\n\n### Wednesday: design and prototype\nOn day three, we translate the sketches into visual design. We design the key screens for the messaging interaction and create a minimal prototype to test drive how the messaging app might feel.\n\n### Thursday: test and refine\nOn the final day, we run several quick user tests with potential customers. We give test users a scenario like “your delivery is coming - use the app to check on its arrival!” and observe how they interact with the prototype. We record any lessons learned - e.g. “user assumed the button was inactive”.\n\nWe then make any quick corrections based on the results of user testing (like making the button appear more active) and document what we learned as potential improvements or things to explore in the future. \n\nThe result of a sprint in this case is a working prototype of messaging for our specific use case, and an understanding of what role this key interaction plays within the larger context of the app.\n\n\n\n## Picking between Sprint and Discovery \n\nTo decide which design process is right, consider the job each process does well. \n\n![A design sprint is like shining a focused flashlight](https://i.imgur.com/weKPZFU.jpg)\n**A sprint** quickly illuminates a specific aspect of your product, for example, a single user story. A series of sprints could produce a full picture, but at some point a Discovery approach becomes more effective.\n\nSprints result in prototypes of your product or parts of it, and allow you to test things quickly. They are most efficient for solving shorter term business goals:  validating or iterating quickly on  a function of an application.\n\n![Design Discovery can help illuminate the bigger picture](https://i.imgur.com/qoYW3wC.jpg)\n[Original image source](https://en.wikipedia.org/wiki/Cave)\n\n**Discovery** usually requires more time and resources, but shows the larger picture.\n\nThe combination of design discovery and visual design is a holistic process. It is a better investment in cases where you’re developing a new product, or have long term business goals and would like an investigation from all angles into how to achieve them.\n\nIf you have a specific question in mind, [contact us](https://dockyard.com/contact/hire-us). We’ll set up a short consultation meeting so we can help find out which process is right for you.\n\n\n\n"},{"title":"CSS Tooltips: What clip-path & gradients can do for us","tags":["css"],"summary":"A way to use clip-path and linear gradients to further customize tooltips.","legacy":false,"illustration_alt":"Design for customized tooltip","illustration":"https://i.imgur.com/baJdTwK.png","id":"2015/08/27/css-tooltips","employee":"Amanda Cheung","date":"2015-08-27T00:00:00","body":"\n\n## What I wanted\n\nThis came about when I was trying to create an error tooltip with borders and a transparent background following this design:\n![Design for customized tooltip](https://i.imgur.com/baJdTwK.png)\n\nIt has a subtle wave texture to it so it was important that the\ntooltip held transparency. I also wanted to set up a constraint for myself\nto not add extra HTML elements.\n\n## The old solutions and why they didn’t work\n\nPreviously, when I wanted to implement a tooltip, I could make it\ntransparent without a border OR have a border and the background would\nhave to be opaque. The only way I knew to do borders was stacking the before and after pseudo elements to <i>simulate</i> a border [like so](http://davidwalsh.name/css-tooltips). This method prevented transparent backgrounds because one pseudo\n element had to be on top of the other pseudo element which had a\n background color of the border.\n\n## New ideas\n\nAfter coming across [Gregor Adams’ Pure CSS Tooltips blog post](http://cssnerd.com/2012/01/08/pure-css-tooltips-transparent-border-box-shadow/), I piggybacked off the idea of using linear gradients to create the triangle of the tooltip.\n\n## Finding a solution\n\nIt was a bit strange trying to figure out how to get a triangle with\nborders only on two sides without extra surrounding\nartifacts (watch what happens when we leave out background-repeat:\nno-repeat in the CodePen at the bottom… weird!). Then came finding a\nsolution for the border around the tooltip. The border had to skip the\nportion where the triangle tip sat.\n\nIt would’ve been cool if we could control dashed lines to be\nable to change the lengths of the dashes or the space in between each\ndash. Unfortunately we don’t have that level of customization for\nborder-style’s. Or if we could use some sort of border gradient with color stops,\nbut after trying that, I figured out that it didn’t play well with border-radius. Then I thought to use some type of clipping\nand I would even be able to angle my clip-path to fit better with my triangle tip! The path I figured worked best is outlined in black:\n![Clip-path I used to remove part of tooltip border](https://i.imgur.com/qNTsmqh.jpg)\n\nIf you are unfamiliar with clip-path, [Bennett Feely’s tool clippy](http://bennettfeely.com/clippy/) helps visualize clip-path polygons and provides a good starting point with its dragging feature.\n\n<p data-height=\"780\" data-theme-id=\"0\" data-slug-hash=\"VLoEqa\"\ndata-default-tab=\"result\" data-user=\"acacheung\" class='codepen'>See the\nPen <a href='http://codepen.io/acacheung/pen/VLoEqa/'>Transparent\ntooltip with border</a> by Amanda Cheung (<a\nhref='http://codepen.io/acacheung'>@acacheung</a>) on <a\nhref='http://codepen.io'>CodePen</a>.</p>\n<script async src=\"//assets.codepen.io/assets/embed/ei.js\"></script>\n\nIt’s not the [DRYest](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself), but it is flexible for tooltips that are multi-line as well\nas tooltips that are longer in length. This also works with box-shadows, but clip-path would need to be adjusted and it can also handle transparency for the borders. Unfortunately at this time, Firefox and IE are not\nsupported because of how clip-path is being used.\n"},{"title":"Clear communication through HTML and GitHub","tags":["html"],"summary":"A technique for clear communication between web application teams through HTML and GitHub","legacy":false,"illustration_alt":"GitHub issue for component comments","illustration":"http://i.imgur.com/8VHiilm.png","id":"2015/09/02/clear-communication-through-html","employee":"Cory Tanner","date":"2015-09-02T00:00:00","body":"\n\nIf you follow the DockYard blog I am sure you are familiar with how we structure our teams.\n\n**Design**\n\nYou can get a feel for how our designers operate by taking a look at Steve's post, [Job: Senior UI & Visual Designer](https://dockyard.com/blog/2015/01/14/sr-ui-designer).\n\n**UX Dev (User Experience Development)**\n\nBrian has a great post describing the UX Dev team, [The most difficult position to hire for in tech right now](https://dockyard.com/blog/2014/08/06/the-most-difficult-position-to-hire-for-in-tech-right-now).\n\n**Development**\n\nMainly with [Ember.js](http://emberjs.com/) the Development team wires up all of the functionality required with the HTML and CSS provided by UX Dev.\n\n## Our current process\n\nWhat helps us the most when we have multiple teams on a project is clear communication.\n\nDockYard has methods of communication between all three teams but this blog post will be focusing on methods the UX Dev team uses to communicate with the Development team.\n\nOur UX Dev team is always looking to make work easier for the Development team and a simple way to do that is through how we communicate an application's conditionals. When we receive designs of the application we need to communicate to Development what the conditionals are in a clear and organized way.\n\nWe have done this through our HTML templating comments and this alone has worked well.\n\nIn a previous post we went over how to add comments to your code in [Helping Our Engineers](https://dockyard.com/blog/2015/03/31/helping-our-engineers), and we go over two methods of communication.\n\n**Note:** we use [Handlebars](http://handlebarsjs.com/) for our templating.\n\n### Pseudo-code comments\n\n```hbs\n<a class=\"t-link\" href=\"\">about</a>\n<a class=\"t-link\" href=\"\">contact</a>\n{{! if signed in}}\n  <a class=\"t-link\" href=\"\">manage</a>\n{{! else}}\n  <a class=\"t-link\" href=\"\">sign in</a>\n{{! end if}}\n```\n\nThis lets our developers know that `if` the user signs into the application, the manage link is added to the HTML, `else` the sign in link should be present.\n\nThis method works great for adding notifications to the page, you just need to say the following.\n\n```hbs\n<input class=\"button\">Log In</input>\n{{! if <input> has errors on submit}}\n  <div class=“notification”>\n    ...\n  </div>\n{{! end if}}\n```\n\n### TODO comment\n\n```hbs\n{{! TODO: Toggle class .is-selected on <a> when active}}\n<a class=\"t-link\" href=\"\">about</a>\n<a class=\"t-link\" href=\"\">contact</a>\n```\n\nIf we don’t need to add complete blocks of code to the HTML we will use a TODO comment to let the developers know a class needs to be added to the next line of code.\n\n## What’s new: Track Everything\n\nIn addition to adding comments it is recommended to provide a trackable issue referencing the comment in your code. On GitHub this is very easy and we can assign the issue to a team member.\n\nWe don’t do this for every individual comment but rather make a checklist in the GitHub issue per modular [component](http://emberjs.com/api/classes/Ember.Component.html) or one issue for simple pages.\n\nAn example of a simple page would be a static \"About Us\" page that only has about 1 - 2 comments and no complex conditionals.\n\n### Issue example\n\n![GitHub issue for component comments](http://i.imgur.com/8VHiilm.png)\n\nHaving trackable issues for comments is helpful because there can be so many of them. Keeping everything organized in a project management system like GitHub is very helpful.\n\n### Final Thoughts\nOur goal as UX Developers is to provide crystal clear communication with the Design and Development teams so the client gets the best product possible.\n\nHaving standardized techniques for communicating the application HTML conditionals within your team can greatly help the workflow and make everyone's life easier.\n\nI hope this helps your templating process with HTML and provides clear communication with your team!\n"},{"title":"Define: Functional Decoration","tags":["design","design process","user experience"],"summary":"Due diligence to repair a meaningful technique","legacy":false,"id":"2015/09/04/define-functional-decoration","employee":"Steven Trevathan","date":"2015-09-04T00:00:00","body":"\n\nIf you’re unfamiliar with the implications of decoration in design, a good place to start is to read Beatrice Warde’s [“The Crystal Goblet, or Printing Should Be Invisible”](http://gmunch.home.pipeline.com/typo-L/misc/ward.htm). It sums up fairly well a belief I carry to the products we produce at DockYard.\n\nDesigners working in graphic, industrial, architectural, and user experience design have experienced many revolutions of overly decorative design followed by a great decorative purge. A most recent example of this is the explosion of “flat design” and aggression turned toward all things skeuomorphic. This was inevitable, and I welcome the sea change.\n\nHowever, I think if we’re able to open our hearts for a minute to unpopular ideas, we’ll find that decoration does indeed have a functional role in design. I think that role could be called Functional Decoration. Let me explain what I think Functional Decoration is by explaining what I think it can do.\n\nFunctional Decoration is decoration that assists in creating a new context through which expectations shift, or distort our sense of \"normal\", to allow us to amplify the messages within the content it surrounds. It can let us exemplify the experience of a thing better than purely representing it in the written word. It can be effective in emphasizing the tone of a process, providing a sense of the experience of an event, or perhaps even an expectation of the performance of a product.\n\nCan you tell me if you felt real emotions when seeing Inside Out, Up, Spirited Away, or Princess Mononoke? What if we stripped the “decorative” medium from these films? The answer is we would have a very different experience with the content. I think proponents for moderate use of decoration are experiencing something similar to attempting to get someone who refuses to watch anime to watch a single animated film. It's an uphill battle, but I digress.\n\nI believe useful decoration - Functional Decoration - extends the readers' imagination to help their mind do the dirty work of turning text into imagined experiences or expectations. Done well, it can be much better than the content on its own.\n\nHere are a few examples of what I'd call Functional Decoration:\n\n- [XOXOs changing background pattern and use of overlay yellow on blue.](http://2015.xoxofest.com/) The absence of photography, the unabashed use of a basic but vibrant blue and yellow, and the dynamic overlaying shapes describe an inclusive nature of their event well: “you're with friends, it's ok to be you here”\n- [Super-Loopers \"pixelated\" visuals](http://superlooper.universlabs.co.uk/) pay homage to the environment that inspired the software but also act as a visual description of the sound you're hearing.\n- [Bloomberg’s \"What is Code?\"](http://www.bloomberg.com/graphics/2015-paul-ford-what-is-code/) by Paul Ford uses graphics and pattern as Functional Decoration in that they themselves are illustrations of the content. They facilitate a sometimes humorous and other times very awe-struck wonder of the origins of computing and its concentric cultures.\n\nAt the end of the day, my goal with the concept of Functional Decoration is to do necessary repair from damages caused by scorched earth dismantling of decoration (such as skueomorphism) and to help myself and my team to make better use of the communicative tool decoration can be.\n\nAnd I really just wish there was a better word than \"decoration\"."},{"title":"Design is about systems","tags":["design","design thinking","observations","ux design"],"summary":"A design change is not just a design change","legacy":false,"illustration_alt":"Three crosswalks to get across one busy street from point A to point B","illustration":"https://i.imgur.com/Uvxx0zl.png","id":"2015/09/10/design-is-about-systems","employee":"Maria Matveeva","date":"2015-09-10T00:00:00","body":"\n\nAs I commute, every time I have to pick between risk and delay.\n\nThere is an intersection that takes a pedestrian three separate lights to cross. For cars, it’s just one. *If you obey all traffic signals* you’ll cross this intersection in two traffic-light cycles heading downtown. In the opposite direction, it can take three full cycles.\n\n![Three crosswalks to get across one busy street from point A to point B](https://i.imgur.com/Uvxx0zl.png)\n\nClearly, this leads to frustration for pedestrians. With cars potentially coming from three different directions (look at Crossing 2), it’s easy to look to just one side, assume there is no traffic, and jaywalk. It often happens just as the cars start moving. In addition to being dangerous for people, this slows down the cars and buses even more, adding to residual delays as they eventually clear the intersection on red.\n\n\n## This intersection design is stupid\n\nAs a pedestrian, I have a choice between jaywalking (running) as I glance left, right, and back to see if any cars are coming - or waiting several minutes extra to cross. It seems such an injustice that I have to request a pedestrian light up to three times while cars clear this monstrous intersection in just one. As a user of this intersection, I feel like I am an afterthought, not a primary consideration. \n\n*What if we mandate that all intersections be crossable in one light? What if we prioritize pedestrians, not cars?*  \n\nI start to imagine potential legislation, participating in a \"healthy city\" campaign of some sort, and even a crosswalk design that would accommodate a faster, safer crossing for me.\n\n\n## This intersection is part of a system\n\nThen I think about it more. Why was this intersection designed to accommodate cars better than pedestrians? Why do most cities in the US still feel like they’re planned for cars and not people? Because they are. Long story. I start to imagine all the infrastructure changes that might be required for this seemingly simple change: to alter the path of a crosswalk, and make it feel more efficient.\n\nI think this way because as a designer, I am responsible for making sure that the things I build and “make pretty” actually work - and for more than one type of user. I don’t put a button or a variable into a mockup unless I know it can be supported by engineering, and is necessary for the user. Because of this sense of responsibility, I can’t really enjoy lofty, speculative discussions about potential changes it might be nice to make. \n\n\n## Design thinking is both a blessing and a curse\n\nAs a designer, I can’t help but think about how the environment around me works, and why. I’m a walking critique machine, a small nudge will get it started. I can see, or at least imagine, the systems that stand behind every designed detail of my life.\n\nBut even when I can often see clear ways to fix situations that annoy me, I can just as clearly see why change won’t usually be easy or fast. A change in my path across a traffic intersection is not just about the intersection. It involves the systems that control traffic flow on the three streets. One of these streets goes underground to flow into a highway, and another exits to Boston’s busy Financial District.\n\nA design approach is powerful precisely because we take into account the systems, requirements, and groups of users who will interact with the thing we design. We aim to help people accomplish their goals while minimizing potential frustrations. This is a lot of responsibility, but it’s exactly what makes our work powerful.\n\nAnd while we can never know about all the components of the systems we design for from the start, we must ask questions and rely on others’ expertise to draw conclusions. The ultimate responsibility in design is to think holistically.\n"},{"title":"Ember Best Practices: Avoid leaking state into factories","tags":["ember","javascript"],"summary":null,"legacy":false,"id":"2015/09/18/ember-best-practices-avoid-leaking-state-into-factories","employee":"Estelle DeBlois","date":"2015-09-18T00:00:00","body":"\n\nAt DockYard, we spend a lot of time with Ember, from building web apps, creating and maintaining addons, to contributing back to the Ember ecosystem. We hope to share some of the experience we've gathered along the way through a series of blog posts that will focus on idiomatic Ember practices, patterns, anti-patterns, and common pitfalls. This is the first in that series, so let's start by going back to the basics with `Ember.Object`.\n\n`Ember.Object` is one of the first things we learn as Ember developers, and to no surprise. Pretty much every object we work with in Ember, whether it's a route, component, model, or service, [extends from Ember.Object](http://emberjs.jsbin.com/boqapo). But every now and then, I see it used incorrectly, like this:\n\n```js\nexport default Ember.Component.extend({\n  items: [],\n\n  actions: {\n    addItem(item) {\n      this.get('items').pushObject(item);\n    }\n  }\n});\n```\n\nTo those who have encountered this before, the problem is obvious. But I'm sure this has trolled many developers at one time or another, so if the issue doesn't immediately jump at you, keep reading!\n\n## Ember.Object\n\nIf you were to browse the [API](http://emberjs.com/api/classes/Ember.Object.html) and deselect all _Inherited_, _Protected_, and _Private_ options, you'll see that `Ember.Object` has no methods or properties of its own. The [source](https://github.com/emberjs/ember.js/blob/v2.0.2/packages/ember-runtime/lib/system/object.js) code couldn't be any shorter. It's literally just an extension of Ember's `CoreObject`, with the `Observable` mixin applied:\n\n```js\nvar EmberObject = CoreObject.extend(Observable);\n```\n\n`CoreObject` provides a clean interface for defining factories or _classes_. It is essentially an abstraction around how you would normally create constructor functions, define methods and properties on the prototype, and then create new objects by calling `new SomeConstructor()`. If you're able to invoke methods of a superclass using `this._super()`, or merge a set of properties into a class via [Mixins](http://emberjs.com/api/classes/Ember.Mixin.html), you have `CoreObject` to thank for. All the methods that come up often when working with Ember objects, such as `init`, `create`, `extend`, or `reopen`, are all defined there too.\n\n`Observable` is the mixin that makes it possible to observe changes to properties on an object, and is where both `get` and `set` methods come from.\n\nWhen developing an Ember app, you would never use `CoreObject` directly. You would extend from `Ember.Object` instead. After all, Ember is all about [reacting to changes](https://medium.com/the-ember-way/ember-js-reactive-programming-computed-properties-and-observers-cf80c2fbcfc), so you need the methods from `Observable` in order to detect when a property value changes.\n\n## Defining a new class\n\nYou can define a new type of observable object by extending from `Ember.Object`:\n\n```js\nconst Post = Ember.Object.extend({\n  title: 'Untitled',\n  author: 'Anonymous',\n\n  header: computed('title', 'author', function() {\n    const title = this.get('title');\n    const author = this.get('author');\n    return `\"${title}\" by ${author}`;\n  })\n});\n```\n\nNew objects of type `Post` can now be created by calling `Post.create()`. Each post instance will inherit the properties and methods that have been defined on the `Post` class:\n\n```js\nconst post = Post.create();\npost.get('title'); // => 'Untitled'\npost.get('author'); // => 'Anonymous'\npost.get('header'); // => 'Untitled by Anonymous'\npost instanceof Post; // => true\n```\n\nYou can change the property values and give the post a meaningful title and author name. These values will be set on the instance, not the class, and therefore will not affect future posts that get created.\n\n```js\npost.set('title', 'Heads? Or Tails?');\npost.set('author', 'R & R Lutece');\npost.get('header'); // => '\"Heads? Or Tails?\" by R & R Lutece'\n\nconst anotherPost = Post.create();\nanotherPost.get('title'); // => 'Untitled'\nanotherPost.get('author'); // => 'Anonymous'\nanotherPost.get('header'); // => 'Untitled by Anonymous'\n```\n\nBecause updating properties this way has no impact on other instances, it is easy to think that all operations done on an instance are safe. But let's expand on this example a bit more.\n\n## Leaking state into the class\n\nA post can have an optional list of tags, so we can create a property named `tags` and default it to an empty array. New tags can be added by calling an `addTag()` method.\n\n```js\nconst Post = Ember.Object.extend({\n  tags: [],\n\n  addTag(tag) {\n    this.get('tags').pushObject(tag);\n  }\n});\n\nconst post = Post.create();\npost.get('tags'); // => []\npost.addTag('constants');\npost.addTag('variables');\npost.get('tags'); // => ['constants', 'variables']\n```\n\nLooks like it's working! But check out what happens when a second post is now created:\n\n```js\nconst anotherPost = Post.create();\nanotherPost.get('tags'); // => ['constants', 'variables']\n```\n\nEven though the goal was to create a new post with empty tags (the intended default), the post was created with the tags from the previous post. Because we never set the post's `tags` property to a new value but simply mutated the underlying array, we have effectively leaked state into the `Post` class, which is then shared by all instances.\n\n```js\npost.get('tags'); // => ['constants', 'variables']\nanotherPost.get('tags'); // => ['constants', 'variables']\nanotherPost.addTag('infinity'); // => ['constants', 'variables', 'infinity']\npost.get('tags'); // => ['constants', 'variables', 'infinity']\n```\n\nIt is not the only scenario where you may confuse instance state and class state, but it is certainly one that comes up more often. In a related example, you may wish to default an object's property named `createdDate` to the current date and time by setting it to `new Date()`. But `new Date()` will only get evaluated once, when the class is defined. So no matter when you create new instances of that class, they will all share the same `createdDate`:\n\n```js\nconst Post = Ember.Object.extend({\n  createdDate: new Date()\n});\n\nconst postA = Post.create();\npostA.get('createdDate'); // => Fri Sep 18 2015 13:47:02 GMT-0400 (EDT)\n\n// Sometime in the future...\nconst postB = Post.create();\npostB.get('createdDate'); // => Fri Sep 18 2015 13:47:02 GMT-0400 (EDT)\n```\n\n## Keeping things under control\n\nIn order to avoid sharing tags between posts, the `tags` property would need to be set when the object is initialized:\n\n```js\nconst Post = Ember.Object.extend({\n  init() {\n    this._super(...arguments);\n    this.tags = [];\n  }\n});\n```\n\nSince `init` is called whenever you call `Post.create()`, each post instance will always get its own `tags` array. Alternatively, you could make `tags` a computed property. It won't observe anything, but will be unique to each instance:\n\n```js\nconst Post = Ember.Object.extend({\n  tags: computed({\n    return [];\n  })\n});\n```\n\n## Conclusion\n\nIt should be obvious now why you should not write components like the example I showed at the beginning of this post. Even if the component only appears once on a page, when you leave the route, only the component instance gets destroyed, not the factory. So when you come back, a new instance of the Component will get created, and this new component will have traces of the previous time you visited the page.\n\nThis error may be encountered when using mixins as well. Even though `Ember.Mixin` is not an `Ember.Object`, properties and methods defined on the mixin get merged with the `Ember.Object` you mix it into. The result would be the same: you may end up sharing state between all objects that use the mixin.\n\nIf you found this post helpful, stay tuned for more blog posts from myself and fellow DockYarders on Ember best practices in the future!\n"},{"title":"What to expect from a Design Sprint","tags":["design sprints","design strategy","ux design"],"summary":"Participation, outcomes, and deliverables","legacy":false,"id":"2015/09/22/What-to-expect-from-a-design-sprint","employee":"Ashley Treni","date":"2015-09-22T00:00:00","body":"\n\nA design sprint is a research strategy which focuses on and explores a feature or specific part of a product. With a limited scope and a short duration of a week, a sprint can test and validate ideas about user flow, functionality, and interaction design around a specific product goal. To elaborate on [Maria's post about Design Sprints] (https://dockyard.com/blog/2015/08/17/design-sprints-what-are-they-for), here's a \"what to expect\" about participation, outcomes, and deliverables.\n\n## Participation\n\nA stakeholder from the product in development is a very important participant in the design sprint, and they should expect to be hands on and present for the full sprint duration. Design sprints move very fast, and their industry knowledge and understanding of the product is key to a successful outcome. The team can move forward quickly and efficiently with the availability to ask questions and help make informed assumptions along the way. Stakeholders come with unique insights about the product that can illuminate conditions of the target market, knowledge about users, business goals, and any known limitations or pre-existing conditions up front.\n\nPlanning the sprint objectives and project goals before the start of the sprint is important to stay focused on the task at hand. New ideas will arise during a sprint - the design team leader will make sure to document for later, or redirect the sprint to address those considerations if they are integral to the solution.\n\n## Outcomes\n\nPart of establishing project goals is determining the outcomes and deliverables that result as a product of the sprint. The outcomes of a design sprint depend on the state of your product before the design sprint, and based on the project goals that were defined. The outcome of a sprint can go many different ways:\n\n * **A working prototype.** Usually for a one-week design sprint, the result is a clickable prototype and one or two user stories. The thinking that went into defining the user flow and key interactions can be tested and validated through the prototype and user testing.\n\n * **Detailed wireframes and a full user flow.** Often times, a series of sprints are held to explore a more complex product. With each week focusing on a different facet of the product, wireframes and prototypes from each sprint can start to carry over to inform design decisions in consecutive weeks. With consecutive sprints, it is possible to explore the product more deeply and examine the connections and interdependencies between the proposed user flows.\n\n * **Preliminary visual design.** If the content of a given sprint is narrow in scope, there may be time at the end of the sprint to begin visual design. Developing a visual style for the product can inform prototypes in consecutive sprints, or lay a framework for visual tone in the product itself.\n\n * **Product direction.** For newer products, sprints can explore the wide landscape of possibilities to discover and prioritize the best ways to move forward. A sprint can help select and test directions early on to determine the strongest product values to put into action.\n\n## Deliverables\n\nThe deliverables for the following outcomes may come in various forms such as original files (Sketch, photoshop, illustrator documents), JPGs/PDFs/PNGs, links to online prototypes, and photographs.\n\n\nThe outcomes of a design sprint are more strategic in nature and not a fully completed project. What you’ll take away from a sprint are research tools, the skeleton of an interface with core features and interactions and, most importantly, a better understanding of the next steps for your product. Setting these expectations for participation, outcomes, and deliverables up front is imperative to a successful design sprint. \n\nWe're excited to share more of our process with you through our soon to be released (and free) design sprints resource guide! Signup to the DockYard newsletter below and we'll let you know when it has been released.\n"},{"title":"Ember Best Practices: DRYer and less fragile Acceptance Tests","tags":["ember","javascript","best practices"],"summary":null,"legacy":false,"id":"2015/09/25/ember-best-practices-acceptance-tests","employee":"Lin Reid","date":"2015-09-25T00:00:00","body":"\n\nThis is the second in a series of posts designed to share our experiences around developing Ember.js apps and the best practices that we've found while doing so.\nIf you missed the first post from Estelle about [not leaking state into factories](https://dockyard.com/blog/2015/09/18/ember-best-practices-avoid-leaking-state-into-factories) you should check it out!\n\n### Intro\nIn this post, I'm going to be talking about writing less fragile acceptance tests that are easier to maintain.\nRenaming CSS classes or refactoring the HTML structure of an application can cause our acceptance tests to fail, even if the end-user experience is the same.\nWhen this happens, it's not uncommon to spend a disproportionate amount of time fixing broken tests rather than refactoring code.\nIf that sounds familiar, I've got a few approaches that you can use to create less fragile acceptance tests.\nAnd more than that, when they do break, you can fix your test logic in one place rather than in every test that's failing.\n\n## Minimize coupling tests to presentation\nThe first approach we’re going to talk about is decoupling your acceptance tests from the HTML structure and CSS of your application.\nIf your tests are breaking due to semantic HTML or class name changes but the end experience to the user is nearly exactly the same, this should be a red flag that your tests are too closely coupled to the HTML and CSS of your application.\nOur acceptance tests should be from the perspective of a user interacting with the application.\nA user doesn’t care about whether the element they are clicking on is a `<button>` or a `<span>` or whether we use a class name of `post` or `blog-post`.\nThey care that they can read a blog post, comment on it, and like it.\n\nHowever, we can’t perfectly decouple our tests from presentation, as we still need to be able to find the elements that we need to interact with and make assertions against.\nOne approach to minimizing the coupling is to add a [data attribute](https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Using_data_attributes) to elements that we want to target during our tests.\nData attributes are attributes that are prefixed with `data-` and are intended to store meta data on elements:\n\n```hbs\n<div data-foo=\"some arbitrary data\" data-bar=\"123\"></div>\n```\n\n### Example test using data attributes\nWe can use these data attributes to identify elements that will be interacted with in our tests:\n\n```hbs\n<div class=\"post-likes\">\n  <span class=\"likes-count\" data-test-selector=\"post-likes-count\">{{likesCount}}</span>\n  <button class=\"btn like\" {{action \"likePost\"}} data-test-selector=\"post-like-button\">Like</button>\n</div>\n```\n\n```js\ntest('a user can like a post', function(assert) {\n  assert.expect(2);\n\n  visit('posts/1');\n\n  andThen(function() {\n    const likesCount = find('[data-test-selector=\"post-likes-count\"]');\n    assert.equal(likesCount.text(), 0, 'precondition - likes count starts at 0');\n  });\n\n  click('[data-test-selector=\"post-like-button\"]');\n\n  andThen(function() {\n    const likesCount = find('[data-test-selector=\"post-likes-count\"]');\n    assert.equal(likesCount.text(), 1, 'clicking the like post button increments the likes count');\n  });\n});\n```\n\nNow, if we want to refactor our like button so it contains the likes count and change around some class names...\n\n```hbs\n<button class=\"btn like-post\" {{action \"likePost\"}} data-test-selector=\"post-like-button\">\n  <span class=\"count\" data-test-selector=\"post-likes-count\">{{likesCount}}</span> Likes\n</button>\n```\n\nOur test still passes without having to update our test logic because we're not targeting elements based on their class names or their relation to other elements on the page.\nSuccess!\n\n## Page Object Pattern\nThe next approach we're going to talk about is using the Page Object pattern to DRY out our test logic.\nThe goal of a Page Object is to represent an area of your UI that gets interacted with during tests.\nPage Objects are responsible for abstracting away the details of how to target and interact with elements in the DOM and providing an API that can be used in tests for page interactions.\nThe name Page Object can be a bit misleading.\nMost \"pages\" have a bit too much going on for them to be encapsulated into one object.\nGenerally, I’ve found that it makes more sense to model Page Objects after logical chunks of the UI.\nYou might have a Page Object representing your nav-bar, side-bar, or a group of components that compose a logical section of the UI.\nFor example, you might have a Page Object that is responsible for providing an API for targeting elements of an individual post:\n\n```js\n// tests/page-objects/post-show.js\n\n// PageObject implementation using es6 Classes\nimport BasePageObject from './base'; // A base class for all page objects to extend from\n\nexport default class PostShowPageObject extends BasePageObject {\n  constructor(assert) {\n    this.assert = assert;\n  }\n\n  // interactions\n  readPostId(id) {\n    visit(`posts/${id}`);\n\n    return this;\n  }\n\n  clickLikeButton() {\n    click('[data-test-selector=\"post-like-button\"]');\n\n    return this;\n  }\n\n  // assertions\n  assertLikesCount(count, message) {\n    andThen(() => {\n      const likesCount = find('[data-test-selector=\"post-likes-count\"]');\n      message = message || `likes count is: ${count}`;\n      this.assert.equal(likesCount.text(), count, message);\n    });\n\n    return this;\n  }\n}\n```\n\nHere's what the exact same acceptance test would look like using our new Page Object:\n\n```js\nimport PostShowPageObject from '../page-objects/post-show';\n\n// other test code\n\ntest('a user can like a post', function(assert) {\n  assert.expect(2);\n\n  new PostShowPageObject(assert)\n    .readPostId(1)\n    .assertLikesCount(0, 'precondition - likes count starts at 0')\n    .clickLikeButton()\n    .assertLikesCount(1, 'clicking the like post button increments the likes count');\n});\n```\n\nThe real benefit here is that if you need to change how you target elements, you only have to fix it in one place rather than every test that interacts with that element.\nBesides the maintainability of the test logic, it makes for super clean and readable tests! One thing to note is that there is some disagreement about\nwhether assertions should be a part of the API of a Page Object. Some people feel that a Page Object should strictly provide an API for page interactions.\nOthers feel that we tend to assert around a certain set of elements in our tests and DRYing up assertion logic by including assertions in the Page Object makes sense.\nIn my experience, I've found that including assertion helpers in my Page Objects has saved me a ton of time when adding new tests and maintaining old tests.\n\n### Additional Resources\nMike North gave a great talk at [Wicked Good Ember](http://wickedgoodember.com/) last year about using Page Objects and data attributes for acceptance testing. I definitely recommend [checking it out](http://confreaks.tv/videos/wickedgoodember2015-compose-all-the-things).\n\n### ember-page-object\nIf you're sold on the idea of using Page Objects and data attributes to target elements in acceptance tests,\n[Lauren](https://twitter.com/sugarpirate_) and I created an addon called [ember-page-object](https://github.com/linstula/ember-page-object) that provides a base PageObject\nclass you can extend from to help get you started! Enjoy!\n"},{"title":"Announcing the Design Sprints Guide","tags":["design","design process","user experience"],"summary":"Collaborative documentation for the road ahead","legacy":false,"illustration_alt":"Design Sprints","illustration":"http://i.imgur.com/wgebVlz.png","id":"2015/10/05/announcing-design-sprint-guide","employee":"Steven Trevathan","date":"2015-10-05T00:00:00","body":"\n\n![Design Sprints](http://i.imgur.com/wgebVlz.png)\n\nWe’re extremely excited to announce the release of our first version of the [Design Sprints Guide](https://dockyard.com/design-sprints). This releases focuses on a special 4-day variant of the ever popular rapid-validation product design methodology.\n\nIn this guidebook we provide everything you can (and cannot) expect of the methodology, the processes and tools you can use for running a design sprint yourself, and a boat-load of resources for further reading.\n\nThis content is free and we’d love for those already running sprints to contribute wisdom from their experiences. For now, anyone who’d like to make edits, suggestions, or additions to this guide may send pull requests or open issues on the github repository. The README has some instructions for how we’ll manage these.\n\nPlans for future releases:\n\n* Adding the original 5-day process plan.\n* Adding more real life examples / photographed documentation.\n* Creating tools that allow readers to suggest and accept additions or edits on the guide.\n\nWe hope you’ll find this guide useful. If not, we really hope you’ll help us improve it.\n\n**Huge credit and thanks to the DockYard design team for putting the Design Sprints Guide together:** Maria Matveeva ([@rgbcolor](https://twitter.com/rgbcolor)), Ashley Treni ([@ashleytreni](https://twitter.com/ashleytreni)), Cory Tanner ([@ctannerweb](https://twitter.com/ctannerweb)), Amanda Chueng ([@acacheung](https://twitter.com/acacheung)), Tim Walsh ([@imakemusic](https://twitter.com/imakemusic)), and Patrick Branigan ([@pbranigan](https://twitter.com/pbranigan))."},{"title":"Ember Best Practices: Using Native Select Elements","tags":["ember","best practices"],"summary":null,"legacy":false,"id":"2015/10/05/ember-best-practices-using-native-input-elements","employee":"Aaron Sikes","date":"2015-10-05T00:00:00","body":"\n\nThis is the third in a [series of posts][ember-best-practices] designed\nto share our experiences around developing Ember.js apps and the best\npractices that we've found while doing so. Check out Lin's post on\n[page objects and acceptance tests][page-objects], or Estelle's post on\n[not leaking state into factories][dont-leak-state].\n\n\nClosure actions\n---------------\n\nEmber 1.13 came with the release of [improved actions][improved-actions].\nA side effect of this feature is that it enables us to move away from\n`{{view 'select'}}` and simply use DOM `<select>` elements with actions.\n\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p lang=\"en\" dir=\"ltr\">trouble with forms/form elements in ember?&#10;&#10;Turn out in 1.13.3 you can just use &quot;THE DOM&quot;&#10;&#10;<a href=\"http://t.co/9U73q0KOOE\">http://t.co/9U73q0KOOE</a></p>&mdash; Stefan Penner (@stefanpenner) <a href=\"https://twitter.com/stefanpenner/status/618530886162579456\">July 7, 2015</a></blockquote> <script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nHis linked JSBin links to Ember canary and no longer works, but a clone\nmodified to use 1.13 is available [here][jsbin].\n\nYou are probably familiar with the previous action bubbling semantics.\nActions in a component are isolated within that component. Actions\noutside a component bubble first through the current controller, then\nthrough the route hierarchy.\n\nThe new approach of closure actions is simply to wrap this action up in\na function and pass it around. Anyone can call this function later. And\nsince the context is wrapped up in the function closure, the caller does\nnot need to know where it came from.\n\nFor us, the important thing is that it enables us to bind actions\ndirectly to elements, like this: `<select onchange={{action \"doThing\"}}>`.\n\nWhat's wrong with `{{view 'select'}}`?\n--------------------------------------\n\nEmber is moving away from two of the core concepts used by `{{view\n'select'}}`.\n\n### Views\n\nThe Ember team, as well as many people in the community building\nEmber apps have discovered that the confusion around view scopes\nhas been a huge source of hassle and bugs. The explicit scoping of\ncomponents is much more maintainable. Thus, the Views section has been\nremoved from the Ember guides, and the `{{view}}` helper has been\n[deprecated][ember-view-helper]. Nowadays, you get one view to go with\nyour route, and otherwise `View` serves simply as a superclass to\n`Component`. As we move towards routable components, even the routes'\nviews will begin to disappear.\n\n### Two-way data binding\nEmber and the Ember ecosystem are also moving away from two-way bindings,\nand towards a Data Down, Actions Up architecture (DDAU).\n\nTriggering an action includes context that is missing with simple data\nbinding. *Why* is this value changing? Did we receive an update from\nthe back-end, or did the user hit save? Lacking this context can lead\nto complicated conditional logic. Or, when combined with observers can\ncause [an infinite loop hitting your back end][tip-jar-context].\n\nIt's also hard to go back once you opt-in to two-way bindings. You've\nhooked up a form field with data binding, and now you realize you need\nvalidation on that field. Oh, you also need a confirmation when it is\nvalid (this is some high-stakes data). You'll find yourself using an\nobserver, or splitting your `value` property into `previousValue` and\n`currentValue` properties. It is easier to hook in for these kinds of\nthings when triggering actions instead.\n\nThere's also an issue of trust and boundaries. It turns out, [\"components\nwant to be able to hand out data to their children without having to be\non guard for wayward mutations.\"][ember-2.0-bindings] Data flowing only\nin one direction keeps things more predictable.\n\nOkigetit, how do I do it?\n-------------------------\n\nWell, [Stefan's JSBin][jsbin] I spoke about above is really a better\nexample than I could give here. But, basically:\n\n1. Use a DOM `<select>` tag, and use an `{{#each}}` to render option tags.\n2. Bind an action to its `onchange` attribute.\n3. Create an action handler to set the property value.\n\nBut what about `{{input}}`?\n---------------------------\n\nAlthough `{{input}}` behaves more like a component than a view, there\nare similar issues around the data binding.\n\nHowever, it turns out the same approach as above does not work quite as well with\n`<input>` tags. Because of how HTMLBars re-renders views, any time you\ntype a character, your cursor will be reset to the end of the text\nfield. This is awful! There's a way around it, using the side effects of\n[readDOMAttr()][readDOMAttr]. I won't go into it here, but Rob Jackson\nhas put together a small [example component][one-way-input] using this technique.\n\n\nMay your forms be filled, your inputs valid, and your error template\nnever render!\n\n_Note: This post has been edited. It originally recommended using\n`<input>` tags with actions. Because of the issues mentioned around\ncursor position, it has been changed to discuss `select` instead._\n\n\n[ember-best-practices]: /blog/categories/ember\n[page-objects]: /blog/2015/09/25/ember-best-practices-acceptance-tests\n[dont-leak-state]: /blog/2015/09/18/ember-best-practices-avoid-leaking-state-into-factories\n[improved-actions]: https://github.com/emberjs/rfcs/blob/master/text/0050-improved-actions.md\n[jsbin]: http://emberjs.jsbin.com/futokumufe/edit?html,js,output\n[ember-view-helper]: http://emberjs.com/api/classes/Ember.Templates.helpers.html#method_view\n[tip-jar-context]: https://youtu.be/7PUX27RKCq0?t=16m30s\n[ember-2.0-bindings]: https://github.com/emberjs/rfcs/blob/master/text/0015-the-road-to-ember-2-0.md#one-way-bindings-by-default\n[readDOMAttr]: http://emberjs.com/api/classes/Ember.View.html#method_readDOMAttr\n[one-way-input]: http://ember-twiddle.com/2d7246875098d0dbb4a4\n"},{"title":"Capturing the colors","tags":["design","color","art","design process"],"summary":"Look at fall leaves to see colors in context","legacy":false,"illustration_alt":"Red fall foliage","illustration":"https://i.imgur.com/5G48mpK.jpg","id":"2015/10/06/capturing-the-colors","employee":"Maria Matveeva","date":"2015-10-06T00:00:00","body":"\n\n*If you’re interested in learning about color for UX Design, we’re [teaching a hands-on workshop](http://www.meetup.com/UX-East/events/225564114/) on October 29th!*\n\n![Red fall foliage](https://i.imgur.com/5G48mpK.jpg)\n\nFor me, autumn is the most fascinating time for colors. The obvious fall foliage attraction (all the streets and parks are suddenly so pretty!) and the fall fashion (summer was casual, fall calls for a slightly dressed-up, more academic, more pulled together style) combine to create an intense appetite for color. Naturally and seasonally, I am attracted to the rich earthy rust and gold in the leaves, but also the burgundy, darker navy and all kinds of leather colors that people wear to the offices downtown.\n\nThere's just one problem. The color effects of autumn are frustratingly difficult to capture.\n\n\n## Difficult to capture.\n\nThe fleeting nature of colors in the fall increases my fascination with them. It’s not just that the leaves change every day, and shrivel up and dry within hours of bringing them home. It’s the difficulty of reproducing how these colors feel.\nPeak foliage color attracts crowds every single year. Everyone dutifully takes photos. But those photos rarely compare to the vibrant feeling in real life.\n\n![Comparing fall colors to an approximation of what the camera might see](https://i.imgur.com/dbESday.jpg)\n\n*How the colors feel in real life (left) does not always match up to the photographic results (right). But which one is more “real”?*\n\n\n## You can’t always capture what’s in your head\n\nThe reason photos often don’t live up to out vibrant expectations (think ~90% of all sunset photos ever) is partially that the camera is only able to capture a small part of what our eye can see (the human eye has a very high dynamic range), and partially our brain.\n\n\nThe way our brains “read” colors is not only based on the colors’ measurable intensity, hue, and brightness, but also on the context. For fall foliage specifically, we might “read” a very saturated orange in the maple leaves when they are surrounded by less saturated brown leaves, grass or buildings, and against a complimentary blue sky.\n\nSo, I imagine that reality is somewhere in-between: my brain makes the fall colors feel very intense, while a camera might dull them in the process of trying to capture all the information.\n\n\n## A way to look at colors\n\nToday at the library, I picked up this book on colors – *Mix your own watercolors : an artist’s guide to successful color mixing* by John Lidzey. I have painted with watercolors for a while, but this specific book attracted me because of its focus on mixing specific shades of colors and getting predictable results. In the introduction, John Lidzey makes an important point distinction: colors will always appear to be a certain way, but we actually need to measure and isolate them to accurately understand the hue and value of the color before we can reproduce it. Context can change a color, and we can only truly see it by isolating a swatch.\n\n![Open book with swatches](https://i.imgur.com/0s063iG.jpg)\n\nHe suggests making a simple tool to help judge colors: a white paper card with a small square cut out of it. Because I am interested in color for many uses, not just on (white) watercolor paper, I modified this tool to have a neutral gray and a black context for the small cut-out as well.\n\n![DIY - making a color tool](https://i.imgur.com/b8GGdww.jpg)\n\nDIY color evaluation tool!\n\n\n## Here’s what I found\n\nI used my new, very scientific (also, a bit like magic!) color analyzing tool. I found actual autumn leaf colors to be more complex and less vibrant than they first appear. I also confirmed that context can significantly alter the perception of a color — a [concept](https://yalepress.yale.edu/book.asp?isbn=9780300115956) I had learned in my freshman year of design school, but keep having to go back to look deeper.\n\nHere’s an exercise straight from the book:\n\n![book without gray swatch](https://i.imgur.com/NhTUABs.jpg)\n\nThe colors in the still life appear more vibrant than the paint swatches next to them.\n\n![book with gray swatch](https://i.imgur.com/8R60zRH.jpg)\n\nHowever, by comparing the swatch of mixed paint to an isolated swatch of the still life, we see the match is very close. Context makes such a difference!\n\n![brown oak leaf on felt](https://i.imgur.com/oxeq4tw.jpg)\n\nThe golden-brown leaf suddenly feels dull when brought in to photograph on a lighter color. But the actual color swatch, when framed by gray, is quite saturated and warm. A good choice of context to bring out this kind of brown is any neutral, like I show here with felt.\n\n![yellow leaf in three views](https://i.imgur.com/qNmw2K3.png)\n\nHere, a yellow leaf looks quite a bit more intense either framed by gray, or on a backing of a less saturated color.\n\n![yellow leaf on top of red leaves](https://i.imgur.com/d1jUz3R.jpg)\n\nIn a pile of leaves, this yellow looks saturated.\n\n![yellow leaf on white](https://i.imgur.com/iLk9Xzf.jpg)\n\nThe yellow by itself, on a lighter background, still looks quite vibrant.\n\n![yellow leaf + flower](https://i.imgur.com/8mKTVwS.jpg)\n\nCompared with a very saturated yellow flower, we see that the leaf was not such a saturated color after all.\n\n\n## What to do\n\nIn summary – I highly recommend making this simple color context tool. It can help evaluate and compare colors in nature, and understand them better. Also, when expectations do not line up with reality, it could be that because the subject was removed from the environment in which it was first evaluated.\nWhen I design, I need to use color well. Today’s exercise helped me get a better understanding of just how important context is. I might alter my process in the future, to start with establishing a “backdrop”, or a context, for my color selections. Just like a painter, I might “underpaint” my Photoshop file before I start fine-tuning the accent colors for any given layout.\n\nAnd I might just use the little gray square trick on my computer screen, when no one is looking.\n"},{"title":"Ember Best Practices: Actions Down, Data Up... wait what?","tags":["ember","javascript","best practices"],"summary":null,"legacy":false,"id":"2015/10/14/best-practices-data-down-actions-up","employee":"Marin Abernethy","date":"2015-10-14T00:00:00","body":"\n\nWelcome back to the fourth installment of DockYard's Ember Best Practices Blog Post Series! Last time Aaron Sikes explains why we can move away from the Ember `{{input}}` helper with angle-bracket components and improved actions. Aaron briefly discusses \"Data down, actions up\", the topic of this post. So if you want a bit of context, stick around here for a minute then head over to his [post](https://dockyard.com/blog/2015/10/05/ember-best-practices-using-native-input-elements) afterwards.\n\n\n## Data Down, Actions Up\n\nTwo-way data binding is what originally attracted many to Ember.js. Data changes that affect the model are\nimmediately propagated to the corresponding template, and conversely, any changes made in the UI are \npromptly reflected in the underlying model. Magic! This conveniently removes unnecessary boilerplate code.\n\nHowever, when employed in large scale and complex applications, two-way data binding can often become more of a\nheadache than a blessing. Have you struggled with where to mutate your data? Have you spent an excessive amount of time tracing the source of mutated data? You are not alone. The Ember core team in their quest for continuous growth and improvement, has decided that in Ember 2.X, one-way bindings will be the default. And the ability to opt in to two-way data binding will be provided. This new adopted data flow model will simplify communication between components and can be encapsulated in the phrase: \"data down, actions up\". \n\nThat's all well and good, but what does that actually look like in the wild? \n\n## Enough jabbering and show us!\n\nLet's build an app together. Our app will be a simple budgeting tool. Picture the money managing application,\n[Mint](https://www.mint.com/), and more specifically an elementary version of its [budgeting feature](https://www.mint.com/how-mint-works/budgets).\n\n```js\n// application/index/route.js\n\nimport Ember from 'ember';\n\nexport default Ember.Route.extend({\n  model () {\n   return this.store.findAll('expense');\n  },\n  \n  setupController(controller, model) {\n    controller.set('expenses', model);\n  }\n});\n```\n\nAssume our server responds with a list of `expenses`, where each `expense` has a `category` and `amount`.\nIn our template we provide an input box for the user to tell us their `income`. Then we iterate over the `expenses`,\nwrapping each `expense` in a component. And lastly, we display their `total` remaining money (`income - expenses`).\n\n```hbs\n{{! application/index/template.hbs }}\n\n<h4>Income:</h4> \n{{input class=\"income-input\" type=\"integer\" value=income}}\n\n<table class=\"expenses\">\n  <tbody>\n    {{#each expenses as |expense|}}\n      {{expense-summary expense=expense}}\n    {{/each}}\n  </tbody>\n</table>\n\n<h4>Total: {{total}}</h4>\n```\n\n```js\n// application/index/controller.js\nimport Ember from 'ember';\n\nexport default Ember.Controller.extend({\n  income:  0,\n  total: Ember.computed('expenses', 'income', {\n    get() {\n      const amounts = this.get('expenses').mapBy('amount');\n      const expenseTotal = amounts.reduce((previousValue, currentValue) => {\n        return previousValue + currentValue;\n      }, 0);\n      \n      return this.get('income') - expenseTotal;\n    }\n  })\n```\n\nIn each row of our expenses table, we have an `expenseSummaryComponent` that displays the expense `category`,\nprovides an input box for the expense `amount`, and has a \"Save\" button.\n\n```hbs\n{{! expense-summary/template.hbs }}\n\n<tr>\n  <td>{{expense.category}}</td>\n  <td>{{input type=\"integer\" value=expense.amount}}</td>\n  <td><button {{action 'amountChanged'}}>Save</button></td>\n</tr>\n```\n\nIn our `expense-summary` component we implement the `amountChanged` action.\n\n```js\n// expense-summary/component.js\nimport Ember from 'ember';\n\nexport default Ember.Component.extend({\n  actions: {\n    amountChanged() {\n      const expense = this.get('expense');\n      expense.save();\n    }\n  }\n});\n```\n\nYay! Done! However, we forgot something - we haven't applied our new mantra, \"data down, actions up\", to this code yet.The issue is that the `expenseSummaryComponent` is updating the data (`expense.amount`), but the data should solely belong to our `IndexController`. Not only did the `IndexController` give the `expenseSummaryComponent` the `expense` data, but it also uses the `expenses` data to calculate the `total`. Meaning, if the `IndexController` was out of sync and had stale `expense` data, it would be displaying the incorrect `total`. While that may not be a huge concern in this simple scenario, it can be really difficult to trace in more extensive and intricate applications.\n\n### The Better Way\n\nInstead we need to pass an action to our `expenseSummaryComponent`.\n\n```hbs\n{{! parent component: expense-table/template.hbs }}\n\n<table class=\"expenses\">\n  <tbody>\n    {{#each expense in expenses}}\n    \t{{expense-summary expense=expense amountChanged=\"update\"}}\n    {{/each}}\n  </tbody>\n</table>\n```\n\nThe `expenseSummaryComponent` template looks the same as before. But this time, the action `amountChanged`, called\nwhen the user clicks the \"Save\" button in the component, will look different. \n\n```js\n// expense-summary/component.js\nimport Ember from 'ember';\n\nexport default Ember.Component.extend({\n  actions: {\n    amountChanged() {\n      const expense = this.get(this, 'expense');\n      this.sendAction('amountChanged', expense); \n    }\n  }\n});\n```\n\nThe `update` action is now sent up to the parent Component or Controller, along with the `expense` as a parameter.\n\n```js\n// application/index/controller.js\nimport Ember from 'ember';\n\nexport default Ember.Controller.extend({\n  ...\n  \n  actions: {\n    update(expense) {\n      expense.save();\n    }\n  }\n```\n\nSince `expense.save()` is now happening in the Controller, the server will respond with the updated\nversion of the `expense` (with the correct `amount`) and update the template automatically.\n\n### The Angle-Bracket Way\n\nIn Ember, components (and solely components) are the way of the future! And the future is now, with the recent\nrelease of [Ember v2.1.0](http://emberjs.com/blog/2015/08/16/ember-2-1-beta-released.html), routable components\nand [`angle-bracket components`](https://github.com/emberjs/rfcs/pull/15) are live on Canary behind a feature flag.\nHere is what that might look like for our budget form example.\n\n```hbs\n{{! expense-table/template.js}}\n\n<table class=\"expenses\">\n  <tbody>\n    {{#each expenses as |expense|}}\n      <expense-summary expense=expense amountChanged={{action \"update\"}}>\n    {{/each}}\n  </tbody>\n</table>\n```\n\n```js\n// expense-summary/component.js\n\nexport default Ember.Component.extend({\n  actions: {\n    amountChanged() {\n      this.attrs.amountChanged(this.get('expense'));\n    }\n  }\n});\n```\n\n## Final Remarks\n\nI won't dive anymore into that in this blog post. A little birdy told me that closure actions will be the subject of\na future Ember Best Practices Post. So look out for it! And remember to go back to Aaron's post on [using native input elements](https://dockyard.com/blog/2015/10/05/ember-best-practices-using-native-input-elements) if you haven't already.\n\nI have put together an [Ember Twiddle](http://ember-twiddle.com/fc4760a5e5c475bbabc1) with the example\nwe worked through today. It also demonstrates how by following the \"data down, actions up\" best practice,\nchanges in the UI of one component can easily propagate and be reflected in other components. Check it out and feel\nfree to play around!\n"},{"title":"Ember Best Practices: Don't Don't Override Init","tags":["ember","best practices"],"summary":null,"legacy":false,"id":"2015/10/19/2015-dont-dont-override-init","employee":"Brian Cardarella","date":"2015-10-19T00:00:00","body":"\n\nThe double negative in the title of this article is a jab at another\narticle I wrote nearly a year and a half ago: [Don't Override\nInit](https://dockyard.com/blog/2014/04/28/dont-override-init). In that\narticle I advocated for never overriding the `init` function for your\n`Ember.Object` derived classes, instead using `Ember.on` to kick off a\nfunction call for what you'd normally put into `init`. At the time I\nstill believe this was a good recommendation. But times they do change,\nand now that we're all happily using\n[es2015](https://babeljs.io/docs/learn-es2015/) features via\n[Babel](http://babeljs.io) we get access to the great \n[`spread`](https://babeljs.io/docs/learn-es2015/#default-rest-spread) operator.\n\nHere is how we are now writing our `init` functions:\n\n```js\nexport default Ember.Object.extend({\n  init() {\n    // our custom code\n    return this._super(...arguments);\n  }\n});\n```\n\nThis is a very clean approach. More importantly: it is more\nperformant. Ok, but what if you were using several `Ember.on` calls? That's\neasy, just break them into functions:\n\nBefore:\n\n```js\nfoo: on('init', () => {\n  // ...\n}),\n\nbar: on('init', () => {\n  // ...\n}),\n\nbaz: on('init', () => {\n  // ...\n})\n```\n\nAfter:\n\n```js\ninit() {\n  this._super(...arguments);\n  this.foo();\n  this.bar();\n  this.baz();\n});\n```\n\n*Bonus* points for taking back control of execution order.\n\nYou don't always have to `return this._super(...arguments);` but in most\ncases you should.\n\nIf you are using [ember-cli](http://ember-cli.com) and you using\n`Ember.on` for init-like functionality you should consider this approach\ninstead. Do Override Init!\n"},{"title":"Chris McCord is a DockYarder","tags":["announcement","new hire","elixir","phoenix"],"summary":null,"legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/mm1doo1.png","id":"2015/10/21/chris-mccord-is-a-dockyarder","employee":"Brian Cardarella","date":"2015-10-21T00:00:00","body":"\n\n![](http://i.imgur.com/mm1doo1.png)\n\nI'm very happy to announce that [Chris McCord](http://twitter.com/chris_mccord), the creator of the \n[Phoenix Framework](http://phoenixframework.org/), has joined the DockYard team!\n\nWe've been working with Phoenix for nearly a year now. We love it. So\nmuch so that we dumped Ruby on Rails and doubled down on Phoenix and\nElixir as the future. With Chris joining our team we hope to invest\nheavily in that future.\n\nChris' primary responsibility at DockYard is to continue building Phoenix\nand make it the best choice for backend frameworks. He will be available\nfor consulting through DockYard in limited capacity but his knowledge is\nalready making its way through our team.\n\n[If you have a project in Phoenix we'd love to\nchat.](http://dockyard.com/contact)\n"},{"title":"Ember Best Practices: Computed Properties with Dynamic Dependent Keys","tags":["ember","javascript"],"summary":"Need to determine the dependent key for your computed property at runtime?","legacy":false,"id":"2015/10/23/ember-best-practices-dynamic-dependent-keys-for-computed-properties","employee":"Michael Dupuis","date":"2015-10-23T00:00:00","body":"\n\nIn Ember, computed properties allow you to declare functions as properties. More often than not, you're going to have a set of dependent keys which invoke a function when their values change:\n\n```js\nconst Team = Ember.Object.extend({\n  city: null,\n  league: null,\n  name: null,\n\n  fullName: Ember.computed('city', 'name', {\n    get() {\n      return `${Ember.get(this, 'city')} ${Ember.get(this, 'name')}`;\n    }\n  })\n});\n\nconst redSox = Team.create({\n  city: 'Boston',\n  league: 'American',\n  name: 'Red Sox'\n});\n\nEmber.get(redSox, 'fullName'); // \"Boston Red Sox\"\n```\n\nIn the example above, `fullName` is dependent on `city` and `name`, so\nit watches those properties, and when either of their values change,\nits `get` function is invoked, thereby returning the updated `fullName`\nproperty for our beloved baseball team.\n\nWhat if you wanted to write a computed property that didn't know what\nkeys it needed to monitor until runtime?\n\nIn our contrived examples below, our `model` is an array of\nbaseball teams which will be passed to a component.\n\n```js\nimport Ember from 'ember';\n\nconst Team = Ember.Object.extend({\n  city: null,\n  league: null,\n  name: null\n});\n\nexport default Ember.Route.extend({\n  model() {\n    return {\n      teams: [\n        Team.create({ league: 'American', city: 'Boston', name: 'Red Sox' }),\n        Team.create({ league: 'American', city: 'New York', name: 'Yankees' }),\n        Team.create({ league: 'National', city: 'Los Angeles', name: 'Dodgers' }),\n        Team.create({ league: 'National', city: 'San Francisco', name: 'Giants' })\n      ]\n    }\n  }\n});\n```\n\nIn a component, we're going to separate our American League teams and our National\nLeague teams.\n\n```handlebars\n{{league-teams leagueData=model}}\n```\n\n```js\n// league-teams/component.js\nimport Ember from 'ember';\n\nexport default Ember.Component.extend({\n  americanLeagueTeams: Ember.computed('leagueData.teams.@each.league', {\n    get() {\n      const teams = Ember.get(this, 'leagueData.teams');\n      return teams.filterBy('league', 'American');\n    }\n  }),\n\n  nationalLeagueTeams: Ember.computed('leagueData.teams.@each.league', {\n    get() {\n      const teams = Ember.get(this, 'leagueData.teams');\n      return teams.filterBy('league', 'National');\n    }\n  })\n});\n```\n\nWe have two computed properties in our component. The first one pulls the\nAmerican League teams and the second pulls the National League teams.\nThe functions performing this work are virtually identical with the\nexception of the value against which they are filtering (i.e.,\n\"American\" and \"National\"). Let's DRY\nthis code up a bit:\n\n```js\nimport Ember from 'ember';\n\nfunction filterByLeague(value) {\n  return Ember.computed('leagueData.teams.@each.league', {\n    get() {\n      const collection = Ember.get(this, 'leagueData.teams');\n      return collection.filterBy('league', value);\n    }\n  });\n}\n\nexport default Ember.Component.extend({\n  americanLeagueTeams: filterByLeague('American'),\n  nationalLeagueTeams: filterByLeague('National')\n});\n\n```\n\nThat refactor removes a bit of code duplication, but we can go further.\nRather than leaning on the static dependent key of\n`leagueData.teams.@each.league`, we can make the `filterByLeague`\nfunction more generic if we can just pass in the key we want to filter\non:\n\n```js\n import Ember from 'ember';\n\n function filterCollectionByValue(collectionKey, propName, value) {\n   return Ember.computed(`${collectionKey}.@each.${propName}`, {\n     get() {\n       const collection = Ember.get(this, collectionKey);\n       return collection.filterBy(propName, value);\n     }\n   });\n }\n\n export default Ember.Component.extend({\n   americanLeagueTeams: filterCollectionByValue('leagueData.teams', 'league', 'American'),\n   nationalLeagueTeams: filterCollectionByValue('leagueData.teams', 'league', 'National')\n });\n```\n\nES6 allows for string interpolation. This means that we can pass in the\nkey we want to filter by and also watch it as the dependent key. If we\nneed to filter a collection based off of keys other than `league` in the\nfuture, we\ncan use this generic `filterCollectionByValue()` util rather than creating\na unique `filterByX()` function for each key.\n\nAnother dimension to the idea of dynamic dependent keys is the ability to watch an arbitrary number of them. The macro computed property `getPropertiesByKeys()` does just that. This function allows you to provide an\narbitrary number of dependent keys and return their values:\n\n```js\nexport function getPropertiesByKeys(...dependentKeys) {\n  const computedFunc = Ember.computed({\n    get() {\n      return Ember.getProperties(this, dependentKeys);\n    }\n  });\n\n  return computedFunc.property.apply(computedFunc, dependentKeys);\n}\n```\n\nAs you can see, this macro is more or less relying on Ember's\n[`getProperties()`](http://emberjs.com/api/classes/Ember.Object.html#method_getProperties) method, but it allows you to specify the dependent keys at runtime.\n\nLeveraging dynamic dependent keys in computed properties opens the door\nto greater refactoring. These helper functions which return a computed\nproperty can be moved into a computed property macros util and imported\nas needed throughout your project.\n\nBetter yet, let my esteemed colleague, Lauren Tan, do the work for you! Her\n[ember-macaroni](https://github.com/poteto/ember-macaroni) library wraps\nup many of the macros we use at DockYard in a convenient [Ember\naddon](https://www.npmjs.com/package/ember-macaroni).\n"},{"title":"Validating your Ecto Models with ValidField","tags":["elixir","testing","phoenix"],"summary":"Unit testing your changesets made easy","legacy":false,"id":"2015/10/26/validating-your-ecto-models-with-valid_field","employee":"Dan McClain","date":"2015-10-26T00:00:00","body":"\n\nWhen we were working with Rails, we would unit test our validations with a\nlibary called [ValidAttribute][valid-attribute]. This library would allow you to\nspecify the attribute and a list of values then check if the values yield\nerrors or not. On a recent client project, I resurrected the pattern and\nextracted it as a Phoenix library this weekend.\n\n## Introducing ValidField\n\nLet's import [ValidField][valid-field] and get right to the tests:\n\n```elixir\ndefmodule App.UserTest do\n  import ValidField\n  use ExUnit.Case\n  alias App.User\n\n  test \".changeset - Validations\" do\n    with_changeset(%User{})\n    |> assert_valid_field(:email, [\"something@else.com\"])\n    |> assert_invalid_field(:email, [\"\", nil, \"test\"])\n    |> assert_valid_field(:password, [\"password123!\"])\n    |> assert_invalid_field(:password, [nil, \"\", \"test\", \"nospecialcharacters1\", \"nonumber!\"])\n  end\n\n  test \".changeset - Validations - complex changeset\" do\n    with_changeset(%User{}, fn (model, params) -> App.UserController.changeset(model, params, :insert))\n    |> assert_valid_field(:email, [\"something@else.com\"])\n  end\nend\n```\n\nFirst, we use `with_changeset/1`, which takes the model struct as the sole\nargument and returns a map that contains an anonymous function that yields a\nchangeset from `Model.changeset`. `with_changeset/1` assumes that your\nchangeset is defined at `Model.changeset/2`. If your changeset is defined\nelsewhere or has additional arguments, you'll want to use `with_changeset/2`.\nThe first argument of `with_changeset/2` is still the model struct, but the\nsecond argument is a function with an arity of 2. The first argument to the\nfunction will be the model struct passed in, the second argument will be a map\nof field values to be set in the changeset.\n\nAfter we have a changeset map, we pass that as the first argument to\n`assert_valid_field/3` and `assert_invalid_field/3`. Instead of returning a\nboolean of whether or not the field is valid for the list of values passed in,\nthese functions run the assertions internally. This is done to provide useful\ntesting errors when running `mix test`. Assume that you inverted the third line\nof the test to be the following (and didn't change your validations), the\nfollowing error will be generated:\n\n```elixir\ndefmodule App.UserTest do\n  import ValidField\n  use ExUnit.Case\n  alias App.User\n\n  test \".changeset - Validations\" do\n    with_changeset(%User{})\n    |> assert_valid_field(:email, [\"something@else.com\"])\n    |> assert_valid_field(:email, [\"\", nil, \"test\"])\n    # (ExUnit.AssertionError) Expected the following values to be valid for \"email\": nil, \"\", \"tests\"\n  end\nend\n```\n\n\n## OK, I see what you did there but why?\n\n### Clean workflow for unit testing changesets\n\nBy grouping all the valid and invalid cases in your tests, you can\nquickly understand what makes your changeset valid. It also allows you to\nupdate your tests by just adding another value to either function call. Say you\nwant to stop accepting Gmail address as valid email address; you just add\n`some-email@gmail.com` to your `assert_invalid_field` call for email, and\nupdate the tests to satisfy this new requirement. We aren't worried about the\nerror message anymore.\n\n### Less brittle tests\n\nMost unit tests around changeset validations use the `error_on` function and\nassert that the field and a specific error message are contained in the list of\nerrors provided. This is a decent starting point, but has a couple of\ndrawbacks. The first is that your test is tied directly to the error message,\nmeaning that changing a validation message requires you to update your test. A\ncorrection to a gramatical error would cause a test failure, showing how\nbrittle this pattern could be. What if you support multiple languages? Since\nyour error messages might be different for an email that contains a space or\none that doesn't contain a valid domain, your tests will be more verbose since\nthe messages need to be matched individually.\n\nWith ValidField, you are testing the behavior of your changeset,\nrather than the implementation of your error messages.\n\n## Go forth and test your changeset\n\nMaking sure your changeset is properly defined is important, and ValidField\nmakes it much easier to unit test them. Having the list of valid and invalid\nvalues for your field in your tests also serves a documentation of what should\nbe accepted for a given field as well.\n\n[valid-attribute]: https://github.com/bcardarella/valid_attribute\n[valid-field]: https://github.com/dockyard/valid_field\n"},{"title":"Ember Best Practices: Stop bubbling actions and use closure actions","tags":["ember","javascript","best practices"],"summary":"Bubbling no longer required","legacy":false,"id":"2015/10/29/ember-best-practice-stop-bubbling-and-use-closure-actions","employee":"Dan McClain","date":"2015-10-29T00:00:00","body":"\n\nBack in January, I talked about [bubbling actions through components][bubbles]\nso that you could nest components and have an action be triggered from the\ndepths of your inner component. This involved passing actions down through your\ncomponents, and then using `sendAction` to trigger the action at each level\nuntil you got all the way out of your nesting. With the introduction of\n[closure actions][closure], you end up passing actions down, but no longer have\nto bubble out.\n\n## Actions down\n\nLet's look at the example from the previous blog post again:\n\n```hbs\n{{! index.hbs}}\n  {{pressCount}} Button presses\n  {{button-wrapper action=\"buttonClick\"}}\n\n{{! components/button-wrapper.hbs}}\n  <h2>Button Wrapper</h2>\n  {{press-button action=\"buttonClick\"}}\n\n{{! components/press-button.hbs}}\n  <button {{action \"buttonClick\"}}>My Button</button>\n```\n\nNotice how we we are using the `action=\"buttonClick\"` above the `press-button`\ncomponent to pass the action down. We end up calling `this.sendAction()` in\nboth components so that the button 2 levels deep calls the action defined in\nthe index controller.\n\nWhat if I told you that you only need to define the templates for the\ncomponents, and no longer need to have any actions defined within the\ncomponents themselves?\n\n```hbs\n{{! index.hbs}}\n  {{pressCount}} Button presses\n  {{button-wrapper click=(action \"buttonClick\")}}\n\n{{! components/button-wrapper.hbs}}\n  <h2>Button Wrapper</h2>\n  {{press-button click=(action click)}}\n\n{{! components/press-button.hbs}}\n  <button {{action (action click)}}>My Button</button>\n```\n\nClosure actions are called by using the `action` helper, which in turn\npasses down the function to the component, defining it at `<property\nname>`, just like other properties passed to your component.At the\nbottom, the `<button>` action just calls the action, and the controller\naction is the same as before. [You can see it in action\nhere][simple-example]. There is no code backing the component at this\npoint.\n\n## Ok, what if I wanted to do something a bit more complicated\n\nThis is where closure actions really show off. With closure actions, you can\nhave the function you pass in to the action *return a value*. This was\npreviously impossible because the return value of a function was used to\ndetermine if the action should bubble. This also highlights one of the\npotential gotchas you may encounter when you first start using closure actions:\nthey don't bubble. If you use a closure action, it won't bubble out of the\ncontroller/component. If you need this behavior, you need to call `this.send`\nin the controller to fire an action that will be triggered in your route. [Here\nis an example][route-action]. Note that the name of the action sent is\ndifferent than the action called, you'll end up in an infinite loop if you try\nto `this.send('buttonClick')`. When routeable components land, you'll likely\nend up passing the route action into the component using closure actions, so\nunless you really need route actions with closure actions, I would recommend\nagainst leaning on this example.\n\n## Can you do anything cool with closure actions?\n\nYes, you can now [curry][curry]! You can pass multiple arguments to the `action` helper\nat each level. Those arguments are added to the function at each scope. Let's\nlook at a bit of code to make this clearer:\n\n```hbs\n{{! index}}\n    Things: {{things}}\n    {{cat-wrapper class=\"button-wrapper\" click=(action \"buttonClick\")}}\n    {{dog-wrapper class=\"button-wrapper\" click=(action \"buttonClick\")}}\n\n{{! components/cat-wrapper.hbs}}\n    <h2>Cats</h2>\n    {{press-button count=1 class=\"press-button\" click=(action click \"cat\")}}\n    {{press-button count=2 class=\"press-button\" click=(action click \"cats\")}}\n\n{{! components/dog-wrapper.hbs}}\n  <h2>Dogs</h2>\n  {{press-button count=1 class=\"press-button\" click=(action click \"dog\")}}\n  {{press-button count=2 class=\"press-button\" click=(action click \"dogs\")}}\n\n{{! components/press-button.hbs}}\n  <button {{action (action click count)}}>{{count}}</button>\n```\n\nNotice how we pass `cat/cats/dog/dogs` to the `action` of each `press-button`\nin the `cat-wrapper` and `dog-wrapper` component, but in the `press-button`\ncomponent, we just pass the count to the `action` helper after passing it the\nfunction we want to call. The function that is called in `press-button` has the\nsignature `function(thing, count)`, so if we click the first cat button, the\n`buttonClick` action in the controller is called with `'cat'` as the first\nargument, and `count` as the second argument. [Here is a living version of\nthis example][currying-action].\n\n## What if I don't use the action helper in my deepest component?\n\nAll the examples so far use the `action` helper in `press-button`, but if you\nwanted to call your action manually, you'd just call `click()` to\ncall the function passed into the component. [Here is an updated version of the\ncurrying example that uses an action in the `press-button`\ncomponent][explicit-call]. We still pass the argument to the curried function.\n\n## Functions Down, Actions up\n\nWith the introduction of closure actions in Ember 1.13, we gained a powerful way\nof passing data down in the form of functions to push data up and out of our\ncomponents. This was possible before, but it was also a lot more work. You'd\nhave to manually bubble actions all the way out, but now we punch a hole down\nto our deepest component and fire the action directly from there. This will\nlead to easier debugging, as the `sendAction` way was a lot harder to grok\nwhere your component actions were breaking.\n\n[explicit-call]: http://jsbin.com/logawi/4/edit?html,js,output\n[currying-action]: http://jsbin.com/logawi/3/edit?html,js,output\n[curry]: https://en.wikipedia.org/wiki/Currying\n[route-action]: http://jsbin.com/logawi/2/edit?html,js,output\n[simple-example]: http://jsbin.com/logawi/1/edit?html,js,output\n[closure]: http://emberjs.com/blog/2015/06/12/ember-1-13-0-released.html#toc_closure-actions\n[bubbles]: https://dockyard.com/blog/2015/01/28/bubbling-actions-through-components\n"},{"title":"How long it took to convert our team from Rails to Phoenix","tags":["elixir","phoenix"],"summary":null,"legacy":false,"id":"2015/10/29/how-long-it-took-our-team-to-move-from-rails-to-phoenix","employee":"Brian Cardarella","date":"2015-10-29T00:00:00","body":"\n\nOne week.\n\nThat is how long it took for our engineers, who had all (but one) worked\nwith [Rails][rails] for a few years, to be productive on a new [Phoenix][phoenix] client\nproject.\n\nI had assigned each of them to read Part 1 of [Dave Thomas' Programming Elixir][book]\nbook which was only 160 pages of material. Part 1 introduces early\n[Functional Programming][fp] concepts and the [Elixir][elixir] standard library. In my\nmind, this is enough to make the switch.\n\n> **“It was cool being able to contribute to a Phoenix app without prior\n> experience with the framework thanks to the similarity in structure\n> with Rails. Elixir is the biggest hurdle, but a quick read through the\n> key concepts is enough to make you productive - not to mention\n> learning a new language is fun!”**\n>\n> *-- Romina Vargas, DockYard Engineer*\n\nAt the higher level of writing actions, routes, tests, models, queries, etc... there is so much\noverlap with the concepts that exist in Rails that it was simply a\nmatter of syntax that had to be learned before a Rails engineer could\nmake contributions back to Phoenix applications.\n\nThere is no doubt that Phoenix borrows *a lot* of concepts and structure\nfrom Rails. For good reason, Rails nailed the [MVC app pattern][mvc]. The\nbenefit here is that a lot of that domain knowledge on how to build\nRails apps can be transferred over to building Phoenix\napps.\n\n> **“Ruby on Rails had a pretty steep learning curve. Not only did I have\n> to study a new programming language, I had to master the MVC framework\n> as well. But with RoR under my belt, the learning curve for Elixir and\n> Phoenix was significantly reduced. Plus pattern matching makes\n> everything way easier!”**\n>\n> *-- Marin Abernethy, DockYard Engineer*\n\nNow, don't get me wrong. I am not suggesting that after this one week\nthat you should be ramped up on the complexities of Elixir and the\nErlang ecosystem. I think there is enough to Erlang that could take\nyears to fully absorb. But that's not the point.\n\nThe best way to write a faster Rails app is to write it in\nPhoenix.\n\n[Get in touch with us if you'd like to move from Rails to Phoenix. We can\nhelp!][cta]\n\n[book]: https://pragprog.com/book/elixir/programming-elixir\n[rails]: http://rubyonrails.org\n[phoenix]: http://phoenixframework.org\n[elixir]: http://elixir-lang.org\n[fp]: https://en.wikipedia.org/wiki/Functional_programming\n[mvc]: http://betterexplained.com/articles/intermediate-rails-understanding-models-views-and-controllers/\n[cta]: https://dockyard.com/contact\n"},{"title":"Data visualization workshop","tags":["data visualization","user experience"],"summary":"Our next UX East hands-on workshop","legacy":false,"illustration_alt":"SoSoLimited","illustration":"https://i.imgur.com/Jsk6FWh.jpg","id":"2015/11/03/data-visualization-workshop","employee":"Ashley Treni","date":"2015-11-03T00:00:00","body":"\n\nI’m very excited to host UX East's next workshop on [data visualization](http://www.meetup.com/UX-East/events/226344211/) here at DockYard! I received my Master’s degree earlier this year from Northeastern’s [Information Design and Visualization](http://www.northeastern.edu/camd/artdesign/academic-programs/mfa-in-information-design-and-visualization/) program, and data visualization is one of my favorite things to geek out about. \n\nThere are many interesting parallels between UX design thinking and the process around creating data visualizations. This workshop will be a comprehensive overview of that process, with a special focus on context and experience. Together, we’ll explore a dataset (a very interesting one!), create a story around a target audience, use the data to define appropriate visualization methods, and storyboard the experience.\n\nCreatives and makers of all types and skill levels are encouraged to come. During this workshop, we’ll manually look through the data and sketch our explorations. No background in engineering or design is needed, but we can  discuss digital visualization tools for those who are interested. It’ll be a very fun collaborative evening. \n\nTo give you a taste of some of the examples to come - here are a few of my favorite data visualizations that create very different experiences. Many more will be included in the pre-workshop presentation about data visualization basics and best practices.\n\n![SoSoLimited][so-so-limited]\n*“CSIS data chandelier” - [SoSoLimited](http://www.sosolimited.com/work/csis-data-chandelier/)*\n\n![Bloomberg][bloomberg]\n*“What’s really warming the world?” - [Bloomberg](http://www.bloomberg.com/graphics/2015-whats-warming-the-world/)*\n\n![Dear Data][dear-data]\n*[Dear Data](http://www.dear-data.com/) - Stephanie Posavec and Giorgia Lupi*\n\nCome make with us! If you have any questions about the workshop, please feel free to [email me](mailto:ashley.treni@dockyard.com). Hope to see you there!\n\n\n[so-so-limited]: https://i.imgur.com/Jsk6FWh.jpg\n[bloomberg]: https://i.imgur.com/cRZM0lH.png\n[dear-data]: https://i.imgur.com/8ZR8Y50.png\n"},{"title":"CSS Dev Conference 2015 Thoughts","tags":["conference","css","html"],"summary":"Brief thoughts on my experience at CSS Dev Conference and all my notes","legacy":false,"id":"2015/11/05/CSSDevConf-2015-thoughts","employee":"Cory Tanner","date":"2015-11-05T00:00:00","body":"\n\nAs a UX Developer I specialize in HTML/CSS so a CSS developer conference could not have been any more perfect. Three DockYarders, including myself, had the opportunity to go to [CSS Dev Conf](http://2015.cssdevconf.com/) last week aboard the Queen Mary in LA.\n\nThe talks went beyond my expectations and I learned something different at each one. Even with new content being presented it was good to see that the tools and opinions of the speakers were all aligned with how we structure HTML/CSS at DockYard.\n\nThe most interesting event at the conference was the open question session at the end of day 2. All the speakers got on stage at once and the audience could go to a microphone in the middle of the room and ask the group any question that came to mind. There were some great insights shared about what CSS developers should expect to see from the job market and what the future of CSS will look like.\n\nThe Queen Mary was amazing to stay on throughout the conference and I have to give a shoutout to left shark, right shark and the giant octopus at the after party. Could not have asked for a better venue. Who wouldn't want to go to a conference on a boat?!\n\nHere are my takeways from the conference!\n\n## Keynote Sara Soueidan\nTwitter: [@SaraSoueidan](https://twitter.com/SaraSoueidan)\n\nSlides: [SVG For Web Designers (and Developers)](http://www.slideshare.net/SaraSoueidan/svg-for-web-designers-and-developers)\n\n- Use SVGs for everything possible and provide fallbacks for browsers that need it\n- Keep in mind you need to look at performance, don’t choose SVGs over performance\n\n### SVG for…\n- Icon systems\n- Add banners\n- Infographics\n- Data visualizations\n- Animated illustrations\n- Filter effects\n- Simple UI shapes\n\n### Future\n- CSS Spec custom add SVGs rules coming soon\n\n### Designing SVGs\n- Every design decision that is made while designing an SVG affects development\n- Developers and Designers need early communication and have some give and take to make both their lives simpler\n\n### Process\n- Outline text that has been changed into vectors are not selectable\n- Outline text preserves font-face\n- Use simple shapes over a `<path>`\n  - easy to maintain\n- Simplify your paths when you use them with simplify path tool in Illustrator\n- Only combine paths if you don’t need sections to be separate for animation or coloring\n- Use organized naming/layer conventions in your SVG code\n- Designers should use SVGs filters that are available in Illustrator effects section\n- Always keep `width` and `height` attributes on the `<svg>`\n  - Great for fallback\n\n### Optimize\n- Most popular tool is SVGO but will change the structure of the SVG, also can break your SVGs :( so use the GUI version with custom options\n- Optimizing your SVG can cut your files size by half\n- Illustrator in the future will have optimize options\n- Sketch has no options yet :(\n\n### Development\n- `<symbol>` and `<use>`\n  - Multiple `<symbol>` elements being combined into one SVG, always include `<title>` and `description` for accessibility\n  - This technique puts the SVGs code in a shadow DOM that is difficult to style\n  - You can leak styles in with CSS variables `var(--prime-color)`\n- Use SVGs `viewbox` to create a view window that only shows a portion of the SVGs file. Also known as the sprite technique\n  - Place your SVG files into the CSS as background-images\n  - support back to IE6\n- Use CSS only for simple animations\n- Use JS for complex animations\n\n### SVG over icon fonts\n- Infinite scale and easy styling\n- Browser content blockers will block fonts and not SVGs\n- Tools for switching from icon-fonts to SVG are out there.\n- [Greensock](http://greensock.com/get-started-js) animation library is a go-to\n- `<object>` is most flexible embedding technique for SVG\n\n## Cracking the SVG Code: Brenda Storer\nTwitter: [@brendamarienyc](https://twitter.com/brendamarienyc)\n\nSlides: [Cracking the SVG Code](http://brendastorer.com/presentations/2015-10-CSSDevConf-SVGs/#intro)\n\n- Queen Mary is in the top 10 most haunted places in the world. Over 150 spirits on the boat\n- Whats inside a SVG? XML!\n  - It's like HTML but for digital drawings instead of content\n- SVG 1.0 became recommended in 2001 by W3C\n- SVG 2.0 maybe in 2018 :)\n- `viewBox` defaults to px if no value is given\n- `viewBox=\"0 0 100 100\"` start x start y end x end y\n- For inline SVG remove all unneeded markup that is inserted by Illustrator\n- `<g>` is the `<div>` of SVGs\n- Stroke = CSS border and fill = CSS background-color\n- GO Shapes! `<rect>`, `<circle>`, `<ellipse>`, `<line>`, `<polyline>`, `<polygon>`\n- In Illustrator you can select what you want to be a SVG and then shorthand copy it, then paste in your text editor\n  - This also starts your `viewBox` at 0 0 !!!\n- Transforms on SVG is not 100% supported with your .css file but if you include the transform inline style its 100% supported\n- Checkout [SVG Compressed](http://www.amazon.com/jQuery-Compressed-Jakob-Jenkov-ebook/dp/B006DI6QJ2/ref=asap_bc?ie=UTF8) book online\n\n## Creative Typography with SVG: Brenna O’Brien\nTwitter: [@brnnbrn](http://twitter.com/brnnbrn)\n\nSlides: [Creative Typography With SVG](http://talks.brennaobrien.com/svg-typography/#/)\n\n- VREAM - viewBox Rules Everything Around Me\n- SVG easy to manipulate with CSS and JS\n- Text becomes completely responsive when inside a SVG\n- Go on a code adventure with SVG you will find new things\n\n### SVG has a `<text>` element\n- `<text>` is accessible!\n  - Inherits font-family from `<body>`\n  - Use fill to change color\n  - `y=\"0\"`is not good, use `y=“1em”`\n  - `font-size=\"80\"` is 80px\n\n### `<tspan>`\n- similar to `<span>`\n- use `x` and `y` for positioning\n\n### Curved text\n- use `<textPath>` and then link it to a `<path>` that is inside your `<defs>` with a `xlink:href=\"pathName\"`\n\n### Gradients on text\n- `<linearGradient>` in your `<defs>`\n- In your `fill` on the `<text>` use `fill=“url(#grad)”`\n\n### Images on text\n- Can put your `<image>` inside a `<pattern>` under your `<defs>` and apply the pattern to the fill on your `<text>`\n- You can also fill text with gifs :)\n\n### Knockout text\n- Place your `<text>` in a `<mask>` and then apply the mask to your element you want the text to be in as `mask=\"url(#knockoutText)\"`\n\n### Self Typing Text\n- Use `<animate>` as a child of what element is being animated with `from` and `to` with a `duration`\n\n### Morph Text Glyphs\n- Convert your text to paths with Illustrator outlines\n\n### Self drawing text\n- `stroke-dasharray` and `stroke-dashoffset` are used to “hack” this effect\n\n## Designing Complex SVG Animations: Sarah Drasner\nTwitter: [@sarah_edo](http://twitter.com/sarah_edo)\n\nSlides: [Designing Complex SVG Animations](http://slides.com/sdrasner/cssdevconf#/)\n\n- Why make complex animations?\n  - powerful to convey meaning\n  - fun :)\n- Animation should be designed and not an afterthought or it will look like sugar on top animations\n- One size does not fit all, look at your website and limitations\n- Checkout Val Head’s “[All the Right Moves](http://valhead.com/category/all-the-right-moves-screencast/)”\n- When designing complex animations try to design everything first and then apply the animations\n- Ugly storyboards save you time (even if ther're ugly)!\n- SVG has less HTTP requests\n- Optimize your SVGs!\n- But don’t overdo the amount of animations you include on your website, simplicity is key\n\n### UI/UX Animation\n- This is used to enhance the information on the page\n\n### Context-Shifting\n- This removes the breakpoints of information being loaded on the page\n- Use animation to fill time while loading to keep the users mind at ease\n- Provide clear focus on what the user should be reading or looking at\n\n### Standalone\n- Questions to ask\n  - Responsive?\n  - toggle on/off?\n  - Easing structures\n  - User flow\n- Easing can contribute to your branding\n  - You can convey emotion with how you animate elements\n- Animation branding guidelines make communication down the line easy\n\n### Animation performance\n- Test everything yourself\n- People expect everything to be faster on the web\n\n### SVG sprites complex to simple\n- Design your three steps for desktop, tablet, and mobile\n- Combine elements where you can so you have less SVGs elements you need to hide when going between views\n- Use animation media queries\n- `viewBox` shift with JS\n- provide fallbacks\n\n### Complex animations\n- Use JS to make this easy\n- Use [Greensock](http://greensock.com/get-started-js)\n- If you need more then 2-3 chained events in your animation its a good idea to use JS\n- Relative color tweening\n  - Example: shifting from day to night scenes\n- Motion along a path is important for realism\n- Responsive animations should be made with thought as you place the elements in DOM\n\n### Design + Animation + Data\n- Combining these things can bring back the success of static infographics used to have\n- We can make them responsive and interactive with SVG\n- Add accessibility with `<title>` tags\n- Go [CodePen](http://codepen.io/)! Easy to learn new things when you can dive into other peoples code\n\n## The Dark Arts of Light Speed: Henri Helvetica\nTwitter: [@HenriHelvetica](https://twitter.com/HenriHelvetica)\n\nSlides: [The Dark Arts of Light Speed](http://www.slideshare.net/HenriHelvetica/?mc_cid=cf53aad878&mc_eid=60d40ffbe3)\n\n- Web performance = speed\n- Font-end development suffers from the embarrassment of riches\n- 57% of visiters will abandon a page after 3 seconds of not loading\n- User experience metrics over network-based metrics\n- Need a culture based on building apps for performance\n- Placing `defer` in your `<script>` tag will download JS at the same time as HTML but execute JS at the end of the HTML loading\n  - async will download JS and load HTML at the same time but pause the loading of HTML when the JS download finishes to execute it\n- Don’t send larger images to mobile when you don’t have to, it waists bandwidth on phones\n- `<srcset>` `<picture>` you can use media queries inside them to load images for specific VW\n- Reduce the number of HTTP requests with combining .css files into one and .js files into one\n\n## No Pain No Gain: Stacy Kvernmo\nTwitter: [@funstacy](https://twitter.com/funstacy)\n\nSlides: [No Pain No Gain](http://www.slideshare.net/Funstacy/no-pain-no-gain-css-code-reviews-ftw)\n\n- Build a culture of code review in your workplace\n  - Catch bugs\n  - Increase familiarity of the project with your team\n  - Education! communication with your team on why you did what you did will tach you to explain things simply\n- Review the compiled code when you use pre-processors\n- Contributing to open source is great and try to repay the contributor somehow\n- Stay positive during code reviews\n- Avoid absolute terms when commenting\n  - Must\n  - Always\n  - Never\n- Ask questions about why the person coded a certain way\n- Document the issues you find\n- Document your code with comments\n- A pull request should say what you did very clearly\n\n### What to review\n- Follow standards\n- Is the code easy to understand\n- Don’t need to nest everything, don’t go as far as 3-4 levels deep\n- Accessibility\n- Using correct vendor prefixes?\n\n## Keynote Jina Bolton\nTwitter: [@jina](https://twitter.com/jina)\n\nSlides: [Designing a Design System](https://speakerdeck.com/jina/designing-a-design-system)\n\n- Communication between Designers and Developers is important\n- designing systems rather then pages\n- style guides should be living and constantly updated\n- [designprinciplesftw.com](http://designprinciplesftw.com)\n- Don’t make things until you need it\n\n### v2mom\n- vision\n- values\n- methods\n- obstacles\n- measures\n\n## Keynote Val Head\nTwitter: [@vlh](https://twitter.com/vlh)\n\nSlides: [Designing Meaningful Animation](http://www.slideshare.net/valhead/designing-meaningful-animation)\n\n- With new tools we have the ability to make accessible responsive and beautiful animations for the web!\n- Using motion in our design language is important\n- When you have motion across all platforms it provides a more recognizable interface for the user\n- Be subtle with movements, a little will go a long way\n\n## CSS Architecture: Jonathan Snook\nTwitter: [@snookca](https://twitter.com/snookca)\n\nSlides: [CSS Architecture](http://environmentsforhumans.com/2015/css-dev-conf/presentations/Snook-CSSDevConf2015-CSSArchitecture.pdf?mc_cid=cf53aad878&mc_eid=60d40ffbe3)\n\n- Build modular systems\n- INLINE STYLES WON'T SAVE YOU FROM INHERITANCE\n- Don’t write multiple of the same rule for one element\n- Future we can us `all: inherit` on an element to ignore all inherited styles\n- Element queries can be used but you need JS to accomplish this\n- Design has a cost on the web just like it does in print\n- Every peace of design ends up in code\n- You can use emojis as class names :P\n\n### Categorization of styles\n- state\n- Theme\n- module\n- layout\n- base\n\n### Naming conventions\n- Use them!\n- [SMACSS](https://smacss.com/)\n- [BEM](http://csswizardry.com/2013/01/mindbemding-getting-your-head-round-bem-syntax/)\n- The goal is to isolate an element from everything else on the page\n\n### Create Standards For Your CSS\n- Without standards and code reviewing, CSS will get out of control\n- [Styleguides.io](http://styleguides.io) is a great resource\n\n### Future\n- Web components\n- Composable UIs\n- Communicate!\n\n\n## Bower Power! Supercharging Front-End Manageability: Eric Carlisle\nTwitter: [@eric_carlisle](https://twitter.com/eric_carlisle)\n\nSlides: [Bower Power! Supercharging Front-End Manageability](http://www.slideshare.net/ericcarlisle/bower-power-54549427)\n\n- Keep It Stunningly Simple (KISS)\n- You get a happy team\n- Better products, process, reduce cost\n- Don’t be afraid to use npm and bower\n\n### Bower keeps it simple\n- Maintains a dependency manifest\n- Fetches them when you need it\n- Tracks dependencies\n- Integrates with everything\n\n### You need\n- Node.js Javascript runtime\n- npm, Node.js package manager\n- git, version control\n\n### Starting the awesome\n- `npm install -g bower`\n- `bower init`\n\n### Installing dependencies\n- `bower install dependenciesName`\n- add a `--save` after install to save that dependency for the project\n- add a `--save-dev` after install to save that dependency for development or debugging\n- Add `bower_components` to `.gitignore`!!\n\n## Fight the Zombie Pattern Library: Marcelo Somers\nTwitter: [@marcelosomers](https://twitter.com/marcelosomers)\n\nSlides: [Fight the Zombie Pattern Library](https://speakerdeck.com/marcelosomers/fight-the-zombie-pattern-library-css-dev-conf-2015)\n\n- “How do you keep building interfaces knowing thats what the world is like”\n- Pattern library accelerate both the design process and development process\n- Photoshop has libraries that you can make/use in multiple files/projects\n  - You can do this in teams also\n- Traditional handoff between designers and developers is broken\n- Use pattern libraries as the connection between the groups\n- Libraries eliminate waste\n- This reduces tweaking static comps to make one small change but rather make one change to an item in a library\n- You want an automated library or a team managing your libraries\n\n### Get started today\n- Take an inventory\n- Take documentation\n  - Base styles\n  - Components\n  - Page templates\n- Focus on standardizing what you find\n- Define CSS standards\n  - Refactor to perfection\n  - Namespace the CSS\n  - Don’t forget about JavaScript applying classes\n- Govern your library\n- Open source culture\n  - [opencss.klamp.in](http://opencss.klamp.in)\n\n### Pattern Library Tools\n- Writing CSS documentation with [KSS](http://warpspire.com/kss/)\n  - will auto document comments in your `.css` file\n- Pattern lab on GitHub\n\n#### The better way\n- [patternpack](https://github.com/patternpack/patternpack)\n  - what it does\n    - Build your static site\n    - Increment your version\n    - Create a new commit\n    - Tag the commit\n  - Lets you share the code to multiple applications\n  - Keeps versions of the design\n  - Start new project with `npm init` and `git init`\n  - Install `npm install --save-dev pattern-pack`\n  - Start with `grunt patternpack run`\n  - Create your first patter with a `.md` and `.css` file\n    -  `.md` is the documentation for the equivalent `css` file\n  - Use semantic versioning for your pattern pack\n  - Publish your patternpack\n    - `grunt pattern pack:release`\n    - `git push —follow-tags`\n\n## Web Components and the Future of Modular CSS: Philip Walton\nTwitter: [@philwalton](https://twitter.com/philwalton)\n\nSlides: [Web Components And the future of Modular CSS](https://philipwalton.github.io/talks/2015-10-26/#1)\n\n- Good news is that web components were primarily a google effort but not all vendors are on board but could be available sometime in 2016\n- Your selectors are the biggest determining factor in how scalable your code is\n\n### Whats changed?\n- Multiple shadow roots have gone away\n- `createShadowRoot()` is now `attachShadow(mode)`\n\n### CSS is hard\n- Manage global names\n- Scoping/isolating styles\n- Specificity conflicts\n- Unpredictable matching\n- Managing styles dependencies\n- Removing unused code\n\n### What is CSS missing\n- Scope or isolate styles to a particular set of DOM nodes\n- Ability to abstract away implementation details\n- Goooo Web components! They do this\n- You don’t want to have to depend on tools that everyone has to learn\n- No ecosystems\n\n### The Anatomy of a Web Component\n- Elements in a shadow DOM\n  - Its a subtree of a DOM node that can’t be styled by CSS\n  - Shadow nodes are private\n- Custom elements\n- HTMl imports\n- The template element\n\n## Keynote Dave Rupert\nTwitter: [@davatron5000](https://twitter.com/davatron5000)\n\nSlides: [The Art Of Being Wrong](https://speakerdeck.com/davatron5000/the-art-of-being-wrong)\n\n- Woot [Shop Talk show](http://shoptalkshow.com/) plug\n- Working on [godaytrip.com](http://godaytrip.com)\n- Remove the must do’s and “facts” from statements online on twitter or medium\n- what you think you know about dinosaurs is WRONG!\n- Be afraid of the Donald Trump effect where you believe bullshit if it is said loud and long enough\n- Don’t spell Sass or SASS wrong or the internet will bring the pitchforks, aka people should not fight about every little thing on the web\n- You don’t have to be right all the time and you don’t have to correct people on everything all the time\n"},{"title":"Ember Best Practices: Extend vs Mixin","tags":["ember","javascript","best practices"],"summary":null,"legacy":false,"id":"2015/11/09/best-practices-extend-or-mixin","employee":"Romina Vargas","date":"2015-11-09T00:00:00","body":"\n\nCode duplication: can’t live with it, _can_ live without it. As\ndevelopers, we’re always trying to find ways to DRY up our code. No\nmatter how big or how small an application, code duplication manages to\nsneak its way into your files. So far in this Ember best practices series, we’ve\nlearned how to write [DRYer computed properties][mike] and [DRYer tests][lin]. What\nabout more general application code?\n\nIn Ember, there are two main concepts that we can adapt in order to\nshare code between different parts of our application: `Ember.Mixin` and\n`Ember.Object.extend()`. Both of these essentially achieve the same end\nresult, but depending on the scenario, one may be a better bet. Let's look at a\nbrief overview of each one.\n\n## Ember.Object.extend()\n\nDeep down, all Ember objects that we create and interact with are an extension of the\n`Ember.Object`. `Ember.Object` itself extends [Ember.CoreObject][core], which\nincludes the [Ember.Observable][observable] mixin, and it's what gives Ember its \"properties and\nproperty observing functionality.\" Without these base objects, there would be no Ember.\n\nWe can create a new _subclass_ by calling the `extend()` method on any Ember\nobject. This will give the new subclass all of the properties of the parent class,\nas well as any properties defined in the new one. You're also allowed to\noverwrite any properties found in the parent by defining them in the new class.\nIf you've written an Ember App, you will be familiar with the following:\n\n```js\n// routes/index.js\n\nexport default Ember.Route.extend({\n  // properties and methods\n});\n```\n\nIn this case, `IndexRoute` will inherit properties, methods, and\nanything else defined in the `Ember.Route` object, as well as everything down\nits prototype chain:\n\n`IndexRoute` **->** `Ember.Route` **->** `Ember.Object` **->** `Ember.CoreObject`\n\nKeep in mind that any properties defined in the parent object will be shared\namong any child object. For this reason, you may want to\ninitialize certain properties inside the `init` constructor, which gets called\nwhenever an instance of an object gets created. This way, each object instance\ngets its own unique set of properties.\n\n## Ember.Mixin\n\nUnlike the `Ember.Object`, mixins don’t get extended. Instead, they get\ncreated via `Ember.Mixin.create()`. When we include the mixin inside an\nEmber object, we’re extending the constructor’s prototype. What this\nmeans is that like using `extend()`, any properties or functionality that is\ndefined inside the mixin will be shared among all classes containing this mixin.\n\n```js\n// mixins/foo.js\nexport default Ember.Mixin.create({\n  bars: []\n)};\n```\n\n```js\n// components/A.js\nimport FooMixin from ‘../mixins/foo’;\n\nexport default Component.extend(FooMixin);\n```\n\n```js\n// components/B.js\nimport FooMixin from ‘../mixins/foo’;\n\nexport default Component.extend(FooMixin);\n```\n\nThe above will result in both component A and component B sharing the same\n`bars` array. Any changes made to the array will be reflected in both\ncomponents. If you want to play around with this sharing business,\nyou can go [here][jsbin]!\n\n\n## Mixin me, Mixin me not...So which do I use?\n\nUltimately, the decision will differ on a case by case basis. We can think of\nit in terms of inheritance vs composition.\n\nA base class can usually live on its own or be extended. Inheriting from a parent\nobject will provide the child with the full functionality of the parent, plus any\nadditional properties and behavior that are specific to the child. _The child should\nbehave like the parent_. Extending works well when you need several variations of\na parent object. Take a form, for example. You may have differing templates,\nbut will have mostly the same component logic. Extending each component from a base\nclass would make sense, and their own component-specific properties would be\ndefined in the new subclass.\n\nThe thing about mixins is that they encapsulate succint pieces of\nfunctionality. The code that they contain can be reused throughout different\nparts of the application, and is not a concern of any one route, controller,\ncomponent, etc. They're also meant to be used with other objects, not as\na stand alone piece; they don't get instantiated until you've passed them\ninto an object, and they get created in the order of which they're passed in.\nMixins can help to avoid long chains of inheritance and adds flexibility if the\nneed for making changes arises.\n\n### Mixin example, plz\n\nA good candidate for a mixin? Pagination! Pagination logic is not very\nextensive and it can be sprinkled throughout an application. Applications\ntend to need pagination for displaying a number of things; a mixin provides\nus with the ability to add this to different routes, without caring about\nthe type of model or object that we're trying to display on the page.\nLet's say we have the following routes:\n\n```js\nexport default Ember.Router.extend({\n  this.route('authors');\n  this.route('blog', function() {\n    this.route('comments');\n  });\n});\n```\n\nAll of these routes need to have pagination built-in. Even though the routes\nare not related, we can utilize the same pagination mixin for all of them. Each\nof these three routes will have to include the mixin like so:\n\n```js\nimport PaginationMixin from '../mixins/pagination';\n\nexport default Route.extend(PaginationMixin);\n```\n\n### Extend example, plz\n\nA good candidate for extension? Authentication! More often than not, we need two\ndifferent types of routes: authenticated and unauthenticated. The best way to\nhandle this is to create a base class for each of those (or just one,\ndepending on your needs!), and extend the routes which need the particular\nfunctionality. If we have the following routes,\n\n```js\nexport default Ember.Router.extend({\n  this.route('blog');\n  this.route('account', function() {\n    this.route('profile');\n    this.route('settings');\n  });\n});\n```\n\n```js\n// routes/authenticated.js\n\nexport default Ember.Route.extend({\n  // check for session & transition accordingly\n});\n```\n\nin `account/index.js` we would just extend `authenticated.js`\n\n```js\n// account/index.js\n\nimport AuthenticatedRoute from 'routes/authenticated';\n\nexport default AuthenticatedRoute.extend();\n```\n\nDoing this will make sure that `account` and any child route is off limits to\nusers who are not signed in. We simply apply this same pattern to any other\nparent routes that need authentication. If we were to use a mixin instead, we\nwould end up with having to import the mixin all over the application - and\nyou're more likely to forget to add it.\n\n## Sum it up!\n\nHopefully this has helped in better understanding the differences between using\n`Ember.Object.extend()` and `Ember.Mixin` as it's not always black or white on\nwhether to use one concept over the other. Ask yourself what the intent of the code is,\nwhere and how often it's going to be used, and make your best judgement. All\nin all, stay DRY!\n\n[mike]: https://dockyard.com/blog/2015/10/23/ember-best-practices-dynamic-dependent-keys-for-computed-properties\n[lin]: https://dockyard.com/blog/2015/09/25/ember-best-practices-acceptance-tests\n[core]: http://emberjs.com/api/classes/Ember.CoreObject.html\n[observable]: http://emberjs.com/api/classes/Ember.Observable.html\n[jsbin]: http://emberjs.jsbin.com/nakube/2/edit?html,js,output\n"},{"title":"Ember Best Practices: Functional Programming and the Observer Effect","tags":["ember","javascript","best practices"],"summary":"Don't use observers.","legacy":false,"id":"2015/11/16/best-practices-functional-programming-and-the-observer-effect","employee":"Lauren Tan","date":"2015-11-16T00:00:00","body":"\n\nMy awesome colleagues have written about patterns and [best practices][bestpractices] we use at DockYard, covering everything from the [Ember][brian] [Object][estelle] [model][romina] and [better acceptance tests][lin], to [native inputs][aaron] and [closure actions][dan]. \n\nToday, I'd like to write about something that is close to all our hearts – <span title=\"Every time you use an observer, Stefan Penner dies a little inside.\">observers</span>; and a topic I think about a lot – functional programming (FP). I'd like to take you through a tour of refactoring away from observers in your application and freeing yourself from the shackles of the \"observer effect\". Let's get started!\n\n## Side effects wreck projects\n\nIn science, the term [\"observer effect\"][ooeffect] refers to the changes that are effected on some phenomenon simply by observing it. This is often because of instruments that alter the state of what they observe in some manner.\n\nSound familiar? Funnily enough, the same effect can probably be found in your Ember application if you use observers. For reasons we'll cover in this post, [observers are an anti-pattern][stef] and should be avoided, as it makes it difficult to reason about and to debug your application.\n\n## Difficult to reason about? ¯\\\\\\_(ツ)\\_/¯\n\n\"Difficult to reason about\" is a term that is commonly thrown around – but what exactly does it mean? Informally, it means being able to tell what a program will do just by looking at its code. That is, running the program _should not_ lead to unexpected surprises. We strive to make our applications easy to reason about because it leads to more maintainable code that is easier to debug and test.\n\n> That is, running the program should not lead to unexpected surprises.\n \nSince JavaScript isn't a purely functional language, it does not enforce immutability by default. Its mutable data structures can sometimes lead to surprising and unintuitive results (making some JavaScript applications difficult to reason about), so various attempts have been made to introduce immutability to the language. \n\nFor example, [ClojureScript][clojurescript] and [Elm][elm] are functional languages that compile down to JavaScript. [Mori][mori] and [immutable.js][immutable] are also excellent libraries that provide immutable data structures you can use in vanilla JavaScript. These tools bring in bits of FP philosophy into JavaScript applications, and have become increasingly popular in front-end development thanks to the introduction of [React][react] and the [Flux pattern][flux].\n\n## The \"rise\" of FP in front end development\n\nFP is not a new programming paradigm – it's been around for a while since the introduction of LISP in the late 50s. However, it's only in recent times that we've seen FP languages become more mainstream, most notably with [Elixir][elixir], which combines the elegance and productivity of Ruby with the performance of the Erlang VM.\n\n> The combination of Ember's conventions (over configuration), Glimmer, and DDAU means that just like Elixir, Ember developers too can find the sweet spot of having both productivity and performance.\n\nWhy is [FP useful][fpben] for building front end applications? React taught us that it is surprisingly cheap to diff the changes on the DOM, and to perform a series of updates to sync the DOM with its virtual representation. In other words, React made its `render` function a pure one (one of the core principles of FP) – you always get the same output (HTML) for a given input (state). \n\nWith the Flux pattern, that is taken a step further and the entire application is treated as a pure function – for a given serialized state, we can predictably render the same output each time. This has allowed Flux implementations like [Redux][redux] the ability to have a [\"time traveling debugger\"][timetravel], which is only possible when you model your architecture with a FP paradigm.\n\n### Object.observe is not the answer\n\nThese philosophies have had resounding success, so much so that `Object.observe` was [withdrawn][oo] from TC39. All this means is that _observing property changes_ are no longer the best way of building web applications, and Ember in general is moving in that direction with its \"Data Down, Actions Up\" (DDAU) philosophy. \n\nIn 1.13.x, [Glimmer][glimmer] landed – it is Ember's new rendering engine based on the same pure render semantics, and gives us fast, idempotent re-renders. The combination of Ember's conventions (over configuration), Glimmer, and DDAU means that just like Elixir, Ember developers too can find the sweet spot of having both productivity and performance.\n\n## Data Down, Actions Up\n\nAlthough you could bring in immutable data structures into your application (a topic for a future post!), that alone wouldn't be enough. We should also strive to make our business logic as pure (free of side effects) as possible. Of course, it wouldn't be possible to make _everything_ pure, as web applications inherently involve mutation (i.e. updating a user record), but it is beneficial to explicitly know and isolate the functions in your app that do have side effects.\n\nIn Ember 2.x, the best way forward is \"Data Down, Actions Up\". This means:\n\n1. One way bindings by default\n1. Explicit closure actions over side effects\n1. Components should not mutate data directly\n\nMy colleagues have already written about [one way bindings][aaron], [closure actions][dan] and [not mutating data in Components][marin], so I will leave you to do further reading in your own time.\n\nInstead, let's continue the discussion above on how best to refactor away observers in your application, so that we can eliminate or reduce side effects.\n\n## Refactoring away observers\n\nLet's say we have an observer in our application that needs to check a user's birthday [(demo)][jsbin]:\n\n```js\n// birth-day/component.js\nimport Ember from 'ember';\nimport moment from 'moment';\n\nconst { \n  Component, \n  computed,\n  get, \n  set\n} = Ember;\n\nexport default Component.extend({\n  isBirthday: false,\n  birthDate: null,\n  \n  age: computed('birthDate', {\n    get() {\n      return moment().diff(moment(get(this, 'birthDate')), 'years');\n    }\n  }),\n\n  checkBirthday() {\n    let today = moment();\n    let birthDate = moment(get(this, 'birthDate'));\n    let isBirthday = (today.month() === birthDate.month()) && \n      (today.day() === birthDate.day());\n\n    set(this, 'isBirthday', isBirthday);\n  },\n\n  init() {\n    this._super(...arguments);\n    this.addObserver('birthDate', this, this.checkBirthday);\n  },\n\n  willDestroy() {\n    this.removeObserver('birthDate', this, this.checkBirthday);\n  }\n});\n```\n\nIn the above example, we're using an observer to set the `isBirthday` flag if it is the user's birthday.\n\n```hbs\n{{!birth-day/template.hbs}} \n{{input value=birthDate placeholder=\"Your birthday\"}}\n\n<p>\n  You are currently {{age}} years old.\n  {{#if isBirthday}}\n    Happy birthday!\n  {{/if}}\n</p>\n```\n\nWhen you find yourself setting some value (be in on the component, record or somewhere else), you can easily refactor away the observer.\n\n### Removing an observer that sets a value on the component\n\nIn this scenario, you can simply replace the observer with a CP. \n\n```js\n// birth-day/component.js\nimport Ember from 'ember';\nimport moment from 'moment';\n\nconst { \n  Component, \n  computed,\n  get\n} = Ember;\n\nexport default Component.extend({\n  // ...\n  isBirthday: computed('birthDate', {\n    get() {\n      let today = moment();\n      let birthDate = moment(get(this, 'birthDate'));\n\n      return (today.month() === birthDate.month()) && \n        (today.day() === birthDate.day());\n    }\n  })\n});\n```\n\n### Using component lifecycle hooks\n\nWe could also move the `input` logic out of this component, and use the [new component lifecycle hooks][hooks] to set the `isBirthday` flag on the component.\n\n```js\n// birth-day/component.js\nimport Ember from 'ember';\nimport moment from 'moment';\n\nconst { \n  Component, \n  computed,\n  get\n} = Ember;\n\nexport default Component.extend({\n  birthDate: null,\n  today: null,\n  isBirthday: false,\n  \n  didReceiveAttrs() {\n    let isBirthday = this.checkBirthday(\n      moment(get(this, 'today')), \n      moment(get(this, 'birthDate'))\n    );\n\n    set(this, 'isBirthday', isBirthday);\n  },\n\n  checkBirthday(today, birthDate)\n    return (today.month() === birthDate.month()) && \n      (today.day() === birthDate.day());\n  })\n});\n```\n\n```hbs\n{{!index/template.hbs}} \n{{one-way-input \n    value=user.birthDate \n    update=(action (mut user.birthDate)) \n    placeholder=\"Your birthday\"\n}}\n{{happy-birthday today=today birthDate=user.birthDate}}\n```\n\n```hbs\n{{!birth-day/template.hbs}} \n<p>\n  You are currently {{age}} years old.\n  {{#if isBirthday}}\n    Happy birthday!\n  {{/if}}\n</p>\n```\n\nBoth approaches let you remove the observer, but the `didReceiveAttrs` example is slightly more explicit, and transforms the component into a pure one. By limiting the scope of the component, we can easily isolate the origins of data mutations. \n\n### Removing an observer that sets a value outside the component\n\nIn this situation, let's say we want to update the user record's `isBirthday` flag instead. We can remove the observer by using one way input actions:\n\nBy bringing in the [`ember-one-way-input`][oneway] addon, we can eliminate the coupling of the component to the user record:\n\n```js\n// birth-day/component.js\nimport Ember from 'ember';\nimport moment from 'moment';\n\nconst { \n  Component, \n  computed,\n  get\n} = Ember;\n\nexport default Component.extend({\n  // ...\n  actions: {\n    checkBirthday(birthDate) {\n      birthDate = moment(birthDate);\n      let today = moment();\n      let isBirthday = (today.month() === birthDate.month()) && \n        (today.day() === birthDate.day());\n      \n      this.attrs.setIsBirthday(isBirthday);\n      this.attrs.setBirthDate(birthDate.toDate());\n    }\n  }\n});\n```\n\n```hbs\n{{!birth-day/template.hbs}} \n{{one-way-input \n    value=user.birthDate \n    update=(action \"checkBirthday\") \n    placeholder=\"Your birthday\"\n}}\n\n<p>\n  You are currently {{age}} years old.\n  {{#if isBirthday}}\n    Happy birthday!\n  {{/if}}\n</p>\n```\n\nAnd then in the Controller:\n\n```js\n// index/controller.js\nimport Ember from 'ember';\n\nconst { Controller, set } = Ember;\n\nexport default Controller.extend({\n  actions: {\n    setIsBirthday(isBirthday) {\n      set(this, 'user.isBirthday', isBirthday);\n      user.save();\n    },\n\n    setBirthDate(birthDate) {\n      set(this, 'user.birthDate', birthDate);\n      user.save();\n    }\n  }\n});\n```\n\n```hbs\n{{!index/template.hbs}} \n{{happy-birthday \n    setIsBirthday=(action \"setIsBirthday\") \n    setBirthdate=(action \"setBirthdate\")\n    isBirthday=user.isBirthday\n}}\n```\n\nIn the above example, we moved the logic for setting the `isBirthday` flag out of the `happy-birthday` component into its Controller. The component no longer needs to directly mutate state (an anti-pattern would be to set `user.isBirthday` directly in the component), and can instead send a closure action up, leaving the Controller to decide how to handle the actions. Data now flows down to the Component, and any changes to the `input` sends actions back up.\n\n## Who should use observers?\n\nNo one.\n\nIf observers are so terrible, why are they in Ember? According to [Stefan Penner][steftweet], observers are used by the framework itself as a low level primitive, so that _you don't need to use them yourself_. So unless you're working on a PR for Ember.js, stay away from observers. \n\nI hope you've enjoyed this post – next week, stay tuned for [Doug][doug]'s post on more Ember 2.x best practices!\n\n[aaron]: https://dockyard.com/blog/2015/10/05/ember-best-practices-using-native-input-elements\n[bestpractices]: https://dockyard.com/blog/categories/best-practices\n[brian]: https://dockyard.com/blog/2015/10/19/2015-dont-dont-override-init\n[clojurescript]: https://github.com/clojure/clojurescript\n[dan]: https://dockyard.com/blog/2015/10/29/ember-best-practice-stop-bubbling-and-use-closure-actions\n[doug]: https://twitter.com/dougyun\n[elixir]: http://elixir-lang.org/\n[elm]: http://elm-lang.org/\n[estelle]: https://dockyard.com/blog/2015/09/18/ember-best-practices-avoid-leaking-state-into-factories\n[flux]: https://facebook.github.io/flux/docs/overview.html#content\n[fpben]: https://www.youtube.com/watch?v=aeh5Fmh_tmw\n[hooks]: https://github.com/emberjs/ember.js/pull/11127\n[glimmer]: https://www.youtube.com/watch?v=o12-90Dm-Qs\n[immutable]: https://facebook.github.io/immutable-js/\n[jsbin]: http://emberjs.jsbin.com/citiwi/edit?js,output\n[lin]: https://dockyard.com/blog/2015/09/25/ember-best-practices-acceptance-tests\n[marin]: https://dockyard.com/blog/2015/10/14/best-practices-data-down-actions-up\n[mori]: https://swannodette.github.io/mori/\n[oneway]: https://github.com/dockyard/ember-one-way-input\n[oo]: https://mail.mozilla.org/pipermail/es-discuss/2015-November/044684.html\n[ooeffect]: https://en.wikipedia.org/wiki/Observer_effect_(physics)\n[react]: https://facebook.github.io/react/\n[redux]: http://redux.js.org/\n[romina]: https://dockyard.com/blog/2015/11/09/best-practices-extend-or-mixin\n[stef]: https://www.youtube.com/watch?v=7PUX27RKCq0\n[steftweet]: https://twitter.com/stefanpenner/status/576511209278582784\n[timetravel]: https://www.youtube.com/watch?v=xsSnOQynTHs\n"},{"title":"Phoenix is not Rails","tags":["phoenix","rails","elixir","ruby"],"summary":"Phoenix is not Rails, but some ideas are borrowed","legacy":false,"illustration_alt":"Imgur","illustration":"http://i.imgur.com/SehijaI.png","id":"2015/11/18/phoenix-is-not-rails","employee":"Chris McCord","date":"2015-11-18T00:00:00","body":"\n\nIn his yearly recap last December, Brian went public with his [plans to transition the company over to Elixir and Phoenix development](https://dockyard.com/blog/2014/12/28/lessons-learned-three-years-running-a-software-consultancy). Throughout this year, he found it was a smooth transition for the team [going from primarily Rails to Phoenix powered applications](https://dockyard.com/blog/2015/10/29/how-long-it-took-our-team-to-move-from-rails-to-phoenix).\nOn the surface, Phoenix shares some familiar conventions with Rails that lets folks jump into new applications and contribute early to a project – on their way to greater mastery. Complete mastery will take a bit more practice than knowing a few shared conventions, but the similar-at-a-glance features has enticed Ruby teams to get involved and many are delighted to get up and running quickly. Unfortunately, it has also led to wrong assumptions about Phoenix's likeness to Rails, causing some to miss the important differences around their core philosophies.\n\nIt is common in the Ruby community to say that there are Rails developers and Ruby developers. We don't expect this to happen with Phoenix. Although Phoenix of course introduces its own abstractions, ultimately writing a Phoenix application is writing an Elixir application. Testing Phoenix code is testing Elixir functions. This post aims to address these ideas by comparing the similarities and differences between Phoenix and Rails and why it matters.\n\n## Similarities\n\nMost of the phoenix-core team comes from a Rails-heavy background, so it's natural we borrow some of the great ideas Rails brings to the table, such as:\n\n- Both focus on productivity, from client to server side\n- Both provide a default directory structure, although Phoenix simply relies on the structure imposed by Elixir applications\n- Both are MVC frameworks (Phoenix does a functional twist on the architecture though) with a router sitting on top\n- Both provide a default stack with relational databases (sqlite3 for Rails, PostgreSQL for Phoenix)\n- Both promote security best practices in their default stack\n- Both ship with a default toolkit for writing and running tests\n\n\n## Differences\n\nWith a few similarities, comes major differences. From how you structure your applications, recover from failure, debug your systems, or talk to a remote client, Phoenix takes an approach that few run-times can offer. We embrace Elixir and OTP conventions in Phoenix so that your Phoenix application is only a component of your greater application infrastructure. This deviation from Rails has effects throughout the stack.\n\n\n\n### Applications\n\nThere is no such thing as a \"Phoenix application\". Your Phoenix projects are first and foremost Elixir applications, which relies on Phoenix to provide part of its functionality. This means there is one way to build, run, and deploy your applications – the Elixir way.\n\n#### Why it matters: no singletons\n\nIn Rails there is a single application that's accessible via `Rails.application`. Rails runs the show, from starting the application, configuration, and even running command line tasks. As an inherent limitation of this approach, you cannot run two Rails applications side by side. If you need sharing, you need to carefully break it apart into engines and learn a new set of rules.\n\nWith Phoenix, nothing is global. There is no monolith. A new Phoenix application will include one Endpoint, one Router, and one PubSub Server, but you are free to add more. With no global state or global servers, you can break your application into pieces as your infrastructure grows.\n\n#### Why it matters: startup and shutdown\n\nElixir conventions structure your projects as small composable \"applications\" that can be started and stopped as a unit. The trail usually goes like this (using Phoenix itself as an example):\n\n1. Every application has a specification, that may specify which module to invoke when the application will be initialized:\n\n  ```elixir\n  def application do\n    [mod: {Phoenix, []},\n     applications: [:plug, :poison, :logger, :eex],\n    ...]\n  end\n  ```\n[source](https://github.com/phoenixframework/phoenix/blob/9f9c4663b304a3ff885cc8356cad278e100eb499/mix.exs#L28-L38)\n\n2. If a module is specified, the `start/2` function of this module is invoked:\n\n  ```elixir\n  defmodule Phoenix do\n    def start(_type, _args) do\n      ...\n      Phoenix.Supervisor.start_link\n    end\n  end\n  ```\n  [source](https://github.com/phoenixframework/phoenix/blob/7692aef141f6eab5ad9a0e88875f42c8b02b117d/lib/phoenix.ex#L3  0)\n\n3. The `start/2` function must return the identifier of a supervised process, such as ` Phoenix.Supervisor.start_link` above\n\n  [source](https://github.com/phoenixframework/phoenix/blob/7692aef141f6eab5ad9a0e88875f42c8b02b117d/lib/phoenix.ex#L41)\n\nA similar flow happens when stopping your application. The consequence is that it doesn't matter if you are using Phoenix or not, every application has its own and contained start/stop mechanism.\n\nThis is a stark contrast to Rails initialization which is extremely complex and requires extensions to hijack a single, sequential initialization flow. For a Rails 4.2.2 app:\n\n```irb\n$ rails c\nLoading development environment (Rails 4.2.2)\nirb(main):001:0> Rails.application.initializers.length\n=> 74\n```\n\nThose are 74 snippets of code (Ruby blocks) spread around multiple files in a non-specified order! Having control of the initialization logic is extremely important to know exactly what your app is running and to keep boot times fast.\n\n#### Why it matters: monitoring and introspection\n\nBy relying on applications, you gain supervision, fault tolerance, and introspection into your running system. We can easily view our applications running as a unit, or as a whole with tools like observer:\n\n![Imgur](http://i.imgur.com/SehijaI.png)\n\nThe beauty is, your project will start as a single application and it may (or may not) be broken into multiple applications naturally, be they all running in a single node or in a service oriented architecture. We pay no upfront cost because the runtime is built on tried and true patterns. In fact, we will cover such an example in an upcoming chapter of the [Programming Phoenix book](https://pragprog.com/book/phoenix/programming-phoenix).\n\n\n\n### Request life-cycle\n\nPhoenix provides fantastic performance out of the box, [with benchmarks](https://gist.github.com/omnibs/e5e72b31e6bd25caf39a) to prove it. The request/response life-cycle in Phoenix differs greatly from the approach Rails takes with Rack.\n\n#### Why it matters: easy to understand\n\nExplicit > Implicit. Almost Always. Phoenix favors explicitness in most of its stack. For example, when generating your Phoenix application, you can see all the \"plugs\" your request goes through in `lib/my_app/endpoint.ex`. Where Rails segregates Rack middleware to a side-loaded part of the application, Phoenix makes all plugs explicit. You have an instant, at-a-glance look into your request life-cycle by viewing the plugs in your endpoint and router.\n\n```elixir\ndefmodule MyApp.Endpoint do\n  use Phoenix.Endpoint, otp_app: :my_app\n\n  socket \"/socket\", MyApp.UserSocket\n  plug Plug.Static, at: \"/\", from: :my_app, gzip: false, only: ~w(css images js)\n  plug Plug.RequestId\n  plug Plug.Logger\n  plug Plug.Parsers, parsers: [:urlencoded, :multipart, :json], pass: [\"*/*\"]\n  plug Plug.MethodOverride\n  plug Plug.Head\n  plug Plug.Session, store: :cookie\n  plug MyApp.Router\nend\n```\n\nA request starts in your Endpoint, flows through the explicit plug \"base middleware\", and is handed off to your Router, which itself as just a plug. Then the router applies its own plugs before handing off to a controller, which is (you guessed it!), a Plug. A single level of abstraction throughout the entire stack makes reasoning about your request life-cycle as clear as possible. It also allows easy third-party package integration because of the simplicity of the Plug contract.\n\nLet's compare two very similar looking controllers to see how Phoenix's functional approach with Plug makes the code easier to understand:\n\ncontroller.rb:\n\n```ruby\nbefore_action :find_user\n\ndef show do\n  @post = @user.posts.find(params[:id])\nend\n\ndef find_user\n  @user = User.find(params[:user_id])\nend\n```\n\ncontroller.ex:\n\n```elixir\nplug :find_user\n\ndef show(conn, %{\"id\" => id}) do\n  post = conn.assigns.user |> assoc(:posts) |> Repo.get(id)\n  render conn, \"show.html\", post: post\nend\n\ndefp find_user(conn, _) do\n  assign(conn, :user, Repo.get(User, conn.params[\"user_id\"]))\nend\n```\n\nUnless you're a seasoned Rails developer, you wouldn't know that `show` calls `render \"show.html\"` implicitly. Even if it was called explicitly, you would have to know that all instance variables are copied from the controller instance to the view instance, which is a layer of complexity that few realize when first getting into Rails development. Convention over configuration is a Good Thing, but there's a threshold where implicit behavior sacrifices clarity. Phoenix optimizes for clarity, in a way that we think strikes a perfect balance with easy to use APIs. Beyond that, as an Object Oriented programmer you must be aware of all the implicit state of the instance, such as the `params` hash, the `request` object, and any instance variables set in `before_action` filters. In Phoenix, everything is explicit. The `conn` is our bag of data and line of communication with the webserver. We pass it along through a pipeline of functions called plugs, transforming the connection, and sending response(s) as needed.\n\n#### Why it matters: easy to test\n\nFunctional programming and the Plug contract make testing your controllers in isolation, or integration testing your entire endpoint, only a matter of passing a `conn` through the plug pipeline and asserting against the result. Additionally, controller actions in Phoenix are just functions, without implicit state. If we need to test the controller in isolation, we call the function!\n\n```elixir\ntest \"sends 404 when user is not found\" do\n  conn = MyController.show(conn(), %{\"id\" => \"not-found\"})\n  assert conn.status == 404\nend\n```\n\nThere's no stumbling with setting up controller instances thanks to functional programming. And when we need to fully integration test through the endpoint, Phoenix just calls the pipeline of functions:\n\n```elixir\ntest \"shows users\" do\n  conn = get conn(), \"/users/123\"\n  assert %{id: \"123\"} = json_response(conn, :ok)\nend\n```\n\nPhoenix views follow the same principle as controllers: they are all just functions, there is no implicit data sneaking in!\n\n#### Why it matters: easy to share code\n\nOnce you end-up relying on controller instance variables and methods, a method that you wrote to run in a Rails controller cannot be easily moved to a Rack middleware because it relies on many controller internals.\n\nSince plugs are just functions, you know what is coming in and you know what is going out. There is one abstraction for the entire HTTP stack: whether in the endpoint, router or controller. For example, let's say you want to apply an `AdminAuthentication` plug to all `\"/admin\"` requests, as well as a special `DashboardController`. We use the same plug at both the Router and Controller levels of abstraction:\n\n```elixir\ndefmodule MyApp.Router do\n  pipeline :browser do\n    plug :fetch_session\n    ...\n    plug :protect_from_forgery\n  end\n\n  pipeline :admin do\n    plug AdminAuthentication\n  end\n  \n  scope \"/\" do\n    get \"/dashboard\", DashboardController\n  end\n\n  scope \"/admin\" do\n    pipe_through [:browser, :admin] # plugged for all routes in this scope\n\n    resources \"/orders\", OrderController\n  end\nend\n\ndefmodule MyApp.DashboardController do\n  plug AdminAuthentication # plugged only on this controller\n\n  def show(conn, _params) do\n    render conn, \"show.html\"\n  end\nend\n```\n\nSince we use `plug` at all levels of the stack, we can plug in the `AdminAuthentication` plug in the Router and controller for fine-grained request rules. In Rails, you would inherit from an `AdminController`, but the clarity of what transformations apply to your request is lost. You have to track down the inheritance tree to find out which rules are applied and where. In Phoenix, router pipelines make the concerns of your request explicit.\n\n### Channels\n\nPhoenix from day one was built to take on the challenges of the modern, highly connected, real-time web. Channels bring transport agnostic real-time connections to your application, which can scale to [millions of clients on a single server](http://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections). This deviates from Rails where historically real-time features have been second-class.\n\n![Imgur](http://i.imgur.com/7CHc1Lh.png)\n\n#### Why it matters: the web is evolving\n\nPhoenix Channels target the Web beyond the browser. The web is evolving to include *connected devices* (phones, watches, smart toasters) – one of which is a browser. We need a framework that can evolve with changing and new protocols alike. That's why Channels are transport agnostic, with native channel clients available on iOS, Android, and Windows platforms. You can see this in action with a [Phoenix chat app running natively on a browser, iPhone, and Apple Watch](https://vimeo.com/136679715).\n\n#### Why it matters: fast performance, with less dependencies\n\nRails' recent entry into real-time features with [Action Cable bring a heavy list of dependencies: Faye, Celluloid, EventMachine, Redis, to name a few](https://github.com/rails/actioncable/blob/master/actioncable.gemspec#L17-L25). Because Phoenix runs on the Erlang Virtual Machine, Phoenix gets real-time features out of the box from the run-time. The run-time is distributed, allowing Phoenix to skip any operational dependency like Redis to orchestrate PubSub messages across servers.\n\n\n### Naming\n\nPhoenix does not impose strict naming conventions, like we see in Rails.\n\n#### Why it matters: easy to learn\n\nPhoenix does not tie module names to the filename. Rails requires a `UsersController` to be located in a file named `users_controller.rb`. We agree conventions like these are good, but Phoenix does not care about such tight restrictions. Instead we promote sane defaults, but are flexible to individual requirements. Naming also creates a lot of confusion for people who learn Rails first then try to write Ruby applications. Because Rails depends on `const_missing` to require files based upon the class name convention of file path, knowing how to require files in a regular Ruby application is a bit of a mystery for programmers looking to move their knowledge outside of Rails.\n\nPhoenix includes a \"web\" directory where you put controllers, views, etc, but it only exists for code reloading purposes which gives you refresh-driven-development.\n\nPhoenix also does not impose singular and plural naming rules. Rails naming rules can confuse beginners and advanced developers alike: models use singular names, controllers use plural ones, URL helpers mix both, and so on. Phoenix consistently uses singular rules, as any other Elixir code. You may use plural names for your tables and router paths, but those are explicitly written at your system boundaries.\n\n\n### Assets\n\nPhoenix uses a tool named [brunch](http://brunch.io) by default for handling static assets, but it allows you to bring your own JavaScript build tool, instead of building one specific to the framework, like Rails does with the asset pipeline. Phoenix also leverages its channel layer to provide live-reload of changes out of the box.\n\n#### Why it matters: ES6/ES2015 is the future\n\nPhoenix promotes ES6/ES2015 instead of CoffeeScript, by supporting ES2015 out of the box for new projects. CoffeeScript served its noble purpose to push the industry forward. ES2015 and its [first-class transpilers](https://babeljs.io) are the clear way forward.\n\n#### Why it matters: live-reload is an essential feature\n\nPhoenix ships with live reload out of the box. As soon as you change a .js or .css file, it is automatically reloaded in your browser. Once you add this feature to your development work-flow, it's one you can't live without.\n\n\n## Wrap-up\n\nRegardless of your background, you'll find Phoenix borrows from great ideas that came before it, while using Elixir to carve its own path to take on the modern web.\n"},{"title":"Ember Best Practices: Handlebars's Overlooked {{#each}} {{else}} Conditional Block","tags":["ember","javascript","best practices"],"summary":"The Handlebars {{#each}} block trick that folks always forget","legacy":false,"id":"2015/11/23/ember-practices-each-else","employee":"Doug Yun","date":"2015-11-23T00:00:00","body":"\n\nIn the past few months, my esteemed coworkers have written about [various\nEmber best practices][best-practices]. To follow suit, I'd like to\nreintroduce an often forgotten Handlebars trick.\n\nHow many times have you stumbled across a template that wrapped an\n`{{#each}}` block with an outer `{{#if}}` conditional block?\n\n## The Verbose\n\n```hbs\n{{! if-and-each-usage.hbs}}\n\n{{#if footballTeams}}\n  {{#each footballTeams as |team|}}\n    Teamname: {{team.name}}\n    City: {{team.city}}\n    Mascot: {{team.mascot}}\n  {{/each}}\n{{else}}\n  No teams to display!\n{{/if}}\n```\n\nLogically, this makes sense. If there aren't `footballTeams` to iterate\nthrough, we render out a message.\n\nHowever, the result is an unnecessary conditional! Thankfully, the\n`{{#each}}` block helper provides us with a more terse solution.\n\n## The Succinct\n\n```hbs\n{{! each-else-usage.hbs}}\n\n{{#each footballTeams as |team|}}\n  Teamname: {{team.name}}\n  City: {{team.city}}\n  Mascot: {{team.mascot}}\n{{else}}\n  No teams to display!\n{{/each}}\n```\n\nWe don't need the outer `{{#if}}` block, and we simply can add an\n`{{else}}` path within our `{{#each}}` block.\n\nAlthough, the change here seems quite trivial, it immediately cleans\nup readibility (which is a huge win in my book).\n\n## More to Come\n\nIf you've enjoyed these [series of best practices][best-practices], stay tuned,\nwe'll be writing more posts soon after the holidays! Thanks!\n\n[best-practices]: https://dockyard.com/blog/categories/best-practices\n"},{"title":"Comparing dates and times in Elixir with Ecto","tags":["elixir","phoenix","ecto"],"summary":null,"legacy":false,"id":"2015/11/30/comparing-date-time-in-elixir-with-ecto","employee":"Brian Cardarella","date":"2015-11-30T00:00:00","body":"\n\nIf you are working with `Ecto.DateTime` in your Phoenix\napplication you may make a comparison of two variables at some point:\n\n```elixir\nd1 = {{2015, 11, 30}, {0, 0, 0}} |> Ecto.DateTime.from_erl\nd2 = {{2015, 11, 29}, {0, 0, 0}} |> Ecto.DateTime.from_erl\n\nassert d1 > d2\n```\n\nThe above ends up passing the assertion, but only by coincidence. What\nif you had a situation where you wanted to assert a comparison between\ntoday and tomorrow, but tomorrow ends up being a different month:\n\n```elixir\nd1 = {{2015, 12, 1}, {0, 0, 0}} |> Ecto.DateTime.from_erl\nd2 = {{2015, 11, 30}, {0, 0, 0}} |> Ecto.DateTime.from_erl\n\nassert d1 > d2\n```\n\nThe above assertion fails. If you think it seems odd that `December 1, 2015`\nwould be less than `November 30, 2015` you'd be correct. To understand\nwhy we have to see what `Ecto.DateTime.from_erl/1` returns:\n\n```elixir\n{{2015, 12, 1}, {0, 0, 0}} |> Ecto.DateTime.from_erl\n\n# => #Ecto.DateTime<2015-11-30T00:00:00Z>\n```\n\nThis is an [Elixir Struct][struct]. The properties of the struct are not\nordered, so the comparison does not actually understand the structure of\ndatetime and how to compare properly. In this case it appears that the\nday values are being compared before the month values, resulting in a\n`false` assertion. To better understand this we need to take a look at\nthe Erlang documentation for Maps (which are just Structs):\n\n> Maps are ordered by size, two maps with the same size are compared by\n> keys in ascending term order and then by values  in key order. In maps\n> key order integers types are considered less than floats types.\n\nTo do a proper datetime comparison between two `Ecto.DateTime` structs we have to convert to a\ntuple. We can do this by using `Ecto.DateTime.to_erl`:\n\n```elixir\nd1 = #Ecto.DateTime<2015-12-01T00:00:00Z>\nd2 = #Ecto.DateTime<2015-11-30T00:00:00Z>\n\nassert Ecto.DateTime.to_erl(d1) > Ecto.DateTime.to_erl(d2)\n```\n\nThis can be cumbersome to write all the time. Thankfully Ecto comes with\na nice [`Ecto.DateTime.compare/2`][compare] function:\n\n```elixir\nd1 = #Ecto.DateTime<2015-12-01T00:00:00Z>\nd2 = #Ecto.DateTime<2015-11-30T00:00:00Z>\n\nassert Ecto.DateTime.compare(d1, d2) == :gt\n```\n\n`Ecto.DateTime.compare/2` takes two time structs and compares the first\nto the second. The result will be `:eq`, `:lt`, or `:gt`.\n\n[struct]: http://elixir-lang.org/getting-started/structs.html\n[compare]: http://hexdocs.pm/ecto/Ecto.DateTime.html#compare/2\n"},{"title":"Speeding up Elixir project build times on Travis CI","tags":["elixir","continuous integration","travis ci"],"summary":null,"legacy":false,"illustration_alt":"total-jobs","illustration":"http://i.imgur.com/jst9V2C.png","id":"2015/12/02/speeding-up-elixir-project-build-times-on-travis-ci","employee":"Brian Cardarella","date":"2015-12-02T00:00:00","body":"\n\nElixir is fast, very fast. So fast that a good chunk of [Continuous\nIntegration][ci] jobs on [Travis CI][travis] for our Phoenix projects were spent in\nfetching dependencies (this is very small, but still a few seconds) and\nthen compiling all of the dependencies.\n\nIf you're willing to deal with getting a failed build once in a while\nthen you can significantly speed up the CI jobs by caching certain\nassets. Specifically the `_build/` and `deps/` directories.\n\nThis strategy can be used on any CI service but the example here is for\nTravis CI. Simply add the following to your `.travis.yml` file:\n\n```yml\ncache:\n  directories:\n    - _build\n    - deps\n```\n\nWe saw a big reduction in total Pull Request CI test run time\n![total-jobs][total-jobs]\n\nHere is a comparison of the individual jobs\n\nBefore:\n\n![before][before]\n\nAfter:\n\n![after][after]\n\nIf you are getting a failing build when you believe you shouldn't, the\nissue could be the cache. You can simply [clear the cache and start it\nfrom scratch at any time][clear-cache].\n\n[total-jobs]: http://i.imgur.com/jst9V2C.png\n[before]: http://i.imgur.com/efm7IPa.png\n[after]: http://i.imgur.com/LfXAuSk.png\n[clear-cache]: https://docs.travis-ci.com/user/caching/#Clearing-Caches\n[ci]: https://en.wikipedia.org/wiki/Continuous_integration\n[travis]: http://travis-ci.org\n"},{"title":"Ember Best Practices: Service Backed Components","tags":["ember","javascript","best practices"],"summary":"Embrace one-way data flow and get your app ready for routable components.","legacy":false,"illustration_alt":"Data down, actions up","illustration":"https://i.imgur.com/A6gg5zA.png","id":"2015/12/07/best-practices-service-backed-components","employee":"Lauren Tan","date":"2015-12-07T00:00:00","body":"\n\nAt EmberConf 2015, [Yehuda Katz][yehuda] and [Tom Dale][tomdale] announced the arrival of certain changes to Ember 2. Most notably, the [routable components RFC][rfc] attracted a lot of attention because of its proposal to deprecate and eventually remove controllers. Naturally, this was alarming to many existing Ember users, especially since Ember and Sproutcore have always been MVC frameworks. \n\n## Goodbye MVC\n\nIt is no secret that many new Ember 2 conventions and changes have direct influence from [React][react] and [Flux][flux] (a pattern for data flow in React apps). What Flux calls the \"unidirectional data flow\" is what we call \"Data down, actions up\" (DDAU) in Ember. \n\nDDAU avoids the traditional MVC pattern in favor of a single flow of data (hence unidirectional), which makes apps easier to reason about, and improves their performance. The fundamental problem with MVC is revealed as your application grows larger and more complex – cascading updates and implicit dependencies lead to a tangled mess and unpredictability. Updating one object leads to another changing, which in turn triggers more changes, and ultimately makes maintaining your application a frustrating experience.\n\n![Data down, actions up][ddau-diagram]\n\nIn the DDAU pattern, data flows one-way and there are no two-way bindings. Different parts of your application can remain highly decoupled and predictable, which means you will always know the source of an object's change. If you've read my post on [functional programming and the observer effect][fp-blogpost], you'll understand why it's important to keep your components free from side effects.\n\nInstead of spending time cobbling together your own makeshift framework with a dozen micro-libraries and bike-shedding on the best way to implement a feature, using Ember means instant productivity and quick developer on-boarding. Combined with the DDAU pattern and the Glimmer rendering engine, Ember developers have both productivity and performance out of the box. \n\n## Preparing your application for DDAU\n\nWhen routable components land, controllers will be deprecated and removed. Controllers and views have always been confusing for new Ember users, and \"80% of their use cases were to do something that was fundamentally a component\" (watch Yehuda and Tom explain more in this [video][routable-video]).\n\nSince Ember components aren't singletons, they will be torn down and re-rendered in an optimized fashion when Glimmer deems necessary. How then to handle state persistence when controllers go away? \n\nFor example, you might have some property on your controller that holds on to state that you would like to preserve throughout the app. To do so in Ember 2 (and today), we can remove that controller property in favor of \"service-backed components\". The service will hold on to singleton component state, and explicitly injected only where necessary. Because services are powerful and can be easily abused, I'll talk more about it at the end of this post.\n\n## Implementing service backed components\n\nIn the following example, I'll demonstrate how you can use services and one-way bindings today. You can follow along below as well as check out the [demo][demo].\n\nOur little application consists of a couple of checkboxes for selecting animals. This selection needs to persist across different routes, and restore state when returning back to the route. All we need is to define a simple service that holds state for the selected items, and then inject it into the routable component.\n\nIn the route's template, we can just render the injected service's state using the `each` helper. \n\n```hbs\n{{! animals/index.hbs }}\n<div class=\"row\">\n  <div class=\"col-md-3\">\n    <h2>Select Animals</h2>\n\n    {{checkbox-group\n        group=animals\n        selectedItems=checkboxGroup.selectedItems\n        check=(action \"check\")\n    }}\n  </div>\n\n  <div class=\"col-md-9\">\n    <h3>Selected Animals</h3>\n    <table class=\"table table-bordered\">\n      <thead>\n        <tr>\n          <th>ID</th>\n          <th>Species</th>\n          <th>Name</th>\n        </tr>\n      </thead>\n\n      <tbody>\n        {{#each checkboxGroup.selectedItems as |animal|}}\n          <tr>\n            <td>{{animal.id}}</td>\n            <td>{{animal.species}}</td>\n            <td>{{animal.name}}</td>\n          </tr>\n        {{/each}}\n      </tbody>\n    </table>\n  </div>\n</div>\n```\n\nIn our controller or routable component, we inject the service and define the action for handling the checked animal. The service's bag of state is then passed into the component, keeping it as pure as possible. Although you could have just injected the service into the component, doing it this way makes things more explicit and allows the component to be decoupled from the service. \n\n```js\n// animals/controller.js\nimport Ember from 'ember';\n\nconst { inject: { service }, Controller } = Ember;\nconst OPERATION_MAP = {\n  true: 'addObject',\n  false: 'removeObject'\n};\n\nexport default Controller.extend({\n  checkboxGroup: service(),\n  \n  // In the future, actions will be defined in the route and passed into the \n  // routable component as `attributes`.\n  actions: {\n    check(group, item, isChecked) {\n      return group[OPERATION_MAP[isChecked]](item);\n    }\n  }\n});\n```\n\nAs mentioned, the service itself is simple. We can define more complex behavior later, but the underlying persistence for its state is just a JavaScript array.\n\n```js\n// checkbox-group/service.js\nimport Ember from 'ember';\n\nconst { Service } = Ember;\n\nexport default Service.extend({\n  init() {\n    this._super(...arguments);\n    this.selectedItems = [];\n  }\n});\n```\n\nBecause our behavior is simple, we don't need to define a sub-classed component in this example. The `check` action is passed in from the routable component / controller, so using closure actions in the component's template means that we don't have to cast `sendAction`s into the void.\n\nIn our component's template, we make use of small, composable helpers. These helpers are just simple JavaScript functions under the hood, and because they have return values, we can use them as Handlebars sub-expressions where we might have once defined a computed property. \n\nThe `contains` helper doesn't ship with Ember, but the function itself is [one line of code][contains-helper]. There are a bunch of useful addons that add helpers such as these to your application – for example, [`ember-truth-helpers`][truth-helpers] is an addon I find myself using in almost all my apps.\n\n```hbs\n{{! checkbox-group/template.hbs }}\n{{#each group as |item|}}\n  <div class=\"checkbox\">\n    <label for={{concat \"item-\" item.id}}>\n      {{one-way-input\n          id=(concat \"item-\" item.id)\n          class=\"checkbox\"\n          type=\"checkbox\"\n          checked=(contains selectedItems item)\n          update=(action this.attrs.check selectedItems item)\n      }} {{item.name}} <span class=\"label label-default\">{{item.species}}</span>\n    </label>\n  </div>\n{{/each}}\n```\n\nAs mentioned in my [previous post][fp-blogpost], the [`ember-one-way-input`][oneway] addon is an easy way to start using one-way bindings today. \n\nI hope this simple example illustrates how you can build maintainable and performant apps with some of my favorite features of Ember – helpers, closure actions, components, and one-way bindings.\n\n## A word of caution about Services\n\nAs the cliché goes, \"with great power...\". Because services in Ember are singletons, it becomes tempting to make multiple services and inject them everywhere. \n\nIf your main reason for creating a service is to use it as a \"global\", that is generally a code smell because dependencies become implicit (we learned earlier that this is a bad thing) and parts of your application become tightly coupled. Instead, expose data and actions via interfaces to keep your code decoupled and explicit. Remember the Principle of Least Power, and only use a service when strictly necessary!\n\n### So when should I use a service?\n\nI like this [Stack Overflow answer][stackoverflow] on when you should use a singleton. Essentially, you should only use one when you can only have a single instance throughout your application. For example, a shopping cart, [flash messages][ember-cli-flash] or activity feed could be great candidates for a service.\n\nThanks for reading!\n\n[contains-helper]: https://github.com/poteto/component-best-practices/blob/master/app%2Fhelpers%2Fcontains.js?ts=2\n[ddau-diagram]: https://i.imgur.com/A6gg5zA.png\n[demo]: https://poteto.github.io/component-best-practices/#/service-backed\n[ember-cli-flash]: https://github.com/poteto/ember-cli-flash\n[eventbus]: http://www.thesoftwaresimpleton.com/blog/2015/04/27/event-bus/\n[flux]: https://facebook.github.io/flux/docs/overview.html#content\n[fp-blogpost]: https://dockyard.com/blog/2015/11/16/best-practices-functional-programming-and-the-observer-effect\n[oneway]: https://github.com/dockyard/ember-one-way-input\n[react]: https://facebook.github.io/react/\n[rfc]: https://github.com/emberjs/rfcs/pull/38\n[routable-video]: https://www.youtube.com/watch?v=QgycDZjOnIg\n[stackoverflow]: http://stackoverflow.com/a/142450/4259952\n[tomdale]: https://twitter.com/tomdale\n[truth-helpers]: https://www.npmjs.com/package/ember-truth-helpers\n[yehuda]: https://twitter.com/wycats\n"},{"title":"Which diagrams when?","tags":["best practices","design strategy","discovery","information graphics"],"summary":"Design best practices - utilizing diagrams","legacy":false,"illustration_alt":"Journey Map","illustration":"https://i.imgur.com/3ZNISil.png","id":"2015/12/21/which-diagrams-when","employee":"Ashley Treni","date":"2015-12-21T00:00:00","body":"\n\nDiagrams are incredibly valuable as methods of communication. Through visual language and spatial representation, diagrams give form to concepts and ideas.\n\nDiagram: (definition) *a simplified drawing showing the appearance, structure, or workings of something; a schematic representation.*\n\nMental model: (definition) *an explanation of someone's thought process about how something works.*\n\nAt DockYard, we use various diagrams at different stages of the design process. Each type documents and captures different aspects of the design research process. It is valuable to know when in the process these diagrams can be used, as they can support conversations between different stakeholders and help to align understanding.\n\nThe following case study utilizes a few of the diagrams we used here at DockYard. Each of these examples highlights the type of diagram and when in the design process they should be used. (We use [OmniGraffle](https://www.omnigroup.com/omnigraffle) to build these diagrams.)\n\n###Case Study: OutdoorKidz.com\n\nOurdoorKidz.com (fictional!) is a new online store that specializes in seasonal outdoor gear and activites for kids. We've been hired to design and build the customer facing website, which houses the entire inventory of products and allows customers to purchase gear directly from the website.\n\n**Target User:** Parents with young kids who are looking for outdoor gear and activities for kids.\n\n**Goal:** Design and build an online store that allows target audience to search for, compare, and purchase items.\n\n\n####1. Journey Map - Design Research\n\nA journey map is diagram in the form of a timeline, which identifies a user’s arrival to and experience surrounding the use of the product. Journey maps are often developed from a user persona based on the target user. They help to understand the context in which someone might interact with the product: why they seek it out, where they interact with it, and what they hope to gain from it. Understanding the use case informs design decisions early on, framing the major actions the user might want to take (features) within the product flow.\n\n\n![Journey Map](https://i.imgur.com/3ZNISil.png)\n[Journey Map PDF](https://www.dropbox.com/s/rr1tik21er82bva/Journey_Map.pdf?dl=0)\n\n\n####2. User Flow - Product Development\n\nA user flow is a diagram of the high level product experience, used to frame the actions taken within the product itself. They are generated from the use case (journey map), allowing us to break down the step by step interactions that must take place for the user to accomplish their goal.\n\nUser flows become the basis for sketching and wireframing major areas of the interface. The navigation, framed around the user experience, informs the information architecture and interface design. Through wireframing, actual content is placed in context and functionalities are incorporated to support calls to action.\n\n\n![User Flow](https://i.imgur.com/qlLEcAd.png)\n[User Flow PDF](https://www.dropbox.com/s/rd4diyfpteogplo/User%20Flow.pdf?dl=0)\n\n####3. Master Product Flow - Product Development\n\nWhen we build complex interfaces, they often have multiple use cases. This master user flow connects the customer facing interface, OutdoorKidz.com online store, to the inventory management system for the employees of OutdoorKidz.com. The products overlap where orders come in and invetory is tracked. Connecting the two separate user flows can show the points where the two systems overlap. This can help to ensure the systems are built efficiently and speak to one another.\n\n\n![Product Flow](https://i.imgur.com/L9jx16u.png)\n[Product Flow PDF](https://www.dropbox.com/s/8g3onvpoqevyllj/Master%20Flow.pdf?dl=0)\n\nKnowing when and how to incorporate these diagrams can be very valuable to your process. Diagrams are also good for documentation and tracking decisions throughout the process. They support discussion around problem solving, and can clarify that all stakeholders in the conversation share a common understanding of the solution.\n\nHere are some of my favorite resources about diagrams and mental models.\n\nReferences:\n\n[101 Design Methods](http://www.101designmethods.com) - Vjay Kumar\n\n[100 Diagrams that Changed the World](http://www.amazon.com/100-Diagrams-That-Changed-World/dp/0452298776) - Scott Christianson\n\n[Models of Design](http://www.dubberly.com/models) - Hugh Dubberly\n\n"},{"title":"How to uncover hidden assumptions","tags":["design","business","design process","planning"],"summary":"Spend the time to talk about assumptions upfront. You'll save effort and frustration on any project.","legacy":false,"illustration_alt":"Invisible Assumptions","illustration":"http://i.imgur.com/lemN7lE.jpg","id":"2015/12/22/how-to-uncover-hidden-assumptions","employee":"Maria Matveeva","date":"2015-12-22T00:00:00","body":"\n\n\n![Invisible Assumptions](http://i.imgur.com/lemN7lE.jpg)\n\n## A 911 fail\n\nThe first time I had ever called 911 was for an almost non-emergency reason. Driving on an Interstate highway through Baltimore, we noticed a large ladder that had fallen off a construction truck. It was blocking two lanes out of four, and cars were veering to the side to avoid it. \n\nBecause we were one of the first ones to notice the ladder falling off, and I was a passenger, I was in a good place to call and report debris on the road. So I called 911, assuming they’d quickly route my call to the department that can easily deal with this stuff.\n\nThe call went something like this:\n\n- Hello, I’d like to report a dangerous situation on the road.\n- Ok, where are you?\n- I’m on Route 95, between exits 51 and 52, heading North, there is dangerous debris on the road…\n- Are you in the city or the county?\n- …\n\nAfter a few attempts back and forth, I couldn’t answer the dispatcher’s question because I didn’t know where the city / county border was. It was certainly not on my phone’s map apps. We were still driving, so I no longer was at the exact location.  I was also getting frustrated because the dispatcher did not seem to care for my attempts to give her a location by highway exit number, or by listing the streets the highway crossed near the area. After a few minutes I gave up and the report went nowhere.\n\n\n\n## Perspectives and assumptions\n\nI can only assume the dispatcher’s role was to route my call to the next responsible party. For her, the agency in charge of traffic safety in the city, and the other agency in charge of the county are completely different things. For me, and anyone on the ground, the difference between those territories could be invisible. The border is not marked, and could lie across two corners of the same intersection. In general, the public won’t usually see these boundaries in the same way administrators do.\n\nHowever, the dispatcher had responded to my call with the assumption that anyone calling 911 locally would know if they are “in the city or the county”. Her assumption and my assumption did not match, and an emergency call failed as a result.\n\nI disagree with that assumption: even though I lived in the Baltimore area for four years, I’d only know the city/county border location for the immediate neighborhood where I lived. Even then, it was only because the university I attended had famously lobbied to move that border so they could have a more prestigious Baltimore city address. I wouldn’t expect a typical 911 caller to know this stuff.\n\nI don’t fault the dispatcher in this case, by the way. Even though she could have been more prepared to understand my perspective, I can see how her environment could have made the city / county distinction so obvious it became an invisible assumption.\n\n\n\n## A designer’s job is to find out\n\nIt is important to discover the assumptions built in to a project. This responsibility is shared, but designers are often in the best position to lead this discovery because we deal both with understanding a user’s needs and the tools we might use to implement a solution. \n\nPart of this discovery process is requirements gathering: we understand and document the business goals the client aims to achieve, the restrictions that will inform the choice of design tools and technologies, and the user and industry insights that will inform the functionality can propose for an application.\n\nBut in addition to gathering requirements, we must discover the “obvious” things to people close to the product. These assumptions are so self-evident to the person who holds them that they won’t likely be included with requirements, or even communicated voluntarily. Designers must ask the “obvious” questions to uncover those things and continue asking them throughout the process. \n\nNot communicating those assumptions makes a project ripe for surprises. If you don’t talk about the obvious things, everyone can hold on to conflicting assumptions for a long time. Making changes to address hidden assumptions after a portion of the work has been done adds cost (and frustration!) and decreases efficiency.\n\n\n\n## How to uncover hidden assumptions\n\nTo uncover hidden assumptions, designers must ensure open and frequent communication. It may feel like over-communicating at first, but will start to feel natural with practice. Here are a few of the practices we use.\n\n**Daily updates**\nOn most projects, we update the client on our progress daily. While it may seem like a chore to write up an additional description after the day’s work has been completed, the updates force us to communicate clearly and often. This gives the client an opportunity to correct our assumptions early in the process.\n\nThese updates can include questions (e.g. “How many people are likely to experience this particular use-case?”) and assumptions we need confirmed (e.g. “We have found that most users will leave this setting untouched, so we included this default value. Is this value a safe one to default to?”). Pro tip: request feedback from a client with a clear list of questions and assumptions they can quickly confirm or correct. This format makes it easier for the client to respond, so it’s more likely that you’ll quickly get the information you need to move forward.\n\n**Flow diagrams**\nWe often produce flow diagrams to map out the universe around the product we’re building. When all team members have access to a visual representation of the entire product, and things that influence it, we often find problems and special cases that were not previously considered.\n\nFlow diagrams often include elements like triggers (what caused a process to be started), decision points (yes / no), variables (including an approximate range) and tentative bits (we are explicitly marking some part of the process as outside the scope, or as a secondary requirement).\n\n**Annotated wireframes and sketches**\nWe always annotate wireframes and sketches. We may draw low-fidelity sketches at first, but will note the type of content that might be included in a specific screen, and the reasoning and user goals that informed a specific layout. Notes like this will help frame the follow-up discussion with the client.\n\n\n\n## TL; DR\n\nA difference in expectations is one of the most preventable causes of projects going wrong. And among all expectations, assumptions can be the most dangerous: they feel so “obvious” that we don’t even bring them up. If even a 911 call can be derailed by a dispatcher’s assumption, so can a large collaborative project. \n\nAnd just like in the 911 call, it’s possible to prevent misunderstanding by asking the “obvious” questions. The dispatcher could have asked for my location in a different way - by street intersection, or exit number. And if her standard process did not include the assumption that a caller would know where the border between the City and the County lies, she would have been able to route me successfully by asking the question in a different form.\n\nDon’t be that 911 dispatcher. Spend the time to [talk about assumptions up front](https://dockyard.com/blog/2014/07/18/design-as-conversation) - and you’ll save everyone on the team time, effort, and unnecessary frustration.\n\n\n"},{"title":"This business needs to be about more than just business","tags":["opinion","business"],"summary":null,"legacy":false,"id":"2016/01/05/this-business-needs-to-be-about-more-than-just-business","employee":"Brian Cardarella","date":"2016-01-05T00:00:00","body":"\n\nI just fired a client. Day one in the year.\n\nI've done it before, I'll likely do it again. This one hurt. We've\nworked with this client for the past eight months to rebuild their\nplatform. I've given them breaks on price. I've given them free\nengineering time. In the end it came down to a lack of respect for the\nrelationship they had.\n\nEach year I've written a retrospective about how the year went, the ups\nand downs of running a consultacy. In the first retrospective I wrote:\n\n[*\"As a consultancy we are looking to make money by engaging clients. If\nanybody tells you they're consulting because it is their passion or work\nwith startups, they are full of shit.\"*][shit]\n\nI can tell you right now that I was full of shit. I got into consulting\n\"for the money\" but over the past four years we've built a company that\nhas grown to 23 people. We've followed our passions with technology and\ndesign. We've made major contributions back to and have financially\nsupported the software projects we think are going to build the web for\nthe next decade and beyond. We made mistakes and we've made incredible\nbets that have paid off.\n\nOne of our engineers recently told me a story about how he was hanging\nout with a friend of his girlfriend. That friend knew our engineer was in\nsoftware but didn't know the name of the company. The friend began to speak\nabout how he was reading a series of blog posts on Ember.js. That blog\nwas our blog and that friend was impressed when our engineer told the friend\nwhere he worked.\n\nThis was actually an incredible moment for me when I\nheard this story. This was the first time that I heard a story about\nsomeone knowing about DockYard without our prompting them. Perhaps this\nmay seem pedantic to you. But knowing that we've built something that\npeople know about and respect has become very important to me.\n\nI realize that I'm emotionally wrapped up in DockYard. Arguably to the\npoint where it may impact my efficacy as CEO. Today I\nfired a client because of the lack of respect they showed to us as\npeople. Is this good business? I don't know, probably not. But I've become convinced\nthat this business needs to be about more than just business.\n\n[shit]: https://dockyard.com/blog/opinion/2012/06/21/lessons-learned-six-month-of-running-dockyard\n"},{"title":"Phoenix best practice: Decorating in views","tags":["elixir","phoenix","best practices"],"summary":"Keeping your logic where it belongs","legacy":false,"id":"2016/01/15/phoenix-best-practice-decorating-in-views","employee":"Dan McClain","date":"2016-01-15T00:00:00","body":"\n\nRecently I was updating an older Phoenix app that was built when I was\nfirst familiarizing myself with Phoenix and realized there were a couple\narchitectural mistakes in some of the controllers and views. I rectified\nthose mistakes with the following patterns.\n\n## Keep your database out of my view by preloading\n\nThe view layer in Phoenix serves as a [decorator][decorator-pattern] for\nthe template you are about to render. It serves to merge data retrieved\nin the controller with the additional details that may be needed. On our\n[JSON API][json-api] backends, we use [ja_serializer][ja_serializer] to\nconvert our models into the proper response. When we have additional\ndetails (say we include a blog post's author for side loading into\nEmber), we  want to make sure that we preload this data before it gets\nto the view. If we preload from the view itself, we will be creating an\n[N+1 scenario][nplusone].\n\nLet's take the case of an index route where you have 20 posts you want\nto render. When we wait until we get to the view's `show.json` (which\nrenders the individual post) to retrieve the author, we will be doing 20\nadditional SQL queries, as we will be getting the post one by one. If we\npreload the author relationship in the controller, we will be executing\na single query that retrieves *all* the authors and places them in the\nstruct with the post information.\n\n## Keep your decoration out of your controllers\n\nYou may have additional information you want your view to have access\nto. In one case that I came across, we query the database to find the\nnumber of blog posts a specific tag has. We end up storing the\ninformation in a map in the function we created to look up that\ninformation, where the key is the id of the tag, and the value is the\nnumber of posts for that tag. We just went over why you don't want to do\nthis work in your view, so how do we pass that information down? We can\nuse the `Plug.Conn.assign` ([docs][assign-docs]) to store the\ninformation on the `conn` which is passed to render in the controller.\nWhat we don't want to do is start `Enum.map`ing across the list of tags\nand munging the data in the controller. That would be *decorating* the\nmodel, which is the job of the view.\n\n## Everything in its right place\n\nBy following the practice of decorating in the view, and doing data\nretrieval in the controller, it actually makes it quite difficult to\ncreate an N+1 query. When you have a list of records, the easiest way to\npreload data (if you aren't using `Ecto.Query.preload`), is to call\n`Repo.preload(collection, keys)`, which will only perform a single query\nin the end.\n\nMoving from Rails to Phoenix, I've personally found there to be fewer\nfootguns to shoot myself with. I think a big part of that ends up being\nthe fact that with a functional language, you can't accidentally make a\ncall to the database because your relationship can't load itself. With\nEcto, I have to explicitly load the data for the relationships and that\nrequires me to think about *when* is the best point to do so.\n\n[decorator-pattern]: https://en.wikipedia.org/wiki/Decorator_pattern\n[json-api]: http://jsonapi.org/\n[ja_serializer]: https://github.com/AgilionApps/ja_serializer\n[nplusone]: http://stackoverflow.com/a/97253\n[assign-docs]: http://hexdocs.pm/plug/Plug.Conn.html#assign/3\n"},{"title":"Heroic Elixir Pipelines","tags":["elixir","best practices"],"summary":"The pipe operator has a huge effect on Elixir for how simple it is. Learn how to use its power in your own functions","legacy":false,"id":"2016/01/22/heroic-elixir-pipelines","employee":"Aaron Sikes","date":"2016-01-22T00:00:00","body":"\n\nOne small source of beauty in Elixir code is the [pipe operator][pipe]. It passes the expression on the left as the first argument to the function on the right:\n\n```elixir\n1..100_000\n|> Enum.map(&(&1 * 3))\n|> Enum.filter(odd?)\n|> Enum.sum\n```\n\nHere, a range of numbers is being passed through a chain of several operations. Much of the Elixir standard library can be used like this.\n\nCode like this is great to read. It’s got a protagonist. Our hero navigates trials, and comes out changed on the other side. Humans are wired to understand a story.\n\nBut do you ever think about how to keep your own functions pipeable? Here’s a hypothetical bit of Elixir code: \n\n```elixir\ndef read_time(str) do\n  str\n  |> String.split(\" \")\n  |> Enum.count\n  |> Kernel./(200)\n  |> Integer.to_string\n  |> Kernel.<>(\"minutes\")\nend\n\ndef related_posts(title, body) do\n  related_posts_by_title(title) ++ related_posts_by_body_text(body)\nend\n\n...\n\ndef publish_post(%Post{body: body, title: title} = post) do\n  word_count = read_time(body)\n  related_posts = related_posts(title, body)\n  App.publish(%{post | word_count: word_count, related_posts: related_posts})\nend\n```\n\nHere, the wonderful piping action is present in the `read_time` function, where you’re sticking to the standard library. But where did it go in the `publish_post` method? The functions you're writing aren't built to facilitate piping. A good pipeable function takes some thought.\n\nWho is your hero? Here it's your `post` object. To write pipeable functions, your functions should take this hero as their first argument, and return a modified version/representation. Your first argument is your pipe intake, and your return value is your pipe outflow.\n\nTaking your hero as your second argument (as the sidekick), or taking only specific properties, or returning another value rather than a modified version can all break pipeability. Sometimes you want to do those things for unit tests, or for encapsulation and reusability, but you can always write a wrapping function that is more pipeable. Here’s how I’d use those techniques here:\n\n```elixir\ndef annotate_read_time(%Post{} = post) do\n  %{post | read_time: read_time(post.body)}\nend\n\ndef add_related_posts(%Post{body: body, title: title} = post) do\n  %{post | related_posts: related_posts(body, title)}\nend\n\n...\n\ndef publish_post(%Post{} = post) do\n  post\n  |> annotate_read_time()\n  |> add_related_posts()\n  |> App.publish()\nend\n```\n\nAh, that’s better! We realized our hero is the humble post. It learns a few things about itself along the way, and at the end of its journey is published to the world.\n\nSo. When writing your code, discover your protagonist. Write functions which take your hero as the first argument, and return it changed for the better. Then The Hero’s Journey will be complete, and you can have beautiful pipelines running all throughout your code.\n\n[pipe]: http://elixir-lang.org/docs/v1.0/elixir/Kernel.html#|>/2\n"},{"title":"Home away from home","tags":["community","culture","team"],"summary":"A short reflection","legacy":false,"id":"2016/01/22/home-away-from-home","employee":"Ashley Treni","date":"2016-01-22T00:00:00","body":"\n\nFor those who don’t know my journey with DockYard, it’s quite an amazing story. \n\nAs an imposingly curious grad student studying data visualization, I absolutely couldn’t resist the urge to jump into a conversation I overheard while bartending at Highball Lounge in March of 2014 (who can resist buzzwords like \"information architecture\", \"JavaScript\", and \"data\"!). A nice chat and a short introduction later, I was invited by Brian and Dan of DockYard to reach out and learn more about the company. I was immediately intrigued - both by the conversation and also the type of people who didn’t dismiss me because of my job (as most tend to do to those who work in the service industry).\n\nI’ll never forget the first conversation I had with Steve when I went to the DockYard office to learn about the design team. I was absolutely amazed that they would consider me for an internship, and saw value in my curiosity and engagement, rather than the checklist of my industry experience (which, for the record, was non-existent). After a summer internship in 2014 where I was welcomed with open arms and [jumped right into the conversation](https://dockyard.com/blog/2014/07/18/design-as-conversation), I joined DockYard full time in January 2015. This was during my final semester of grad school, and I received a tremendous amount of support from my colleagues while I worked simultaneously on my [Master’s thesis project](http://www.designtaxonomy.com/#/standardimprovisations/).\n\nA few weeks later, I moved to Brooklyn for summer 2015. I saw an opportunity to bridge two worlds that were very important to me - DockYard’s consulting services and civic technology. I asked for permission to take a leave of absence to attend a fellowship at [Blue Ridge Labs](http://labs.robinhood.org/), a social impact incubator focused on problem solving with technology for low income communities in New York. It was an amazing thing to receive their blessing and support.\n\nDockYard is an amazing place that values people and relationships. But I think the most incredible part, which I’ve been so fortunate enough to receive time and again, is the grace of its individuals' willingness to mentor and teach. While some companies are in search of unicorns and are in the game of stealing resources, DockYard seeks out something special in its employees more important than skill, and fosters the growth of individual people as well as talent. \n\nToday is bittersweet, because it is my last day at DockYard, and in the city of Boston. What I’ve been lucky to find I will be taking with me - the awareness to pay attention to qualities rather than attributes, to share and to be open, and to prioritize heart, sincerity, drive, and curiosity above all else.\n\nDockYard is truly special (and you’d be hard pressed to find a [DockYarder](https://medium.com/@sugarpirate/warning-breaking-changes-afeb2544d0f5#.ata8oqafn) who doesn’t feel this way). I feel proud and quite blessed to say that DockYard is my home away from home. I’d like to take this opportunity to thank my friends, colleagues, and mentor, Steve, at DockYard; it's been an absolute privilege to learn and grow in this community with all of your support.\n"},{"title":"Running Elixir and Phoenix projects on a cluster of nodes","tags":["elixir","phoenix","deployment"],"summary":"How to use distributed elixir in a few simple steps","legacy":false,"id":"2016/01/28/running-elixir-and-phoenix-projects-on-a-cluster-of-nodes","employee":"Chris McCord","date":"2016-01-28T00:00:00","body":"\n\nOnce you're ready to deploy your Elixir application to multiple servers, you'll want to take advantage of the distributed features that the runtime offers. For example, if you are using Phoenix channels, you'll want broadcasts to be sent across the cluster. You can setup your deployment as a cluster in a few simple steps:\n\nStart by creating a new `sys.config` file in your project. We'll conventionally use the name `sys.config` because Erlang assumes exactly one system configuration file is used when building releases, with this name. Add the following contents the new file:\n\n```erlang\n[{kernel,\n  [\n    {sync_nodes_optional, ['n1@127.0.0.1', 'n2@127.0.0.1']},\n    {sync_nodes_timeout, 10000}\n  ]}\n].\n```\n\nIn this example, we have two nodes in the cluster, `n1@127.0.0.1` and `n2@127.0.0.1`. The `sync_nodes_optional` configuration specifies which nodes to attempt to connect to within the `sync_nodes_timeout` window, before continuing with startup. There is also a `sync_nodes_mandatory` key which can be used to enforce all nodes are connected within the timeout window or else the node terminates. With our `sys.config` in place, we can pass a VM `-config` flag to use our configuration when booting the Erlang VM. For example, you could start two iex sessions like this:\n\n```console\nn1@host$ iex --name n1@127.0.0.1 --erl \"-config sys.config\" -S mix\nn2@host$ iex --name n2@127.0.0.1 --erl \"-config sys.config\" -S mix\niex(n2@127.0.0.1)1> Node.list\n[:\"n1@127.0.0.1\"]\n```\n\nIf you're building Phoenix projects, you could start your servers like this:\n\n```console\nn1@host$ elixir --name n1@127.0.0.1 --erl \"-config sys.config\" -S mix phoenix.server\nn2@host$ elixir --name n2@127.0.0.1 --erl \"-config sys.config\" -S mix phoenix.server\n```\n\nYou might be wondering why we have to use Erlang-based configuration in our `sys.config` instead of Mix configuration. This is because the configuration must be passed to the Erlang VM when starting. By the time Mix configuration would be loaded, the VM has already booted. That said, we can use Mix configuration to drive our `sync_nodes_optional` list if we are using [exrm](https://github.com/bitwalker/exrm) to build releases for deployment. `exrm` builds your Mix configuration into a `sys.config` within the release, which lets you specify your node configuration like this, in your Mix config:\n\n```elixir\nconfig :kernel,\n  sync_nodes_optional: [:\"n1@127.0.0.1\", :\"n2@127.0.0.1\"],\n  sync_nodes_timeout: 10000\n```\n\nThen you build and run your releases as normal and the proper VM configuration is provided when starting. For a complete rundown on using `exrm` to deploy a Phoenix project, see the [official guide](http://www.phoenixframework.org/docs/advanced-deployment).\n\nThat's all it takes to run distributed Elixir on a cluster of servers! The Erlang VM supports a number of more advanced options and strategies for running distributed applications, including automatic application failover to a configured subset of nodes, and more. See the [Erlang documentation](http://erlang.org/doc/design_principles/distributed_applications.html) for a comprehensive rundown.\n"},{"title":"Elixir Best Practices - Deeply Nested Maps","tags":["elixir","best practices"],"summary":null,"legacy":false,"id":"2016/02/01/elixir-best-practices-deeply-nested-maps","employee":"Brian Cardarella","date":"2016-02-01T00:00:00","body":"\n\nWhen writing Elixir apps you'll typically find yourself building up\nstate in a [map][map]. Typically these maps contain deep \nnesting. Updating anything deeply nested means you have to write something like:\n\n```elixir\nmy_map = %{\n  foo: %{\n    bar: %{\n      baz: \"my value\"\n    }\n  }\n}\n\nnew_bar_map =\n  my_map\n  |> Map.get(:foo)\n  |> Map.get(:bar)\n  |> Map.put(:baz, \"new value\")\n\nnew_foo_map =\n  my_map\n  |> Map.get(:foo)\n  |> Map.put(:bar, new_bar_map)\n\nMap.put(my_map, :foo, new_foo_map)\n```\n\nThat's pretty complex for a simple nested key update!\nElixir has a better way: [`Kernel.put_in/3`][put_in_3]\n\nThis function uses the [Access][access] \"behaviour\" to drastically\nreduce the keystrokes for inserting into deeply nested maps. Let's take\na look at refactoring the above example:\n\n```elixir\nmy_map = %{\n  foo: %{\n    bar: %{\n      baz: \"my value\"\n    }\n  }\n}\n\nput_in(my_map, [:foo, :bar, :baz], \"new value\")\n```\n\nThat's it! The really nice thing about this function is that the 2nd\nargument is simply a list which means when we're dealing building\ncomplex maps during recursion we can simply append to the list.\n\nSimilarly, we can get deeply nested values in a map using\n`Kernel.get_in/2`:\n\n```elixir\nmy_map = %{\n  foo: %{\n    bar: %{\n      baz: \"my value\"\n    }\n  }\n}\n\nget_in(my_map, [:foo, :bar, :baz]) == \"my value\"\n```\n\nLet's go deeper. Does the list syntax feel like too many characters to\nyou? Let me introduce you to [`Kernel.put_in/2`][put_in_2]\n\n```elixir\nput_in(my_map.foo.bar.baz, \"new value\")\n```\n\nThis version of the function is a [macro that will break up the syntax\nand deal with each part of the path individually][put_in_2_macro]. It may feel like\nmagic but it's just Elixir doing what it does best: blowing your mind.\n\nStill going deeper...\n\nNow its time to get fancy. Let's say you want to update the values\naccording to a function. To do that we'll use\n[`Kernel.update_in/3`][update_in_3]\n\n```elixir\nmy_map = %{\n  bob: %{\n    age: 36\n  }\n}\n\nupdate_in(my_map, [:bob, :age], &(&1 + 1))\n#=> %{bob: %{age: 37}}\n\nupdate_in(my_map.bob.age, &(&1 + 1))\n#=> %{bob: %{age: 37}}\n```\n\n### Dealing with Lists and Structs\n\nDeeply nested lists can also make use of these functions. However, there\nis a difference in the short-hand syntax.\n\n```elixir\nmy_list = [foo: [bar: [baz: \"my value\"]]]\n\nput_in(my_list[:foo][:bar][:baz], \"new value\")\n```\n\nThis is referred to as \"[field-based lookup][field-lookup]\" and can\ndiffer depending upon the type you are acting upon. Maps can work with\neither form:\n\n```elixir\nmy_map[:foo][:bar][:baz]\n#=> \"my value\"\n\nmy_map.foo.bar.baz\n#=> \"my value\"\n```\n\nLists only work with the bracket form:\n\n```elixir\nmy_list[:foo][:bar][:baz]\n#=> \"my value\"\n\nmy_list.foo.bar.baz\n#=> ** (ArgumentError) argument error\n```\n\nStructs only work with the path form:\n\n```elixir\nmy_struct.foo.bar.baz\n#=> \"my value\"\n\nmy_struct[:foo][:bar][:baz]\n#=>  ** (UndefinedFunctionError) undefined function MyStruct.fetch/2\n```\n\nI hope this helps you deal with deeply nested maps, lists, and structs!\n\n[map]: http://elixir-lang.org/getting-started/keywords-and-maps.html\n[merge]: http://elixir-lang.org/docs/stable/elixir/Map.html#merge/2\n[put_in_3]: http://elixir-lang.org/docs/stable/elixir/Kernel.html#put_in/3\n[put_in_2]: http://elixir-lang.org/docs/stable/elixir/Kernel.html#put_in/2\n[put_in_2_macro]: https://github.com/elixir-lang/elixir/blob/v1.2.2/lib/elixir/lib/kernel.ex#L1831-L1839\n[access]: http://elixir-lang.org/docs/stable/elixir/Access.html\n[update_in_3]: http://elixir-lang.org/docs/stable/elixir/Kernel.html#update_in/3\n[field-lookup]: https://github.com/elixir-lang/elixir/blob/v1.2.2/lib/elixir/lib/access.ex#L50\n"},{"title":"How to contribute to Elixir","tags":["elixir"],"summary":null,"legacy":false,"id":"2016/02/02/how-to-contribute-to-elixir","employee":"Brian Cardarella","date":"2016-02-02T00:00:00","body":"\nI just got my [first commit accepted into the Elixir programming\nlanguage][first-commit]. Here are some notes on how to build and test [Elixir][elixir-website] on your\nmachine to help you make your own contributions.\n\n### Up and running\n\nAfter you've [cloned Elixir][elixir-github] you'll need to ensure that the state of your\ncopy builds properly and all the tests pass. To do this you'll need to\nuse [Make][make]. Simply run the following:\n\n```console\n$ make compile\n$ make test\n```\n\nHopefully the purpose of each command should be obvious. The entire test suite for\nthe language doesn't take too long to complete. Once all the tests pass\nyou can start. In the event that any of the two steps fail I would\nrecommend getting help in the `#elixir-lang` IRC channel on Freenode.\n\n### You've made your changes\n\nAssuming you've made your changes you'll need to test them. For any\nchanges that you've made to the language you'll need to recompile. You\ncan re-run the commands from above in the root directory of the project.\n\nElixir itself is made up of several packages. They're all listed in the\n`lib/` directory:\n\n```\nlib\n├── eex\n├── elixir\n├── ex_unit\n├── iex\n├── logger\n└── mix\n```\n\nDepending upon the package you are making changes to you may not want to\nrun the entire test suite. For example, to compile and run the tests for\n`ex_unit` only you can run:\n\n```console\n$ make test_ex_unit\n```\n\n[Check out the `Makefile` in Elixir for the available commands for testing \nindividual packages][make-test-commands].\n\nEven this can be tedious. If you really want to move fast you can target\na specific test file to run. Let's say you want to target the test file\nfor `ExUnit.Case`:\n\n```console\n$ make compile\n$ bin/elixir -r lib/ex_unit/test/test_helper.exs lib/ex_unit/test/ex_unit/case_test.exs\n```\n\nThe second command will use the custom build of Elixir that is the\nresult from `make compile`. The option `-r` will run the specific\nfile at that path.\n\nThis should get you into a faster feed-back loop to ensure that your\ntests for the changes you've made are passing.\n\n### Real-world testing\n\nIt could be that you are making a commit to scratch an itch in an app\nyou're building. In that event it would be great to ensure that the\nchanges you're making in the language actually work for you. We can\neasily test this by using the custom build of Elxiir with your\napplication.\n\nIn a Linux-based shell you can prepend the `bin/` path of the custom\nElixir build onto `$PATH` so it takes precedence:\n\n```console\n$ export PATH=/home/yourname/elixir/bin:$PATH\n```\n\nReplace `/home/yourname/elixir/bin` with whatever the path is for your\nmachine. If you really want to live on the edge you can add this to your\n[Bash][bash] or [Zsh][zsh] config, but I wouldn't recommend it.\n\nYou should confirm that your custom build is the one found. You can do\nthis by running: `which elixir` and `which mix`. If it doesn't return\nthe path for the custom build you should revisit the steps above and see\nwhy not.\n\nYou will likely need to recompile the dependencies for the custom build\nof Elixir:\n\n```console\n$ mix do deps.clean, deps.get, deps.install\n```\n\nAssume your application is using the changes you've made just run `mix\ntest` as normal to confirm that your changes work.\n\n### Documentation\n\nYou may have to document your changes. [Please see the Elixir guide on\nwriting good documentation][doc-guide].\n\n### Bad builds\n\nSometimes there may be a bad build during compilation. In this event you\ncan just run:\n\n```console\n$ make clean\n```\n\nThis will reset the project to a clean state. You can now try to\nre-compile.\n\n### Finish up\n\nI think you'll be surprised how easy and straight forward it is to\ncontribute back to Elixir. Hopefully these tips have made it a bit\nsmoother for you.\n\n[first-commit]: https://github.com/elixir-lang/elixir/pull/4233\n[elixir-website]: http://elixir-lang.org\n[elixir-github]: https://github.com/elixir-lang/elixir\n[make]: https://en.wikipedia.org/wiki/Make_(software)\n[bash]: https://en.wikipedia.org/wiki/Bash_(Unix_shell)\n[zsh]: http://www.zsh.org/\n[doc-guide]: http://elixir-lang.org/docs/master/elixir/writing-documentation.html\n[make-test-commands]: https://github.com/elixir-lang/elixir/blob/d9748b4e3139fbac98119aa8ee697af06c40b0ec/Makefile#L206\n"},{"title":"Setting up revision previews with Ember CLI Deploy","tags":["ember"],"summary":null,"legacy":false,"id":"2016/02/03/ember-cli-deploy-revision-previews","employee":"Marten Schilstra","date":"2016-02-03T00:00:00","body":"\n\nI recently set up previewing revisions with [Ember CLI Deploy][ember-cli-deploy].\nThere is no single best practice on how to do this yet, but here is how I did\nit.\n\n_This post assumes you use the\n[ember-cli-deploy-revision-data][ember-cli-deploy-revision-data] plugin in\nconjunction with an index adapter ([Redis][redis-index], [S3][s3-index],\n[SSH][ssh-index]) for Ember CLI Deploy._\n\n### About revisions\n\nEverytime you deploy `index.html` with Ember CLI deploy, it gets tagged with a\nrevision. By default this is an MD5 hash of the `index.html` file itself, but it\ncan also be a Git commit hash, or the version from your `package.json`.\n\nHow exactly `index.html` gets tagged depends on the index adapter. For example:\nusing the S3 adapter, the tag will be appended to the filename; using Redis, the\ntag will be part of the key where the file is stored.\n\nOnce you have one or more revisions deployed to the target server, you can\nactivate one of the revisions, which will be the default `index.html`\nthe users of your app will see.\n\n### Viewing revisions without having to activate them\n\nIt would be very nice to be able preview a revision (maybe QA test) on the\nproduction server, before you activate it and release it to the public. My idea\nwas to be able to do this by visiting\n`https://example.com/rev-a76df687f97e9ab8ca82d1a1/`.\n\nIt is really simple to set up your webserver to do this, so I won't go into\nthat, but there is a caveat on the Ember side of this. If you navigate to the\nrevision, the router will throw an error: `The route rev-a76df687f97e9ab8ca82d1a1/\nwas not found`.\n\nWhat is happening? The `Ember.Router` is not intelligent enough to know that you\nmeant to route after the `/rev-a76df687f97e9ab8ca82d1a1/` portion of the path.\n\nYou have to explicitly configure the router to route on a path other than `/`.\n\n### Fixing the router\n\nSetting up the router to work from a base path should be fairly straightforward,\nfor example to route on `/awesome-app/` you can set the\n[`rootUrl`][ember-docs-root-url]:\n\n```javascript\nimport Ember from 'ember';\n\nconst { Router } = Ember;\n\nconst Router = Router.extend({\n  location: 'auto',\n  rootURL: `/awesome-app/`\n});\n```\n\nTo route revisions is a little more complex, as you can't just type in a simple\nstring and be done with it. To be able to handle revisions, you can make the\n`rootURL` a computed property instead:\n\n```javascript\nimport Ember from 'ember';\n\nconst {\n  Router,\n  computed,\n  isPresent\n} = Ember;\n\nconst Router = Router.extend({\n  location: 'auto',\n\n  rootURL: computed(() => {\n    let path = window.location.pathname;\n\n    // Looks for /rev-a76df687f97e9ab8ca82d1a1/ at the beginning of the path\n    // Tweak this regex to match your own style of revisions.\n    let revisionMatch = new RegExp('^/(rev-[^/]+)').exec(path);\n\n    // If there was a revision at the beginning of the path\n    // return it as rootURL\n    if (revisionMatch && isPresent(revisionMatch[1])) {\n      return `/${revisionMatch[1]}/`;\n    } else {\n      return '/';\n    }\n  })\n});\n```\n\nWhen the application loads, the `rootURL` computed property will be executed once.\nIf the `rev-*` part is in the path it will return that as the `rootURL`, else it\nwill just return the default `/`.\n\n### Caveat: baseURL is set in ENV\n\nBy default the `baseURL` property in your `config/environment.js` is `/` and\ndoes not interfere with the `rootURL` in the router, but when it is something\nlike `/awesome-app`, then you will run into trouble.\n\nIt is best to not use `baseURL` in conjunction with `rootURL`. If you have a base\npath the app is served from, I would recommend you add it to the `rootURL`.\n\nHere is how I solved it:\n\n```javascript\nimport Ember from 'ember';\nimport config from './config/environment';\n\nconst {\n  Router,\n  computed,\n  isPresent\n} = Ember;\n\nconst Router = Router.extend({\n  location: 'auto',\n\n  rootURL: computed(() => {\n    let baseRootURL = config.baseRootURL || ''; // NOTE: This is not baseURL\n    let path = window.location.pathname;\n\n    let revisionMatch = new RegExp(`^${baseRootURL}/(rev-[^/])`).exec(path);\n\n    if (revisionMatch && isPresent(revisionMatch[1])) {\n      return `${baseRootURL}/${revisionMatch[1]}/`;\n    } else {\n      return `${baseRootURL}/';\n    }\n  })\n});\n```\n\n### So now you know\n\nIf you have a backend that serves revisions on a scheme like\n`/rev-a76df687f97e9ab8ca82d1a1/`, then this is one way to set up your Ember app\nto work with that scheme. Don't forget to check your app's `baseUrl`.\n\nIf you figured out another way to set up something like this, then please share\nit!\n\n[ember-cli-deploy]: http://ember-cli.com/ember-cli-deploy/\n[ember-cli-deploy-revision-data]: https://github.com/ember-cli-deploy/ember-cli-deploy-revision-data\n[redis-index]: https://github.com/ember-cli-deploy/ember-cli-deploy-redis\n[s3-index]: https://github.com/ember-cli-deploy/ember-cli-deploy-s3-index\n[ssh-index]: https://github.com/green-arrow/ember-cli-deploy-ssh-index#readmehttps://github.com/green-arrow/ember-cli-deploy-ssh-index#readme\n[ember-docs-root-url]: http://emberjs.com/api/classes/Ember.Router.html#property_rootURL\n"},{"title":"Ember Best Practices: Brace Expansion for Computed Properties","tags":["ember","javascript","best practices"],"summary":"DRYing up computed properties since 2014","legacy":false,"id":"2016/02/05/ember-practices-property-brace-expansion","employee":"Doug Yun","date":"2016-02-05T00:00:00","body":"\n\nAs an Ember developer, I can count on fresh features popping up almost every\nother month within a new release. There are numerous benefits to this, which\ncertainly are out of the scope of this blog post. However, I will briefly\ncover one particular gem from 2014 - an oldie, but goodie - of a feature.\n\nHow many times have you written something like this?\n\n```js\nimport Ember from 'ember';\n\nconst {\n  Component,\n  computed,\n  get\n} = Ember;\n\nexport default Component.extend({\n  farmSentence: computed('animal.species', 'animal.noise', 'farmer.name', 'farmer.location', {\n    get() {\n      let animal = get(this, 'animal');\n      let farmer = get(this, 'farmer');\n\n      return `At ${get(farmer, 'location')}, Farmer ${get(farmer, 'name')} owns a ${get(animal, 'species')} that says \"${get(animal, 'noise')}!\"`;\n    }\n  })\n});\n```\n\nNotice how we consume `animal.species`, `animal.noise`, `farmer.name`, and `farmer.location`?\nThere are a lot of *shared* dependent keys. Gross.\n\n## Computed Property Brace Expansion\n\nWell, [back in 2014, \"brace expansion\" was introduced][brace expansion].\nLet's use this feature and tidy up our component!\n\n```js\nimport Ember from 'ember';\n\nconst {\n  Component,\n  computed,\n  get\n} = Ember;\n\nexport default Component.extend({\n  farmSentence: computed('animal.{species,noise}', 'farmer.{name,location}', {\n    get() {\n      let animal = get(this, 'animal');\n      let farmer = get(this, 'farmer');\n\n      return `At ${get(farmer, 'location')}, Farmer ${get(farmer, 'name')} owns a ${get(animal, 'species')} that says \"${get(animal, 'noise')}!\"`;\n    }\n  })\n});\n```\n\n## Why use Brace Expansion?\n\nIsn't that much nicer? I prefer using brace expansion, because it **organizes** the dependent keys and\nmakes it **easier to read**. Goodness forbid a coworker of yours writes dependent keys without ordering\nthem alphabetically:\n\n```js\n...\n\n// This ordering isn't ideal\nfarmSentence: computed('animal.noise', 'farmer.name', 'animal.species', 'farmer.location', {\n  get() {\n    let animal = get(this, 'animal');\n    let farmer = get(this, 'farmer');\n\n    return `At ${get(farmer, 'location')}, Farmer ${get(farmer, 'name')} owns a ${get(animal, 'species')} that says \"${get(animal, 'noise')}!\"`;\n  }\n})\n\n...\n```\n\nTo those new to Ember, hope you learned something new!\nAnd to those experienced in Ember, hope this was a refresher!\nAnd to my coworkers that don't use brace expansions, shame on you!\n\nThanks for reading.\n\n[brace expansion]: http://emberjs.com/blog/2014/02/12/ember-1-4-0-and-ember-1-5-0-beta-released.html#toc_property-brace-expansion)\n"},{"title":"Pens, Paper, Scissors","tags":["design","design process"],"summary":"Reintroducing materials into a web design process.","legacy":false,"illustration_alt":"Pens","illustration":"https://i.imgur.com/hwHiUis.jpg","id":"2016/02/05/pens-paper-scissors","employee":"Patrick Branigan","date":"2016-02-05T00:00:00","body":"\n\nI was recently involved in a staff augmentation project with one other DockYarder. The project involved us working at\nour client’s office for approximately three months. Aside from a shift in daily culture and a completely different perspective on the project’s challenges, I did discover a couple very, very simple techniques\nI’ll be exploring further in the future.\n\nWhile my fellow DockYarder was tasked with user interface work for an existing application build, my task was to research,\nconceptualize, and design a full fledged careers section of a website. This website is the marketing tool for a greater\nweb service. It’s aimed at new users and represents the breadth of what the service and its suite of tools and programs\nhas to offer. What it failed to provide was a way for the client to recruit and entice prospective employees, which they would need in order to fill an immense amount of positions that were opening up in multiple locations.\n\nA lot of my time on this project was spent in research and brainstorming concepts, which meant a lot of data harvesting\nand sketching. The results, prior to executing visual design, came in the form of Content Frames (a term I'll explain in a later post). Using qualitative and quantitative research, we were able to quickly determine a viable layout\nand hierarchy option for the careers section. We did this without any content having been developed by the client. In fact,\nthere was zero content at this point! Backwards sounding? Perhaps to some. That’s not what I’m going to discuss though.\nInstead I want to note just two simple techniques that made a strong impact on how the team communicated, and eventually on\nhow we were able to begin prototyping without content.\n\n## Sketch with ink\n\nThe first technique is to use ink when sketching. I use a set of Micron pens for various design tasks away from the screen. I’ve recently begun sketching all of my lower fidelity wireframes with them. Why? Because drawing out my wireframes is a therapeutic process. It allows me time to further think about what I’m executing in the moment.\n\n![Pens](https://i.imgur.com/hwHiUis.jpg)\n\nThe varying weights also allow me to quickly suggest element context (buttons are a thicker 0.8mm line while images are 0.5 for example). Also because ink is permanent. This challenges my mind to make more calculated decisions in what I’m sketching and it disallows my cautious self to throw away or erase ideas that I put on paper. You never know how valuable a seemingly wrong idea might be later on.\n\n## Construct with paper, scissors, and tape\n\nThe second technique is utilizing the sketches to determine the content flow.\n\n![Dot grid paper](https://i.imgur.com/KZDG5Qu.jpg)\n\nInstead of limiting my sketches to the size of the dot grid paper (or any boundary for that matter) I sketched the page as\nI saw it in its full length, running on to a new piece of paper when needed. At the end I simply taped them together. The\nresults were full page sketches that allowed the client to see the content holistically and sequentially, rather than parsed in a series of sketchbook pages, or having to continuously scroll multiple artboards on screen.\n\n![Scissors](https://i.imgur.com/Zz6oaHw.jpg)\n\nIf you have multiple concept sketches for the page, like I did, use scissors to cut and paste your concepts’ components together. Do this with the client. In fact, have the client do the cutting and taping. It emphasizes involvement, provides the client a sense of authority, and allows for the entire team to immediately rearrange, reorganize or compile their feedback and ideas by cutting and retaping components to one another. After just one meeting, we were left with a new page concept. It was derived from, and composed of, components from two of the four concept sketches we started with.\n\n![Tape](https://i.imgur.com/StONm4D.jpg)\n\nThere’s something refreshing about incorporating materials into an approach. Everyone felt more connected, more involved,\nand frankly more confident with the work as we progressed. Granted the circumstances and constraints of my particular\nsituation allowed for me to experiment with my process in this way. But I’d argue it’s always worth considering alternative\nroutes in the creative process when the situation allows for it.\n"},{"title":"How to have a side project","tags":["art","design","creativity","culture","inspiration","team"],"summary":"Focus on one project at a time. Bonus: see what DockYarders do outside work!","legacy":false,"illustration_alt":"watercolor sketch with abstract shapes","illustration":"https://i.imgur.com/5Tw9qYB.jpg","id":"2016/02/10/how-to-have-a-side-project","employee":"Maria Matveeva","date":"2016-02-10T00:00:00","body":"\n\nPretty much every designer I know has a side project (or five). They are often in a field related to design, but do not replicate exactly what they do at their full time job. Side projects and hobbies are great for relaxing, while adding extra skills or addressing a passion that does not yet have a place in one's career.\n\nHere’s what I learned about what works well, and what can be problematic for side projects I’ve had over the years. Hope it helps you in your own creative pursuit!\n\n![watercolor sketch with abstract shapes](https://i.imgur.com/5Tw9qYB.jpg)\n*My watercolor sketch to study shapes and colors from Wassily Kandinsky*\n\n\n## 1: Different enough\nTo let your brain rest and relax, a side project should be different enough from what you do during the day. When a day’s work is mostly at the computer, I feel a need to switch to analog afterwards, and still have lots of energy. If this is a [design sprint](https://dockyard.com/design-sprints) week, and I’m on my feet most of the day, sketching or writing on the whiteboard - then curling up on my couch with a laptop feels like a welcome break. Essentially, I have different types of energy I could use up during the day, and switching between activities allows me to get more done.\n\nAnother principle to keep in mind is to avoid conflicting interests between work and personal projects. When they are different enough, there is a clear separation between the two. I won’t resent filling my week-ends with the personal project, because it does not feel like work. It feels like play!\n\nSports or dance make a great hobby & side project. I used to spend hours each week rock climbing, then switched to social dancing a few years later. It may seem like there’s no overlap in the skills - but the ability to clearly lead and follow (typical Tango dance roles) within a larger group setting is a great communication skill for a team of designers as well. It also helped me learn my limitations. When you’re several rope-lengths up a cliff and need to tell something to other climbers on the team without seeing them, my voice never seemed loud enough to get across. Since then, I always think of a backup communication method. Do two tugs on the rope mean “go”? You only know if you’ve arranged it ahead of time.\n\n\n## 2: Similar enough\n\nWhen work and play are in related disciplines, you get a lot of benefit in combining the two. For example, my photography hobby provided a ton of material for my design work - material that I owned and could art-direct myself. Hours of practicing lighting and portrait photography on the weekend allowed me to quickly organize consistent and flattering staff photos at work. Photography wasn’t exactly in my job description, but it gave me better material to design the website.\n\n![a friendly goat](https://i.imgur.com/xekWIad.jpg)\n*Photography is a hobby that often encourages me to get, and stay, outside*!\n\nAn active pursuit of two related disciplines can **act as a multiplier**, where they feed off each other. Hobbies can “feed” on my primary work as well: I usually take time to design a logo and a few other pieces for each side project.\n\n\n## 3: Frustrated? Pick just one\n\nOne problem with side projects is that they often compete for time with chores, rest and relaxation. And if I have too many side projects at the same time, the apparent lack of progress can be frustrating. At some point I remember I was doing a half-day photo shoot every other weekend (if you do photography, you’ll know how much extra time it takes to sort and process the raw photos), had a pretty involved sewing project going (which takes both time and physical space), was learning French twice a week, and attempted to do a daily watercolor illustration. Oh, and a full time job with a lengthy commute.\n\n![sewing project](https://i.imgur.com/aReedp3.jpg)\n*I miss sewing projects, but stopped doing them for the time being so I can focus on one thing at a time, with higher quality and time investment*.\n\nI would write an overly optimistic to-do list for my week-end, but only get about halfway through it. I was probably less effective at my day job than I could have been, due to lack of sleep. My side projects felt stagnant because there wasn’t enough happening in each one from week to week. With these projects, the end goal was to produce a portfolio of creative work to apply to grad school. But I felt trapped because even with hard work, I wasn’t making enough progress.\n\nI eventually climbed out of this. I negotiated Fridays off at work, trained the designer who would replace me, put together a portfolio and moved to Canada for a year to study. The experience left me with a better understanding of how important focus really is.\n\n\n## Focus\n\nI now know I can’t get good results from trying to juggle several side projects at a time. But deciding to do just one thing can feel scary. I often wonder if I'll ever get to work on my other projects. But it’s the only sure way to make progress.\n\n![Color blocks and sticky notes](https://i.imgur.com/kIUHUpm.jpg)\n*Johannes Itten’s classic Elements of Color (the book belongs to both ym art life and my design life) and some sticky notes we use for UX design. The colors match perfectly.*\n\nIn 2015, I decided to focus on one side project: my exploration of the [overlap between design and modern art](http://www.designartpractice.com/). I put away my sewing machines, and set my Etsy shop in holiday mode. I even stopped nagging myself to keep practicing with watercolors or hand lettering. I now have a more realistic to-do list, and can feel “done” and accomplished with the weekly illustrated articles that I plan to write for a year.\nI’ll be honest: I miss the other side projects I had put on hold. But I'm OK with not doing them for a while so that once I get to them, I’ll be able to make progress and commit to giving those other passions the focused time they deserve.\n\n\n## More examples!\n\nI went around and asked my intimidatingly talented colleagues to share examples of what they’re up to. Here they go!\n\n\n## Estelle\n\n![pencil portrait by Estelle](https://i.imgur.com/Bqyq3ws.jpg)\n*Pencil Portrait from my very limited [portfolio](https://www.behance.net/edeblois)*\n\n**What do you do outside work?**\nI tend to go back to the things I enjoyed doing before discovering the joy of programming. I have a variety of hobbies that I try to juggle as time permits, ranging from drawing or painting, practicing photography (I took an online photography course at the Photography Institute a few years ago and try to keep up), practicing piano (I’ve been taking weekly piano lessons for the past six years), and just gaming.\n\n**How do you feel it feeds into your work, if at all**?\nI don’t particularly feel that any of those activities feed into my work at all, but it’s a nice distraction from my day-to-day work.\n\n\n## Brian\n\n![Elixir](https://i.imgur.com/PCu2yYF.jpg)\n*[Elixir Language](http://elixir-lang.org/) logo (image via [Bruna Kochi](http://brunakochi.com/projects/elixir.html))*\n\nMy after-hours time is spent on open source software. Right now I am working on Elixir tools that will be used to support our future application development efforts.\n\n\n## Steve\n\n![Black and white photo of hands](https://i.imgur.com/Smaad8H.jpg)\n*A self portrait done on 35mm black and white film*.\n\n![abstract photo of ice](https://i.imgur.com/odVVRMv.jpg)\n*This is a picture I took of ice. Its appearance is more smokey than usual due to melting and refreezing, and because of the size of the river I took this in, I was able to capture somewhere around 15 original compositions*.\n\n![Musical notation](https://i.imgur.com/BjGN6fP.jpg)\nThis is purely representational for me of a possible musical composition. As I do not know how to write and read music, this serves as a visual for my work. Memory alone isn’t enough.\n\n\n**What do you do outside work**?\nI compose and play music on various instruments. I also do photography.\n\n**How do you feel it feeds into your work, if at all**?\nI think in any medium it is really important to let it express itself as much as I can allow it. I do not attempt to make them feed into each other. However, as I dive deeper into the creative process for each there is something, some way of thinking or structure, that I’m able to carry back. For instance, I attempted to create 20 original songs in 12 hours, which sounds absolutely insane, but it is truly possible depending on how ‘big picture’ you’re willing to remain on the compositions. It really engrains the concept of taking broad strokes more seriously before getting caught in the details.\n\n\n## Amanda\n\n![Portrait of a girl with eyes closed](https://i.imgur.com/5DITjtO.jpg)\n*Oil and graphite on panel (18” x 24”)*\n\n**What do you do outside work**?\nPrior to design and web development, my main passion was painting. During undergrad, I spent most of my time in the studio oil painting and I still do it occasionally. This painting was for the Fountain Art Fair in Chicago a couple years ago.\n\n**How do you feel it feeds into your work, if at all**?\nIn UX development, I work closely with designers. Understanding basic design principles is useful. Many practices are transferrable like balance, contrast, composition and attention to detail. More abstractly, coding and painting come together quite similarly to me. Individual brush strokes or pencil lines form a hand or a pillow. In code combinations of letters and numbers make up shapes and components of a website.\n\n\n\n## Jon\n\n![Mountain biker in the woods](https://i.imgur.com/QTHMjM5.jpg)\n*2015 Pukwudgie Time Trial - Assonet, MA*\n\n**What do you do outside work**?\nCompetitive mountain biking\n\n**How do you feel it feeds into your work, if at all**?\nOver the years I have participated in many team sports where the performance of the collective group dictates outcome of the competition.  Competitive mountain biking has taken out the variable of team and placed full responsibility on me.  Any success I have realized in this endeavor (which has been minimal to date) is a fringe benefit of deliberate training, sacrifice, failure and exhibition of mental toughness.  \n\nI love the fact teams are a significant part of my professional life - It is the only way I would want it to be.   However, outside of work I have chosen something that is “Different Enough” to keep my other lesser used mental and physical muscles engaged.\n\n\n## Lauren 🐷 paints! \n\n![Character sketch](https://i.imgur.com/2Scgp0F.jpg)\n![Character sketch](https://i.imgur.com/6jhegwr.jpg)\n![Character sketch](https://i.imgur.com/6e2Nq1G.jpg)\n\n*[Moar here](https://i.imgur.com/a/RamRz#0)*\n\n**What do you do outside work**?\nDraw / paint characters and landscapes (usually from imagination, but sometimes from real life), but I haven’t done it in a while and I miss it a lot. I want to buy a Wacom tablet again as my old one was left (sadly) in Australia.\n\n**How do you feel it feeds into your work, if at all**?\nArt has taught me how to *see* things, and my approach to painting has always been about improvisation. I usually work in digital, and I generally splash blocks of color and refine silhouettes that form into something coherent. I like to think of them as happy accidents that I can then go on and transform into something interesting.\n\nOne of the best lessons I’ve taken away from art that translates well into programming is to pause occasionally, take a step back and evaluate the bigger picture before getting lost in the details. Composition is important, as is other elements like color, lighting, and brush stroke economy. Similarly, composing applications in the form of their architecture is also a process that requires much thought before a single line of code goes into the project.\n\n\n## Cory\n\n![Snowboarder sitting down on the slope](https://i.imgur.com/Wmq5T0U.jpg)\n*Tremblant, Canada over winter break. Went for a week and stayed at a hostel and met amazing people*.\n\n![snowboard view](https://i.imgur.com/CpwlIgn.jpg)\n*Weekend trip up to Loon mountain for the first time. Big fan of exploring new mountains*.\n\n**What do you do outside work**?\nEvery year I attempt to plan out my winter snowboarding trips and look for new mountains I have not explored yet. I try to do at least one multi-day solo trip every year to absorb the entire experience differently than going with friends. Snowboarding for me is about connecting to nature and getting an adrenaline rush while pushing my limits as a snowboarder. The best day on a mountain for me is having no clouds in the sky, great music while riding, fluffy powder and empty slopes. Searching for that “unicorn” type of day is what keeps the excitement of going snowboarding fresh.\n\n**How do you feel it feeds into your work, if at all**?\nI feel the constant exploration and creativity of snowboarding directly relates to UXD at DockYard. I am constantly trying to find new ways to build things and you have to be creative/think outside the box sometimes to come up with the best solution. Not only thinking outside the box but stepping outside your comfort zone is something I do with snowboarding and trying a new CSS technique. Taking a chance on something you are not sure you can do and just going for it has been something that has helped me as a developer and a snowboarder.\n\n\n## Marten\n\n![sweet potato appetizer](https://i.imgur.com/tcv5SiN.jpg)\n*Appetizer I made for Christmas dinner*.\n\n**What do you do outside work**?\nIn the weekends I like to go nuts on cooking. Weekdays I keep it simple.\n\nI also spend a lot of time in a local bar that has many different craft beers + drink craft beer at home.\n\n\n## Marin\n\nHandmade bags:\n![side project example](https://i.imgur.com/ZXHGU50.jpg)\n*(See [more bag pics](https://i.imgur.com/a/bTGuK))*\n\nSculpture:\n![sculpture outdoors](https://i.imgur.com/1Pl6uad.jpg)\n![sculpture indoors](https://i.imgur.com/fxUwznk.jpg)\n\nSketches:\n![sketch](https://i.imgur.com/wKMw5r1.jpg)\n![sketch](https://i.imgur.com/8rOqtyT.jpg)\n![sketch](https://i.imgur.com/cfnq4Of.jpg)\n\n**What do you do outside work**?\nI make laptop cases, pencil cases and general purpose bags (pouches?) out of scrap fabric that I find or have. I also enjoy making sculptures out of various media, including metal, wire, or anything I can find (one time I used hundreds of marbles for a piece). And I like sketching people/faces using charcoal. Unfortunately, I don’t have access to a big studio and lots of materials, so recently, I mostly stick with the bag making.\n\n**How do you feel it feeds into your work, if at all**?\nIn one sense I don’t feel like my hobbies feed into my work very much. Which is nice because it's a break from my day-to-day; getting to use my hands, and unwind. On the other hand, programming involves creativity and thinking outside of the box just like art.\n\n\n## Romina\n\n![runner](https://i.imgur.com/5gJeZb8.jpg)\n\n**What do you do outside work**?\nI enjoy cooking most nights of the week, I game, and I exercise. Fitness is my main focus, however.\nYear-round (except winter), I run outside, otherwise I lean to miscellaneous fitness classes and gym equipment. I love racing and the competitive aspect of it; I’ve been running competitively since I was 11 years old. I strive to beat my previous times in races that I have previously ran. I just completed my first half marathon a few months back, which was a fun challenge. I love and hate the feeling when you’re about to start a race!\n\n**How do you feel it feeds into your work, if at all**?\nI don’t feel like my hobbies feed directly into my work, but they do play a role in my overall well-being since they serve as relaxation and a way to unwind from work and things life throws at me.\n\n\n## Tim\n\nMandala Project\n\n![Mandala art](https://i.imgur.com/LXtShBx.jpg)\n*After sketching, I arrived at the above digital renderings*.\n\n![Mandala on the side of a building](https://i.imgur.com/hVzc2u6.jpg)\n*The final result*.\n\n**What do you do outside work**?\nThe images above are from a quick side project I worked on where I was commissioned to create and put up a mandala - a spiritual symbol representing the universe and often geometric in design. \n\n**How do you feel it feeds into your work, if at all**?\nThis was a huge learning process for me. Wheatpaste, a technique for applying artwork often associated to street art, was something I had never before attempted. This project allowed me to hone in on my digital design capabilities as well as practice a craft that requires more of a hands-on approach.\n\n\n## Patrick\n\n![Beer photo shoot](https://i.imgur.com/NsN6tcv.jpg)\n*2015 pumpkin beer bottle shoot light boxing*.\n\n![Beer](https://i.imgur.com/SMNONrT.jpg)\n*Pumpkin beer and light photo experimentation*.\n\n![Beer](https://i.imgur.com/yUKe8tt.jpg)\n*Preliminary top downs of pumpkin beer pours for 2016 pumpkin beer photo mosaic*.\n\nOutside of work, I spend time tasting, photographing, and reviewing craft beer, particularly pumpkin beer. I run a pumpkin beer review site at [bumpinpumpkinbeer.com](http://www.bumpinpumpkinbeer.com/) where every year I taste close to 100 of the previous years’ best pumpkin beers. I curate photography experiments by doing so, as well as build archives of data on ingredient, recipe, and batch alterations, transitions, and successes which I enjoy visualizing. \n\n![beer](https://i.imgur.com/bf3f6un.jpg)\n![beer](https://i.imgur.com/ncFBGkd.jpg)\n*Logo and color scheme for the Bumpin’ Pumpkin Beer review site*\n\nI think this hobby has fed into my design work in that it has inspired me to pursue different avenues in design, and gain greater interest into parallel areas. For one, it’s constantly forcing me to write (reviewing means writing of course!) which in turn has made me feel more comfortable writing about design. It also has inspired me to pursue photography (out of need originally) and hand lettering (which is prominent in craft beer labeling and branding). It’s constantly inspired me to pay closer attention to the immense complexity that goes into creating something seemingly so simple and beautiful. The grandeur of the craft, from years of testing recipes to the intricate labor of its packaging design, never ceases to impress me, especially since it’s a commodity that’s taken for granted so often.\n\n"},{"title":"The Self-reflecting Designer","tags":["design","design process"],"summary":"Using self-reflection as a means to build character and confidence as a designer.","legacy":false,"id":"2016/02/10/the-self-reflecting-designer","employee":"Patrick Branigan","date":"2016-02-10T00:00:00","body":"\n\nMeditation or serious thought about one’s character, actions, and motives. This is the definition of self-reflection. \n\nSelf-reflection is something a lot of designers don’t consciously do enough of. Yet self-reflection is something designers \ntake part in daily on behalf of other people. We are busy addressing other people’s needs, attempting to produce through \nother people’s’ eyes, and realizing other people’s thoughts and ideas, in pursuit of creating phenomenal products and \nservices. This is what we love to do and sometimes we happen to be really good at it. However, we’re also users of our \nown products. We are the result of our own processes. It’s worth spending time reflecting on our creative selves in order \nto continue to produce better for others. \n\nBeing a designer who’s able to self reflect comes with many benefits including the ability to be aware of progress, the \nability to identify challenges, and the ability to become more observant.\n\nIf designers take time to self reflect, they can intermittently check their work progress. Stepping back and looking at \nyour work as an observer, not a designer, will often reveal sequences, patterns, and trends in progress. Perhaps you notice \nit’s taking longer than expected to produce a piece of work. Why is that? Perhaps you notice the redesign you did last year \nis similar to the one you’ve just completed. Why is that? Perhaps you find that your process hasn’t evolved, yet your work \nhas. How is that possible? By surveying your work and reflecting upon it often, you’re likely to become more aware of \nprogress and more cognizant of growth. \n\nSelf-reflection can also help us in identifying challenging situations before they occur. We gain experience through the \nwork we’ve created, and often remember failures more than successes. Does this project meeting seem similar to a past \nconversation that went awry? What happened and how did you react? Perhaps a project brief scares you because it calls for \na similar result to a project that once fell through. How did you handle that? What part did you play in its failure? \nFailure is an important part of the evolution of a designer and therefore should be reflected on in an effort to inform \nfuture decision-making and reasoning.\n\nMost importantly, self-reflection allows us to become more observant of ourselves when in motion. Observation produces \ncuriosity and drives the imagination. However it also has the power to reveal negative tendencies and habits that have \nleaked into our processes over time. For example, you might find that you’re approaching the design of an application in \nthe same way you’re approaching the design of a website. Is it because they both call for the same approach? Or is it \nbecause you’re subconsciously relying on the same approach due to its success in previous work? Trends and comfort are two \naspects to design that, if you don’t take time to question, can hinder experimentation and progress. Being able to better \nobserve how you’re working while you’re working is beneficial to any designer.\n\nYou’d think self-reflection is easy, but it’s not. It’s hard to find the time. It’s hard to be honest with oneself. It’s \nhard to occasionally focus on yourself in an industry where you’re constantly focused on the actions and reactions of \nconsumers and peers.\n\nHere’s a couple ways to help begin injecting self-reflection into your life as a designer:\n\n## Meet People\nSurround yourself with friends and peers from other disciplines as often as you can. This will consistently provide \nperspective and insight into spaces and ideas you otherwise might be blind to in your everyday routine. It may allow for \ninsight into your work that you might not have otherwise experienced.\n\n## Write Often\nThe rhythm and pace of writing your thoughts out, regardless of what they are, may in fact help you retain and further \ndigest what you’re trying to express. It also allows you to reflect on your thoughts later on. \n\n## Extend Your Workspace\nWork in spaces that are foreign to your everyday routine. A new space may influence both your thought process and work ethic. \nThis presents the potential to make you question your routine and habits, therefore emphasizing self-reflection. Perhaps \nconsider a sabbatical even.\n\n## Keep Your Books\nIf you take physical notes or have sketchbooks, archive them somewhere. Store them in a manageable place, in an organized \nway that allows for you to reference content from specific years or projects past. This allows for very easy self-reflection \nthat will help you better understand what you have and have not accomplished in your journey as a creative. It’s motivating \nat the very least.\n\nI’ve found the most beneficial quality of self-reflection to be its ability to provide a valuable perspective on your \ncreative self. It forces consideration of what you’ve accomplished, as well as how far you’ve come. This helps in \nidentifying future pursuits.\n"},{"title":"Why DockYard transitioned to PostCSS","tags":["css","postcss"],"summary":"DockYard’s UX Development team thought process behind transitioning to PostCSS","legacy":false,"id":"2016/02/11/transition-to-postcss","employee":"Cory Tanner","date":"2016-02-11T00:00:00","body":"\nThe UX Development Team at DockYard takes pride in the ability to adapt to the latest tools that improve our workflow and benefit the team. We are always looking for tools that help with maintaining [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) CSS and quicken the development time of a project’s CSS. Because of [PostCSS’s](https://github.com/postcss/postcss) evolving plugin library, PostCSS is the latest addition to our development process.\n\nPostCSS is the new [big kid on the block](https://twitter.com/PostCSS/status/689886395763179522) and for good reason. It has provided developers with modularity and flexibility in CSS development. The ability to add and remove plugins that fit a project’s development process separates PostCSS from other tools that we used in the past.\n\n#What we used in the past\nIn the past we used Sass for all our projects and utilized the parts of Sass that we needed. Along with Sass we used a combination of [BEM](https://css-tricks.com/bem-101/) and [SMACSS](https://smacss.com/) for naming conventions and file structure based on DockYard’s styleguides.\n\nWhen we began using Autoprefixer, we had to lay it on top of Sass. This meant that we had to manage multiple tools, which increased setup time.\n\nWe were using the best available tools within our workflow that we could at the time. As you know, it feels like a new development tool comes out every month. Over time, we felt we could improve the environment of how we were writing our CSS.\n\n#Introducing PostCSS\nPostCSS provides us with the flexibility to adopt new plugins with ease and within one NPM package that we manage at DockYard.\n\nThe PostCSS plugins we choose focus on two things. DRY CSS that does not trip over itself on overlapping styles, and creating organized CSS modules that have class names that explain themselves based on DockYard’s [styleguides](https://github.com/DockYard/styleguides/tree/master/ux-dev).\n\nWe want developers who see our project tomorrow (or in two years) not to be confused by our naming conventions.\n\nWe use five PostCSS plugins in our projects. To get our projects up and running even easier, we combined them into a package called [narwin-pack](https://github.com/dockyard/narwin-pack).\n\n- [postcss-partial-import](https://github.com/jonathantneal/postcss-partial-import)\n- [postcss-nested](https://github.com/postcss/postcss-nested)\n- [postcss-custom-properties](https://github.com/postcss/postcss-custom-properties)\n- [postcss-svg-fragments](https://github.com/jonathantneal/postcss-svg-fragments)\n- [autoprefixer](https://github.com/postcss/autoprefixer)\n\nThose five plugins allow us to have modular CSS and use simple variables to speed up our development time. We are able to choose plugins that meet our development needs with no extra “bells and whistles”. What makes PostCSS so appealing is the ability to easily add and remove plugins from our custom made package.\n\nWe also have syntax rules that we follow while using these plugins - more on those in our next blog post going over each plugin in detail.\n"},{"title":"Ember Data: Worryless Model Defaults","tags":["ember","javascript","best practices"],"summary":"Take some precaution when setting object and array defaults on Ember Data models","legacy":false,"id":"2016/02/12/defaults-in-ember","employee":"Romina Vargas","date":"2016-02-12T00:00:00","body":"\n\nWhen working with Ember Data models, it’s common to want to set default values for\ncertain attributes. Setting a default value on a model is super easy and\nyou've probably done it countless times:\n\n```js\nimport Model from 'ember-data/model';\nimport attr from 'ember-data/attr';\n\nexport default Model.extend({\n  isHungry: attr('boolean', { defaultValue: true })\n});\n```\n\nThe above syntax works flawlessly for `Boolean`, `String`, and `Number`\ntypes. But what if you want to set defaults on an `Object` or an\n`Array` type?\n\nBefore answering that question, you should note that Ember Data does not\nhave out of the box support for `Object` and `Array` types. Well, kinda.\nIf you don't specify a type as the first argument to `DS.attr`, it just\nmeans the value for that attribute will be untouched rather than coerced\nto the matching JavaScript type. You can easily add a\n[transform][transforms] for a custom type. _Your transform should provide\nserialize and deserialize methods for proper processing_.\n\nNow to answer the above question, your first instinct might be to do the\nfollowing:\n\n```js\n// app/models/person.js\nimport Model from 'ember-data/model';\nimport attr from 'ember-data/attr';\n\nexport default Model.extend({\n  favoriteThings: attr('object', { defaultValue: {} })\n});\n```\n\nHere, every new record created with the `Person` model would be expected to have a\n`favoriteThings` value of `{}`, rather than `undefined`. Which is correct, but\nonly until you begin setting content on that object. An Ember Data model extends\nfrom `Ember.Object`, meaning that arrays and objects will be shared among\nall instances of that model. If you're not too familiar with that concept,\ncheck out this past Ember Best Practices [blog post][leakingstate] from Estelle!\n\nThe result from setting a model attribute default to an empty object:\n\n```js\nlet foo = this.store.createRecord('person');\nget(foo, 'favoriteThings'); // => {}\nset(foo, 'favoriteThings.food', 'pozole');\nget(foo, 'favoriteThings'); // => { food: 'pozole' }\n\nlet bar = this.store.createRecord('person');\nget(bar, 'favoriteThings'); // => { food: 'pozole' }\n```\n\nTrolling at its finest. Bar doesn't even know what \"pozole\" is. (By the way, if you've\nnever had Mexican [pozole][pozole], you're missing out!)\n\nThis quirky functionality isn't particular to Ember, however. It all stems from\nJavaScript itself; this also happens with POJOs:\n\n```js\nvar foo = { name: 'foo' };\nvar bar = foo;\n\nbar.name = 'bar';\n\nconsole.log(bar); // { name: 'bar' }\nconsole.log(foo); // { name: 'bar' }\n```\n\nLucky for us, Ember has made it easier to avoid this pitfall by deprecating the use of a\ncomplex object as a default value for a model property. If you try to set an attribute with\na default value of type `\"object\"`, you'll see a warning message: `Non primitive\ndefaultValues are deprecated because they are shared between all instances. If you would\nlike to use a complex object as a default value please provide a function that returns the\ncomplex object.` This is your cue to undo.\n\n## A better, and often forgotten option\n\nDon't fret, because this issue is just a simple fix away. `defaultValue` also accepts\na function. Hooray! Let's modify our code to work as we would expect.\n\n```js\n// app/models/person.js\n\nimport Model from 'ember-data/model';\nimport attr from 'ember-data/attr';\n\nexport default Model.extend({\n  favoriteThings: attr('object', { defaultValue: () => {} })\n});\n```\n\nThat's it! This will ensure that every `favoriteThings` attribute contains its own object\ninstance. Having the ability to pass in a function to `defaultValue` can also\nprove helpful if you would like to set custom defaults based on computed\nproperties, as well as other attributes of the same model.\n\nHope this served as a sweet reminder, or as something new that you can leverage\nin your projects from now on.\n\n[transforms]: https://guides.emberjs.com/v2.3.0/models/defining-models/#toc_transforms\n[leakingstate]: https://dockyard.com/blog/2015/09/18/ember-best-practices-avoid-leaking-state-into-factories\n[pozole]: https://en.wikipedia.org/wiki/Pozole\n"},{"title":"Ember Best Practices: Route Actions","tags":["ember","javascript","best practices"],"summary":"Bubble your closure actions to the route instead of the controller.","legacy":false,"illustration_alt":"controllers are dead","illustration":"https://i.imgur.com/TgmUDac.png","id":"2016/02/19/best-practices-route-actions","employee":"Lauren Tan","date":"2016-02-19T00:00:00","body":"\n\nIn my [previous post][previous-post], I wrote about moving singleton state in Controllers into Services that back components. This means being able to lighten the responsibility of Controllers in your application, and in some cases even remove them completely. However, a common pain point that remains for many is that it isn't really clear what _should_ live on a Controller, if anything. \n\n![controllers are dead](https://i.imgur.com/TgmUDac.png)\n\n[Locks][locks] has written an excellent [blog post][controllers-are-dead] on this topic. Unless you require query parameters, I'd say that you probably don't need one. That said, I wouldn't go out of your way to creatively avoid using Controllers, and would only remove them if it makes sense to do so.\n\n## Refactoring away from Controllers\n\nIf you do want to remove Controllers from your application given that they are going to be deprecated and removed in the future, great! \n\nOne of the benefits of removing Controllers is that it reduces the amount of \"glue code\" you need to write to connect your data (route) and its presentation (components). This means a simpler mental model, and reduces the amount of \"Ember\" you need to write. Instead, you can rely on regular JavaScript you're already familiar with to build your applications.\n\n## Sending closure actions directly to the route\n\n[Closure actions][closure-actions] are probably one of my favorite additions to Ember. Instead of casting string actions into the void and praying that something is listening, we can instead use an action like we would any other JavaScript function. This means that we can do useful things like curry arguments, utilize return values, and all of the other good stuff we expect from a regular JS function call. \n\nFor example, the following action is implicit in that you have no idea where the action actually lives – it could be on a component, controller or route.\n\n```hbs\n{{! where does `myAction` live? }}\n<button {{action \"myAction\"}}>Do it</button>\n```\n\nUnfortunately, Ember's in a bit of an awkward transition phase right now. Without bringing in an addon (or making a custom helper), it's not possible to use a closure action directly from the route – it would have to be defined on the Controller. \n\nIf you wanted to remove Controllers from your application, then you would have to resort to using string based actions instead of closure actions. This seems like a lose-lose situation, so I worked together with [rwjblue][rwjblue] to turn his [jsbin spike][jsbin] into a working addon.\n\n[`ember-route-action-helper`][ember-route-action-helper] lets you use closure actions defined on the route in your templates, meaning that many Controllers that only exist to implement actions can now be removed. You can install it today with:\n\n```\nember install ember-route-action-helper\n```\n\nAnd to use it, you can just use `route-action` in place of `action` inside of your route's template, like so:\n\n```hbs\n{{! foo/template.hbs }}\n{{foo-bar click=(route-action \"updateFoo\" \"Hello\" \"world\")}}\n```\n\nThis addon gives you all the goodness of closure actions, and is a great way of taking steps to future proof your Ember application. When Routable Components do land, and actions work correctly, then upgrading your app simply becomes a search and replace for `s/route-action/action`.\n\n## Power up your Handlebars templates with Helpers\n\nHelpers are a really nice way of extracting utility functions that you can use in your application. You can create class based Helpers, like `ember-route-action-helper`, or simple pure-function ones using [`Helper.helper`][helper-helper] like the one used in [`ember-toggle-helper`][ember-toggle-helper]. \n\nPure-function helpers are simple to grok and understand, so a look at addons like [`ember-truth-helpers`][ember-truth-helpers] is sufficient to understand them.\n\n`ember-route-action-helper` uses the class based implementation, which must define a `compute` method. This is then invoked every time one of the positional arguments to the helper changes. \n\nUnder the hood, the `route-action` helper retrieves the router from the application instance as a computed property, then locates the function reference from the currently active routes:\n\n```js\nfunction getRouteWithAction(router, actionName) {\n  let handler = emberArray(getRoutes(router)).find((route) => {\n    // find the route with the action\n  });\n\n  return { action, handler };\n}\n```\n\nThe action and the handler (route) is then returned, and wrapped with a closure action, which allows us to do all the nice stuff we expect from any other closure action in Ember. By returning a function in a helper, you can essentially \"decorate\" the action helper with some custom functionality.\n\n```js\ncompute([actionName, ...params]) {\n  let action = function(...invocationArgs) {\n    let args = params.concat(invocationArgs);\n    let { action, handler } = getRouteWithAction(router, actionName);\n\n    return run.join(handler, action, ...args);\n  };\n  \n  // return the closure action\n}\n```\n\nAnd because Helper classes are just like any other class in Ember, you can do the usual things like inject services, define computed properties, and so on. Here's a contrived example:\n\n```js\nimport Ember from 'ember';\n\nconst {\n  inject: { service },\n  Helper,\n  observer,\n  get\n} = Ember;\n\nexport default Helper.extend({\n  session: service('session'),\n\n  compute([shoe]) {\n    return parseInt(get(this, 'session.currentUser.shoeSize')) === parseInt(get(shoe, 'size'));\n  },\n\n  onShoeSizeChange: observer('session.currentUser.shoeSize', function() {\n    this.recompute();\n  })\n});\n```\n\nThe simplified Helper class was introduced in [`1.13`][helper-introduced], and are an excellent addition to Ember. In my next post, I'll talk a little bit more about them and how we can use them to replace certain CPs.\n\nUntil next time, thanks for reading!\n\n[closure-actions]: https://dockyard.com/blog/2015/10/29/ember-best-practice-stop-bubbling-and-use-closure-actions\n[controllers-are-dead]: https://locks.svbtle.com/controllers-are-dead-long-life-controllers\n[ember-route-action-helper]: https://github.com/dockyard/ember-route-action-helper\n[ember-toggle-helper]: https://github.com/poteto/ember-toggle-helper\n[ember-truth-helpers]: https://github.com/jmurphyau/ember-truth-helpers\n[helper-helper]: http://emberjs.com/api/classes/Ember.Helper.html#method_helper\n[helper-introduced]: http://emberjs.com/blog/2015/06/12/ember-1-13-0-released.html#toc_new-ember-js-helper-api\n[jsbin]: http://jsbin.com/jipani/edit?html,js,output\n[locks]: https://twitter.com/locks\n[previous-post]: https://dockyard.com/blog/2015/12/07/best-practices-service-backed-components\n[rwjblue]: https://twitter.com/rwjblue\n"},{"title":"Code Linting: An Inside Look","tags":["ember","javascript"],"summary":null,"legacy":false,"id":"2016/02/29/code-linting-inside-look","employee":"Estelle DeBlois","date":"2016-02-29T00:00:00","body":"\n\nA little while back, I wrote a [blog post][suave-up-your-code] introducing [`ember-suave`][ember-suave], an addon that we created at DockYard to help enforce a common code style across all of our projects. With the addon installed, any code that doesn't align with the established styleguide will cause the build to fail. During development, as files are modified, the linter will reprocess the changed files, displaying errors in the console right away.\n\nIf you've adopted `ember-suave` in your own projects, you may be content to find that things just work. But there's a lot of satisfaction to be had with understanding how the addon does what it does.\n\nLet's start at the core with JSCS.\n\n## JSCS\n\n[JSCS][jscs] is the wonderful library that uses a set of predefined code style rules to lint your code. It comes with a very simple API:\n\n```js\nlet Checker = require('jscs');\nlet checker = new Checker();\n\nchecker.registerDefaultRules();\n\nchecker.configure({\n  verbose: true, // shows rule name next to error messages\n  requireSpaceBeforeBinaryOperators: true,\n  requireSpaceAfterBinaryOperators: true\n});\n```\n\nAs this snippet shows, once you install [`jscs`][node-jscs] from NPM and create a new `Checker` instance, all you need to do is register the default JSCS rules and configure which ones to enable. You can now start linting your code:\n\n```js\nlet results = checker.checkString('let x = y+z;');\nlet errors = results.getErrorList().map((error) => {\n  return results.explainError(error);\n});\nconsole.log(errors.join('\\n'));\n```\n\nRunning this example will output the following:\n\n```\nrequireSpaceBeforeBinaryOperators: Operator + should not stick to preceding expression at input :\n     1 |let x = y+z;\n-----------------^\nrequireSpaceAfterBinaryOperators: Operator + should not stick to following expression at input :\n     1 |let x = y+z;\n------------------^\n```\n\nIt's as simple as that! Of course, this example is merely checking a String literal. In practice, you would want to check the content of your application files, one at a time. This is where [broccoli-jscs][broccoli-jscs] comes in.\n\n## broccoli-jscs\n\n`broccoli-jscs` was created by [Kelly Selden][kellyselden], and encompasses both a Broccoli plugin and an Ember CLI addon.\n\nAs a [plugin][broccoli-plugin], `broccoli-jscs` implements a `JSCSFilter` function that accepts a collection of input nodes, which map to file paths. Each file is read into a string, which is then passed to JSCS's `checkString` method for linting. Every time that you make a change to a file while `ember s` is running, the file will be reprocessed by the plugin, and any JSCS errors found will be displayed in the console.\n\nIn addition, `JSCSFilter` will generate a test file for every file represented in the input nodes. Given `foo/example.js`, the plugin will output a test file named `foo/example.jscs-test.js`, with the following content:\n\n```js\nmodule('JSCS - foo');\ntest('foo/example.js should pass jscs', function() {\n  ok(false, 'foo/example.js should pass jscs.\\nrequireSpaceBeforeBinaryOperators: Operator + should not stick to preceding expression at foo/example.js :\\n     1 |let x = y+z;\\n-----------------^\\n     2 |\\nrequireSpaceAfterBinaryOperators: Operator + should not stick to following expression at foo/example.js :\\n     1 |let x = y+z;\\n------------------^\\n     2 |');\n});\n```\n\nIf no JSCS errors are found, the test file is still generated, but with a passing assertion: `ok(true, /* message */)`.\n\nAs an addon, `broccoli-jscs` implements the `lintTree` function, which is one of the many hooks that Ember CLI exposes, as a way to extend the core build pipeline. In this case, the function simply creates a new instance of the `JSCSFilter` plugin and returns it. Ember CLI will call the hook for every addon discovered inside a project, if it is defined. So if you install `broccoli-jscs` as an addon, its `lintTree` function will be called on every build or re-build, therefore linting your code every time it changes.\n\nIt is worth mentioning that the `JSCSFilter` plugin instance returned by `lintTree` is also considered a node (representing the collection of JSCS test files), and this node further serves as an input node to additional plugins along the course of building out the project. For instance, it is passed to `broccoli-babel-transpile` to turn ES2015 code into ES5 syntax, then to `broccoli-concat` in order to be concatenated with other files and produce a single `assets/tests.js` file.\n\n## So where does `ember-suave` fit in this picture?\n\nIf you install `ember-suave`, the Ember CLI addon portion of `broccoli-jscs` isn't used. The goal of `ember-suave` is to augment the plugin provided by `broccoli-jscs`, by configuring it with a set of rules (both JSCS built-in rules as well as custom ones defined inside of `ember-suave`), so you don't have to do so for each project. As such, it has its own `lintTree` implementation that calls out to the `JSCSPlugin`.\n\n## Eager for more?\n\nEven though this post focuses on `ember-suave`, you can imagine the process being very similar for other linters, such as JSHint or ESLint.\n\nUnderstanding the inner workings of a build helps tremendously for various situations: when something breaks, you know where and what to look for. Furthermore, you are now better equipped to build extensions of your own, should the need arise.\n\nIf you found this post informative, and would love to learn more about Ember CLI's build process, available hooks, and how to use them, [EmberConf][ember-conf] is right around the corner. I'll be diving more into this topic as part of my talk on \"Dissecting an Ember CLI Build\".\n\n[suave-up-your-code]: https://dockyard.com/blog/2015/08/07/suave-up-your-code\n[ember-suave]: https://github.com/DockYard/ember-suave\n[jscs]: http://jscs.info/\n[node-jscs]: https://www.npmjs.com/package/jscs\n[broccoli-jscs]: https://github.com/kellyselden/broccoli-jscs\n[kellyselden]: https://github.com/kellyselden\n[broccoli-plugin]: https://github.com/broccolijs/broccoli-plugin\n[ember-conf]: http://emberconf.com/\n"},{"title":"TIL: Elixir maps have built in syntax for updating","tags":["elixir","til"],"summary":null,"legacy":false,"id":"2016/03/07/til-elixir-maps-have-built-in-syntax-for-updating","employee":"Marin Abernethy","date":"2016-03-07T00:00:00","body":"\n\nI am relatively new to Elixir and often find there are numerous ways to\nimplement a single task. For example, when I want to update a key value in a map, I have several options before me...\n\nGiven, `expenses = %{groceries: 200, rent: 1000, commute: 70}`, I could\nemploy:\n\n* [`Map.merge(map1, map2)`][merge] if I want to update multiple key value pairs\nand/or several new ones\n\n```elixir\nMap.merge(expenses, %{\n  rent: 1200,\n  comcast: 100\n})\n```\n\n* [`Map.put(map, key, val)`][put] if updating or adding a single key value\n\n```elixir\nMap.put(expenses, :booze, 100)\n```\n\n* [`Map.update(map, key, initial, fun)`][update]: if I want to increment a value by a certain degree\n\n```elixir\nMap.update(expenses, :misc, 300, &(&1 * 2))\n```\n\n* [`Kernel.put_in(data, keys, value)`][put_in]: if I want to update a value in a nested structure\n\n```elixir\nexpenses = %{groceries: %{milk: 5}, apartment: %{rent: 1000, comcast: 100}}\nput_in(expenses, [:rent, :comcast], \"too much\")\n```\n\nHowever, **today I learned**, maps come with a built in syntax for updating\none or more key values!\n\n```elixir\n %{expenses | groceries: 150, commute: 75}\n```\n\nWhile a bit obscure, and not easily found in the [elixir docs][docs], this trick is definitely nice to have in my elixir tool belt. The only thing to remember is that this syntax requires `groceries` and `commute`\nto already exist. Otherwise, it will fail with an error. Hopefully, this syntax comes in handy for you now too!\n\nIf you want to know more about how to deal with nested structures, check out Brian's post [\"Elixir Best Practices - Deeply Nested Maps\"][brian]!\n\n[merge]: http://elixir-lang.org/docs/stable/elixir/Map.html#merge/2\n[put]: http://elixir-lang.org/docs/stable/elixir/Map.html#put/3\n[update]: http://elixir-lang.org/docs/stable/elixir/Map.html#update/4\n[put_in]: http://elixir-lang.org/docs/stable/elixir/Kernel.html#put_in/3\n[docs]: http://elixir-lang.org/docs.html\n[brian]: https://dockyard.com/blog/2016/02/01/elixir-best-practices-deeply-nested-maps\n"},{"title":"How we taught an intro to UX design workshop","tags":["ux design","design","user experience","community","training"],"summary":"Earlier this week, Amanda and I taught a workshop for the Northeastern University Women in Tech group.","legacy":false,"illustration_alt":"Workshop participants","illustration":"https://i.imgur.com/aTVPBvY.jpg","id":"2016/03/08/how-we-taught-an-intro-to-ux-design-workshop","employee":"Maria Matveeva","date":"2016-03-08T00:00:00","body":"\n\nEarlier this week, my colleague [Amanda](https://twitter.com/acacheung) and I taught a workshop for the\n[Northeastern University Women in Tech\ngroup](http://nuwit.ccs.neu.edu/index.html). More than 35 computer\nscience majors, as well as designers and inter-media studies students\njoined us for two hours of hands-on learning.\n\nBy presenting this workshop, we got a chance to meet and collaborate\nwith a great bunch of motivated students, and learned a few things\nourselves!\n\n![Workshop participants](https://i.imgur.com/aTVPBvY.jpg)\n\n## You can learn fast when you start with a common background\n\nA big portion of the workshop consisted of a hands-on exercise:\nthe participants conducted [design sprints](https://dockyard.com/design-sprints) from user interviews to screen\nflows. The constraints were that our audience was generally new to UX\ndesign and the workshop was to fit in a one hour timeframe. We started\nwith an [introductory UX design presentation](https://speakerdeck.com/rgbcolor/intro-to-ux-design-a-dockyard-workshop) and then posed our workshop\nprompt. The hypothetical client and problem set was intimately familiar\nto all of the participants: the Boston MBTA.\n\n![Workshop participants](https://i.imgur.com/YKLlo6u.jpg)\n\nParticipants switched between end-user and interviewer roles, and\nconducted quick interviews to find problems to solve. The process went\nvery smoothly and had quite a few laughs, as we all shared painful\nexperiences we’ve all had on the clunky and crowded transit system.\n\n## When in doubt, propose a magical solution\n\nBecause the goal of the workshop was an introduction to the whole UX\ndesign process, rather than a refinement of a particular skill, we\ndecided to move away from any potential time-consuming sticking points\nlike detailed research or gathering real data.\n\n![UX Design workshop](https://i.imgur.com/9O8LN7G.jpg)\n\nOur demo: the low-fidelity presentation of UX problems and solutions for\na unicorn to find a compatible public transit car.\n\nAs an example outcome, we demonstrated a UX design proposal that solves\nthe problem a unicorn might have when she doesn’t know if a\nunicorn-compatible train car is available on the MBTA. This is clearly\nnot a practical design premise. What it is, is a story so ridiculous and\nopen to interpretation that it gives participants the license to invent\na solution, however crazy, rather than get stuck in the process. As a\nresult, folks were able to improvise solutions quickly.\n\n## Present what you’ve learned\nHands-on learning seems like the best method to internalize new concepts\nquickly. But to really make sure that our participants are able to\nremember and apply their new UX design skills in their work going\nforward, we asked them to present their findings at the end of the\nworkshop. Each team of 5-6 people was asked to pitch their app proposal\nto the entire group. They had to explain each proposed interface\nsolution by stating what user problem they had discovered through\ninterviews, and how the interface would address that problem.\n\n![Workshop participants](https://i.imgur.com/j0ss1Zn.jpg)\n\nBy “pitching” UX design considerations for the fictional MBTA app, the\nparticipants got practice and gained confidence to do it again in a\nfuture project.\n\n## What’s next\n\nIn the follow-up discussion, a participant asked what the next step\nmight be for someone learning UX design for the first time. We did not\nhave a prepared answer at the time, except for this: **anyone can and\nshould include UX design considerations at the beginning of any project\nto save time and effort**.\n\nHere is a list of actionable items to further your initial set of skills\nso you can start including UX in projects in any discipline:\n\n*   Join UX-oriented Meetups and learn through presentations, networking,\nworkshops, and panel discussions. DockYard hosts [UX\nEast](http://www.meetup.com/UX-East/), which includes quarterly\nworkshops, plus other educational events.\n*   Watch [this great introductory\nvideo](https://www.youtube.com/watch?v=Ovj4hFxko7c) that’s drawn on a\nwhiteboard!\n*   Read this article on [Simplicity vs. clarity in UX Design by Robert\nHoekman\nJr.](http://www.wired.com/2015/12/simplicity-is-overrated-in-ux-design/)\n*   Read IDEO’s primer on Design Thinking, [The Field Guide to Human Centered\nDesign](http://www.designkit.org/resources/1), available in print or as a free PDF\n*   Read Erika Hall’s A Book Apart book, [Just Enough\nResearch](https://abookapart.com/products/just-enough-research), a solid\nintroduction to the why’s and how’s of design research\n\n## This was fun. Let’s do it again!\nThe workshop results surpassed our expectation: every group put together\na fun, articulate presentation with their UX considerations for a\nfictional app. We saw many fun creative ideas, as well as “aha” moments\nwhere an obvious problem and a simple solution found a match. We had a\ngreat group of students, and saw a lot of results in the two hours they\ninvested into learning with us.\n\n![UX Design example](https://i.imgur.com/3WkjbBS.jpg)\n\nThe creatively named “MBT-Yay” app\n\n## Interested in hands-on learning?\n\nIf you and your team are curious about hands-on workshops, and would\nlike to chat to one of us about potentially hosting one, get in touch!\n[We’d love to collaborate](mailto:maria.matveeva@dockyard.com).\n"},{"title":"A learning experience in web application design (part 1 of 2)","tags":["design","design process","design thinking"],"summary":"A speculative project that would challenge me to confront the differences between print and web application design.","legacy":false,"illustration_alt":"Components","illustration":"http://i.imgur.com/G0ZEL3x.jpg","id":"2016/03/11/a-learning-experience-in-web-application-design-part-1","employee":"Chris Bowers","date":"2016-03-11T00:00:00","body":"\n\nAfter a summer of freelance magazine work, I joined the DockYard design team. This has required my design practice to evolve. My education and experience in editorial and publication design made me comfortable with visual systems and hierarchy—a skill fundamental to any design project. Yet, shifting my focus to UI involves working through a new set of problems. \n\nEven though I use web applications daily, it doesn’t mean I understand every crucial detail that makes a successful interface. I know when a design doesn’t work, but the thing about good UI is that it can slip right by you. If you asked me what the loading state for tumblr was, I would have to go and check even though I see it everyday. \n\nA common idea in UI design is to fail fast and iterate often. Understanding means nothing without experience. With this in mind, I chose to design the UI for a speculative project that would challenge me to confront the differences between print and web application design.\n\nDesigning for the user, not for yourself almost seems like a new concept born out of interaction design, but editorial is no stranger to this ideology. Just like with any web application, a magazine’s user needs to be able to absorb the important information quickly and navigate seamlessly. Good print design is consistent with grid, type, and color choices. This consistency provides a level of comfort for the user. \n\nUnlike a magazine, an application should provide constant feedback to communicate with its user. Every action needs an appropriate reaction to simplify and support the user’s journey. Interface responses manifest themselves in different component states. “Why is this taking so long?” is met with a skeleton UI that makes the application appear faster than it is. Answering a user’s instinctive questions lets the brain focus on the task at hand. \n\nFor this project, I focused on a concept for a produce delivery service from [an article by Steven Trevathan](http://www.creativebloq.com/web-design/design-single-page-app-ember-121518402). Working on this app gave me a chance to explore different states and forms of feedback for many application components. For a range of different states, I planned to design the components shown below.\n\n![Components](http://i.imgur.com/G0ZEL3x.jpg)\n\nTo guide this project, I referenced [The Nine States of Design article](https://medium.com/swlh/the-nine-states-of-design-5bfe9b3d6d85#.agxc5g36b) by Vince Speelman. Given that these states are a necessity for any web application, the exciting part is experimenting with the form and language of them. My next post will show my own process designing states that align with a specific brand personality. Well crafted states can give the user an experience to enjoy and not just tolerate, even when they deviate from the intended path. \n"},{"title":"Why?","tags":["agile","project management","product management","development"],"summary":"Don't underestimate the power of this simple question","legacy":false,"id":"2016/03/17/why","employee":"Jon Lacks","date":"2016-03-17T00:00:00","body":"\nJust the other day amidst working on what would be classified as a longer term client engagement for DockYard, I was reminded of the power of ‘Why’.  One of the most wonderful things about being human (and what separates us from machines) is that we are motivated by many different things both in our personal and professional lives.  \n\nWhen it comes to working on projects which involve the design & development of a product not owned by our company, it’s easy to get stuck in a rut of just churning out “Deliverables” and forgetting what you're actually contributing to in the greater scheme of things.    A good work environment, generous compensation and work life balance can only go so far.  High performing teams also need to know and feel that they are contributing to the world they live in - sometimes in an evolutionary way and sometimes a very revolutionary way. \n\nOne important distinction which sometimes gets missed - “why” is very different from “how”.  “How” is much more easily defined.\n\n - How = adverb. In what way or manner; by what means.\n - Why = adverb. For what reason or purpose.\n\nIt might come as a surprise to some of our clients how personally vested we get in their products even though we may be acting as supporting cast.  You have to consider that we essentially live and breathe our clients’ products while they are in development.  We think about it during our workday, we think about it while commuting and we think about while taking a shower - TMI perhaps!  After many months of contributing to a product's evolution, to maintain motivation, we must remind ourselves ‘Why’ we are there in the first place.\n\nPassionate product owners are those who always provide their team with a compass heading towards an eventual goal. The path to get there is twisty and bumpy but at end of the day the team knows what the end game looks like and how it contributes to the world.    As an agency we are always looking to amplify this real-world connection for our team members  to make sure they feel aligned with the overall product objective.  Our Project Management team at DockYard shouldered this responsibility, making sure they stay aligned to our clients’ compass throughout the project journey.  This will no doubt allow our team to better navigate that twisty/bumpy path towards the overall product objective while at the same time providing a motivating work environment for our most valued company resource: the employees.\n"},{"title":"Ember's getWithDefault","tags":["ember","javascript","best practices"],"summary":"A quick look at a common gotcha.","legacy":false,"id":"2016/03/18/get-with-default","employee":"Michael Dupuis","date":"2016-03-18T00:00:00","body":"\n\n## Getting Default Values\nHere's a quick look at a common gotcha that slips into pull requests\nfrom time to time.\n\nWhen working in Ember, you'll often want a default value for\ncertain properties. Ember provides a convenient means for getting a\ndefault value with the aptly named, [`getWithDefault`][getWithDefault]:\n\n```javascript\nEmber.getWithDefault(person, 'lastName', 'Doe');\n```\n\nThe above code would retrieve the `lastName` property off of the\n`person` object, and if the value is `undefined`, it will return\n`Doe`.\n\n## An Example\nLet's say we're working on a campaign application with a `Donation` model. This\napp will primarily be used by [Super PACs][super-pacs] to fund campaigns\nof legislators who represent the interests of a small group of deep-pocketed\nindividuals. These well-funded legislators will [win their elections\nabout 90% of the time][money-in-elections].\n\nNaturally, if the donor does not disclose her name, \nthe Super PACs would like the default donation to display \"Anonymous.\"\n\nOur first pass looks something like this:\n\n```javascript\n// app/donation/model.js\n\nimport Model from 'ember-data/model';\nimport attr from 'ember-data/attr';\nimport computed from 'ember-computed';\nimport get from 'ember-metal/get';\n\nexport default Model.extend({\n  amount: attr('number'),\n  fullName: attr('string'),\n\n  displayName: computed('fullName', {\n    get() {\n      return get(this, 'fullName') || 'Anonymous';\n    }\n  })\n});\n```\n\nWe soon realize we can clean up our `displayName` computed property with `getWithDefault`:\n\n```javascript\ndisplayName: computed('fullName', {\n  get() {\n    return getWithDefault(this, 'fullName', 'Anonymous');\n  }\n})\n```\n\nUsing `getWithDefault` in that example is a bit cleaner and easier to\nread.\n\nThen one day, we wire up with a new, external API. The JSON payload from this backend\nsends `null` for `fullName` if the record does not have a\nvalue. Our `displayName` no longer defaults to \"Anonymous\" and we're\nslightly confused. If our `fullName` value is falsy, why does\n`getWithDefault` not return our default value?\n\nRemember, `getWithDefault` is not evaluating\nwhether or not the return value is truthy or falsy: it only returns the\ndefault value if the `get` returns `undefined`. The value that was once\n`undefined` is now `null`, so `getWithDefault` returns `null`.\n\nThe solution here is probably to cleanup the JSON payload in the\nserializer so that `null` values are treated as `''`. \nBut for this contrived example, and for any instance in\nwhich you would like to set a default value based off a falsy return\nvalue, use a good, old-fashioned `or` operator:\n\n```javascript\ndisplayName: computed('fullName', {\n  get() {\n    return get(this, 'fullName') || 'Anonymous';\n  }\n})\n```\n\nI hope this prevents a few people from scratching their heads when\n`getWithDefault` doesn't behave as expected.\n\nThanks for reading, and\ndon't forget to support campaign finance reform this tax season by\nopting into the [Presidential Election Campaign Fund][pecf] (it's free)!\n\n[getWithDefault]: https://github.com/emberjs/ember.js/tree/v2.4.0/packages/ember-metal/lib/property_get.js#L152\n[super-pacs]: https://www.opensecrets.org/pacs/superpacs.php\n[money-in-elections]: http://www.opensecrets.org/news/2008/11/money-wins-white-house-and/\n[pecf]: https://en.wikipedia.org/wiki/Presidential_election_campaign_fund_checkoff\n"},{"title":"The things about Red, Green, Refactor that nobody ever talks about","tags":["engineering","best practices","opinion"],"summary":null,"legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/acmyARH.png","id":"2016/03/23/the-thing-about-red-green-refactor-nobody-talks-about","employee":"Brian Cardarella","date":"2016-03-23T00:00:00","body":"\n\n![](http://i.imgur.com/acmyARH.png)\n\n\"Red\", \"Green\", \"Refactor\"\n\n*Red*, *Green*, *Refactor*\n\n**RED** **GREEN** **REFACTOR**\n\nThis process has been drilled into our head for over ten years. The goal\nis to push to writing better software by ensuring that only what you\nhave spec'd out is implemented. The problem however is when you're in\nnew territory. In order to write proper tests you need to have an\nunderstanding of the system it is spec'ing. If the implementation of\nthat system is still a mystery then you can find yourself getting\nblocked trying to dream up how to test a system you have no idea is\ngoing to work.\n\nDoes this sound familiar?\n\nThe dogmatic approach of Red, Green, Refactor can sometimes be a\nblocker. If it is preventing you from delivering business value what\ngood is it doing?\n\nWell, I've got some secrets to share about Red, Green, Refactor...\n\n### It's OK to spike the implementation first\n\nWhen trying to implement something new writing the actual implementation\nis sometimes easier than reasoning about how to test said system. In\nthese cases it is perfectly reasonable to:\n\n1. Code spike the implementation\n2. Gain knowledge on what the boundaries and requirements of the implementation are\n3. Toss out the spiked code\n4. Write the tests\n5. Write the new implementation\n\nMore often than not you'll find this strategy to be very effective and\nyou'll break through the wall faster than attempting to dream up the\nimplementation in your head before writing the tests. You may also find\nthat when you get to Step 5 the re-implemented code is much better than\nthe spike you originally wrote.\n\n### You don't have to follow any \"order\"\n\nTake a look at the graph at the top of the page. Where does it start?\nWhere does it end? Most people, because of the phrase \"Red, Green,\nRefactor\" feel they *must* start with \"Red\". Well, you don't. Let's\nassume you inherit an application that has poor, or no, test coverage.\nIt's perfectly OK to write simple acceptance tests that assert the\ncurrent behavior of the application. Go directly to \"Green\". This is OK\nbecause the application is already live, it's working. Once you have the\nhappy paths covered in the acceptance tests you've written you can\nrefactor with confidence.\n\n### Break the \"rules\"\n\nLike most rules \"Red, Green, Refactor\" makes sense for most cases, but\nnot all. In situations where you find yourself restricted or not moving forward\nfeel free to break the rules until you can get back to a place where\nobserving them again makes sense.\n"},{"title":"Testing function delegation in Elixir without stubbing","tags":["engineering","elixir","testing"],"summary":null,"legacy":false,"id":"2016/03/24/testing-function-delegation-in-elixir-without-stubbing","employee":"Brian Cardarella","date":"2016-03-24T00:00:00","body":"\n\nIn other lanugages mocking/stubbing are part of your regular toolbelt, in Elixir Jose has\ncome out against them \n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I will fight against mocks, stubs and YAML in Elixir with all my... friendliness and energy to promote proper education on those topics.</p>&mdash; José Valim (@josevalim) <a href=\"https://twitter.com/josevalim/status/641617411242913792\">September 9, 2015</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nInstead he suggests\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/bcardarella\">@bcardarella</a> for tests, create a simple module (or an agent if you need flexibility) that will be used by your app during your tests</p>&mdash; José Valim (@josevalim) <a href=\"https://twitter.com/josevalim/status/641619543543152640\">September 9, 2015</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nI've been trying to practice this until the other day when I was\nbuilding a library that was adapter based. I wanted to unit test the\nparent module that would delegate to the adapter. The adapters can\nchange and I don't want the unit test of the parent module to be tied to\nany particular child. As a matter of example, we could have something\nlike this:\n\n```elixir\ndefmodule Parent do\n  defmacro __using__([adapter: adapter]) do\n    quote do\n      def __adapter__, do: unquote(adapter)\n      def make_it_so(command) do\n        __adapter__.make_it_so(command)\n      end\n    end\n  end\nend\n```\n\nIn other languages I would stub out `Parent.make_it_so/1` and assert that\nthis function was being called. For example, if you were using the\n[`mock`][mock] Elixir library you would do:\n\n```elixir\ndefmodule CustomParent do\n  use Parent, adapter: FooBar\nend\n\nwith_mock CustomParent, [make_it_so: fn(command) -> command end] do\n  CustomParent.make_it_so(:ok)\nend\n```\n\nBut as Jose has pointed out we don't want to do this.\nSo how do we test that the adapter's `make_it_so/1` function is being\nproperly delegated to without stubbing? Well we can rely on Elixir's\n[`send/3`][send] and [`assert_receive`][assert_receive].\n\nKeep in mind that `send` will allow you to put messages into a process's\nmailbox and `assert_receive` will allow you to test against that.\n\nHere is how you might test the delegation:\n\n```elixir\ndefmodule ParentTest do\n  use ExUnit.Case\n\n  defmodule CustomAdapter do\n    def make_it_so(_command) do\n      send self(), :ok\n    end\n  end\n\n  defmodule CustomParent do\n    use Parent, adapter: CustomAdapter\n  end\n\n  test \"delegates to the adapter\" do\n    CustomParent.make_it_so(%{foo: \"bar\"})\n\n    assert_receive :ok\n  end\nend\n```\n\nAnd that's it. You can handle more complex situations by adding your own\nlogic inside the `CustomAdapter`s function, to send or not send\ndepending upon the value passed in but that should depend upon your\nuse-case.\n\nSo what happens when you are testing with a module that might spawn its\nown process? In those cases I might have an `opts` argument that I can\nwork with. Let's assume that for whatever reason `Parent.make_it_so`\nis working in a process on its own:\n\n```elixir\ndefmodule ParentTest do\n  use ExUnit.Case\n\n  defmodule CustomAdapter do\n    def make_it_so(_command, opts) do\n      send opts[:pid], :ok\n    end\n  end\n\n  defmodule CustomParent do\n    use Parent, adapter: CustomAdapter\n  end\n\n  test \"delegates to the adapter\" do\n    opts = [pid: self()]\n    CustomParent.make_it_so(%{foo: \"bar\"}, opts)\n\n    assert_receive :ok\n  end\nend\n```\n\nThis works because each test in `ExUnit` runs in its own process. You\ncould even do this in a `setup` block if you needed to capture the PID\nfor many tests. However, you cannot do this in `setup_all` as that runs\nin a different process than the individual tests.\n\nTesting in Elixir has been fun as it has forced me to think about things\ndifferently than I've been used to over the past few years. If this\ntopic is of interest to you check out my talk from [ElixirDaze][elixirdaze] on Building and Testing\nPhoenix APIs\n\n<iframe width=\"560\" height=\"315\"\nsrc=\"https://www.youtube.com/embed/zoP-XFuWstw\" frameborder=\"0\"\nallowfullscreen></iframe>\n\n[ecto]: https://github.com/elixir-lang/ecto/blob/master/lib/ecto/repo.ex#L83-L100\n[send]: http://elixir-lang.org/docs/stable/elixir/Process.html#send/3\n[assert_receive]: http://elixir-lang.org/docs/stable/ex_unit/ExUnit.Assertions.html#assert_receive/3\n[elixirdaze]: http://elixirdaze.com\n[mock]: https://github.com/jjh42/mock\n"},{"title":"What makes Phoenix Presence special, and a sneak peek","tags":["phoenix","elixir","presence"],"summary":"Phoenix Presence brings cutting edge features unmatched by other frameworks. Find out how with a sneak peek.","legacy":false,"id":"2016/03/25/what-makes-phoenix-presence-special-sneak-peek","employee":"Chris McCord","date":"2016-03-25T00:00:00","body":"\n\nAt DockYard, our goal is to build the fastest and most robust\napplications for our clients both on the front-end and back-end. When\nit comes to the server, Elixir and Phoenix give us the fastest\nplatform with the highest productivity. And it just keeps getting\nbetter. New features like the much anticipated Phoenix Presence have\nus extremely excited about treading new ground on what a Web framework\ncan accomplish.\n\nHere's a sneak peek of the new features in action that show how we're\nputting cutting edge CS research into practice and how you can try it out for yourself.\nJump below for full details:\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/9dALrnCOLNE\" frameborder=\"0\" allowfullscreen></iframe>\n\n\n### Phoenix Presence\n\nPhoenix Presence is an upcoming feature in Phoenix 1.2 which brings\nsupport for registering process information on a topic and replicating\nthis information transparently across a cluster. Its simplest use-case\nwould be showing which users are currently online in an application,\nbut we're excited about other lower-level uses such as service\ndiscovery. This feature at first seems simple and mundane, but most\nlibraries fail to properly tackle it and those that do introduce extra\ndependencies without solving edge-cases. Not so with Phoenix.\n\n### What makes it special?\n\nWhat's special about Phoenix's implementation is we have a system that\napplies cutting edge CS research to tackle day-to-day problems in the\napplications we all write. Phoenix Presence:\n\n- has no single point of failure\n- has no single source of truth\n- relies entirely on the standard library with no operational\ndependencies\n- self heals\n\nUnlike most libraries and web frameworks in various languages, Phoenix\ndoes not require a central datastore to hold presence information.\nWhile having to deploy Redis or similar datastores increases your\noperational overhead, it also introduces a couple severe penalties – a\nsingle point of failure, and central bottleneck. Worse still, if one\nof your servers goes down, you'll have orphaned data stuck permanently\nin your database. With Phoenix, we've developed a system based on a\ndistributed heartbeat/gossip protocol which uses a\n[CRDT](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type)\nto replicate data in a conflict-free way. This gives you high\navailability and performance because we don't have to send all data\nthrough a central server. It also gives you resilience to failure\nbecause the system *automatically recovers from failures*. This\nincludes other nodes going up or down or spotty networks causing\nnetsplits and missed data replication.\n\n### Great platforms yield great solutions\n\nNone of this would be possible without the innovations from Elixir and\nErlang which gives us a distributed runtime that's unmatched by other\nlanguages. When we sat down to design Phoenix Presence, instead of\nimmediately asking \"which database would be best to hold presences?\",\nwe could ask \"how can we best replicate data in a distributed system\nwithout the user having to worry about it?\". The platforms you build\non top of drive the design decisions you make in your products. With\nElixir, you are empowered to tackle problems that in other platforms\nwould feel impossible to solve without tradeoffs with heavy dependencies.\nOvertime these decisions play out to more reliable products and services, \nand better user experiences.\n"},{"title":"Prefer Integration Tests over Acceptance Tests","tags":["ember","javascript","testing"],"summary":"Integration testing should be an integral part of your test suite.","legacy":false,"id":"2016/03/28/prefer-integration-tests","employee":"Marten Schilstra","date":"2016-03-28T00:00:00","body":"\n\nIt is suprisingly easy to test your whole Ember.JS application using acceptance tests only. All you have to do is to reproduce how you would normally navigate through the application using a [stellar set of helpers](https://guides.emberjs.com/v2.4.0/testing/acceptance/). Don't want to test your API? [Add ember-cli-mirage](http://www.ember-cli-mirage.com)!\n\nYou should realize though, that each acceptance test boots up the whole Ember.JS application and starts you at the `application.index` route. You then have to navigate to the right page and then test the thing you wanted to do. This is fine when you want to test a complex user-flow through an app, but a big waste of time and CPU cycles to verify if a form submit button is unclickable when the data is invalid.\n\nIf you create acceptance tests for every edge case and every regression, then it will be likely that your test suite will quickly grow to be five, ten or more minutes long. That is a problem since slow test suites are likely to be run less often by the developer, and test failures won't be caught quickly. I have caught myself relying on the CI server to run the tests for me, while doing other stuff, because I didn't want to wait for just five minutes.\n\nHaving said all that, I think we should write more integration tests and less acceptance tests. Integration tests in most cases run much faster, because you don't have to boot a whole app, or navigate to the page where your component is being used.\n\nIntegration tests are also more flexible than most people think. They're not only for testing components, you can also test [template helpers](https://github.com/DockYard/ember-composable-helpers/blob/master/tests/integration/helpers/map-by-test.js). Actually you can test anything with an [integration test](https://github.com/switchfly/ember-test-helpers/blob/master/lib/ember-test-helpers/test-module.js#L26). For example a model that has logic depending on its relationships is a good example where you can use a non-component integration test.\n\nUsing component integration tests to test components should also improve your component design. Test driving individual components will make you think more about their external API, prevents building a [LMAO](http://slides.com/miguelcamba/composable-components#/8) and promotes [loose coupling](https://en.wikipedia.org/wiki/Loose_coupling).\n\nThere is, however, a small downside to integration tests: the API for writing component integration tests is completely different than the api for writing acceptance tests, so you will have to learn another totally different style of writing tests while maintaining the knowledge of how to write acceptance tests. Luckily there is a [motion to unify](https://github.com/emberjs/rfcs/pull/119) the API for integration and acceptance tests.\n\nIf you aren't that familiar with EmberJS' integration tests I'd recommend to read Alisdair McDiarmid's [Ember component integration tests](https://alisdair.mcdiarmid.org/ember-component-integration-tests/) post.\n\nClosing out I'd like to say that this post isn't mean't to say don't do any acceptance testing anymore. Acceptance tests are still necessary to smoke test the whole application.\n"},{"title":"Served with FastBoot (again)","tags":["ember","fastboot"],"summary":"You are now reading a live FastBoot site","legacy":false,"id":"2016/03/29/served-with-fastboot-again","employee":"Dan McClain","date":"2016-03-29T00:00:00","body":"\n\nA little less than a year ago, we launched the redesigned DockYard.com,\nwhich at launch was running an early version of [FastBoot][fastboot].\nAnd by early version, I mean alpha version, when Ember had some memory\nleaks, which caused FastBoot to crash. Since then, DockYard.com was a\n*FastBoot Rendered, Statically Served*™ site. I would run a local\ninstance of FastBoot, use a custom crawler to crawl everything but the\nblog and save static files of the site. I would then push those static\nfiles to the server and let Nginx serve the files. This gained us the\nbenefits of running FastBoot (except on the blog), without FastBoot\nrunning and crashing because of the memory leaks. The reason that the\nblog was left out was because of the fact that using `{{{blog.body}}}`\nwas not rendered in that version of FastBoot, leaving the post content\nof every blog post out of the page source.\n\n## FastBoot keeps moving\n\nAs time went on, the memory leaks in Ember were fixed, and FastBoot has\nbeen continually developed. Ember has also been updated so that stable\nreleases, as of 2.3.0, support FastBoot. Previously you had to use the\ncanary version and enable a feature flag to allow Ember to work with\nFastboot.\n\nAnd recently, I revisited the DockYard site and worked to reimplement\nFastBoot. In terms of work on DockYard.com, there was little to no work,\nwe had previously submitted pull requests to addons we were using to\nmake them FastBoot compatible. Most of the recent work was around\ncontributing to FastBoot to help make it easier for applications to drop\nin.\n\nThere have been many contributors to FastBoot, helping to make it a\nreality.  Ember Data, [as of 2.4.0][ember-data], works with FastBoot with little\nconfiguration (you need to provide the `host` to your adapter for now,\nas relative URLs do not work for FastBoot's AJAX layer).  There is a\n[FastBoot service available to your Ember app that gives you access to\ncookies][cookies], [headers][headers] and [the requested host in the FastBoot version of your\napplication][host]. DockYard.com may be a bit on the bleeding edge, but a\nproduction version of FastBoot is not that far off.\n\nIf you and your company are looking for help getting your application\nFastBoot ready we'd love to help. [Please reach out to us][contact].\n\n[ember-data]: http://emberjs.com/blog/2016/03/13/ember-data-2-4-released.html#toc_fastboot-support\n[cookies]: https://github.com/tildeio/ember-cli-fastboot/pull/121\n[headers]: https://github.com/tildeio/ember-cli-fastboot/pull/123\n[host]: https://github.com/tildeio/ember-cli-fastboot/pull/136\n[fastboot]: https://github.com/tildeio/ember-cli-fastboot\n[contact]: https://dockyard.com/contact/hire-us\n"},{"title":"Announcing: ember-deferred-content","tags":["ember"],"summary":"Handling the states of async content","legacy":false,"id":"2016/03/30/announcing-ember-deferred-content","employee":"Dan McClain","date":"2016-03-30T00:00:00","body":"\n\nThere are times that you may have some content that you want to load\noutside of the `model` hook. An example of this would be a blog post with\ncomments. You want your post to be loaded in the `model` hook of your\nroute, but don't necessarily want to wait for all of the comments to\nload before displaying the blog post.\n\n[ember-deferred-content][github] takes the promise you need to resolve to show\nyour content, and yields four subcomponents that you can use to show\ncontent during the different states of your promise:\n\n```hbs\n{{#deferred-content promise=promise as |d|}}\n  {{#d.settled}}<h2>Your content!</h2>{{/d.settled}}\n  {{#d.pending}}Loading your content...{{/d.pending}}\n  {{#d.rejected as |reason|}}<strong>Could not load your content:</strong> {{reason}}{{/d.rejected}}\n  {{#d.fulfilled as |stuff|}}<strong>Loaded:</strong> {{stuff}}{{/d.fulfilled}}\n{{/deferred-content}}\n```\n\nIf you want to handle transitions with something like [liquid\nfire][liquid-fire], you can use `if` (or `liquid-if`) statements and the flags provided:\n\n```hbs\n {{#deferred-content promise=post.comments as |d|}}\n    {{#if d.isSettled}} <h2>Comments</h2> {{/if}}\n    {{#if d.isPending}} <img src=\"spinner.gif\"> {{/if}}\n    {{#if d.isFulfilled}}\n      <ul>\n        {{#each d.content as |comment|}}\n          <li>{{comment.author}} said: {{comment.body}}\n        {{/each}}\n      </ul>\n    {{/if}}\n    {{#if d.isRejected}} Could not load comments: {{d.content}} {{/if}}\n  {{/deferred-content}}\n```\n\n[Demo][demo-link]\n\nAs you can see above, you pass the promise to the `deferred-content` component,\nthen you get four contextual components for the four states of the promise:\n`settled`, `pending`, `fulfilled`, and `rejected`. Each is a block component where the\ncontent you place the content you want to see when the promise is in that\nstate. `rejected` and `fulfilled` yield the result of their states to the\ncomponent so you can reference the result of the promise.\n\n\n## Let's take one step further\n\nLet's peak at an example in which we have no asynchrony in our `model`\nhook: [Example app][example-app]\n\nSo what's happening here? This app simulates a slow loading blog post.\nWe have some basic information on the blog list page (the title), and we\ncan use this to do a hero animation right away, instead of waiting for\nthe `model` hook to resolve. Clicking the deferred link shows that, as\nclicking on the normal link waits for the model to be fetched in the\n`model` hook before starting the transition.\n\n### Deferring asynchrony to the template\n\nWhen we use `deferred-content` to show the loading state note that the\nURL update and animation happens immediately, as opposed to waiting for\nthe `model` hook to resolve. This approach will also encourage you to\nmodel your data slightly differently so that you push your asynchronous\nto logical divisions in your templates.\n\nBy utilizing animations to mask your loading times you improve your [perceived\nperformance][perc-perf]. Given that two sites take the same ammount of time to\nrender, the one with a loading animation will be perceived as\nfaster, and tends to be less likely to lose conversions.\n\n### Where this really shines\n\nPages with multiple pieces of async content benefit the most from this\napproach. You can load in each piece of content as you receive it,\nmaking the page more responsive.\n\n## Handle the states of your content easily\n\nWith `ember-deferred-content` it becomes trivial to handle async content after\nrendering the page. You can provide a pending state to let your users know that\ncontent is incoming, and switch over to the actual content once it's loaded.\n\n[demo-link]: https://ember-twiddle.com/8ca7a5edd5ab0df72c0c?numColumns=1&openFiles=application.template.hbs%2C\n[github]: https://github.com/danmcclain/ember-deferred-content\n[example-app]: http://deferred-example.danmcclain.net/\n[perc-perf]: http://blog.teamtreehouse.com/perceived-performance\n[liquid-fire]: http://ember-animation.github.io/liquid-fire/\n"},{"title":"Announcing VerifyOrigin","tags":["phoenix","security"],"summary":"Securing your API without a CSRF token","legacy":false,"id":"2016/03/31/announcing-verify-origin","employee":"Dan McClain","date":"2016-03-31T00:00:00","body":"\n\nIn web applications, if you are using cookies for storing authentication\nstate, you should be worrying about [Cross Site Request Forgery][csrf]\n(CSRF). In short, when using cookies, other sites can create an HTML\nform that submits to your backend. When your browser submits that form,\nit will attach any cookies it has that are associated with the URL that\nthe form is submitted to. Without any steps taken to mitigate this, a\nmalicious third party could create a form on their site that performs an\naction on application, maybe as harmless as following them on a site, or\nas malicious as deleting your account or transferring funds. [OWASP has\nmore details on CSRF attacks as well][owasp-csrf].\n\n## Typical CSRF prevention\n\nThe way that most applications mitigate CSRF attacks is by utilizing a\nsynchronizer CSRF token that is stored in a hidden HTML input in the\nform which matches a token in the current user's session. In short,\nmalicious forms will be lacking this token and will be rejected. [More\ndetails on token based mitigation are covered in this\nOWASP page][owasp-csrf-mitigation].\n\n## What about Single Page applications? Is a JSON only API vulnerable?\n\nCSRF tokens work well for server side rendered applications (SSR), since\nthe HTML generated on the server can securely include the token that is in the\nsession cookie. But what about single page application like Ember? Can\nyou craft an HTML form to submit a valid request to a JSON based API?\nThe answer is [yes it is possible][csrf-vs-json].\n\nOk, so how can we secure this API backend without a CSRF token?\n\n### Enter Referer/Origin header verification\n\nWith the exception of `GET` requests, when your browser submits a\nrequest, it attaches both a `Referer` (that typo is historical) and\n`Origin` header. The `Origin` header is a bit newer, it was originally\nintroduced for Cross Origin Resource Sharing (CORS), but has been\nrepurposed for CSRF mitigation as well. We can use the `Referer` or\n`Origin` header to verify that the request originated from the domain we\nexpect. In this case, I prefer the `Origin` header. When a request\noriginates at an HTTPS page and is made against an HTTP page, the\n`Referer` header is dropped, while the `Origin` header will continue to\nbe sent. Both [OWASP][owasp-origin] and [Mozilla][mozilla-origin] talk\nabout the validity of using the `Origin` header as a way to mitigate\nCSRF attacks.\n\n## Places where CSRF prevention fails\n\nNo matter how good your CSRF prevention is, there are other vectors that\nwill open your application to malicious requests. If your session cookie\nis not `HTTPOnly` ([details][httponly]), and/or you accidentally allow malicious JavaScript to\nexecute on your site, you have a couple of problems. When not using\n`HTTPOnly` cookies, your cookies can be retrieved via JavaScript, and if\nyou have malicious JavaScript on your site, someone could siphon off all\nyour session cookies. At that point, this third party could forge any\nheader it needs to, and then include the session cookie to automate requests\nagainst your server, so it could bypass the `Origin` check. They could\nalso replace the cookie in their browser with another person's cookie\nthat they stole, and use your site as that user, bypassing CSRF Tokens.\nIf your cookie is marked as `HTTPOnly`, they can still use malicious\nJavaScript via a [Cross Site Scripting][xss] (XSS) attack, since any users'\nbrowser that executes this malicious JavaScript will make the request\nwith either the necessary CSRF token or `Origin` header.\n\n## Ok, so why all this information about CSRF mitigation?\n\nAt DockYard, we produce Ember applications for our clients. Since Ember\nis a single page application, `Origin` header checking is the best way\nwe can protect any backends we produce. To the end, I recently published\n[VerifyOrigin][verify-origin] to\n[hex.pm](https://hex.pm/packages/verify_origin). VerifyOrigin\nprovides a `Plug` you can add to your applications pipeline to only\nallow requests from `Origin`s you expect:\n\n```elixir\nplug VerifyOrigin, [\"https://example.com\"]\n```\n\nThe plug expects a list of valid `Origin` URLs. If the request does not\nhave an `Origin` header that matches your list, then it returns a `400\nBad Request` response to the client. Simple CSRF mitigation for your\nPhoenix app is at your fingertips!\n\nA special thanks to [Craig Ingram][cji], who I consulted with multiple\ntimes when coming up with this plug!\n\n[csrf]: https://en.wikipedia.org/wiki/Cross-site_request_forgery\n[owasp-csrf]: https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)\n[owasp-csrf-mitigation]: https://www.owasp.org/index.php/CSRF_Prevention_Cheat_Sheet#General_Recommendation:_Synchronizer_Token_Pattern\n[csrf-vs-json]: https://www.gracefulsecurity.com/csrf-vs-json/\n[owasp-origin]: https://www.owasp.org/index.php/CSRF_Prevention_Cheat_Sheet#CSRF_Prevention_without_a_Synchronizer_Token\n[mozilla-origin]: https://wiki.mozilla.org/Security/Origin\n[httponly]: https://www.owasp.org/index.php/HTTPOnly\n[xss]: https://en.wikipedia.org/wiki/Cross-site_scripting\n[verify-origin]: https://github.com/danmcclain/verify_origin\n[cji]: https://twitter.com/cji\n"},{"title":"EmberConf 2016 - Bigger and Better","tags":["engineering","ember","opinion"],"summary":"A personal look at EmberConf 2016","legacy":false,"illustration_alt":"","illustration":"http://images3.cloudhdr.com/users/63df8506-b9d4-11e2-944b-eebc857a8e43/thumbnails/c961d5f8-f614-11e5-912c-ca74e7c7373d/hd_P3293226.jpg","id":"2016/04/01/emberconf-2016-bigger-better","employee":"Brian Cardarella","date":"2016-04-01T00:00:00","body":"\n\nLeading up to this year's [EmberConf][emberconf] I wasn't sure I was going to attend.\nMy indecisiveness had nothing to do with concerns about Ember or DockYard's\ncommitment to the framework. It was simply that I personally haven't been\nwriting much Ember over the past six months. Between being a new dad, buying\na house, running DockYard, and exploring Elixir I lacked the bandwidth to\nkeep up with what has been happening in Ember.\n\nThe deciding factor was to lend moral support for two of our\nengineers who were speaking: [Estelle DeBlois][estelle] and [Lauren Tan][lauren]. They both\ngave great talks and if that was the only reason it would have been more\nthan worth the trip. However, like many things, I was thankfully wrong\nabout my concerns attending and would like to share my experience this\nyear.\n\n![](http://images3.cloudhdr.com/users/63df8506-b9d4-11e2-944b-eebc857a8e43/thumbnails/c961d5f8-f614-11e5-912c-ca74e7c7373d/hd_P3293226.jpg)\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">.<a href=\"https://twitter.com/sugarpirate_\">@sugarpirate_</a>\ntakes the stage at <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> //\n<a href=\"https://twitter.com/hashtag/emberjs?src=hash\">#emberjs</a> <a\nhref=\"https://twitter.com/DockYard\">@DockYard</a> <a\nhref=\"https://t.co/aWMmgIaIMp\">pic.twitter.com/aWMmgIaIMp</a></p>&mdash;\nMike North (@michaellnorth) <a\nhref=\"https://twitter.com/michaellnorth/status/715245083927314432\">March\n30, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\nFirst, I'd like to point out how great of a job [Leah Silber][leah] has done\nbuilding and organizing EmberConf. This year the attendance was just shy\nof 1,000. That's almost double from last year. I've heard the aim is for\n1,500 next year. As someone who has run a few conferences I can say that\nLeah has been kicking ass.\n\nMy time was split about 50/50 between the hallway track and the talks. [Tom][tom] &\n[Yehuda's][yehuda] keynote was probably my favorite talk as we're very interested\nin the mobile web becoming more competitive against native. Elements\nof that keynote should play out over the next year or so to help\nposition Ember as the best choice for [Progressive Web\nApplications][pwa].\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Enjoying <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> so\nfar w <a href=\"https://twitter.com/bcardarella\">@bcardarella</a> <a\nhref=\"https://twitter.com/jeremy_w_rowe\">@jeremy_w_rowe</a> <a\nhref=\"https://twitter.com/tundal45\">@tundal45</a> <a\nhref=\"https://twitter.com/atonse\">@atonse</a> <a\nhref=\"https://twitter.com/sweatypitts\">@sweatypitts</a> <a\nhref=\"https://twitter.com/hashtag/emberjs?src=hash\">#emberjs</a> <a\nhref=\"https://t.co/J7Tr8fWTex\">pic.twitter.com/J7Tr8fWTex</a></p>&mdash;\nTracy Lee | ladyleet (@ladyleet) <a\nhref=\"https://twitter.com/ladyleet/status/714869714799894528\">March 29,\n2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\nI was really impressed with how many people were interested in\n[Elixir][elixir].\nEasily a majority of the conversations I had were with people \ncurious about Elixir or actively using it. I don't want to dwell on\nElixir too much because this was EmberConf but this reinforced my\nopinion that Elixir/Phoenix are a natural fit for Ember backends. It\nseems there are many people out there that have the same idea.\n\nThis is now my fourth EmberConf (if I'm counting the original\n[EmberCamp][embercamp]) and catching up with old friends is important but I really\nenjoyed meeting new people. As always, the regret is not meeting enough\npeople. I wish that future EmberConfs were more days with more down time. I\nrealize this is not realistic as the days really increase the cost to \nrun the conference and\nmore down time creates less incentive for companies to send employees,\nbut I personally find the most value from networking.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Climbing right after <a\nhref=\"https://twitter.com/EmberConf\">@EmberConf</a> with these great\nemberiños 💪👍 <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://t.co/TsWWZ1c2mF\">pic.twitter.com/TsWWZ1c2mF</a></p>&mdash;\nFilipe Bragança (@filipecrosk) <a\nhref=\"https://twitter.com/filipecrosk/status/715409635033817088\">March\n31, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\nI am aware of DockYard's place in the Ember community. Thinking\nback to the earlier [RailsConfs][railsconf], and companies that were in a similiar\nposition to DockYard, I don't recall the leaders of those companies being\nvery accessible. There were clear social cliques that these people\nstuck to. I'm trying not to repeat that. At times I found\nmyself gravitating towards friends but after a few minutes I'd excuse\nmyself so I could meet new people.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Thanks <a href=\"https://twitter.com/DockYard\">@DockYard</a>\nfor sponsoring amazing time at <a\nhref=\"https://twitter.com/GroundKontrol\">@GroundKontrol</a> <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://t.co/2NEiXp4ZbO\">pic.twitter.com/2NEiXp4ZbO</a></p>&mdash;\nTom Chen (@tchen) <a\nhref=\"https://twitter.com/tchen/status/715042486171910144\">March 30,\n2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\nTuesday night we hosted an event at [Ground Kontrol][gk]. For those\nunfamiliar, Ground Kontrol is a video arcade with a bar. We rented the\nentire space for three hours and had close to 100 EmberConf attendees\nthrough the doors that evening. All the games were free. When I walked\nin to get the place ready for the event it was like stepping into a time\nmachine. Nearly ever coin-op game from my childhood was there. If I\nlearned anything that evening it is that I vastly over estimated my\nskills as kid. Or I am just rusty. Or it was the controller... all of\nthe controllers. Also, I am really out of touch with modern arcade games\nas I was completely unaware of this [Killer Queen][killer-queen] game.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Killer Queen at Ground Control at 9! Ping us and let us know\nif you can make it!<a\nhref=\"https://twitter.com/hashtag/EmberConf?src=hash\">#EmberConf</a></p>&mdash;\nEmber Weekend (@emberweekend) <a\nhref=\"https://twitter.com/emberweekend/status/715347575491002369\">March\n31, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\nA good conference leaves you feeling energized and wanting more,\nEmberConf has done that for me every year. A great conference gives you\nthe opportunity to connect with friends new and old, and it takes a\ngreat community to build what Ember has. We hear a lot about *Ember vs X*.\nNot often enough do I hear the practitioners of other frameworks\nbragging about their community the way Ember does. I think there is a\ngood reason for that. Twenty years from now I'm not going to give a shit\nabout which library rendered which obscure demo the fastest. But I will\nremember...\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Who is a better puppy? <a\nhref=\"https://twitter.com/bcardarella\">@bcardarella</a> or <a\nhref=\"https://twitter.com/mikepack_\">@mikepack_</a> ? Follow\n&quot;modernweb&quot; on snapchat for the full story <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://t.co/VBPruOLft2\">pic.twitter.com/VBPruOLft2</a></p>&mdash;\nTracy Lee | ladyleet (@ladyleet) <a\nhref=\"https://twitter.com/ladyleet/status/714298487857262592\">March 28,\n2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Having some fun with the tomster at <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://twitter.com/EmberConf\">@EmberConf</a> 🇨🇴 <a\nhref=\"https://t.co/zjFd3ll5EB\">pic.twitter.com/zjFd3ll5EB</a></p>&mdash;\nJulián Cárdenas Mazo (@juliankmazo) <a\nhref=\"https://twitter.com/juliankmazo/status/715343497956438016\">March\n31, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Kudos to <a\nhref=\"https://twitter.com/thejameskyle\">@thejameskyle</a> for the most\nvisually entertaining talk at <a\nhref=\"https://twitter.com/hashtag/EmberConf?src=hash\">#EmberConf</a> <a\nhref=\"https://t.co/INwmqboMVo\">pic.twitter.com/INwmqboMVo</a></p>&mdash;\nWedge Salad Antilles (@suzidao) <a\nhref=\"https://twitter.com/suzidao/status/715297031703568384\">March 30,\n2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">I love <a href=\"https://twitter.com/EmberConf\">@emberconf</a>\n<a href=\"https://twitter.com/hashtag/ImgPlay?src=hash\">#ImgPlay</a> <a\nhref=\"https://t.co/plZWIsoyku\">pic.twitter.com/plZWIsoyku</a></p>&mdash;\nEmanuele Tozzato (@mekdigital) <a\nhref=\"https://twitter.com/mekdigital/status/714954113050501122\">March\n29, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Loved my new Ember socks :) thanks <a\nhref=\"https://twitter.com/EmberConf\">@EmberConf</a> <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://twitter.com/hashtag/portland?src=hash\">#portland</a> <a\nhref=\"https://twitter.com/hashtag/socks?src=hash\">#socks</a> <a\nhref=\"https://t.co/X2odXYlgVK\">pic.twitter.com/X2odXYlgVK</a></p>&mdash;\nFilipe Bragança (@filipecrosk) <a\nhref=\"https://twitter.com/filipecrosk/status/714592198868611072\">March\n28, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">So good seeing <a\nhref=\"https://twitter.com/cball_\">@cball_</a> at <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a>!\n❤️💛💚💙💜 see you at <a\nhref=\"https://twitter.com/WickedGoodEmber\">@wickedgoodember</a>? <a\nhref=\"https://twitter.com/hashtag/emberjs?src=hash\">#emberjs</a> <a\nhref=\"https://t.co/fpW6HlinlA\">pic.twitter.com/fpW6HlinlA</a></p>&mdash;\nTracy Lee | ladyleet (@ladyleet) <a\nhref=\"https://twitter.com/ladyleet/status/715719754661502977\">April 1,\n2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\"\ndir=\"ltr\">Farewell Ember Conf, until next time. <a\nhref=\"https://twitter.com/hashtag/emberconf?src=hash\">#emberconf</a> <a\nhref=\"https://t.co/7PsVcd7lsR\">pic.twitter.com/7PsVcd7lsR</a></p>&mdash;\ntomguisuru (@tomoguisuru) <a\nhref=\"https://twitter.com/tomoguisuru/status/715415989110747136\">March\n31, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\"\ncharset=\"utf-8\"></script>\n\n...the people.\n\n[gk]: http://groundkontrol.com/\n[leah]: http://twitter.com/wifelette\n[elixir]: http://elixir-lang.org\n[pwa]: https://developers.google.com/web/progressive-web-apps?hl=en\n[emberconf]: http://emberconf.com\n[estelle]: http://twitter.com/edeblois\n[lauren]: http://twitter.com/sugarpirate_\n[tom]: https://twitter.com/tomdale\n[yehuda]: https://twitter.com/wycats\n[embercamp]: https://web.archive.org/web/20130613165616/http://lanyrd.com/2013/ember-camp\n[railsconf]: http://railsconf.com\n[killer-queen]: http://killerqueenarcade.com/\n"},{"title":"Some user involvement is good for design. But is more better?","tags":["design","design process","design thinking"],"summary":"Collaborative design is being touted as the next level of user-centered design. But it doesn't guarantee a better outcome. Learn about some of the pitfalls — and how to avoid them.","legacy":false,"illustration_alt":"beigecar","illustration":"https://i.imgur.com/pzsFUsU.jpg","id":"2016/04/05/some-user-involvement-is-good-for-design-but-is-more-better","employee":"Mark Kaplan","date":"2016-04-05T00:00:00","body":"\n\nIn a typical UX project, user involvement begins early on, as part of research. This leads to insights, which lead to a concise definition of the design problem(s) we're tasked with solving. Then we disappear and transmogrify our inputs into concepts. The users return for usability testing. Their collective feedback informs the next iteration of the concept.\n\nA movement to keep users around for the entire design process has been gaining traction. Whether it's called \"collaborative design,\" or \"co-creation,\" or \"generative design,\" the starting premise is that everyone, users included, is capable of being a designer. Stick figures welcome.\n\nI recently attended a local design thinking meetup which sought to introduce us to co-creation by having us each design a new service for ordering pizza or sushi. First we’d each sketch something using Sharpies and Post-Its. Then we’d engage one our peers as a “user” to interpret and edit what they saw. We repeated this 3 times, with each user moving the design forward from the point where the last left off.\n\nIt was a lot of fun and highly engaging. The reactions from the participants were overwhelmingly enthusiastic. But I was surprised to find that the end result was a room full of nearly identical designs — both to each other and to what already exists in the marketplace. All were some variation of: 1 Select a location, 2 View the menu, 3 Order something, 4 Check out, 5 Thank you.\n\nWith a design brief that was akin to, \"Design a new car — anything you want,\" we ended up with a lot full of lookalike beige sedans. No bold hypercars. No original go-anywhere vehicles that could hop a chasm if commanded to do so. This outcome was especially concerning given we weren't \"typical users\" — we were mostly \"designers.\" So, what happened?\n\n![beigecar](https://i.imgur.com/pzsFUsU.jpg)\n\nImage Credit: [KIA Media](http://www.kiamedia.com/us/en/models/amanti/2006)\n\n##Don’t Facilitate — Collaborate\n\nWe were asked to adopt a facilitator's mindset when co-designing. This meant that we pushed and prodded our users into both finding problems and fixing them with design.\n\nUsers are experts in identifying that problems exist. This is why usability testing works so well. But their ability to articulate the cause(s) of problems and designing solutions varies with their expertise, experience, and aptitudes. A user can tell you they hear a rattle when making a left turn, but unless they have experience in auto mechanics, they likely can’t tell you what’s causing the noise, or make the repair.\n\n![mechanic](https://i.imgur.com/DiADxmL.jpg)\n\nImage Credit: [Funzy Pics](http://funzypics.com/board/pins/376/16036)\n\nFinding problems and fixing problems are not the same activity. While simple problems have an obvious cause and effect, most problems faced by designers are complicated or complex — their causes and/or solutions are not obvious and require further analysis or expertise. Homer Simpson can bang together a doghouse from a bunch of boards, but only skilled architects, engineers and builders can erect a skyscraper and expect it to stand.\n\n![homerdoghouse](https://i.imgur.com/0H4NRPL.jpg)\n\nImage Credit: [frinkiac.com](https://frinkiac.com/caption/S03E16/1107454)\n\n###Tips for Designers:\n1. Design with the user as an equal partner. Think through problems and solutions together, allowing both of your perspectives and expertise (them as user, you as designer) to inform where things go.\n2. Put faith in what users identify as problems. Even if all they can articulate is that “something doesn’t feel right,” chances are, they’ve stumbled upon something that needs to be thought through.\n3. Encourage multiple cause hypotheses and multiple solutions by coaching the user through the problem solving process:  What do you think is the cause of that problem?  What else could it be?  What else? What’s a solution for it?  What’s another?  And another?\n4. Pool the ideas generated from co-creation activities with other possible ideas conceived separately by designers; downselect from there. Designers have an obligation to propose the best possible solutions. It is important to include ideas from designers who know many design patterns (and when to use them), understand context and behavior, and give equal weight to what's left unsaid or undone.\n\n##Use the Appropriate Concept Fidelity\n\nThe ground rules for the collaborative part of the pizza/sushi activity were to use Socratic questioning, similar to how we do it in usability testing: the facilitator should answer “What is this?” with \"What do you think it is?\"  As a result, none of my users were able to decipher this image:\n\n![stickynote](https://i.imgur.com/WpoacJi.jpg)\n\nIt was supposed to be a livestream of a sushi chef making your sushi, in an attempt to bring the sushi-bar experience home.\n\nBecause the method we used called for real-time editing, one of the potential differentiating features was edited-out solely because of a poorly drawn stick figure. So much for the premise that \"everyone is a designer.\"\n\n###Tips for Designers:\n\n1. When sketching concepts, consider increasing the fidelity beyond the bare minimum of Sharpies on Post-its — for example, use pencils and/or larger Post-Its. This can allow for a bit more detail and/or annotations for those that prefer words to pictures.\n2. If a user cannot interpret a low-fidelity sketch, allow clarifying questions to be asked and answered, in addition to Socratic questioning.\n\n##Avoid Design by Committee\nTeamwork is effective in accomplishing shared goals: Dribble, pass, shoot, score. But have you heard the expression \"too many cooks spoil the broth?\"  The idea is that each might add a different ingredient, which, in the end, creates something unpalatable.\n\n![designcurve](http://i.imgur.com/Qw31rmg.jpg)\n\nImage Credit: [Moz](https://moz.com/blog/how-to-ruin-a-web-design-the-design-curve)\n\nIf we allow every user to manipulate the design — one after the other — we may end up with an unappetizing design that pleases no one. That’s what happened In our sushi/pizza exercise — each user started where the previous user left off and were free to change the design to their liking.\n\nWhat if a user changed or removed something a subsequent user might have found compelling in its earlier form?  What if the final user added something that none of the previous users would have found to their liking, or removed something that excited all the others?  Clearly, the order in which users took their turn designing impacted the outcome. It was a handoff, rather than a handshake.\n\nYou don't need a whole committee to spoil the broth — one empowered user can muck things up quite well on their own given half a chance. Homer Simpson was tasked with designing a car for the \"average American\" and came up with The Homer, a completely unworkable solution:\n\n![thehomer](https://i.imgur.com/vbeJYbg.png)\n\nImage Credit: [Simpsons Wiki](http://simpsons.wikia.com/wiki/The_Homer)\n\n###Tips for Designers:\n1. Provide users with a common problem statement. All designers need context and constraints. Provide these in a well-articulated problem statement (e.g. \"We're trying to do [something] for [someone], without [negative consequences/constraints]\"). Edit out any ideas that don't conform to the statement.\n2. Reset the concept between users. Let everyone begin at the same place and end up where they will. Compare and contrast the results.\n3. Use other collaborative design methods that allow multiple users to work together on the same problem at the same time. Two examples are [Lego Serious Play](http://www.lego.com/en-us/seriousplay), and [Convivial Toolbox](http://www.bispublishers.com/elizabeth-sanders-and-pieter-jan-stappers-convivia.html).\n\nAs seen with the pizza and sushi app exercise, collaborative design has the potential lead to a lesser result than if users had only been consulted before and after the act of designing. But it still offers tremendous potential to improve products and services. In the next post, I’ll talk about some areas where collaborative design can add value.\n"},{"title":"A Match Made In Heaven","tags":["engineering","ember"],"summary":"An example of how `ember-concurrency` could have helped reduce code complexity in a timer-heavy app.","legacy":false,"id":"2016/04/10/a-match-made-in-heaven","employee":"Estelle DeBlois","date":"2016-04-10T00:00:00","body":"\n\nUnless you've been living in a bubble, I'm sure you've all heard of [`ember-concurrency`][ember-concurrency-gh]. It's been all over Twitter; it's been brought up on Ember Weekend; it was even mentioned during this year's EmberConf keynote.\n\nThis past February, [Alex Matchneer][machty] gave us a walkthrough of his addon at the monthly [Boston Ember.js Meetup][boston-ember]. There is ample documentation and examples on the [website][ember-concurrency-docs] already, so I will forgo the details, but the TL;DR is that `ember-concurrency` offers an elegant way to write asynchronous, cancelable tasks in an Ember app. It also leverages the power of [generators][generators] so we can adopt a more readable, synchronous-like syntax.\n\nI was unfortunately way too busy working on my talk for EmberConf at the time, that I didn't really get a chance to take the addon for a spin. But it was clear in my mind that the problems the addon addresses were the exact type of problems we had to solve in more traditional ways a year ago, as part of a client project.\n\nIt's a project I have brought up in the past when [demonstrating][ember-nw] the use of Ember in a NW.js-powered desktop app, but it just happens to also be a perfect candidate for `ember-concurrency`.\n\n* Did we find ourselves having to invoke `Ember.run.cancel` to cancel previously scheduled tasks? Yes, indeed.\n* Did we have to clean up asynchronous tasks in `willDestroy` hooks? Absolutely.\n* Did we have to write guards to prevent an operation from running concurrently? For sure!\n\nOne of the goals of the app was to provide indoor cycling instructors with a better interface for managing and running a class, including a built-in roster and classroom map of which bikes riders had reserved, tools to start a class, start a race, view real-time stats and ranking, etc.\n\nWhile we wrapped up the project a while ago, I felt compelled to recreate the elements that could have benefited from `ember-concurrency` in this (highly) simplified [demo app][demo-app].\n\nTo give a bit of context, a class runs for a specific amount of time, e.g. 1 hour. During that time, students can ride at their own pace. At various times during the session, the instructor may initiate a race that lasts 30, 45, or 60 sec. Racing occurs numerous times during a class, and one critical piece of information the app needs to convey to the instructor is how much time is left within any given race, as well as how much time is left before the end of a class. You don't want to accidentally start a 60 sec race if there's only 10 sec left of class time!\n\nLet's take a look at the more traditional approach of managing a race timer with `Ember.run.later`.\n\nWe have a `race-panel` component that holds the race buttons for various race duration options. When a race button is pressed, the `race-panel` component's `startRace` action is invoked with the duration specified by the button itself (in seconds):\n\n```js\n// In app/components/race-panel/component.js\nactions: {\n  startRace(duration) {\n    if (!get(this, 'isRaceInProgress')) {\n      this.startTimer(duration);\n    }\n  }\n}\n```\n\nThe first thing we do is check whether a race is already in progress, as there can only be at most one active at any given time.\n\nIf the way is clear, we start the race timer. The main function here is `updateTimer`, which calls itself every second, each time decrementing the race counter, until we reach 0.\n\n```js\nisRaceInProgress: computed.gt('countdown', 0),\n\nstartTimer(duration) {\n  set(this, 'countdown', duration);\n  this.updateTimer();\n},\n\nupdateTimer() {\n  let timerId = run.later(() => {\n    let countdown = this.decrementProperty('countdown');\n    if (countdown > 0) {\n      this.updateTimer();\n    } else {\n      this.stopTimer();\n    }\n  }, 1000);\n\n  set(this, 'timerId', timerId);\n},\n\nstopTimer() {\n  set(this, 'timerId', null);\n},\n```\n\nThe reason we need to store the ID of the operation started by `run.later` is so we can cancel it should the user navigate away (e.g. by aborting the class rather than let it run to completion). This means we also need to implement a `willDestroy` hook to do the clean up work:\n\n```js\nwillDestroy() {\n  let timerId = get(this, 'timerId');\n  if (timerId) {\n    run.cancel(timerId);\n  }\n},\n```\n\nThe value assigned to the `countdown` property is used by the component to display a race timer in the instructor's UI.\n\nThis isn't rocket science, but if you consider the fact that we also need to disable race buttons depending on whether a race is already in progress, or disable specific race duration options depending on how much time is left in a class, all while keeping track of the class overall progress and possible early termination, this does end up being quite a lot of timer-related code to get right and maintain.\n\nWith `ember-concurrency`, the above can be simplified to just the following:\n\n```js\nraceTask: task(function* (duration) {\n  let countdown = set(this, 'countdown', duration);\n  while (countdown > 0) {\n    yield timeout(1000);\n    countdown = this.decrementProperty('countdown');\n  }\n}).drop()\n```\n\nThe generator function allows us to write asynchronous code that feels synchronous, while the special `task` function lets us adhere to the idea of [structured concurrency][structured-concurrency].\n\nWe can instantiate the race task directly from the template, using the `{{perform}}` helper that the addon provides. In addition, figuring out if a race is in progress is just a matter of checking the value of `raceTask.isRunning`.\n\n```hbs\n{{#each raceDurations as |duration|}}\n  <button disabled={{or raceTask.isRunning (gte duration classTimeRemaining)}}\n      onclick={{perform raceTask duration}}>{{duration}}</button>\n{{/each}}\n```\n\nEven though we are disabling the race buttons when a race is already in progress, having the option to use the `.drop()` task modifier in the component code guards us further against concurrent races in a more elegant way than if we had to do so via an internal property. The modifier ensures that future requests to run the race task will be dropped until the current one completes.\n\nThe best part, however, is that we no longer need those `willDestroy` hooks as `ember-concurrency` automatically manages the lifecycle of these tasks for us, so we can rest at ease knowing that when our component is destroyed, all tasks will be cancelled and cleaned up as well.\n\nThe result is a clear reduction in boilerplate code to manage asynchronous tasks and timers, as well as code that is much more readable overall. In short, I wish this had existed a year ago when we were still active on the project, but these sorts of asynchronous operations are common enough that they're sure to come up again. They don't have to necessarily deal with time-related events, as you can `yield` promises that hit some backend API as well, and let `ember-concurrency` handle the trickier concurrency or task cancellation logic.\n\n[ember-concurrency-gh]: https://github.com/machty/ember-concurrency\n[machty]: https://twitter.com/machty\n[boston-ember]: http://www.meetup.com/Boston-Ember-js/events/228333385/\n[generators]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function*\n[ember-concurrency-docs]: http://ember-concurrency.com/\n[ember-nw]: https://dockyard.com/blog/2015/03/26/bringing-ember-to-the-desktop-part\n[demo-app]: http://brzpegasus.github.io/concurrency-demo/\n[structured-concurrency]: http://alexmatchneer.com/ec-prezo/#/?slide=structured-concurrency-1\n"},{"title":"TIL: Elixir can pattern match at multiple depths in a single statement","tags":["elixir","til"],"summary":null,"legacy":false,"id":"2016/04/13/til-elixir-can-pattern-match-at-multiple-depths-in-a-single-statement","employee":"Marin Abernethy","date":"2016-04-13T00:00:00","body":"\n\nOne of Elixir's greatest assets is its [pattern matching][matching-post]. If you have\never used Elixir, you have probably had the pleasure of writing\nsomething like:\n\n```elixir\ndef background_check(%{manager: employee} = company) do\n  %{name: full_name} = employee\n\n  from(c in Criminals,\n  where: c.full_name == ^full_name,\n  select: c)\n  |> Repo.one\n  |> case do\n    nil -> congratulate(employee)\n    criminal -> notify(company)\n  end\nend\n```\n\nHere we are assigning the entire parameter map to a variable called\n`company`, and pattern matching to get the `employee` we want to\ndo a background check on. We need to query our `Criminals` database\ntable for a `criminal` with the same name as our `employee`. To do so, we first have to grab\nthe `name` property off the `employee` object.\n\nWell, **today I learned**, that you can have multiple matches in a\nsingle statement! With this newly acquired knowledge, we can simplify\nour `background_check()` function definition:\n\n```elixir\ndef check_company(%{manager: %{name: full_name} = employee} = company) do\n  from(c in Criminals,\n  where: c.full_name == ^full_name,\n  select: c)\n  |> Repo.one()\n  |> case do\n    nil -> congratulate(employee)\n    criminal -> notify(company)\n  end\nend\n```\n\nNow we can pattern match to get the `employee`'s `full_name`, while also\nassigning the entire map under the `manager` key to the variable `employee`, as we did before.\n\nHopefully, you learned something too! Enjoy.\n\n[matching-post]: https://dockyard.com/blog/2014/12/26/pattern-matching-in-elixir-for-rubyists\n"},{"title":"Ember: Declarative Templating with Composable Helpers","tags":["ember","javascript","addon"],"summary":"Use small, composable helpers to power up your templates.","legacy":false,"id":"2016/04/18/ember-composable-helpers","employee":"Lauren Tan","date":"2016-04-18T00:00:00","body":"\n\n[Previously][previous-post], I mentioned that Ember's new `Helper` implementation landed in [1.13][helper-introduced]. In my opinion, helpers are one of the most useful, yet least talked about features in Ember.\n\nIn my EmberConf 2016 talk ([video][idiomatic-ember]) on Idiomatic Ember, I spoke about helpers in detail, showing how they can be used to power up and essentially extend [Handlebars][handlebars] with custom functionality. These helpers can then be used to allow declarative templating - a style of templating by composing actions, and giving templates more responsibility with regards to presentational logic.\n\nTogether with fellow DockYarder [Marten Schilstra][marten], we've created the [ember-composable-helpers][ember-composable-helpers] addon. It's a package of declarative helpers that lend themselves naturally for composition, and using it can help remove boilerplate code in your app. You can install it today with:\n\n```\nember install ember-composable-helpers\n```\n\nOne of my favorite helpers in the addon is the `pipe` helper (and its closure action cousin, `pipe-action`). This lets you declaratively compose actions in your template, instead of creating many variants in your Component:\n\n```hbs\n{{perform-calculation\n    add=(action \"add\")\n    subtract=(action \"subtract\")\n    multiply=(action \"multiply\")\n    square=(action \"square\")\n}}\n```\n\n```hbs\n{{! perform-calculation/template.hbs }}\n<button {{action (pipe add square) 2 4}}>Should be 36</button>\n<button {{action (pipe subtract square) 4 2}}>Should be 4</button>\n<button {{action (pipe multiply square) 5 5}}>Should be 625</button>\n```\n\nThis pipe helper was inspired by Elixir's pipe operator (`|>`), which lets you write the following:\n\n```elixir\nA(B(C(D(E), \"F\"), \"G\"), \"H\")\n```\n\nAs a series of data transforms:\n\n```elixir\nE\n|> D()\n|> C(\"F\")\n|> B(\"G\")\n|> A(\"H\")\n```\n\nUsing the pipe operator, we can naturally express how `E` is passed to the `D` function, then the return value of that function is passed into `C` as its first argument, and so on. I think we can agree that the pipe version is a lot easier to read!\n\n## If only you knew the power of the Helper\n\nYou can think of a helper as a primitive `KeyWord` construct used by Ember and HTMLBars to extend the ordinary expressions provided by Handlebars. At its most basic level, the Handlebars library is responsible for compiling the `hbs` language down to HTML:\n\n```hbs\n<p>{{myText}}</p>\n<!-- compiles down to: -->\n<p>Hello world!</p>\n```\n\nEmber and HTMLBars then builds on top of this, adding useful keywords like `action`, `mut`, `get`, and `hash`. In fact, all the familiar keywords you've been using (everything from `each` to `component`) are [actually HTMLBars helpers under the hood][everything-is-a-helper]!\n\nEmber Helpers operate at a higher level compared to HTMLBars helpers, but can also be used as a way to let you create new keywords in Ember, effectively allowing you to extend templating with custom behavior.\n\n## It depends\n\nMore experienced or conservative developers might see this as a red flag: while making this framework construct available to end-users is useful, it can also open up potential for abuse. \n\nFor example, in Elixir, macros can be used to extend the language, but aren't recommended unless you _really_ need to. In fact, this has been informally codified in the excellent [Metaprogramming Elixir][meta] book by [Chris McCord][chris] – \"Rule 1: Don't Write Macros\".\n\nFortunately, helpers aren't quite as powerful as Elixir macros, and play an important role in the Ember programming model. Unlike a macro, which lets you reach down to the AST, using an Ember helper to extend presentational logic is OK _as long as we don't abuse it_, and that distinction is where experience comes into play. So use helpers responsibly.\n\n## Get your logic off my lawn\n\nSome people may feel uneasy using addons containing helpers because of the misconception that it introduces too much logic in their templates, and that they prefer to keep their templates logic-free.\n\nAs a best practice, we should strive not to have complicated logic in our templates, and when your sub-expression looks like this:\n\n```hbs\n{{#unless (or (and (gte value 0) (lt value 0.0001))\n              (and (lt value 0) (not allowNegativeResults)))}}\n  ...\n{{/unless}}\n```\n\nIt's a sign that you're better off using a computed property. \n\nOn the other hand, keeping your templates 100% logic-free is really hard – you're likely already using a logical helper like `if/else` or `unless`. It can be easy to lose sight of the fact that the amount of logic in your template lies on a spectrum, and is not a strict dichotomy.\n\n## Back to the future\n\n`ember-composable-helpers` doesn't significantly increase the amount of logic in your templates – in fact, if used correctly, it encapsulates presentational logic within these helpers, and in many cases can help you eliminate now redundant code in your Components or Controllers.\n\nFor example, you might have written something like this in your app:\n\n```js\nimport Ember from 'ember';\n\nconst { \n  Component, \n  computed: { filterBy, setDiff }, \n  set \n} = Ember;\n\nexport default Component.extend({\n  activeEmployees: filterBy('employees', 'isActive'),\n  inactiveEmployees: setDiff('employees', 'activeEmployees')\n});\n```\n\nIt's quite common to have \"intermediary\" CPs in your Component that you then use in some other CP. Using `ember-composable-helpers` lets you compose that directly in the template, where the intent becomes incredibly clear:\n\n```hbs\n<h2>Active Employees</h2>\n{{#each (filter-by \"isActive\" engineers) as |employee|}}\n  {{employee.name}} is active!\n{{/each}}\n\n<h2>Inactive Employees</h2>\n{{#each (reject-by \"isActive\" engineers) as |employee|}}\n  {{employee.name}} is inactive!\n{{/each}}\n```\n\nYou can think of a composable helper as a kind of computed property macro that you can use and compose directly in your template. And since you can compose sub-expressions in Ember, these can become powerful constructs to reduce boilerplate code in your application.\n\nWith that said, remember not to get too carried away with deeply nesting helpers!\n\n## Exercise best judgment\n\nAs with all programming tools, it's important to exercise best judgment and use them responsibly. \n\n> Just because you can do something doesn't mean that you _should_.\n\nA well written view layer means that templates should be as declarative as possible (communicate intent clearly), and not that we should avoid logic altogether. That said, we're not advocating for moving all your logic into your template – again, it's not a dichotomy, but a spectrum.\n\nIf you'd like to see how the addon is being used, [Katherin Siracusa][katherin] wrote an excellent [blog post][katherin-blogpost] about how she uses `ember-composable-helpers` at [AlphaSights][alphasights]:\n\n> This pattern, of performing some significant, data-changing action and subsequently performing a more ancillary, short-term state-like action, keeps arising in our application. Using [...] composable-helpers, we can take care of this in a fairly straightforward way, without much duplication and without having to worry about unintended side effects.\n\nYou can also join in the discussion on our Slack channel [`#e-composable-helpers`][slack].\n\nAs always, thanks for reading!\n\n[alphasights]: https://www.alphasights.com\n[chris]: https://twitter.com/chris_mccord\n[ember-composable-helpers]: https://github.com/DockYard/ember-composable-helpers\n[everything-is-a-helper]: http://emberjs.com/api/classes/Ember.Templates.helpers.html\n[handlebars]: http://handlebarsjs.com/\n[helper-introduced]: http://emberjs.com/blog/2015/06/12/ember-1-13-0-released.html#toc_new-ember-js-helper-api\n[idiomatic-ember]: https://www.youtube.com/watch?v=lP9ap-AKBAM&list=PL4eq2DPpyBblc8aQAd516-jGMdAhEeUiW\n[katherin-blogpost]: https://m.alphasights.com/composable-helpers-and-route-actions-two-ember-add-ons-you-should-know-655cf39fd9de#.y63wvqjpm\n[katherin]: https://twitter.com/katherinlaine\n[marten]: https://twitter.com/Martndemus\n[meta]: https://pragprog.com/book/cmelixir/metaprogramming-elixir\n[previous-post]: https://dockyard.com/blog/2016/02/19/best-practices-route-actions\n[slack]: https://ember-community-slackin.herokuapp.com/\n"},{"title":"Is it time to call a designer?","tags":["design","ux design","business","design strategy"],"summary":"Since its beginnings in the 1800s, design as a profession has grown to the point that it now touches almost every aspect of our lives. But we still often assume it’s just about decoration.","legacy":false,"illustration_alt":"","illustration":"https://i.imgur.com/nqrP5EE.jpg","id":"2016/04/19/is-it-time-to-call-a-designer","employee":"Maria Matveeva","date":"2016-04-19T00:00:00","body":"\n\n\nThere is an old fable about a philosopher. A baby was born, and the parents presented the baby to the philosopher in their city at the age of just one month. They apologized for being so early, and asked for advice on how to best plan for an education so the baby would grow up as a proper citizen. To which the philosopher replied - “You’re not too early. You are ten months late.”\n\nI could not track down a proper source for this - most likely it’s an ancient Confucian fable. But I always come back to it when I plan and schedule design work. The moral of it keeps coming to mind: “you thought it was too early, but it’s best to start even earlier.”\n\n\n## Why we think “it’s too early” to add design\n\nIn fact, many people have the understanding of what design can do for business based on a historical truth. The value (and timing) for design seems closely tied to the idea of decoration and the value it could add to mass produced consumer products. This understanding is rooted in the late 1800s, when adding decorative elements to mass produced consumer goods made them more attractive to the public. The decoration helped increase sales from what people practically needed and drove consumer demand based on a desire for updated styles.\n\n\n![](https://i.imgur.com/nqrP5EE.jpg)\n\n*Mass production allowed for “designed” (but actually decorated) consumer products to be widely available at the turn of the last century.*\n\n\n## The other jobs of design\n\nI often hear a similar “decorative” understanding of design when I talk to people about what my job is today. At the recent MIT Ideas [Global Challenge](http://globalchallenge.mit.edu/), hosted at the Media Lab, I talked to several of the teams about their goals, and UX design. All the teams were very enthusiastic, but in every conversation I heard the phrase “once we finish X technology, we’ll be ready for design…” This phrase reveals an assumption that design is something you might apply on top of an existing product or service, once it’s almost finished.\n\n\n\n![](https://i.imgur.com/ao0QwB0.jpg)\n\n*MIT Ideas Global Challenge presentations event in April 2016*\n\nThe way to think about what design can do for business, in fact, is almost exactly the opposite. Applying design - specifically, design thinking - at the inception of a project will allow for the greatest impact.\n\n\n## Why start with design\n\nDesign today is well adapted to dealing with unknowns, considering the big picture, and proposing a way forward. You can name specific steps, such as design research, user experience design, and user story development - or keep everything under the bigger umbrella of “design”. But it is the ability to start early (before everything is known) and move forward in an iterative manner (by testing and improving) that makes design impactful at the early stages of a product or service.\n\n\n![](https://i.imgur.com/YNN6FhV.jpg)\n\n\nBusiness leaders are well aware of the value visual design can bring to their products. But strategic design, applied early in the life of a project, is often a missed opportunity. To get the best value from the latest design practices, consider it early, and bring a designer to the table at the first stages of product strategy. \n\nFor a deeper look into the relationship between design & business, check out John Maeda’s [Design in Tech report](http://www.kpcb.com/blog/design-in-tech-report-2016). In it, he presents compelling proof of the value design brings, and predicts the top three directions in which design will experience the most growth over the next year.\n"},{"title":"A learning experience in web application design (part 2 of 2)","tags":["design","design process","design thinking"],"summary":"A speculative project that challenged me to fully consider a range of interface states.","legacy":false,"illustration_alt":"sp_01","illustration":"http://i.imgur.com/FtLpVfM.png","id":"2016/04/20/a-learning-experience-in-web-application-design-part-2","employee":"Chris Bowers","date":"2016-04-20T00:00:00","body":"\n\nIn my [last post](https://dockyard.com/blog/2016/03/11/a-learning-experience-in-web-application-design-part-1), I described Sprout Pass, a speculative project for a web application that would deliver fresh local produce right to one’s doorstep. Sprout Pass is inspired and informed by the idea of community-supported agriculture, also known as farm sharing. Sprout Pass would facilitate orders and delivery between users and their local farmers. \n\nUsers need a UI they can trust and enjoy, especially for a perishable product like produce.  Coming to DockYard from a background in print design, I wanted to explore how an interface provides user support. An interface communicates with a user through feedback and component states, which have the potential to build trust and positive experiences. I consolidated my exploration, planning, and research to focus on the visual UI design. To cover my bases, I designed component screens with a broad range of associated states. \n\nMy first consideration for the app's visual design was its color selection. Produce delivery applications aren’t exactly a flooded market, so while green might be an “obvious” choice, it was a viable branding option. I chose a positive green that’s closer to blue than yellow to avoid an overly acidic aesthetic. For the typography, I relied on the humanist sans serif Whitney, because the heavier weights of this typeface have an honest and friendly tone that establish the personality of Sprout Pass. Let's go through a few examples of different states an interface can be in. \n\n##Before a user does anything\n\nEvery introduction has the potential to start a new, meaningful relationship. Before subscribing, a user must know what Sprout Pass can do to enhance their quality of life. The introduction for Sprout Pass allows the user to swipe through as much of the content as they want while always providing a path to sign up or login. \n\n![sp_01](http://i.imgur.com/FtLpVfM.png)\n\nBackground photo credit: [Sven Scheuermeier](https://unsplash.com/photos/4R1YpmGO52I)\n\n##Confirmation & errors\n\nConfirmations and errors will dynamically appear next to input fields, to reassure the user of their progress as they work on the form. For questions that require more thought on the user's part, inline validation messages can help people complete web forms faster and with less effort. If you’d like a more detailed reference for when to show inline validation, Luke Wroblewski [tested inline validation](http://alistapart.com/article/inline-validation-in-web-forms) against the submit-and-refresh model. \n\nFor this sign up, both input states use color and icons to identify and distinguish themselves without being overly dramatic. The brand color is a saturated green, which correlates with correct and positive states. The submit button would turn this color when every validation has been satisfied. \n\nError states are a necessary part of any application, but the language and form of them is often overlooked. The brand’s personality should manifest itself through all bits of copy, even the error states. Negativity and blame in error states doesn’t contribute to a successful application experience. For the invalid email example, Sprout Pass takes the blame for the error and offers a solution. Model applications like MailChimp and Tumblr maintain a charming personality while doing this as well. \n\n![sp_02](http://i.imgur.com/duEZdAS.png)\n\n##Empty state | An existing component with no data\n\nNew users typically love to poke around before making any purchases or commitments, but Sprout Pass initially won’t have any data to fill its various components. Engaging and informative empty states support this behavior, and can lead to greater customer retention. Other instances of empty states can exist when a user clears the data or an error occurs. When a new user opens Sprout Pass, there won’t be much to show them at first, but they can still be engaged.  A successful empty state will delight, educate, and motivate the user to add information and interact with the app. In this empty state, a bit of copy identifies what will eventually exist, and the vibrant green button is used as direction.\n\n![sp_03 + sp_04](http://i.imgur.com/0v94ZqZ.png)\n\nBackground photo credit: [Matt Benson](https://unsplash.com/photos/rHbob_bEsSs)\n\n##Done | Ensuring a successful transaction\n\nTo reassure the user of their order completion, the brand color overtakes the screen for a positive order confirmation. The color and icon, consistent with the completed state, combine to substantiate the order confirmation. This screen also prompts the user with two paths forward. This keeps the user engaged while the application is in between waiting for and scheduling packages.\n\n![sp_05 + sp_06](http://i.imgur.com/wI2iN9u.png)\n\n##Ideal state\n\nThe completed package screen is where most users will become more familiar with the application. They will see this section for the longest amount of time, unlike some of the other states that will be viewed only for a few moments. The selection process and empty state have prepared the user for this level of complexity. Because the primary objective of this product is a delivery service, the status of the next delivery is most prominent. This screen updates to track delivery progress, and the editing function becomes inactive 48 hours before deliveries. \n\n![sp_07 + sp_08](http://i.imgur.com/JUVj8sQ.png)\n\n##Too much | Managing full data sets\n\nWhen the past orders history exceeds the set limit of five items, this state identifies quantity and provides access to the full dataset. The user is going to want to know how much more history there is available to them.  If the quantity and navigation of your data isn't intuitive, a too much state can be very frustrating. This Sprout Pass content is condensed and limited by time, so the full history does not require pagination.\n\n![sp_09](http://i.imgur.com/zyIrMiE.png)\n\n##Final thoughts\n\nExploring Sprout Pass helped me develop a familiarity with interface states that I admittedly would have overlooked. After understanding the value and characteristics for each state, I was able to apply my knowledge of visual systems and hierarchy. Every state of a web application component is integral to a user’s positive experience and should be designed with intention. Thoughtfully designed interface states will reduce the risk of confusing or surprising a user, and all of these states work together to make a streamlined experience. \n"},{"title":"Choosing a Strategy + Design Partner","tags":["design","design process","design thinking"],"summary":"It can be hard to tell agencies apart. Strategy can make all the difference. Learn how to spot a strategic agency.","legacy":false,"illustration_alt":"Mad Men Barbie Dolls","illustration":"https://i.imgur.com/iHgcgzh.jpg","id":"2016/04/26/choosing-strategy-design-partner","employee":"Mark Kaplan","date":"2016-04-26T00:00:00","body":"\n\n![Mad Men Barbie Dolls](https://i.imgur.com/iHgcgzh.jpg)\nImage Credit: [AMC](http://www.amc.com/shows/mad-men/extras/mad-men-barbie-dolls#/1)\n\nYou’re interviewing candidates for an opening on your team. You’re torn between two finalists. Each has deep skills and experience, comes with solid references, and would increase diversity. In both a subjective or objective evaluation, they’d be equal.\n \nHow can you make such an important decision, without resorting to a coin flip?  \n\nChoosing a partner for strategy and design of web applications is a lot like hiring that new team member. Every agency you’ll meet will tell you about their services and “The Process.” They’ll share a cloud of client logos and case studies with slick creative and impressive results. Their offices will be way more hip than yours. You’ll be shown a photo of a designer pointing to a wall of design artifacts.\n \nWith every agency pitching what can feel like the same experience and capabilities, how do you choose?  \n\n## The Client Should Always Come First\n\n>“A gossip talks about other people. A bore talks about himself. A brilliant conversationalist talks to you about yourself.”\n>\n>—Unknown\n\nIn a similar vein, an agency that understands the importance of objectives in design will move quickly from talking about their reputation, to a deeper conversation about you and your business goals. They’ll get excited about what could be accomplished together. \n\nDo the memebers of the team seem interested in listening to you, and learning from you?  Are they focused on trult understanding the problems, rather than jumping to their favored solutions?  \n\nAre they asking deep questions about your goals?  Your past successes and failures?  Your personal situation? They should regard their job as not only to deliver what you want and need but also to make you look good.\n\n## Become Comfortable by Being Uncomfortable\n\n>“If it scares you, it might be a good thing to try.”\n>\n>—Seth Godin\n\nAs you answer the agency’s questions, also pay attention to the kinds of questions they ask. Are they making you uncomfortable with some of those questions? That’s OK.  \n\nSometimes the most important questions are uncomfortable because they challenge some sacred-cow assumptions. They may force you to reconsider things that really need fixing. Being hopeful that stuff will work out is the opposite of strategy. It’s always better to know — or at least to be less uncertain. \n \nStrategic designers routinely chart a course through uncertain seas. They should be comfortable being uncomfortable and they should help you feel the same way. Rather than being taken aback, take a shot at answering those questions.\n\n## Direct vs. Indirect Experience\n\n>“Experience is simply the name we give our mistakes.”\n>\n>—Oscar Wilde\n\nA claim of “experience” is no guarantee of a favorable outcome. Experience is a set of responses to particular business problems (not yours), in particular contexts (not yours, either). That’s why duplicating a successful company’s business model or solution rarely works out. Despite what best-selling business books seem to suggest, there’s no single recipe for success. Every challenge is fresh, and every solution begins with a blank page.\n \nIf an agency claims direct experience in your industry, ask to also see examples of how they solved problems like yours for clients in other industries. Have they worked through problems of similar scale or complexity?\n\nThere are scenarios where specialized experience does matter. This is particularly true in industries that are highly-regulated or highly-competitive. If having specific domain knowledge on your project is important, discuss that. For example, if you’re a pharma brand with a “black box warning” on your product, you’d ask about their understanding of the specific FDA rules.\n\nIn some cases, an agency’s lack of direct experience can be an asset rather than a liability. Sometimes distance makes things clearer. This is especially true for an industry or company that tends to be a technology laggard. Expect to hear pushback on phrases like, “We’ve always done it that way” or “That would never work here.”  It’s likely they’ve met similar resistance elsewhere — and overcome it.\n\n## Experts Are Made, Not Born\n\n>“An expert is someone who tells you why you can’t do something.”\n>\n>—Sir Alec Issigonis, designer of the Morris Mini (predecessor to the Mini Cooper)\n\nAn agency should be able to show how fast they can learn your business. Even in the earliest meetings, they should bring insights and a pain hypothesis. They’re outsiders to your private domain, so the attempt means more than getting the details right. \n\nLook for evidence for how an agency leverages “abductive reasoning,” which is the seemingly magical ability to synthesize what they’ve learned into actionable insights and design ideas. They should tap both personal and institutional knowledge and apply it to new learnings about your circumstances.\n\nA rich set of design-thinking tools and methods will enable the agency to wrap their heads around the unfamiliar. Ask them not just which problems they’ve solved but also how they learn and share knowledge.\n\n## It’s Decision Time\n\n>“Trust yourself, you know more than you think you think you do.”\n>\n>—Dr. Benjamin Spock\n\nLike hiring the right team member, finding the right agency partner is as much about _who they are_ as _what they know_. To ensure a good fit, the agency should care as much about figuring out if you’re a good client for them, as you do figuring out if they’re a good agency for you.\n\nDon’t look for an agency who claims they can solve all your problems. Look for one who will face them with you.\n"},{"title":"EmberConf 2016 Recap","tags":["ember"],"summary":"The Year of Progress and Progressive Web Apps","legacy":false,"id":"2016/04/29/ember-conf-recap","employee":"Marten Schilstra","date":"2016-04-29T00:00:00","body":"\n\nLast year's [EmberConf][emberconf] was a conference packed with exciting new things.\nThe Ember 2.0 release was closing in. A lot of 1.0s of big Ember projects would\nbe shipped soon. [FastBoot][fastboot] was announced and so was [Glimmer][glimmer].\nOur new rendering engine got on par with React's blazingly fast\nrendering engine. There was a lot of hype and excitement.\n\nThis year the atmosphere of the conference was different. Not a bad different\nper se, but different. This year felt as if we had just completed major goals\nset out at last year's conference, and that we were now on track to keep leveling\nup those achievements in the foreseeable future.\n\nFor example, Glimmer II drastically improves upon Glimmer I. The 60fps\nrendering demo was mind blowing, but it felt different from seeing for the\nfirst time how comically bad the rendering engine was before Glimmer 1.0 and then\nsee it run as fast as React's rendering engine. It was already expected\nthat Glimmer II would improve upon Glimmer I.\n\nThere is one big new movement this year. It is the movement of\n[Progressive Web Apps][pwa] (_PWA_). FastBoot 1.0 will be released soon and\nthere are a bunch of other exciting projects putting effort into pairing up\nEmber with [ServiceWorkers][sw] and other PWA tools that (recently) have been added\nto (mobile) browsers.\n\nBecause of these developments I would like to dub this year:\n> __\"Year of Progress and Progressive Web Apps\"__.\n\nThere is another thing I want to mention: [Living Styleguides][styleguides].\nChris LoPresto gave a talk about this. I did not yet know of this movement\nuntil Luke Melia told me I should go see Chris' talk. It was supposed to be\nawesome. I'm glad I followed Luke's advice and went to see Chris' talk.\nYou may think that styleguides are for designers, but the way these styleguides\nare built will actually help developers architect better components.\n\nI had a really good time at EmberConf 2016. I'm excited to start trying out Living\nStyleguides at DockYard. We're already using [FastBoot][fastboot-post] and we're\nalso actively experimenting with Progressive Web App technology.\n\nI look forward to another round of talks that show how the Ember ecosystem has been\nimproved and solidified in 2017. Also to meet all the wonderful people I've met this\nyear again.\n\n[emberconf]: http://emberconf.com\n[fastboot]: http://www.ember-fastboot.com\n[glimmer]: https://github.com/tildeio/glimmer\n[pwa]: https://developers.google.com/web/progressive-web-apps?hl=en\n[styleguides]: http://chrislopresto.com/presentations/living-style-guide-driven-development?c=false&h=0&ph=900&pw=1600&v=0\n[fastboot-post]: https://dockyard.com/blog/2016/03/29/served-with-fastboot-again\n[sw]: http://www.html5rocks.com/en/tutorials/service-worker/introduction/\n"},{"title":"Phoenix Tips and Tricks","tags":["elixir","phoenix"],"summary":"Tips and tricks to keep your phoenix code clean and concise","legacy":false,"id":"2016/05/02/phoenix-tips-and-tricks","employee":"Chris McCord","date":"2016-05-02T00:00:00","body":"\n\nAs newcomers get up and running quickly with Phoenix, we see folks hit a few common issues that they can cleanly solve with a few simple tips.\n\n\n### Override `action/2` in your controllers\n\nOften times, you'll find yourself repeatedly needing to access connection information in your controller actions, such as `conn.assigns.current_user` or similarly reaching deeply into nested connection information. This can become tedious and obscures the code. While we could extract the lookup to a function, such as `current_user(conn)`, then we are needlessly performing extra map access when we only need to do the lookup a single time. There's a better way.\n\nPhoenix controllers all contain an `action/2` plug, which is called last in the controller pipeline. This plug is responsible for calling the function specified in the route, but Phoenix makes it overridable so you can customize your controller actions. For example, imagine the following controller:\n\n```elixir\ndefmodule MyApp.PostController do\n  use MyApp.Web, :controller\n\n  def show(conn, %{\"id\" => id}) do\n    {:ok, post} = Blog.get_post_for_user(conn.assigns.current_user, id)\n    render(conn, \"show.html\", owner: conn.assigns.current_user, post: post)\n  end\n\n  def create(conn, %{\"post\" => post_params}) do\n    {:ok, post} = Blog.publish_post(conn.assigns.current_user, post_params)\n    redirect(conn, to: user_post_path(conn, conn.assigns.current_user, post)\n  end\nend\n```\n\nNot terrible, but the repeated `conn.assigns.current_user` access gets tiresome and obscures what we care about, namely the `current_user`. Let's override `action/2` to see how we can clean this up:\n\n```elixir\ndefmodule MyApp.PostController do\n  use MyApp.Web, :controller\n\n  def action(conn, _) do\n    args = [conn, conn.params, conn.assigns[:current_user] || :guest]\n    apply(__MODULE__, action_name(conn), args)\n  end\n\n  def show(conn, %{\"id\" => id}, current_user) do\n    {:ok, post} = Blog.get_post_for_user(current_user, id)\n    render(conn, \"show.html\", owner: current_user, post: post)\n  end\n\n  def create(conn, %{\"post\" => post_params}, current_user) do\n    {:ok, post} = Blog.publish_post(current_user, post_params)\n    redirect(conn, to: user_post_path(conn, current_user, post)\n  end\nend\n```\n\nMuch nicer. We simply overrode `action/2` on the controller, and modified the arities of our controller actions to include a new third argument, the `current_user`, or `:guest` if we aren't enforcing authentication. If we want to apply this to multiple controllers, we can extract it to a `MyApp.Controller` module:\n\n\n```elixir\ndefmodule MyApp.Controller do\n  defmacro __using__(_) do\n    quote do\n      def action(conn, _), do: MyApp.Controller.__action__(__MODULE__, conn)\n      defoverridable action: 2\n    end\n  end\n\n  def __action__(controller, conn) do\n    args = [conn, conn.params, conn.assigns[:current_user] || :guest]\n    apply(controller, Phoenix.Controller.action_name(conn), args)\n  end\nend\n```\n\nNow any controller that wants to use our modified actions can `use MyApp.Controller` on a case-by-case basis. We also made sure to make `action/2` overridable again to allow caller's downstream to customize their own behavior.\n\n\n### Rendering the `ErrorView` directly\n\nMost folks use their `ErrorView` to handle rendering exceptions after they are caught and translated to the proper status code, such as a `Ecto.NoResultsError` rendering the \"404.html\" template or a `Phoenix.ActionClauseError` rendering the \"400.html\" template. What many miss is the fact that the `ErrorView` is just like any other view. It can and should be called directly to render responses for your error cases rather than relying on exceptions for all error possibilities. For example, imagine handling the error cases for our `PostController` in the previous example:\n\n```elixir\ndef create(conn, %{\"post\" => post_params}, current_user) do\n  with {:ok, post} <- Blog.publish_post(current_user, post_params) do\n    redirect(conn, to: user_post_path(conn, current_user, post)\n  else\n    {:error, %Ecto.Changeset{} = changeset} -> render(conn, \"edit.html\", changeset: changeset)\n    {:error, :unauthorized} ->\n      conn\n      |> put_status(401)\n      |> render(ErrorView, :\"401\", message: \"You are not authorized to publish posts\")\n    {:error, :rate_limited} ->\n      conn\n      |> put_status(429)\n      |> render(ErrorView, :\"429\", message: \"You have exceeded the max allowed posts for today\")\n  end\nend\n```\n\nHere we've used the Elixir 1.3 `with/else` expressions. Note how we are able to succinctly send the 401 and 429 responses by directly rendering our `ErrorView`. We also passed the template name as an atom, such as `:\"401\"` so our template will be rendered based on the accept headers such as `\"401.json\"` or `\"404.html\"`.\n\n\n### Avoid Task.async if you don't plan to Task.await\n\nElixir Tasks are great for cheap concurrency and parallelizing bits of work, but we often see `Task.async` used incorrectly. The most important thing to realize is that the caller is linked to the task. This means that if the task crashes, the caller does as well, and vice-versa. For example, the following code is perfectly fine because we await both tasks and we expect to crash if they fail:\n\n```elixir\ndef create(conn, %{\"access_code\" => code}) do\n  facebook = Task.async(fn -> Facebook.get_token(code) end)\n  twitter  = Task.async(fn -> Twitter.get_token(code) end)\n\n  render(conn, \"create.json\", facebook: Task.await(facebook),\n                              twitter: Task.await(twitter))\nend\n```\n\nIn this case, we want to fetch a token from Facebook and Twitter, and we can do this work in parallel since the tasks are not coupled in any way. When rendering our JSON response for the client, we can await both tasks and send the response back. This use of `Task.async` and `Task.await` is just fine, but now imagine another case where we want to fire off a quick task and immediately respond to the client.\n\n```elixir\ndef delete(conn, _, current_user) do\n  {:ok, user} = Accounts.cancel_account(current_user)\n  Task.async(fn -> Audits.alert_cancellation_notice(user) end)\n\n  conn\n  |> signout()\n  |> put_flash(:info, \"So sorry to see you go!\")\n  |> redirect(to: \"/\")\nend\n```\n\nIn this case, we want to notify our staff about an account cancellation, say by sending an email, but we don't want the client to wait on this particular work. It might feel natural to use `Task.async` here, but since we aren't awaiting the result and the client isn't concerned about its success, we have an issue. First, we are linked to the caller, so any abnormal exit on either side will crash the other. The client could get a 500 error after their account has been canceled and not be sure if their operation was successful. Likewise, our staff notice could be brought down by an error when sending the response, preventing our staff being alerted of the completed event. We can use `Task.Supervisor` and its `async_nolink` to achieve an offloaded process that is isolated under its own supervision tree.\n\nFirst, we'd need to add our own `Task.Supervisor`, to our supervision tree, in `lib/my_app.ex`:\n\n```elixir\nchildren = [\n  ...,\n  supervisor(Task.Supervisor, [[name: MyApp.TaskSupervisor]])\n]\n```\n\nNext, we can now offload the task to our supervisor. We'll also use the `async_nolink` function to isolate the task from the caller:\n\n```elixir\ndef delete(conn, _, current_user) do\n  {:ok, user} = Accounts.cancel_account(current_user)\n  Task.Supervisor.async_nolink(MyApp.TaskSupervisor, fn ->\n    Audits.alert_cancellation_notice(user) end)\n  end)\n\n  conn\n  |> signout()\n  |> put_flash(:info, \"So sorry to see you go!\")\n  |> redirect(to: \"/\")\nend\n```\n\nNow our task is properly offloaded to its own supervisor who will take care of any failures and proper logging. Likewise, any crash in the task, or the controller, won't affect the other.\n\n\nWith these tips, you'll keep your code clean and to the point, and isolated when required.\n"},{"title":"Building a Space: Learning the Ropes","tags":["design","design process","office"],"summary":"A short series about transforming the DockYard workspace.","legacy":false,"illustration_alt":"Before","illustration":"https://i.imgur.com/lsnnMrZ.jpg","id":"2016/05/04/building-a-space-learning-the-ropes","employee":"Patrick Branigan","date":"2016-05-04T00:00:00","body":"\n\nDockYard has been growing over the past couple years. In 2015 we relocated to a larger space which resulted in a lot of \ncreative opportunities internally. “Building a Space” is a short series of articles about our successes, failures, and \nlessons learned from stepping outside our comfort zone and designing for a medium we admittedly are not experts in: our \nphysical work environment. We start with elements of the lobby area.\n\n## Our challenge\n\nPreviously when someone entered our office, they’d be greeted at the door and instructed to take a seat. Between them and \nthe immediate seating area was this curved wall. They’d step over it. They’d step around it. They’d even ask us whether to \nstep around it! It was a surprisingly large interruption in the initial experience of visiting the office.\n\nWhen building a work space it’s important to ensure the space not only benefits the employee but also prospective clients \n(or really anyone visiting the office). When a guest visits a space there are a lot of moments that leave a lasting \nimpression. Having a sign that directs guests where to go impacts a guest’s experience. Greeting guests with a smile as \nthey enter the space impacts a guest’s experience. Having a space for guests to queue in while awaiting their meeting impacts \na guest’s experience. So when a guest enters a space for the first time and is confronted by a curved wall-curb-thing, their \nexperience is impacted, likely for worse if they don’t know what it is they’re being confronted with.\n\n![Before](https://i.imgur.com/lsnnMrZ.jpg)\n\nWhat is that?! Well, we’re not completely sure what it is, what it was or what its intended purpose might have been. We \nrefer to it as a curved wall yet it’s barely a wall. This was the most immediate challenge. This small curved wall was one \nof the points in the greater project we’ve tasked ourselves with: the client experience.\n\nSo how did we go about solving this challenge?\n\n## Use rope\n\nMaterials are plentiful in the life of a designer. Paints, inks, brushes, pens, pencils, stock, fabrics, devices, and so on. \nThese are typical materials needed perhaps when one is exploring creative outlets, studying for a career in the arts, or \nmerely going about their career as a designer. These are our familiar materials when solving a challenge. But how often do \nyou see rope used to solve a design challenge? \n\nOkay, that’s not a shocking or specific question. Let me rephrase: how often do you see a group of web application designers \nusing rope to solve a spatial design challenge?\n\n![Rope](https://i.imgur.com/fkJyHS4.jpg)\n\nRope is potent with creative potential because of its malleability. Its ability to structure complex forms and functions \nwas something we believed we could use to our advantage. After all, it’s been used since...forever, and in a seemingly infinite \namount of scenarios. These characteristics proved beneficial to solving the challenge we were faced with.\n\n## Why?\n\nWe pursued this challenge with rope for three primary reasons. First, it provided a boundary between the reception area and \nthe lobby area. This was important as it gave both our employees and our guests respective space to tend to their tasks. This \nalso allowed for easy communication. With a traditional wall or barrier, one party or the other would have to physically move \nto converse with or greet the other. Instead, a rope wall provides a subtle sense of privacy while still allowing for \ninteraction between reception and guests at any given time. It effectively solidified a comfortable space for simply waiting. \nNo more guests wandering onto the floor. No more need for reception to reassure the space as a waiting area. \n\n![Anchoring rope](https://i.imgur.com/XFwLxxB.jpg)\n\nSecondly, it was achievable with the tools at our disposal and the ambition of our design team. We believed that it was \ncompletely possible for us to build this wall on our own even though none of us had experience in building such a structure. \nWe saved a lot of money purchasing and installing materials ourselves and by using materials we already owned. We also wasted \nno time as we were able to complete the project on our own schedule with time we’d allot to it.\n\n![Tools](https://i.imgur.com/mVRO1Gd.jpg)\n\nLastly, it speaks to our brand. Being a raw manila rope, it’s physical qualities suggest  a nautical theme. Aesthetically, \nthe rope’s texture and color complement other items in the space, fitting the overall vision of our DockYard lobby area \nperfectly. We also searched for anchoring hardware that would supplement a subtle nautical theme. This led us to choosing \neye screws as our anchor hardware. They’re unobtrusive, visually satisfying when sequentially ordered, and can be found \nthroughout nautical products and scenarios.\n\n![Anchors](https://i.imgur.com/B9v1BpJ.jpg)\n\n## How?\n\nWe approached the project in a way very similar to how we approach any of our web application projects: by researching, \nplanning, prototyping, and executing.\n\nWe first gathered inspiration from a variety of sources. We found everything from loosely hanging rope acting as entryway \ndrapes, to beautifully anchored, tightly positioned lines of rope acting as entire room dividers. From what we found, we \nknew we wanted our rope wall to use anchored rope and not to be too tightly arranged. This required a bit of prototyping. \nWe utilized string and tape to measure and mock the arrangement of the rope.\n\n![Prototype](https://i.imgur.com/hggZLNH.jpg)\n\nWe then researched how to anchor the rope. As we weighed our options a few considerations became clear. Each vertical piece \nof rope needed to be measured close enough to one another to approximate the curve of the wall. We also realized we couldn’t \nanchor individual lines of rope because it would require labor and resources we didn’t budget for. These insights informed \ntwo key decisions. First, each vertically positioned piece of rope needed to be within 4-6 inches from one another which \nhappened to align with our prototype measurements. Second, we needed to use one piece of rope to thread the entire wall. \n\n![More anchors](https://i.imgur.com/Qw59vJj.jpg)\n\nThe result? A slightly angled, “tooth shaped” pattern we love. It’s clean cut, but it’s movement provides a dynamic unlike \none we’ve come across in terms of rope walls. In more ways than one it not only achieves the goals we began with but also \nprovides a variety of interesting perspectives to a space previously in search of an identity. \n\n![After](https://i.imgur.com/c8ntwRi.jpg)\n\n## A closer look at the process\n\n![More prototyping](https://i.imgur.com/NPtGps5.jpg)\n\n![Drilling](https://i.imgur.com/WFidbXt.jpg)\n\n![Screwing](https://i.imgur.com/ciRooiP.jpg)\n\n![Top anchors](https://i.imgur.com/USzEKBG.jpg)\n\n![Knot](https://i.imgur.com/VuNwOlY.jpg)\n\n![Bottom anchors](https://i.imgur.com/vVqxF4g.jpg)\n\n![More top anchors](https://i.imgur.com/1VNFFWz.jpg)\n\n![Final rope](https://i.imgur.com/QG5KbxA.jpg)\n"},{"title":"Building a Space: Chart a Course","tags":["design","design process","office"],"summary":"A short series about transforming the DockYard workspace.","legacy":false,"illustration_alt":"Reception wall","illustration":"https://i.imgur.com/llUDC0k.jpg","id":"2016/05/06/building-a-space-chart-a-course","employee":"Patrick Branigan","date":"2016-05-06T00:00:00","body":"\n\nDockYard has been growing over the past couple years. In 2015 we relocated to a larger space which resulted in a lot of \ncreative opportunities internally. “Building a Space” is a short series of articles about our successes, failures, and \nlessons learned from stepping outside our comfort zone and designing for a medium we admittedly are not experts in: our \nphysical work environment. \n\n## Reception wall\n\nAdjacent to our lobby, divided by our newly built [rope wall](https://dockyard.com/blog/2016/05/04/building-a-space-learning-the-ropes \"rope wall\"), there is our reception area. The previous tenant painted the \nreception wall a vibrant red. It provided a brilliance to the environment that was visually stimulating and aligned with \ntheir brand colors. However, the walls were painted white prior to our move in, leaving us with a space that lacked character. \nThough white walls made the space feel “clean,” it also made it seem unfinished. The vision for our lobby area already relied \nheavily on a lighter palette so we knew this reception wall was an opportunity for creativity.\n\n![Reception wall](https://i.imgur.com/llUDC0k.jpg)\n\n## Challenges and constraints\n\nOnce a guest walked through our door, the first thing they would encounter was the big blank wall. There wasn’t a lot of \ndiscussion surrounding fixtures for the wall, such as shelving, hanging artwork, or additional lighting. Instead we \ngravitated towards the idea of painting a mural. The question was, what do we paint? Before answering this question, \nthere were items to consider. Much like the rope wall, the mural was dependent upon a few considerations.\n\nFirst, our team wanted to be able to execute the mural on its own. This would lessen the time and budget needed, but it \nalso provided the prospect of working on a project we don’t often get the chance to. This resulted increased motivation and \nmorale throughout the team. The cost of doing it ourselves equated to the time it would take us (about a week). We found \nthat hiring an outside artist would likely put pressure on the budget or the deadline. Plus, we’re imaginative! We’ve all \npainted before! Surely we can rely on our own expertise, right? We’re designers after all!\n\nSecond, we needed to make sure to maintain a realistic perspective on time and budget without sacrificing our ambition and \npassion for an excellent result. This meant paying close attention to the complexity of executing the piece on the wall. \nAgain, much like the rope wall, we hadn’t had much recent experience in works of this nature. Paint primer? What’s that? \nThis didn’t hinder our ambition, however. Instead it helped us focus on a single direction.\n\nThat direction was to hand letter the entire mural. We thought painting the mural in our DockYard blue provided a weight \nand simplicity that would counter the existing white space. This color also wouldn’t interfere with the personality of the \nletterforms or the message in its entirety. The idea of a lettered piece allowed us to clearly display meaning to our new \nspace, our guests and our employees. However, the meaning of the words would prove to be the most complex challenge of them \nall.\n\n## What to say\n\nInitially our design team constructed a list of statements we envisioned on the reception wall. Most had to do with \nwelcoming guests or providing inspirational words to entice potential clients. Some options were merely two words in \nlength while others were entire quotes from some of history’s great creative minds. We then consulted with others internally. \nWe wanted the statement to be representative of not just designers but also developers, managers, and the entire company’s \nshared vision. This is when a larger question surfaced.\n\n#### What does this mean to us?\n\nWhat are we trying to accomplish in this space? Does it align with the aspirations and desires of our guests? It turns out \nthis wasn’t just a greeting to be written on a wall. We were actually touching on a brand element, a mantra that could \nresonate with both our employees and our guests – anyone who entered the office. It had to be something motivating and \nthought-provoking. It had to represent not just our progress as a company but the journeys we take our guests, clients and \npartners on.\n\n## Chart a course\n\nAfter much more discussion, we landed on “chart a course.” There are many reasons why we believe this is a fitting statement \nfor the space.\n\n![Brainstorm](https://i.imgur.com/Uewqtg3.jpg)\n\nConsidering its position and audience it made sense to present something that is instantly digestible in the reception space. \nThe statement has the ability to hold different meanings for different audiences, all resembling the idea of progression or \nforward thinking. Charting a course is what we do with clients and employees. We push their adventures and ideas forward, \nwhether it be a career or a project. \n\nAlso, like the rope wall, it subtly hints at a nautical theme. Though the nautical theme isn’t meant to be at the forefront \nof the entire office experience, it can be delightful to encounter our name, “DockYard,” upon entry and then extend the \nintroduction with a corresponding statement such as “chart a course”. The name and the statement calmly connect the \nentire entry experience, which may help in a guest’s ability to recall our brand name. \n\n## How?\n\nWhere do we start? Sketches of course! We brainstormed multiple compositions, arrangements, letterform weights and styles. \nWe played with decoration, shadows and highlights. Here are just a few:\n\n![Sketch collage](https://i.imgur.com/CvZZxQZ.jpg)\n\nAfter reviewing countless sketches and ideas, we discovered one which was particularly engaging to us. The fluidity and \nmovement of the letterforms caught our attention. The sequence in size and weight helped guide the eye from start to \nfinish. We weren’t exactly sold on the arrangement, but it was a great starting point.\n\n![Sketch](https://i.imgur.com/dd8Mh2j.jpg)\n\nAs with any project, we began to iterate. The piece changed with time for the better. We rearranged the words, and began \nto pronounce a specific brush lettering style. We used tracing paper, pencil and ink to continuously refine the letterforms \nuntil it satisfied our vision. We then finished refinements on screen.\n\n![Refined sketch](https://i.imgur.com/h6qNZil.jpg)\n\n![Final sketch](https://i.imgur.com/zTbGsNT.jpg)\n\nThe rest of the process was smooth sailing. We matched our DockYard blue with Behr paint professionals to arrive at a \ncolor named Secret Society. We used a projector to outline the piece on the reception wall. Lastly we spent hours painting, \nstarting with the outlines and finishing with the fills.\n\n![Paint](https://i.imgur.com/JlE0R0F.jpg)\n\n![Projector](https://i.imgur.com/RsBFfC5.jpg)\n\nWhat we ended up with was a beautiful hand lettered mural that has the potential to greet and engage anyone who enters our \noffice. It’s fluid, flexible and, most importantly, it retains a human personality. It doesn’t feel manufactured. It \ndoesn’t speak arbitrarily. It represents the beginning of everything we stand for at DockYard. \n\n![Final design](https://i.imgur.com/GC3rGpj.jpg)\n\n## Here's a look at more of the process:\n\n![Chris painting](https://i.imgur.com/yB1TukV.jpg)\n\n![Team painting](https://i.imgur.com/tsTz8fp.jpg)\n\n![Finishing touches](https://i.imgur.com/HEF14PM.jpg)\n\n![Tim painting](https://i.imgur.com/QsBFWni.jpg)\n\n![Close up](https://i.imgur.com/LK656G4.jpg)\n"},{"title":"Transitioning into Tech: From Googling “What is Ember.js?” to Interning at a Software Consultancy","tags":["marketing","culture","ember","intern","observations","services"],"summary":"I was conducting psychiatric research at one of the nation’s oldest hospitals. Now I intern at DockYard, a software consultancy that’s at the forefront of web design and development. Here are my observations from my first thirty days.","legacy":false,"illustration_alt":null,"illustration":"http://i.imgur.com/8kKOeAA.gif","id":"2016/05/11/transitioning-into-tech-from-googling-what-is-ember-to-interning","employee":"Maggie Gigler","date":"2016-05-11T00:00:00","body":"\n\n“Emma, have you ever heard of Ember?” I asked my roommate, a friend of mine from college who works as a user experience (UX) designer at a tech company here in Boston. I was looking for marketing positions and came across a software consultancy company called DockYard. I was drawn to their professional yet approachable feel: While they had built software applications for several big name clients (e.g. NASDAQ, the Democratic National Committee, Constant Contact), the language they used was straightforward and sincere. What’s more, they were a startup that didn’t feel the need to have the word “awesome” splashed all over their website, and their job titles didn’t include the words “ninja” or “jedi.” It was an exciting find.\n\nAt the time, I wasn’t familiar with Ember.js, Phoenix, or Elixir, which are several of the technologies we use here at DockYard in web application design and development. My background is in psychology and research, and I previously worked in the Department of Psychiatry at Massachusetts General Hospital (MGH). But I figured I’m a millennial, right? I grew up as the sophistication and use of the Internet took off on a global scale, and I can write HTML/CSS. If on one end of the spectrum you have my father, who is a businessman yet has neither an e-mail address nor a computer in his office, and on the other end you have your Mark Zuckerbergs and your Tim Berners-Lees of the world, then I fall somewhere in the middle. As I sat there wavering between the feelings of apprehension and audacity, I remembered my dad saying that the guy who leads the league in home runs usually also leads the league in strikeouts. So, I decided that I had nothing to lose and went for it: I filled out the “Join Us” form on DockYard’s website, and now I’m sitting here reflecting on my first thirty days as a marketing intern.\n\nBeing new can be awkward as you try to orient yourself within the organization, but you also have the unique opportunity to look at something from an original, unlearned perspective.\n\n<a href=\"http://imgur.com/8kKOeAA\"><img src=\"http://i.imgur.com/8kKOeAA.gif\" title=\"source: imgur.com\" /></a>\n\n_The reaction you fear as a new employee when you’re about to say nearly anything_\n\nWhat I realized is that while I’ve always had a lot of respect for web developers and designers, I had never considered the future of tech in terms of the long-term viability of software applications or what that means for these roles. Admiration is not the same thing as appreciation, because to truly appreciate what someone does, you have to recognize the skill that it requires and the challenges facing that industry. It’s easy to take software and other forms of technology for granted without considering the engineering and design that have gone into creating them.\n\nPrior to my interview at DockYard, I found it nearly impossible to find material that would explain Ember.js, Phoenix, or Elixir at a level that someone who was tech-savvy but not a developer could grasp (e.g., me). As I have an acute dislike of that left-out, lost feeling that accompanies not fully understanding a topic, I’ve been absorbing as many new concepts as I can while also learning about DockYard’s approach to design and engineering. What’s really impressed me in my first month is the careful consideration about the long-term viability of the applications we create.\n\nOne can further see the foresight of DockYard’s leadership in the deliberate technology choices that we make. For example, at DockYard we specialize in single-page applications that have an average shelf-life of ten years. The average iOS application that you purchase in the App Store, also known as a “native app” due to its installation onto the phone itself, has a shelf life of one to two years.  This disparity is due to a variety of factors, including that the software has to be compiled specifically for that operating system, the expense of marketing a native app in hopes of climbing the App Store ladder, and importantly, the backwards compatibility of the JavaScript framework we use—Ember.js. It is noteworthy that this backwards compatibility is what precludes the issues that native apps typically face when new versions are developed, as it is a good demonstration of the web’s design as a platform to endure. On the backend, we employ Phoenix and Elixir, Phoenix being the framework and Elixir being the language. It’s ironic that the language we use for back end development is called “Elixir,” because DockYard’s ingenuity originates from the pursuit of sustainable progress as opposed to the industry’s panacea. \n\nThe experience for employees is no different from DockYard’s approach to design and engineering—transparent and uncomplicated. The value placed on communication was echoed during my first meeting with our CEO, Brian. When asked if there was anything I should be sure to do as a new employee, he said: “If you’re siloed in by yourself, that’s seen as a failure here.” \n\nLooking over the past thirty days, I think my biggest fear was feeling embarrassed about my lack of software know-how on top of being a new employee. That being said, my difference in background hasn’t made me feel like the albatross of DockYard. Rather, what we have at DockYard is a unique kind of strength that is the result of the inclusion of people from different backgrounds and different skillsets. William Arthur Ward was quoted as saying, “When we seek to discover the best in others, we somehow bring out the best in ourselves,” and at least at DockYard, that’s incredibly true.\n"},{"title":"{{component helper}}","tags":["ember","javascript","best practices","engineering"],"summary":"Help optimize your code with the component helper, in conjunction with other helpers","legacy":false,"id":"2016/05/13/component-helper","employee":"Romina Vargas","date":"2016-05-13T00:00:00","body":"\n\nAt DockYard, one pattern that we've been noticing in some of our projects is\nneeding to render different components based on some value. This value could\ncome from a computed property, a model attribute, etc. Typically, this means\nthat your template will contain some branching logic to figure out the\nappropriate template to render. A helpful helper that became available pre-Ember\n2.0 is the `{{component}}`. With its help, we can clean up our template logic.\n\nA distinguishing factor between the `{{component}}` helper and the traditional\ncomponent invocation is that the helper expects the component name as the first\nparameter following the helper name, and will dynamically render out the component\nspecified by that parameter. An arbitrary number of parameters may follow the\ncomponent name; these are what the rendered component expects.\n\n`{{component myComponentName param2=param2 param3=param3 ...}}`\n\nSuppose we have a `Food` model. And each `Food` model instance has a `taste`\nattribute. We want to render a certain template depending on the string value of\n`food.taste`. Prior to having the `{{component}}` helper, we'd do something like\nthe following:\n\n```js\n// food/component.js\nimport Ember from 'ember';\nconst { Component, computed: { equal } } = Ember;\n\nexport default Component.extend({\n  isSpicy: equal('food.taste', 'spicy'),\n  isSweet: equal('food.taste', 'sweet')\n});\n```\n\n```hbs\n{{! food/template.hbs }}\n\n{{#if isSpicy}}\n  {{food/spicy-food food=food}}\n{{else if isSweet}}\n  {{food/sweet-food food=food}}\n{{else}}\n  {{food/other-food food=food}}\n{{/if}}\n```\n\nWe defined a couple of computed properties and threw in some `if` statements\nin our template to dictate which component to render based on the food taste.\nBut we can do better! Let's see how our app cleans up when using the helper.\n\n```js\n// food/component.js\nimport Ember from 'ember';\nconst { Component, computed, get } = Ember;\n\nexport default Component.extend({\n  tastyComponentName: computed('food.taste', {\n    get() {\n      let foodTaste = get(this, 'food.taste');\n      return `food/${foodTaste}-food`;\n    }\n  })\n});\n```\n\n```hbs\n{{! food/template.hbs }}\n\n{{component tastyComponentName food=food}}\n```\n\nNice. Our template became a one-liner, and we were able to remove the\ncomputed properties that we had to define for each food taste that we\nwanted to render a separate component for. All of the logic  is now consolidated\ninto one computed that returns the name of the component that should be rendered.\nWe can pass this property as the second argument inside `{{component}}`.  If we\nwanted to later introduce new food tastes and components to go along with them,\nno changes would need to be made in these two files, since `tastyComponentName`\ntakes care of all cases.\n\n## More powerful templates\n\nIn the above example, we are using the computed property `tastyComponentName` to\nname our template. But it's not immediately obvious what the template actually is\nwithout looking at the computed property itself. We can forgo the CP altogether\nand use Handlebars subexpressions to keep all logic within the template.\n\nRecently, [Lauren][lauren] and [Marten][marten] released the\n[ember-composable-helpers][ember-composable-helpers] addon whose aim is to make\nlogic in your Ember templates more declarative. How convenient that this addon\ncomplements `{{component}}` well! The helpers within `ember-composable-helpers`\ncan be used in different combinations to format your component name depending\non your needs. Furthermore, Ember itself ships with some\n[built-in helpers][ember-helpers] that can be used inside our templates as well.\n\nThe Ember helper `concat` is one of the helpers we use fairly often. It's\ncommon to name components based on a value of an attribute. In our example,\nthe component name is based on `food.taste`. How would we modify our example\nto make use of the `concat` helper?\n\n```hbs\n{{! food/template.hbs }}\n\n{{component (concat \"food/\" food.taste \"-food\") food=food}}\n```\n\nAnd just like that, the `food/component.js` file is no longer needed. The `concat`\nhelper replaces the computed property entirely. If the value of `food.taste` is\n`sweet`, then the helper will output `food/sweet-food`.\n\nAnother useful helper that works well in conjunction with `concat` is `dasherize`.\nThis helper is part of `ember-composable-helpers` addon and will take care of\nlowercasing and dasherizing a given value. Sometimes, we have to work with camelized\nvalues, and using `dasherize` will convert them to a more desired format. Here's\nan example of how the helpers would be used together:\n\n`{{component (concat \"food/\" (dasherize food.taste) \"-food\") food=food}}`\n\nIn this case, if the value of `food.taste` is `SuperSour`, then our rendered\ncomponent will be `food/super-sour-food`. With all the helpers we have available\nto us, think of all the combination possibilities!\n\n[lauren]: https://twitter.com/sugarpirate_\n[marten]: https://twitter.com/Martndemus\n[ember-helpers]: http://emberjs.com/api/classes/Ember.Templates.helpers.html\n[ember-composable-helpers]: https://github.com/DockYard/ember-composable-helpers\n"},{"title":"How does project communication become complex?","tags":["design","business","observations","product management","team"],"summary":"Learning about communication patterns in larger teams","legacy":false,"illustration_alt":"A small team communicates simply","illustration":"https://i.imgur.com/cj1M4K3.jpg","id":"2016/05/25/how-does-project-communication-become-complex","employee":"Maria Matveeva","date":"2016-05-25T00:00:00","body":"\n\n\nProjects of larger scale or longer duration often involve a large design team. We typically keep everyone informed and share information efficiently on teams roughly the size of a large family. But we don't have that intuitive understanding of how teams work once they get much larger than that. \n\nAs I’ve gotten the chance to look into how larger teams work on projects, I realized that they have the potential to get too complex for one person to understand, and therefore communication requires careful attention and structure.\n\nOn a project of any size, there is inherent value in communication: it allows everyone to know what they’re working on, and to avoid getting in the way of others. The value of clear and efficient communication is a subject for another time. What I’m most concerned with here is how the level of complexity grows with team size.\n\nLet’s see what happens as the number of people on a team grows. We’ll assume the hierarchical structure stays the same, leaving everyone roughly on the same level and allowing all team members to communicate with one another like they would on a small team.\n\n## A team of two or more needs to communicate.\n\n![A small team communicates simply](https://i.imgur.com/cj1M4K3.jpg)\n\nWith a team size of two, everyone’s ideas and questions can be exchanged freely, and all team members are on the same page as these conversations happen.\n\n\n## With more people on a team, communication adds up.\n\n![larger team needs more communication](https://i.imgur.com/JaKGFon.jpg)\n\nIf team communication style stays the same as a team grows, eventually it becomes more and more difficult for everyone to tell everyone else everything. At first it may look like the complexity of communication grows in a linear way, along with team size. But the pattern soon changes. \n\n## On larger teams, unmanaged communication becomes overwhelming.\n\n![A very large team needs even more!](https://i.imgur.com/hSl0xUo.jpg)\n\n\nIf everyone keeps telling everyone everything, without a defined structure to contain those conversations, the amount of communications will grow (nearly) exponentially faster, even as team size grows in a linear fashion.\n\nRemember that math problem from school, where you’d count the number of combinations of several objects? The teacher would make you go through manually counting the combinations for 2, 3, and maybe 4 objects until at 5 or 6 you’d determine that the number of combinations gets really big really fast. This is the same pattern I suspect would emerge if we allowed a flat structure of everyone talking to everyone, with no teams or management effort, for a large group of people. \n\n## Manage the conversations on larger teams. Because you have to.\n\n![layered communication](https://i.imgur.com/emvoO7J.jpg)\n\nThe answer to the math problem is structure. As team sizes grow, managers or team leaders emerge who become responsible for keeping on top of communications within a smaller team (think - the drawing of four people above) as well as for relaying that information to other team leaders. \n\n## Reinventing the wheel?\n\nThe need for management is not a new concept. As I was discovering it for myself, I was surely reinventing the wheel. Colleagues advised that the number of connections between nodes is described by [Metclafe’s Law](https://en.wikipedia.org/wiki/Metcalfe%27s_law).\n\n  \n![Metclafe’s Law](https://i.imgur.com/Iv59ich.png)\n\n\n\n\n\nThe information exchange in a group could be managed by breaking down & [managing different stakeholders](https://en.wikipedia.org/wiki/Stakeholder_management) depending on their influence (power) and influence level. \n\n\n\n![Stakeholder Management](https://i.imgur.com/MpNKIY0.png) \n\n\n\nI also learned that [coordination cost](https://blog.bufferapp.com/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done) becomes one of the factors in determining the productivity of a team.\n\nAll these are great ways to look at getting things done with more perspective than I would have had before I took on a management role. Re-discovering some of these principles for myself, and learning from colleagues has been a rewarding process - and I can’t wait to see what’s next!\n"},{"title":"TIL: Elixir pattern matching for argument equality","tags":["til","elixir"],"summary":"pattern matching versus guard expressions","legacy":false,"id":"2016/05/26/til-elxir-pattern-matching-for-argument-equality","employee":"Marin Abernethy","date":"2016-05-26T00:00:00","body":"\n\n[Pattern matching][pattern-matching] and [guard expressions][guard-expressions] are fundamental to\nwriting recursive function definitions in [Elixir][elixir]. Sometimes guard clauses and pattern matching\ncan be used for the same purpose. For example:\n\n```elixir\n# pattern matching\ndefmodule Exponent do\n  def power(value, 0), do: 1\n  def power(value, n), do: value * power(value, n - 1)\nend\n\n# guard expression\ndefmodule Exponent do\n  def power(value, n) when n == 0, do: 1\n  def power(value, n), do: value * power(value, n - 1)\nend\n```\n\nIn both cases above, we only want the first `power` function to run when the second argument is equal to `0`.\nWhen it is as simple as equality, I tend to use the pattern matching syntax. I typically leave the guard for more complex\nlogic like `when rem(x, divisor) == 0`. However, to check whether one argument is equal to another I thought a guard was neccessary: `when a == b`.\nBut, **today I learned**, this can also be handled with pattern matching, like so:\n\n```elixir\n# guard\ndef equality(a, b) when a == b, do: IO.puts \"equal\"\ndef equality(a, b), do: IO.puts \"not equal\"\n\n# pattern matching\ndef equality(a, a), do: IO.puts \"equal\"\ndef equality(a, b), do: IO.puts \"not equal\"\n```\n\nTada! There you have it. It seems so simple I don't know how I hadn't tried it earlier!\n\n[pattern-matching]: http://elixir-lang.org/getting-started/pattern-matching.html\n[guard-expressions]: http://elixir-lang.org/getting-started/case-cond-and-if.html#expressions-in-guard-clauses\n[elixir]: http://elixir-lang.org/\n"},{"title":"Narwin-Pack: A PostCSS Package for DRY and Efficient CSS","tags":["postcss","css"],"summary":"After DockYard’s recent transition to PostCSS, we realized that we needed better plugin organization. So we created narwin-pack. Here’s an overview of the plugins that make up narwin-pack and why our UXD team chose each PostCSS plugin.","legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/x6596A7.jpg","id":"2016/05/27/narwin-pack-the-postcss-package","employee":"Cory Tanner","date":"2016-05-27T00:00:00","body":"\n\nIn my last blog post, [Why DockYard transitioned to PostCSS](https://dockyard.com/blog/2016/02/11/transition-to-postcss), I explained why our UXD team adopted [PostCSS](https://github.com/postcss/postcss) into our development process.\n\nDuring the transition process we realized it would be best to only use PostCSS plugins that meet two criteria:\n\n- Encourages DRY CSS\n- Simplifies our development process\n\nThat’s when [narwin-pack](https://github.com/DockYard/narwin-pack) was born, An easy-to-use PostCSS package that holds all six of our plugins in one easy-to-use package.\n\nHaving many plugins bundled into one package that can easily be included in our projects is valuable to our team. It gives our UXD team a structured environment to develop CSS.\n\nIf another UX developer wants to add a plugin to narwin-pack a discussion is had within the narwin-pack repository and we discuss the pros and cons of using that plugin. If everyone agrees that a plugin is needed then it will be added to narwin-pack.\n\nPostCSS has options for hundreds of plugins that you can include in your project. Having only one package to use for our projects provides consistency, knowing that every developer within out team will be using the same plugins.\n\nThe plugins in narwin-pack are as follows:\n\n- [postcss-partial-import](https://github.com/jonathantneal/postcss-partial-import)\n- [postcss-custom-properties](https://github.com/postcss/postcss-custom-properties)\n- [postcss-nested](https://github.com/postcss/postcss-nested)\n- [postcss-calc](https://github.com/postcss/postcss-calc)\n- [autoprefixer](https://github.com/postcss/autoprefixer)\n- [postcss-svg-fragments](https://github.com/jonathantneal/postcss-svg-fragments)\n\n# 1. postcss-partial-import\n\nThe postcss-partial-import plugin provides the environment for a modular CSS file structure. You can have multiple CSS files and then with the help of postcss-partial-import we merge all our CSS files into one central file that the browser will use.\n\nThe ability to have multiple CSS files but only reference one CSS file in our HTML is important for page performance. The browser now only has to ask the server for one CSS file. At the same time using multiple CSS files lets us modularly organize our CSS based on BEM [naming conventions](https://github.com/DockYard/styleguides/blob/master/ux-dev/class-naming-conventions.md) and SMACSS file architectures.\n\nModular CSS file structure:\n\n```\nstyles/\n  modules/\n    header.css\n    footer.css\n    nav.css\n  base.css\n  load.css\n  layout.css\n  type.css\n```\nUsing this CSS architecture we can now add all of those CSS files into one central CSS file. Our CSS file with `@imports` pointing to other CSS files could look like the following:\n\n```css\n@import: \"load.css\";\n@import: \"type.css\";\n\n@import: \"modules/header.css\";\n@import: \"modules/footer.css\";\n```\nThe plugin will recognize the `@import` and add the contents of the referenced CSS files into this one CSS file.\n\n![](http://i.imgur.com/x6596A7.jpg)\n\n# 2. postcss-custom-properties\n\nWho doesn’t love using variables!\n\nThe use of variables in CSS has been a hot topic lately, and eventually all browsers will support them. Firefox and Chrome already have [support ](http://caniuse.com/#search=variables), but we are still waiting on Edge and mobile browser support. Until all browsers support variables, we will need a plugin.\n\nI think most developers would agree with me when I say that I would rather remember a color for its name, as opposed to its hex code. Further, we make sure to organize our variables with naming conventions so they are easy to both read and use.\n\nAn example of how we organize our variables in our `load.css` file is as follows:\n\n```css\n:root {\n  /* COLORS */\n  --white: #FFFFFF;\n  --green: rgb(61, 154, 104);\n    --75-green: rgba(61, 154, 104, .75);\n\n  /* FONT WEIGHTS */\n  --light: 200;\n  --bold: 600;\n}\n```\nNotice that we break our variables down into sections and give them easy to use names with indentation. This way other developers can look at this CSS file and know what everything does.\n\nAn important thing to remember is that if you want variables available globally, wrap them in a `:root {}`.\n\nHere’s a quick example of how to use variables:\n\n```css\n:root {\n  --green: rgb(61, 154, 104);\n}\n```\nIn other CSS files, you can just use the variable name in place of the color code.\n\n```css\n.text {\n  color: var(--green);\n}\n```\nThe output of this will be the `rgb` color code. This is simple but allows us to organize colors and other variables.\n\n# 3. postcss-nested\n\nNesting is a technique that we use, but in moderation. We make sure not to nest class names for easier “BEM-ing” because it can be difficult to try to find BEM classes that are made with nesting. We can’t search for `.hero__heading` if `__heading` was added to `.hero` with nesting.\n\nIncorrect Example:\n\n```css\n.hero {\n  margin-top: 10px;\n  &__heading {\n    color: blue;\n  }\n}\n```\nUsing BEM’s naming conventions without nesting keeps our CSS files readable and searchable.\n\nCorrect Example:\n\n```css\n.hero {\n  margin-top: 10px;\n}\n.hero__heading {\n  color: blue;\n}\n```\nWe do use nesting for media queries, pseudo elements/classes and parent dependent classes styles.\n\nExample:\n\n```css\n.nav__links {\n  float: right;\n  .body--black & {\n    border-color: var(--white);\n  }\n  .body--white & {\n    border-color: var(--black);\n  }\n}\n\n.nav__link {\n  color: var(--green);\n  &.is-active,\n  &:focus,\n  &:hover {\n    color: var(--50-green);\n  }\n  @media (max-width: 599px) {\n    display: block;\n  }\n  @media (min-width: 600px) {\n    display: inline-block\n  }\n}\n```\nThe block of CSS above is a simple example of good nesting according to the guidelines we have set for ourselves.\n\n# 4. postcss-calc\nHaving this plugin included in narwin-pack is a result of having postcss-custom-properties. With this plugin we can include variables inside `calc()` equations if we would like.\n\nInput:\n\n```css\n:root {\n  --font-size: 18px;\n}\n```\n\nAny CSS file within the same root folder:\n\n```css\n.text {\n  font-size: calc(var(--font-size) * 2);\n}\n```\n\nOutput:\n\n```css\n.text {\n  font-size: 36px;\n}\n```\n\n# 5. postcss-svg-fragments\n\nA downside of using the [symbol](https://css-tricks.com/svg-symbol-good-choice-icons/) method for multiple SVG’s is that it’s not supported with inline CSS, only inline HTML. SVG Fragments solves this problem for us.\n\nWithout this plugin, we would need to have individual SVG files for `background-images` in CSS, and the browser would have to pull multiple SVG files when loading a page. The plugin postcss-svg-fragments solves this by doing what its name implies, it adds SVG fragments into CSS.\n\nWe take all our SVG files and add them to [icomoon.io](https://icomoon.io/app/#/), generate a new SVG with a `<use>` that has an unique `id`. Then we add the new SVG code to our `defs.svg`.\n\nInput:\n\n```css\n.background-patter {\n  background-image: url(defs.svg#pattern);\n  fill: blue;\n  stroke: black;\n}\n```\n\nOutput:\n\n```css\n.background-patter {\n  background-image: url(/* SVG data */);\n  fill: blue;\n  stroke: black;\n}\n```\n\n# 6. autoprefixer\n\nOne of the most used tools by HTML/CSS developers is autoprefixer. Before having autoprefixer as a PostCSS plugin, we would go to [caniuse.com](http://caniuse.com/) to see what CSS rules still needed browser prefixes. Even developers who don’t use PostCSS use the autoprefixer plugin in their projects.\n\nNow, we have a plugin that looks at the CSS and searches for what prefixes are needed. Then adds them into the compiled CSS file according to how it’s configured. Autoprefixer lets us configure custom browser support.\n\nExample with autoprefixer:\n\n```css\n.block {\n  display: flex;\n}\n```\n\nOutput:\n\n```css\n.block {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n}\n```\n\n# Takeaways\n\nWe choose these plugins because they are intended to make our lives easier as developers. Further, these plugins will help us develop DRY and efficient CSS, which is significant because that is the interface with which the user will interact.\n\nIf chosen carefully, the combination of plugins and self-set guidelines can foster a great environment in which to make exceptional CSS.\n"},{"title":"TIL: Ecto supports a query inside another query","tags":["ecto","elixir","til"],"summary":null,"legacy":false,"id":"2016/05/27/til-ecto-supports-query-inside-query","employee":"Marin Abernethy","date":"2016-05-27T00:00:00","body":"\n\nIf you read the [Ecto.Query][ecto-query] documentation, one of the first sections explains how\nEcto queries are composable. Meaning, we can extend a query after creating it. Like so:\n\n```elixir\nquery = from e in Event,\n  where: e.category == ^event.category\n\ncase event.host do\n  host -> from e in query, where: e.host == ^host\n  _ -> query\nend\n```\n\nThis was a feature that I learned a while after starting Elixir (apparently I didn't read the docs well enough).\nAnd it is totally awesome. But **today I learned** Ecto also supports nested queries!\n\n```elixir\nlast_event = from e in Event,\n  distinct: e.id,\n  order_by: [desc: e.inserted_at]\n\nquery = from a in Attendee, preload: [events: ^last_event]\n```\nHere, we are referencing a query (`last_event`) from within another query. How exciting! It is also important to mention\nthat Ecto 2.0 supports [subqueries][subqueries] in the `from` and `join` fields (see example below). This makes queries even more malleable and powerful.\nHope you enjoy it as much as I do!\n\n```elixir\nquery = from e in Event, select: e\nq = from e in subquery(query), select: e.summary\n```\n\n[ecto-query]: https://hexdocs.pm/ecto/Ecto.Query.html\n[subqueries]: https://github.com/elixir-lang/ecto/pull/1231\n"},{"title":"How to make sense of a complex project, fast","tags":["design","design process","design thinking"],"summary":"The time and effort we spend together in up-front sense-making may not feel like “design.” But it’s one of the most important and best investments you can make.","legacy":false,"illustration_alt":"Aircraft Carrier","illustration":"https://i.imgur.com/9X2i99sl.png","id":"2016/06/02/make-sense-complex-project-fast","employee":"Mark Kaplan","date":"2016-06-02T00:00:00","body":"\n\nWe live in an increasingly complex world. Your business doesn’t exist in a vacuum, and there’s so much to keep track of. When you have a problem that needs solving, it’s often hard to define what that problem is, who’s having it, and what the solution might look like. Everyone seems to have a different opinion. And just when you think you’re making progress trying to understand things, something changes. Or everything changes. No wonder folks become overloaded and frustrated&thinsp;&mdash;&thinsp;what a mess! \n\n### Complex, dynamic systems often exist beyond understanding by any individual.\n![Aircraft Carrier](https://i.imgur.com/9X2i99sl.png)\n\nImage Credit: [Telegraph](http://www.telegraph.co.uk/finance/newsbysector/industry/defence/10723462/HMS-Queen-Elizabeth-Britains-new-aircraft-carrier-in-detail.html)\n\nNo one person on an aircraft carrier understands all of the complex systems on board&thinsp;&mdash;&thinsp;not even the captain. And yet, that ship is able to function as it does due to a network of common understandings and cooperation. Design Thinking is a set of tools and methods we can deploy to make sense of the jumble before solving problems. The goal isn’t to simplify what’s inherently complex, but rather to embrace that complexity through better, shared understanding. \n\nWe take our first steps by wrapping our heads around what we already know or have. Working together, we’ll create models, much like scientists do. This gives us something in common - something we can all point at and discuss. \n\nWe often start with language, by naming things. From there, we’ll create sketches collaboratively, defining concepts, showing relationships and allowing us to compare and contrast. We’ll do this iteratively, which increases our collective understanding over time. Knowing where we are today&thinsp;&mdash;&thinsp;and then layering on where we’re trying to get to and how we’ll know when we get there&thinsp;&mdash;&thinsp;gives us a sound framework for future decision-making.\n\nOne of our client’s goals is to open up a system used internally to external customers, for self-service. The current system was developed over many years and has hundreds of screens and functions. It’s not only a complex workflow - it’s a complicated user interface, a rat’s nest of tabs and sub-tabs and pop-ups that open pop-ups.\n\nWe couldn’t possibly begin to redesign it without trying to make sense of it first. But how? This is a problem best approached from several directions.\n\nFirst, we’d gain some level of shared understanding of the present system. Like that aircraft carrier, it seems like not one person understands the whole system. We’d talk to the product owners, engineers, support team, and existing users. We’d also make our own way around the app. Along the way, we’d create and validate mental models and sketches. \n\n### The goal is orientation, not complete understanding.\n![Neighborhood Map and Street Map comparison](https://i.imgur.com/ioyW0XI.jpg)\n\nImage Credits: [Boston Discovery Guide](http://www.boston-discovery-guide.com/boston-neighborhoods.html), [Wikipedia](https://en.wikipedia.org/wiki/Template:Location_map_Boston)\n\nSecond, we’d look toward the future. We’d talk to the business stakeholders, to gain their understanding of the problem we’re trying to solve, and for whom it is a problem. Do they all agree? We’d also examine the external contexts that the system will exist in: user, industry, and technology.\n\nThird, we’d talk to the prospective self-service users. Our client isn’t the only player in its huge market, and most of their customers are already familiar with several competing systems. By comparing and contrasting the language and mental models of these customers with what we know about the existing internally-focused system, we’d discover where we have alignment and where we have conflict.\n\nBecause it’s always easier to leverage entrenched behaviors than to try to instigate new behaviors, our insights will directly influence the prioritization, naming, and design of the features, functions, and flows of the new system. We’ll even spot opportunities to be better than the competition!\n\nFinally, we’d design and construct prototypes&thinsp;&mdash;&thinsp;and test them.\n\nThe time and effort we spend together in up-front sense-making may not feel like “design.” But it’s one of the most important and best investments you can make.\n"},{"title":"New to Elixir 1.3 - Kernel.pop_in","tags":["elixir","engineering"],"summary":"Working with large objects just became easier","legacy":false,"id":"2016/06/05/elixir-1-3-kernel-pop-in","employee":"Brian Cardarella","date":"2016-06-05T00:00:00","body":"\n\nBack in February I wrote about [how to work with deeply nested\nmaps][deepmaps]. One missing piece was the ability to easily prune data\nfrom a deeply nested map. Today I'd like to introduce you to\n`Kernel.pop_in` which will be available in Elixir 1.3.\n\nGiven the following:\n\n```elixir\nmy_map = %{\n  foo: %{\n    bar: %{\n      baz: \"my value\"\n    }\n  }\n}\n```\n\nIn order to delete the `baz` atom you would have to write something like\nthis:\n\n```elixir\nput_in(my_map, [:foo, :bar], %{})\n```\n\nFor this contrite example it may not seem that bad. But let's take a\nlook at another example:\n\n```elixir\nmy_map = %{\n  foo: %{\n    bar: %{\n      baz: \"my value\",\n      qux: \"other value\"\n    }\n  }\n}\n```\n\nIf we wanted to preserve the `qux` atom we'd write:\n\n```elixir\nput_in(my_map, [:foo, :bar], Map.delete(my_map[:foo][:bar], :baz))\n```\n\nNow we're starting to see something that could get ugly. This is where\n`Kernel.pop_in` can help:\n\n```elixir\npop_in(my_map, [:foo, :bar, :baz])\n```\n\nThat's nice and clean! However, unlike the other accessor-based\nfunctions this one returns a tuple:\n\n```elixir\n{\"my value\", %{foo: %{bar: %{qux: \"other value\"}}}} = pop_in(my_map, [:foo, :bar, :baz])\n```\n\nThe first element in the tuple will be the value that is being removed.\nThe second element will be the new map.\n\nElixir 1.3 comes packed with a bunch of improvements for the developer\nexperience like this one. Hopefully we can all start enjoying it soon!\n\n[deepmaps]: https://dockyard.com/blog/2016/02/01/elixir-best-practices-deeply-nested-maps\n"},{"title":"Answering questions early with design sprints","tags":["design sprints","design process","design thinking","business"],"summary":"Learn how using Design Sprints to validate assumptions in the initial planning stages of your project helps ensure its success.","legacy":false,"id":"2016/06/13/answering-questions-early","employee":"Maria Matveeva","date":"2016-06-13T00:00:00","body":"\n\n\nIn this day and age, efficiency is crucial—we live in a world where the rate at which we progress is almost unsettling. In business, efficiency becomes essential in that we must keep up with our competitors, not waste anyone's time, and operate economically and efficiently, all without sacrificing quality. While strategy is possible without an outside party, we’re often too close to a situation to see the drawbacks and obstacles. \n\nWe’re often sensitive about the things we know best, and that’s not a bad thing—it only makes sense that we should be so invested in our work. A new perspective is advantageous in that it allows for a number of unique observations, exposing potential pitfalls and eliminating assumptions. A design sprint can be a good way to enlist that outside perspective.\n\nA while back, I explained [what design sprints are for](https://dockyard.com/blog/2015/08/17/design-sprints-what-are-they-for):\n>The purpose of a sprint is not to deliver a whole product, but a realistic model of a product experience. In a few cases a product experience may be small and focused enough to be encompassed entirely in the sprint. More likely, a design sprint focuses on a specific aspect of an application, and a single user story.\n\nAction towards the implementation of a product may seem more favorable option than planning. However, strategizing and answering unknowns via a design sprint is an investment that will pay dividends by saving so much time and sparing a lot of frustration down the line. Further, involving all the different players (e.g. strategists, engineers, designers, potential users) allows us to brings realism to the project. \n\nThe best time for a sprint is not after a project has already started, but before any implementation work has begun. A design sprint early in the planning stages will go a long way to reduce uncertainty and validate the current project’s merit.  That way, your team can confidently focus on the project’s success.\n\n[Harvard Business Review](https://hbr.org/2016/03/sprints-are-the-secret-to-getting-more-done) recommends sprints because they help “focus on what’s important.” To get an idea of how a design sprint could work for you, check out the open source [Design Sprint Guide](https://dockyard.com/design-sprints) we’ve produced to explain how design sprints can reduce uncertainty by efficiently testing business ideas. \n"},{"title":"Today, User Experience is King—Why Your Technology Choices Should Reflect That","tags":["design","design process","design thinking","marketing","ember","services","single page applications"],"summary":"Users expect both the responsiveness and functionality of native apps, but users also appreciate the convenience of the web. Learn how choosing single-page applications allows you to deliver both.","legacy":false,"id":"2016/06/13/how-technology-choices-affect-user-experience","employee":"Maggie Gigler","date":"2016-06-13T00:00:00","body":"\n\nIn Norton Juster’s _The Phantom Tollbooth_, an intriguing character introduced as The Whether Man tells the protagonist Milo, “Expectations is the place you must always go to before you get to where you're going. Of course, some people never go beyond Expectations, but my job is to hurry them along, whether they like it or not.” While Expectations is an actual locale in a children’s novel, web developers and designers should similarly go beyond Expectations, although the Whether Man is right in that some never do. In order to do so, one must recognize that in today’s market, user experience reigns supreme. The most direct way to surpass Expectations is by delivering a user experience via a mobile web app but that feels like a native app (such as an iOS application that you purchase through the App Store).\n\nI had an English teacher in high school who said that you need to hold your reader’s hand through an essay, meaning your writing should be clear and easy to understand. Similarly, an application should deliver a user interface where a user can move intuitively and fluently through each piece of the application. That being said, that experience can only be as good as the tools that are used to create it. At DockYard, these tools include design strategy and Ember.js as our client-side framework to build the single page applications that we design and develop in-house. \n\nSingle page applications, also known as client-side applications (as opposed to server-rendered applications), are web applications that upload to a single HTML page, dynamically updating the experience as the application is in use. Because of a client-side configuration, an application can respond to its users instantly. The design supports self-directed navigation, and the process is not disrupted by the reload of a page, which creates a more native feel. Further, these web applications cater to all variants of operating systems, and the framework we use to build these applications—Ember.js—is backwards compatible, meaning there will be support for the long haul. Ember.js is also a versatile framework, so it can also be used to build can be used for hybrid apps, which live within a native app “shell” but can be launched within a web browser (e.g. [LinkedIn](http://www.linkedin.com), [Groupon](https://www.groupon.com/), and [Yahoo](http://www.yahoo.com) use Ember.js).\n\nBy design, these applications help to alleviate information overload and simplify navigation, which allows users to easily understand content. Users are therefore encouraged to engage further, whether they are aware of it or not. Before I started working here, I didn’t really pay attention to UX. Now, I’ve noticed that users, including myself, become frustrated with longer-than-needed loading times and poor design. Importantly, applications that have faster response times yield higher conversions, so you get a greater return on investment with a single page app. Additionally, [according to surveys done by Akamai and Gomez.com](https://blog.kissmetrics.com/loading-time/), nearly half of web users tend to abandon a site that isn’t loaded within 3 seconds. 79% of web shoppers who have trouble with website performance say they won’t return to the site to buy again.\n\nWhen you think from the perspective of the user and strategize production with them in mind, you set yourself up for the greatest chance of success. You can ensure that your product is user-driven from the beginning by engaging design strategies, such as user research and prototyping, which can allow you to test initial hypotheses and create a product development roadmap. In this way, you can build reliably and save yourself time and frustration in the future.\n\nWhen applications are built well, its users have more agency to interact with the application more deeply. The single page web app model is at the forefront of mobile and web design and development, allowing both designers and developers to consider unique solutions. Please be advised: if you’re not paying attention, you can quickly find yourself in the Doldrums, and no one wants that.\n"},{"title":"Is design really just decoration?","tags":["design sprints","design process","design thinking","business"],"summary":"What exactly is design? What does it mean to take a design-first approach to solving problems?","legacy":false,"id":"2016/06/13/is-design-decoration","employee":"Mark Kaplan","date":"2016-06-13T00:00:00","body":"\n\nHistorically, design has been [an afterthought](https://dockyard.com/blog/2016/04/19/is-it-time-to-call-a-designer), the philosophy behind it being, “Build something, then we’ll employ design afterwards to improve its appeal.” That being said, as Mike Monteiro describes in [You’re My Favorite Client](https://abookapart.com/products/youre-my-favorite-client), bringing in designers once a product has been built is “akin to baking a cake, and *then* hiring a baker to make it taste good.”\n\nIn today’s competitive marketplace, solid user experience design is a key advantage—you can’t succeed without it. Products can no longer succeed simply because they work—there are too many other products competing for your users’ attention. Users want to be impressed, and starting with exceptional UX design is a necessity to achieve that.\n\n##Visual design refinement *can* be left for later.\n\nInvolving design brings up another common misconception that begs the question, “What is exactly is included in design?” If  we narrowly define design as color, typography, pattern, and layout, then it is understandable how that might be left for later. \n\nThere are a few instances when it does make sense to begin a project with visual design—particularly for branding and marketing campaigns. If you’re tasked with designing a digital experience for disinfectant wipes, you could use a design sprint to create and test visuals-and-copy concepts. You might come out with two concepts: one around “a mother’s instinct to care for her family” and the other “the inconvenience of taking a sick day.” \n\nWithout a strong visual component, it would tough to communicate these emotional concepts to potential consumers to gauge their response. One or more additional sprints could be used to flesh out the features and functionality of a campaign and application that leverage the concept that emerged from that initial sprint.\n\nHowever, in most of the projects we encounter, we're not designing visual branding elements in isolation. Rather we're working out complex experiences for products and services, along with the visual identity, the sum total of which *become* the brand. In these, it does not make sense to lead with visual design. In order to design and create an effective, well-done user experience, one must establish who the users are, what the goals are for the product, and validate the product’s workflows. \n\n##What’s there beyond visual design?\n\nA designer can barely [cross the road](https://dockyard.com/blog/2015/09/10/design-is-about-systems) without considering the systems and forces in place that are behind a variety of scenarios. While one potential solution for a poorly-designed crosswalk is creating a better-looking sign, most of the work behind that decision will be strategically thinking about the systems behind the crosswalk and relevant interactions.\n\nMany parts of our design-first approach to business problems at DockYard could go by different names. Here are some examples that are crucial to its process despite not being initially associated with design:\n\n###Product strategy\nAs designers, we ask lots of questions about why and how a product will serve its users, while at the same time achieving business goals of the product owner. \n\n###Research\nResearch at the early stages of a project can prevent expensive mistakes later down the line. Questions we ask could include:\n- “Does your audience actually want the product?” \n- “What does the audience think the product does?” \n- “Does your audience exist? Is there a viable market for this product?”\n\n###Planning\nOnce we start building, we discuss what should be built first and how production can be implemented in manageable chunks, with testing and check-ups in between. We examine if there are certain parts of the product or service and any differences between them.\n\n###Testing\nHaving real users perform a specific task on a real product or a prototype is the only way to discover whether it actually works in the way which you expect. Moreover, user research allows you to potentially uncover and fix glitches early. User tests are more valid and the data is more authentic if an outside party helps run the tests in an impartial manner.\n\n###Setting up goals & measures\nFinally, we operationally define success and how to measure that success. By setting a baseline early on, you have a standard to which to compare later performance.\n\nPlanning, testing, and research are all parts of design. When applied early, these exercises are magnified in terms of effectiveness. Afterwards, during the product development stage, we'll have some basis for making each of the hundreds decisions that go into your product.  \n"},{"title":"Bringing Ecto Changesets into Ember.js","tags":["ember","javascript","addon"],"summary":"Changesets in Ecto are composable and allow casting and validation when manipulating models. We brought this concept over into Ember.js, which makes dealing with complex forms a cinch.","legacy":false,"id":"2016/06/17/ember-changeset","employee":"Lauren Tan","date":"2016-06-17T00:00:00","body":"\n\nThe past month or so, I've been working on an [Elixir][elixir] and [Phoenix][phoenix] API for a client. I am blown away by how nice it is working with Elixir and functional programming (FP) concepts. FP feels more intuitive and less prone to \"shoot yourself in the foot\" scenarios compared to OOP. In fact, I try to use functional approaches wherever possible in JavaScript as well.\n\nThat isn't to say that one is better than the other, but in my experience less unexpected behavior occurs in FP. It turns out whole classes of bugs disappear when embracing immutability and pure functions.\n\n## Ecto Changesets to the Rescue\n\nIn Elixir, we use [Ecto][ecto], a DSL for writing queries and interacting with databases. One of the core concepts in Ecto is the [changeset][ecto-changeset] – an atomic collection of changes. Changes are validated and checked against database constraints (such as uniqueness) before casting. This ensures that we catch invalid data in the app layer before insertion into the database. Ecto is often confused with [Rails][rails]' [ActiveRecord][active-record], but it isn't an ORM, and shouldn't be used like one.\n\nThe idea for bringing changesets into Ember occurred to me while I was working on a new client app. An edit page featured 3 forms, all bound to the same model. Each hidden form had separate \"toggle\", \"save\" and \"reset\" actions. Using [`ember-form-for`][ember-form-for] and [`ember-cp-validations`][ember-cp-validations], this turned out to be harder than I thought. Editing one form would immediately update the model with 2-way bindings. This was a poor user experience, since you might edit more than 1 form at a time, but want to separate saves and resets.\n\n## Changesets in Ember\n\nIn my mind, I could see a solution using changesets. Each form would have a separate changeset, so changes (and validations) would be independent. It turns out that this approach works really well, and I'm happy to announce that you can install it today as an addon with:\n\n```\nember install ember-changeset\nember install ember-changeset-validations\n```\n\nI wrote the addon with compatibility in mind, so it's easy to wire up with your favorite validation library. The simplest way to incorporate validations is to use [ember-changeset-validations][ember-changeset-validations], a companion addon. It has a simple mental model, and there are no observers or CPs involved – just pure, plain JavaScript functions.\n\nLet's take a look at [`ember-changeset`][ember-changeset] is implemented, and we'll also demonstrate how they align with Ember's [Data Down Actions Up][ddau] (DDAU) philosophy.\n\n## Virtual Properties with `unknownProperty` and `setUnknownProperty`\n\nThe core concept behind `ember-changeset` is the definition of `unknownProperty` and `setUnknownProperty`. These methods are invoked (if present) in `Ember.get` or `Ember.set` whenever an Ember Object does not define a property. Ruby developers would be familiar with this behavior via the `method_missing` method. A colleague I used to work with wrote an excellent [blog post][metaprogramming-in-ember] on this topic, please check it out if you're interested in finding out more!\n\nFor example:\n\n```js\nlet Person = EmberObject.extend({\n  firstName: null,\n  lastName: null,\n\n  unknownProperty(key) {\n    console.log(`Could not get ${key}!`);\n  },\n\n  setUnknownProperty(key, value) {\n    console.log(`Could not set `${key} with ${value}!`);\n  }\n});\n```\n\nWhen a `Person` is created, trying to `get` or `set` a property other than `firstName` and `lastName` will invoke the `unknownProperty` and `setUnknownProperty` methods respectively:\n\n```js\nlet jim = Person.create({ firstName: 'Jim', lastName: 'Bob' });\njim.get('firstName'); // \"Jim\"\njim.get('fullName'); // \"Could not get fullName!\"\njim.set('age', 25); // \"Could not set age with 25!\"\n```\n\nThese two methods allow us to _proxy_ our changeset to the actual model, meaning we can hold back changes but still forward `get`s to the model. \n\n## Storing Changes\n\nOur changeset needs a reference to the underlying model, as well as an internal list of changes to be applied. We can set this up in the `init` method of our object, which is invoked whenever a new instance is created. \n\n```js\nexport function changeset(obj, validateFn/*, validationMap */) {\n  return EmberObject.extend({\n    init() {\n      this._super(...arguments);\n      this._content = obj;\n      this._changes = {};\n      this._errors = {};\n      this._validator = validateFn;\n    }\n  });\n}\n\nexport default class Changeset {\n  constructor() {\n    return changeset(...arguments).create();\n  }\n}\n```\n\nWe want to be able to forward `get`s to `_content`, but hold back `set`s on `_changes`, and this is easy enough to set up via virtual properties:\n\n```js\n{\n  unknownProperty(key) {\n    let content = get(this, '_content');\n    return get(content, key);\n  },\n\n  setUnknownProperty(key, value) {\n    return this._validateAndSet(key, value);\n  },\n\n  _validateAndSet(key, value) {\n    // if valid, set it on `_changes`\n    // otherwise set it on `_errors`\n  }\n}\n```\n\nSince a changeset should only allow valid changes to be set, we validate the change using the `validateFn` function that was passed in to the changeset factory. If a change is valid, we add it to the hash of changes in `_changes`, and if it's invalid and returns an error message, we add it to the hash of `_errors`. \n\nOf course, there are more implementation details than that, but the concept remains unchanged. After defining a simple public API for using changesets, there wasn't too much more code to add! For example, this is how you would use a changeset:\n\n```js\nlet changeset = new Changeset(user, validatorFn);\nuser.get('firstName'); // \"Michael\"\nuser.get('lastName'); // \"Bolton\"\n\nchangeset.set('firstName', 'Jim');\nchangeset.set('lastName', 'B');\nchangeset.get('isInvalid'); // true\nchangeset.get('errors'); // [{ key: 'lastName', validation: 'too short', value: 'B' }]\nchangeset.set('lastName', 'Bob');\nchangeset.get('isValid'); // true\n\nuser.get('firstName'); // \"Michael\"\nuser.get('lastName'); // \"Bolton\"\n\nchangeset.save(); // sets and saves valid changes on the user\nuser.get('firstName'); // \"Jim\"\nuser.get('lastName'); // \"Bob\"\n```\n\nRolling back changes, and even merging them, becomes trivial with a changeset: \n\n```js\nchangeset.set('firstName', 'Milton');\nchangeset.get('isDirty'); // true\nchangeset.rollback();\nchangeset.get('isDirty'); // false\n```\n\n```js\nlet changesetA = new Changeset(user, validatorFn);\nlet changesetB = new Changeset(user, validatorFn);\nchangesetA.set('firstName', 'Jim');\nchangesetB.set('firstName', 'Jimmy');\nchangesetB.set('lastName', 'Fallon');\nlet changesetC = changesetA.merge(changesetB);\nchangesetC.execute();\nuser.get('firstName'); // \"Jimmy\"\nuser.get('lastName'); // \"Fallon\"\n```\n\n## Data Down Actions Up, Not 2-Way Bindings\n\nOne of the reasons DDAU is so strongly emphasized in Ember 2.x is because it helps us avoid shooting ourselves in the foot with 2-way bindings (2WBs). 2WBs were the \"killer feature\" of many JavaScript frameworks when they first debuted. As client side applications matured and became more sophisticated, developers realized that 2WBs were more harmful than useful. 2WBs led to instability and difficult debugging in the form of cascading changes, and [React][react] was the first library to attempt to solve this problem.\n\nReact's breakthrough was in the use of a virtual DOM, a representation of the actual DOM as a tree-like data structure. Diffing the changes between the virtual and real DOM paved the way for the complete removal of 2WBs – the application simply re-renders whenever there is a change in value. \n\nThis continues to be a simpler mental model, and just like Elixir (and other functional languages), eliminates a whole class of bugs. DDAU in Ember.js is built upon the same idea, that data should flow one way.\n\nUsing changesets in Ember takes the DDAU philosophy used in rendering into the realm of interacting with client side view models. Instead of 2WBs, changesets allow one way data flow to a model, ensuring that they are always valid, and eliminating a whole class of synchronization headaches.\n\n## Is This Real Life?\n\nWhen I dropped in `ember-changeset` and `ember-changeset-validations` into my client app, it instantly clicked with the way I've been writing Ember, using DDAU. My complex forms now have independent validations and changes, and I no longer need to worry about saving an unintended change in one form when I submit another. \n\nBecause `ember-changeset` can be used directly in place of an ember-data model, using it with a form library like [`ember-form-for`][ember-form-for] is trivial using the `changeset` helper:\n\n```hbs\n{{dummy-form changeset=(changeset model (action \"validate\"))}}\n```\n\n```hbs\n{{#form-for changeset as |f|}}\n  {{f.text-field \"firstName\"}}\n  {{f.text-field \"lastName\"}}\n  {{f.date-field \"birthDate\"}}\n\n  {{f.submit \"Save\"}}\n{{/form-for}}\n```\n\n## Validating Changesets\n\nValidation becomes even simpler with changesets. Throughout Ember's history, we have largely relied on addons like [`ember-validations`][ember-validations] which make extensive use of observers. Newer libraries like `ember-cp-validations` use computed properties (CPs) instead, but that still relies on 2WBs. \n\nUsing `ember-changeset` and `ember-changeset-validations`, you can take a functional approach with validations. A validator function is passed into the changeset, that is invoked whenever a property is set. This validator function then looks up the appropriate validator (say `presence` or `format`) on the validation map, and returns `true` or an error message.\n\n```js\nimport {\n  validatePresence,\n  validateLength,\n  validateConfirmation,\n  validateFormat\n} from 'ember-changeset-validations/validators';\nimport validateCustom from '../validators/custom'; // local validator\nimport validatePasswordStrength from '../validators/password-strength'; // local validator\n\nexport default {\n  firstName: [\n    validatePresence(true),\n    validateLength({ min: 4 })\n  ],\n  lastName: validatePresence(true),\n  age: validateCustom({ foo: 'bar' }),\n  email: validateFormat({ type: 'email' }),\n  password: [\n    validateLength({ min: 8 }),\n    validatePasswordStrength({ minScore: 80 })\n  ],\n  passwordConfirmation: validateConfirmation({ on: 'password' })\n};\n```\n\nA validator like `validatePresence` is simply a function that returns a function:\n\n```js\n// validators/custom.js\nexport default function validateCustom({ foo, bar } = {}) {\n  return (key, newValue, oldValue, changes) => {\n    // validation logic\n    // return `true` if valid || error message string if invalid\n  }\n}\n```\n\nWhich is simpler to reason about compared to an OOP implementation that relies on extending base classes and holding on to state. Because validation maps are simply POJOs, composing validators is intuitive:\n\n```js\n// validations/user.js\nimport {\n  validatePresence,\n  validateLength\n} from 'ember-changeset-validations/validators';\n\nexport default {\n  firstName: validatePresence(true),\n  lastName: validatePresence(true)\n};\n```\n\nYou can easily import other validations and combine them using `Ember.assign` or `Ember.merge`.\n\n```js\n// validations/adult.js\nimport Ember from 'ember';\nimport UserValidations from './user';\nimport { validateNumber } from 'ember-changeset-validations/validators';\n\nconst { assign } = Ember;\n\nexport const AdultValidations = {\n  age: validateNumber({ gt: 18 })\n};\n\nexport default assign({}, UserValidations, AdultValidations);\n```\n\nThis approach lets you build up validations independent of the model. Ember Data models aren't 1 to 1 representations of server-side records, they're View Models. This means we shouldn't need to validate them the same way we would a server-side model. For example, you might have `User` models in your application, and some of these users might have different roles that require different validation. Best of all, we don't need to use observers or CPs!\n\n## The Only Constant is Change\n\nI hope you enjoyed reading about the concept and implementation of changesets in Ember. DDAU on your models will make your life simpler and your app easier to reason about! Work is still on-going on these addons, so please try them out and let me know if you have any issues or feedback.\n\nAs always, thanks for reading!\n\n[active-record]: http://guides.rubyonrails.org/active_record_basics.html\n[ddau]: https://dockyard.com/blog/2015/10/14/best-practices-data-down-actions-up\n[ecto-changeset]: https://hexdocs.pm/ecto/Ecto.Changeset.html\n[ecto]: https://github.com/elixir-ecto/ecto\n[elixir]: http://elixir-lang.org/\n[ember-changeset-validations]: https://github.com/poteto/ember-changeset-validations/\n[ember-changeset]: https://github.com/poteto/ember-changeset\n[ember-cp-validations]: https://github.com/offirgolan/ember-cp-validations\n[ember-form-for]: https://github.com/martndemus/ember-form-for\n[ember-validations]: https://github.com/DockYard/ember-validations\n[metaprogramming-in-ember]: https://emberway.io/metaprogramming-in-emberjs-627921395299#.8m07o1i8u\n[phoenix]: http://www.phoenixframework.org/\n[rails]: http://rubyonrails.org/\n[react]: https://facebook.github.io/react/\n"},{"title":"Git Init: My First Two Weeks at DockYard","tags":["culture"],"summary":"A review of my first two weeks at DockYard.","legacy":false,"illustration_alt":"Dozens!","illustration":"https://66.media.tumblr.com/8599b2611b8f19e9bb51bb629367a7ea/tumblr_o7pfsqcV6B1uk136vo1_250.gif","id":"2016/06/17/my-first-two-weeks-at-dockyard","employee":"Rowan Krishnan","date":"2016-06-17T00:00:00","body":"\n\n## How I Got Here\n\nTwo weeks ago I started working as an intern at DockYard - though it feels like I’ve been learning from the employees here long before then. If that sounds a bit confusing, I can explain.\n\nAs a young and (excessively) restless developer, I’m constantly experimenting with new libraries and frameworks. The “Projects” directory on my laptop is a messy graveyard of half-finished Todo apps, CRUD blogs, and coding sandboxes created to try out a promising new language or technology. You probably know the type, or share some of these same symptoms.\n\n![Dozens!](https://66.media.tumblr.com/8599b2611b8f19e9bb51bb629367a7ea/tumblr_o7pfsqcV6B1uk136vo1_250.gif)\n\nI decided to check out [Ember.js](http://emberjs.com/) a year ago, and soon realized that I kept finding myself back here on [ReefPoints](https://dockyard.com/blog). I was reading fantastic pieces by DockYard engineers on almost every topic pertaining to Ember development. I learned a tremendous amount about the various nooks and crannies of the framework, but more importantly, began to recognize what makes Ember such a great tool for building truly ~ambitious~ web applications.\n\nSo when I read Michael Dupuis’ email to the Tufts CS group about DockYard looking for new developers, I knew that this would be a fantastic opportunity. Directly working alongside some of the most prolific OSS contributors and JavaScript engineers in the Boston area is not something to miss out on. DockYard takes their engineering seriously, and I really wanted to level up my engineering skills this summer. It was a perfect match.\n\nIn the past couple of weeks, however, I’ve realized that there’s far more to this place than just a deep knowledge of web development.\n\n## What makes DockYard so special?\n\nOne of the things that I immediately noticed clearly defines this place is the sheer amount of collective knowledge shared between everyone in the company. I’ve only just started to get to know people here, and it seems like each member of the twenty-two person team has a unique area of expertise. DockYarders include the creator of an incredible web framework, expert JavaScript and Ember.js engineers, Boston architectural enthusiasts, and craft beer sommeliers. If you put all of these people in a room together and have them work on creative projects, you’re bound to get great results. There is a contagious, inventive energy in the air that is noticeable right when you walk into the office, and you can tell that DockYarders are proud of the work that they do.\n\nExpertise and mastery of craft is ingrained in the culture here, but so is self-improvement and knowledge sharing. DockYard does a fantastic job of consulting and working with their clients, but they do just as great a job of training and educating their own employees.\n\nI've experienced this first hand. Despite how intimidating it could have been to pair program with an engineer on an Ember client project (and fumble around with an addon *that they created*), it has never really felt that way. It’s why every Thursday two DockYarders do an in-depth presentation on a topic of their choosing, which are then frequently taken to conferences around the country. It’s why the Slack channels for technologies like Ember and Phoenix are constantly buzzing with questions and back-and-forth conversations about best practices. And it’s why you’re reading this blog post from me right now: sharing of experience is not just encouraged, it’s expected.\n\n## Time to get to work!\n\nI think I’m joining DockYard at a really exciting time for both the company and the software consultancy industry as a whole. There’s such a wide variety of interesting and challenging projects being started, and the tools with which to build them have never been more promising or enjoyable to use. DockYard recognizes this more than anything else, and makes sure to invest their time in projects and technologies that have the most future potential.\n\nMy goal for the next three months is to learn as much as possible from the many talented individuals in the office, and hopefully be able to contribute in my own way. I’m excited to get hands-on experience working with clients, but I’m also looking forward to participating in the many traditions that separate DockYard from other companies: Wicked Good Ember, hallway talks, monthly outings, DockYard Fridays, and countless others. I know that at many points I will struggle, and perhaps even fail, but that’s okay. In fact, that’s what I signed up for - a challenging new experience. Here’s to a great summer.\n"},{"title":"Component Dependency Injection for Testing In Ember.js","tags":["ember","javascript"],"summary":"Dependency injection is a useful technique for decoupling parent components from its children.","legacy":false,"id":"2016/06/28/component-dependency-injection","employee":"Lauren Tan","date":"2016-06-28T00:00:00","body":"\n\nThe [Dependency Injection][dependency-injection] (DI) pattern is a subset of [Inversion of Control][ioc], and is a useful technique for decoupling the creation of a dependency from the object itself. Don't let the terminology scare you though! DI is really just [giving an object its instance variables][di-demystified]. \n\nFor example, below is a simple example of the `Player` class being implicitly coupled to the `Bag` class. The `Player` is responsible for creating the dependent objects.\n\n```js\nexport default class Player {\n  constructor() {\n    this.inventory = new Bag({ /* ... */ });\n  }\n\n  add(item) {\n    return this.inventory.add(item);\n  }\n}\n\nlet bob = new Player();\n```\n\nAlthough the example is simple, it's fairly easy to see that this implementation could be difficult to test in isolation, as you now need to know about the `Bag` class in the `Player` class' test. DI can help us here:\n\n```js\nexport default class Player {\n  constructor({ storageObject }) {\n    this.inventory = storageObject;\n  }\n\n  add(item) {\n    return this.inventory.add(item);\n  }\n}\n\nlet bob = new Player({ storageObject: new Bag({ /* ... */ }));\n```\n\nIn the second example, we \"inverted control\" of the player's inventory, and now we pass the storage object instance at runtime. This means that in our test, we can simply stub the inventory object out:\n\n```js\ntest('it adds an item', function(assert) {\n  let dummyStorage = { /* ... */ };\n  let dummy = new Player({ storageObject: dummyStorage });\n\n  assert.ok(/* ... */);\n});\n```\n\nThe `Player` class no longer needs to know anything about the `Bag`, and also allows other kinds of storage object classes to be used. Great!\n\n## Component Dependency Injection\n\nI recently realized that the DI pattern can also be used to great effect in Ember components. For example, let's say you have a container or parent component that uses multiple child components:\n\n```hbs\n<!-- templates/application.hbs -->\n\n{{edit-location location=location}}\n```\n\n```hbs\n<!-- components/edit-location.hbs -->\n\n{{google-map \n    lat=location.lat \n    lng=location.lng \n    setLatLng=(action \"setLatLng\")\n    setMarkerRadius=(action \"setMarkerRadius\")\n}}\n{{edit-location-form location=location}}\n{{location-activity location=location}}\n```\n\nThe parent component `edit-location`'s primary responsibility is to provide UI to edit a location. It could have actions defined on it, like so:\n\n```js\n// components/edit-location.js\n\nexport default Component.extend({\n  actions: {\n    setLatLng(latLng) {\n      // logic\n    },\n\n    setMarkerRadius(radius) {\n      // logic\n    }\n  }\n});\n```\n\nThe `google-map` component provides UI for the user to drop a marker on a map, and adjust the radius around the marker by using the radius control. Needless to say, that UI interaction is quite difficult to test, and is tested in the `google-map` component test itself. Because the `edit-location` component is tightly coupled to its child components, testing it is no easy task. We need to make sure all the child components are setup just right, which introduces a lot of boilerplate in our component integration test.\n\n## Not my concern\n\nIn this scenario, the `edit-location` component itself shouldn't need to concern itself with _how_ the `latLng` and `radius` arguments are passed into its actions. The drag and drop UI is a concern of the `google-map` component, and as such should be tested in its own component integration test.\n\nUsing DI, we can decouple the `edit-location` component from its child components, and clean up our tests. This technique is currently only possible with [contextual components][contextual-components] due to the use of the `component` and `hash` helpers, which were made available in [Ember 2.3.0][ember-2-3]. \n\n```hbs\n<!-- application.hbs -->\n\n{{edit-location \n    location=location\n    ui=(hash\n      location-map=(component \"google-map\")\n      location-form=(component \"edit-location-form\")\n      location-activity=(component \"location-activity\"))\n}}\n```\n\nWe've passed in a hash of the child components using the `hash` and `component` helpers. This effectively inverts control to the template that calls the `edit-location` form:\n\n```hbs\n<!-- components/edit-location.hbs -->\n\n{{ui.location-map \n    lat=location.lat \n    lng=location.lng \n    setLatLng=(action \"setLatLng\")\n    setMarkerRadius=(action \"setMarkerRadius\")\n}}\n{{ui.location-form location=location}}\n{{ui.location-activity location=location}}\n```\n\nNow, in our tests, we'll need to write a little test helper to create a dummy component we can use to no-op (do nothing). Credit goes to [@runspired][runspired] for nudging me in the right direction:\n\n```js\n// tests/helpers/dummy-component.js\n\nimport Ember from 'ember';\n\nconst {\n  Component,\n  assign,\n  getOwner\n} = Ember;\n\nexport default function registerDummyComponent(context, name = 'dummy-component', opts = {}) {\n  let owner = getOwner(context);\n  let options = assign({ tagName: 'dummy' }, opts);\n  let DummyComponent = Component.extend(options);\n\n  unregisterDummyComponent(context);\n  owner.register(`component:${name}`, DummyComponent);\n}\n\nexport function unregisterDummyComponent(context, name = 'dummy-component') {\n  let owner = getOwner(context);\n\n  if (owner.resolveRegistration(`component:${name}`)) {\n    owner.unregister(`component:${name}`);\n  }\n}\n```\n\nThis test helper registers a fake component in the container, making it available for us to use in our component integration test:\n\n```js\n// tests/integration/edit-location-test.js\n\ntest('it ...', function(assert) {\n  registerDummyComponent(this);\n  this.set('location', {});\n  this.render(hbs`\n    {{edit-location\n        location=location\n        ui=(hash\n          location-map=(component \"dummy-component\")\n          location-form=(component \"dummy-component\")\n          location-activity=(component \"dummy-component\"))\n    }}\n  `);\n\n  assert.ok(/* ... */);\n});\n```\n\nNow we can test the `edit-location` component itself without worrying about setting up child components. That said, DI still allows us to test those child components integrating with `edit-location`, in a more controlled environment:\n\n```js\n// tests/integration/edit-location-test.js\n\ntest('it updates location via the form', function(assert) {\n  registerDummyComponent(this);\n  this.set('location', {});\n  this.render(hbs`\n    {{edit-location\n        location=location\n        ui=(hash\n          location-map=(component \"dummy-component\")\n          location-form=(component \"edit-location-form\")\n          location-activity=(component \"dummy-component\"))\n    }}\n  `);\n\n  assert.ok(/* ... */);\n});\n```\n\nI hope you find this useful! It's not a silver bullet by any stretch, but DI can help you write better isolated components and simplify your tests.\n\n[contextual-components]: http://emberjs.com/blog/2016/01/15/ember-2-3-released.html#toc_contextual-components\n[dependency-injection]: http://martinfowler.com/articles/injection.html\n[di-demystified]: http://www.jamesshore.com/Blog/Dependency-Injection-Demystified.html\n[ember-2-3]: http://emberjs.com/blog/2016/01/15/ember-2-3-released.html\n[ioc]: http://martinfowler.com/articles/injection.html#InversionOfControl\n[runspired]: https://twitter.com/runspired"},{"title":"The Personal Growth Cycle: Learning How To Learn","tags":["alumni"],"summary":"Learning a skill is rewarding, but learning how to learn is even more so.","legacy":false,"id":"2016/07/01/cycle-of-growth","employee":"Lauren Tan","date":"2016-07-01T00:00:00","body":"\n\nFor the longest time, I've felt like an imposter in the ever-increasingly complex world that is the tech industry. New terminology and best practices emerge every other day at a relentless pace. Frameworks come and go, new ideas become standard, and thought-leaders discover that _yet another thing_ is considered harmful.\n\nWith an intense culture unlike any other, it's no surprise that feelings of inadequacy are commonplace. Prior to joining DockYard, I was just another Australian developer enjoying internet anonymity. The [startup][everperform] I worked with (2014) then used Ember on the front-end, and my colleagues and I found it difficult to work with. This was prior to Ember 1.13, so things were a lot different back then!\n\n## The first step is admitting it\n\nI started my [blog][blog] during that time, mostly writing about \"cool\" things we had done with Ember like drag and drop, flash messages, and so on. I didn't think too much of it then. After all, I was still considered relatively junior, it being my first real job outside of my [own startup][pricegeek]. \n\nStarting out as a self-taught designer, I learnt front-end development while working on my startup, and in my time at my first job. Coding was unlike anything I had ever done before, but I loved it, and kept at it even when I was frustrated.\n\nMy writing was a way to document (and learn from) how I tried to solve a particular problem. To my surprise, some of the more prominent members of the Ember community started to take notice, and I was asked to try my hand at submitting a talk to [EmberConf][emberconf-2015]. \n\n## Get out of your comfort zone\n\nPublic speaking was (and still is) my greatest fear, so it took a little convincing before I decided I would try submitting a proposal. My talk ended up being accepted, and despite being absolutely terrified, I walked up on stage facing hundreds of people, and [delivered the talk][ambitious-ux] I had prepared so hard for.\n\n[Brian][brian] reached out to me shortly after, and I joined DockYard in March last year. He saw the potential in me I couldn't, and in the past year or so, I've grown in many ways. There are amazing people here who constantly push you to become better, and it's no exaggeration when I say that DockYard is one of the best places I've been fortunate enough to work at.\n\nWhen I first started, I was [terrified][its-ok]. I didn't think I could do it, because I had little experience. Despite that fear, I kept at it – things started making sense, and I could even explain to others. \n\nThis year, I worked solo on a project for a client – an API built using Elixir / Phoenix. I was terrified, again. I didn't think I could do it, because I had only read a book and wrote a tiny bit of Elixir. Despite that fear, I kept at it – things started making sense, and now I'm a self-taught full stack developer.\n\n## The cycle of growth\n\nI'm not going to tell you that getting good at something takes 10,000 hours, but it does take time and effort. Learning a new skill or improving one is rewarding, but _learning to learn_ will reward you many times over.\n\nUnfortunately, I can't teach you how to learn. Everyone learns differently, and you must discover it for yourself. What I can tell you, is that _how_ you learn (visual, experiential, etc) is merely an implementation detail. What's important is the cycle:\n\n1. Reflect – Know where you stand\n2. Do – Get out of your comfort zone\n3. Learn – Fail and try again\n\nIf you're familiar with the [Lean Startup][lean-startup], you'll notice that the steps are the same. The cycle is your real world [REPL][repl], and just like programming, is an excellent way to take a more exploratory approach to learning.\n\n## Help someone else to grow\n\nWhen you find yourself in a position to mentor, embrace it. Although the cycle is personally rewarding, being able to help someone else to \"learn how to learn\" is even more so. \n\nIt's bittersweet, but this month will be my last month working with this amazing team. DockYard has been the perfect environment to put this in practice, and I am eternally grateful that I had the chance to be a part of something special. \n\nHere's to more growth!\n\n[ambitious-ux]: https://www.youtube.com/watch?v=TlU0m18Pr-Y\n[blog]: https://medium.com/@sugarpirate/\n[brian]: https://twitter.com/bcardarella\n[emberconf-2015]: http://2015.emberconf.com/\n[everperform]: https://everperform.com/\n[its-ok]: https://gds.blog.gov.uk/2016/05/25/its-ok-to-say-whats-ok/\n[lean-startup]: http://theleanstartup.com/\n[pricegeek]: http://www.thepricegeek.com/\n[repl]: https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop\n"},{"title":"DockYard Expands To San Diego","tags":["announcements","business"],"summary":"Coast to coast","legacy":false,"id":"2016/07/05/dockyard-expands-to-san-diego","employee":"Brian Cardarella","date":"2016-07-05T00:00:00","body":"\n\nFor almost two years I've been talking a big game inside DockYard about\nopening a San Diego office. The need for this became more apparent after\nthe winter of early 2015 in Boston. Try recruiting anyone to move to\nBoston after hearing about nearly 20 ft of snow being dumped on the\ncity. So I figured we'll open an office in the nicest place in America.\n\nHaving a San Diego office gives us a West Coast presence. Heading up\nthis effort we've hired [Heather Brysiewicz][heather]. She's been heavily involved\nwith the tech community in San Diego for a few years now, running the [SD\nJS meetup][sdjs] and founding the [SD Ember meetup][sdember]. She recently started\nco-organizing the [SD Elixir meetup][sdelixir]. On top of that she's an amazing\nengineer.\n\nWe're beginning to explore other locations as well. As we continue to\ngrow some of our existing employees have expressed interest in leaving\nBoston. Until recently we held a \"Boston-only\" policy but over the past six\nmonths we've been experimenting with changing this. Our reluctance lay\nwithin managing client projects with remote devs properly and exporting\nour culture. Our team has been working hard to codify many of the\naspects of what it means to work at DockYard but also work with\nDockYard. We've come to a good comfort level with remote developers \nand the idea of other \"DockYard\"s outside of Boston.\n\nStarting today we're now accepting contracts and offering on-site\ntraining for Ember.js and Elixir for the West Coast. <a\nhref=\"https:/dockyard.com/contact\">If you have a\nproject in mind please get in touch!</a>\n\n[heather]: https://twitter.com/caligoanimus\n[sdjs]: http://www.meetup.com/sandiegojs/\n[sdember]: http://www.meetup.com/sandiego-ember/\n[sdelixir]: http://www.meetup.com/San-Diego-Elixir-Erlang/\n"},{"title":"Gotta Catch 'em All!","tags":["design","design thinking","observations"],"summary":"DockYarders' take on Pokemon GO with some UX flavor","legacy":false,"illustration_alt":"Drowzee","illustration":"http://i.imgur.com/vCbmLzz.jpg","id":"2016/07/20/gotta-catch-them-all","employee":"Romina Vargas","date":"2016-07-20T00:00:00","body":"\n\n![Drowzee](http://i.imgur.com/vCbmLzz.jpg)\n\nIf you haven't yet heard of Pokemon GO, you might be living under a rock. Or\nunder an Onyx. Pokemon GO was released on July 7, 2016 in the United States and\nit immediately became viral. It's a mobile application that makes use of the GPS\nand camera to bring the user an Augmented Reality experience by allowing them\nto catch Pokemon in a real-world environment. The game encourages its users to\ngo outside and become the [Pokemon Masters](https://www.youtube.com/watch?v=NcfdoSuC6MI)\nthey always dreamed of being, or now dream of being. Talk about nostalgia. Even\nif one didn't grow up with the franchise, the newly-released game is still\nrevolutionary due to its immersive nature and social aspect. Like much of the\nworld, most DockYarders have picked up the game and some would like to share\ntheir thoughts and experiences with you!\n\n# Maria M: Pokemon GO UX Lessons\n\nI took four days to experiment casually with the game - and looked over the\nshoulder of a few others with a far more serious approach to it. Here's what I\nlearned about UX design.\n\n### 11:30pm, near downtown Boston\n\nI'm an observer right now, not actively playing. Pleasant summer night in\nBoston and a whole lot of people are walking circles around the body of water\nnear the Christian Science Center - a complex made up of a large cathedral and\nan even larger administrative building. Normally, the area is pretty empty at\nthis hour. Not everyone is staring directly down at their phone screen, but I\ncan pretty much tell who is playing the game and who is here for other reasons.\nThe players are all in their 20s, and come from a similar demographic, about\nhalf white and half Asian. (This does not represent what I have seen in Boston\non average, or even in the Boston tech and design scene.)\n\n### Population\n\nOnce I got adjusted to the sight of the chill looking crowds gathering in spaces\nthat are normally emptier, I realize what looks “off” about the situation. It’s\nthe feeling I might get on a college campus tour, when everyone’s around my age.\nI am guessing the earliest adopters of Pokemon GO very clearly the people of more\naccess to games and the Internet and technology in general. I spot just one\nfamily with a stroller - and they stand out. I realize that just being able to\ngather here unencumbered by 6am school drop-offs, caring for a family, or working\nseveral jobs represents privilege and access to leisure that not everyone has.\n\nI think this reveals that we often end up designing for folks just like us. Early\nadopters of the Pokemon GO are probably similar to the first users who sign up for\nmany web apps, and even though we assume we're making something that's good for\nthe “general public” we’re often actually catering only to ourselves.\n\n### The space\n\nObviously one of the reasons that the game is so addicting is that it uses 3-D\nspace to play the game. You physically have to be close to an object to claimant\nin the game and geolocation is playing a major role in making that happen. The\ngame is designed for walking on foot but sometimes you can cheat a little bit and\nfor example the on the bike or claim some of the objects from a public bus. But\nin either case I found that I've learned remarkably well after just a few attempts\nexactly how close I have to be physically to a marks location in order to claim it.\nI think this is especially interesting because before this I had a general sense\nof how accurate things like GPS and Wi-Fi are to locate me in 3-D space but now I\nhave a physical sense in my body exactly how far I need to walk to or from the\ncorner to be within reach of a specific object on the 3-D map. If nothing else,\nthe game will vastly improve our understanding of the accuracy of GPS and Wi-Fi\nlocation tracking.\n\n### When a digital experience works, it changes the world\n\nThe third takeaway for me is a really hopeful one. Obviously I'm not going to be\nthe only one who says that his game is changing the world. People are not just\nsitting or walking staring at their phones by themselves. They are chatting with\nother people, yelling out when when they successfully capture rare Pokémon they\nreally wanted and in general or just smiling at each other. I assume these are\nthe same people who would normally sit at home by themselves staring at the\npersonal screen and not talking to anyone. And even though we fight around the\nsame damn pool of water near the Christian science center about seven times\nalready, I'm getting a fun romantic evening walk with my s/o, when normally at\nthis time I would have been staring blankly at my own screen.\n\nHe just informed me that it is midnight and we should probably leave so we could\nget home in time to get a little bit asleep before starting work tomorrow. But\noverall it was a fairly nice night and he seems happy as well.\n\nBut more importantly, the experience people are having in this park and in many\nplaces in the world right now with this game is not virtual — it's real. And it\ngives me hope because when working for a long time on complex products it's easy\nto get discouraged. When you're tired, it’s easy to slip into thinking that\nwhatever you're making will not make a difference. This game offers us a reminder\nfor me of real change in the physical world that can happen when an interaction\nis built just right.\n\n>[_\"Broken tech culture is seeing the success of Pokémon Go & attributing it to AR\ninstead of a huge 25-year-old global cultural phenomenon.\"_](https://twitter.com/anildash/status/753261028801187840)\n\n# Cory T: Expert user point of view\n\nWith walking everywhere and following PokemonGoHub on [Twitter](https://twitter.com/pokemongohub),\nI have been appointed DockYard Pokemon GO expert! This game has been on my radar\never since one of the first teasers surfaced online and the nostalgia hits you\nlike a punch from Rocky Balboa.\n\nTen minutes after Pokemon GO was available in the Play Store (thanks Twitter) I\nhad the game downloaded and caught my first and favorite Pokemon of all time,\nSquirtle. After seeing Squirtle in my Pokedex I legitimately felt like I was\nback in 4th-6th grade collecting Pokemon cards in my 3-ringed binder. Crazy\nthing is I now I have my own freaking Pokedex on my phone with Pokemon I caught\nin the real world!\n\nNostalgia aside, I might have a different opinion on the UX of the game.\n\nI like it.\n\nFor example, Pokemon GO doesn’t tell you to spin the ball in order to throw curve\nballs (this makes it easy to catch rare Pokemon). The mechanics on how to fight a\ngym is never explained. How to pick what your Eevee will evolve into is not obvious.\n\nDoes this game tell you how to do anything? No. But, I actually like figuring out\nhow to play this game - socializing with other people about new tricks they have\nfound has been great.\n\n### What I want to see\n\n* Web app that lets me manage my Pokemon online\n* Pokemon trading (coming very soon according to Pokemon GO)\n* Have the ability to select multiple Pokemon and transfer them to Professor Ashe\n  * Currently 3 clicks to transfer a Pokemon\n* Currently the game is a grind to find the best version of a specific Pokemon\nspecies, I would rather invest and care for one that I catch and train the Pokemon\nnew attacks and upgrade its statistics. Will make them more personable and pet-like\n\n[Pro tip](https://www.youtube.com/watch?v=M6ereCy5qY4): If you want to actually\nknow what your Eevee will evolve into compared to the random selection, give\nEevee the desired nickname. This should work every time unless there is a\nbug/glitch. The trainers of Vaporeon, Flareon and Jolteon in episode 40 of the\nTV show are the key to this trick:\n\n * Pyro = Flareon\n * Sparky = Jolteon\n * Rainer = Vaporeon\n\n# Patrick B: Resister Turned Lover\n\nGenerally when an audience as large as...well...seemingly the entire world...takes\nnotice of an application, game or service, I start my relationship with said\napplication, game or service with resistance. Not because I don’t want to involve\nmyself but because I want to witness the reactions of others. I’m not judging\npeople using it. I’m observing people using it. Eventually I give in (usually\nafter patch 1 or 2) and then compile my thoughts and assemble my like or dislike\nfor the application, game or service.\n\nThis process has never been harder than with Pokemon GO. Perhaps it’s because no\napplication for a mobile device has become this popular this quickly. Perhaps it’s\nbecause I love(d) Pokemon and don’t want to tarnish my grand memories of the\nfranchise. Perhaps it’s because...it wouldn’t install the first few attempts.\n\nI resisted hard at the beginning. One week later, I’m level 13 and furiously\ncollecting as many Pokemon as I can. I love it as much as I hoped I would. I love\nit as a designer. I love it as a casual fan of Pokemon. I love it as a heavy gamer.\nMy mother loves it. My brother loves it. My cousin loves it. None of them design,\ngame or were ever engulfed in the world of Pokemon.\n\nAt the very least, you should try Pokemon GO. Perhaps you’ll love it too. Here are\nfour reasons why in one week you just might find yourself taking notice to the game\neveryone’s talking about:\n\n### Nostalgia\n\nIf you were at all in tune with video games through the 90s and 00s, you’re\ninevitably familiar with at least the name “Pokemon.” However if you’re familiar\nwith the name, you likely fell hard in love to some degree with the Pokemon empire\n(whether you’d like to admit it or not). If you traded, collected or sold the\ncards you’re very likely to enjoy this game. If you were consumed by the colored\nGameboy games you’re very likely to enjoy this game. If you dreamt of the Snap or\nStadium realms being real environments for you to roam and interact with beyond\nthe 64 joystick you’re very likely to enjoy this game. If you’ve lived by Nintendo\nplatforms in general you’re very likely to enjoy this game. What once was a game\nthen became an empire. That empire is now an entire world.\n\n### We Love Collecting\n\nWhile it remains a strange compulsion, it’s no secret that people like to collect\nthings. Cars, video games, sports memorabilia, sneakers, art, you name it and there\nare people who focus on collecting as much of it as they can. There’s an addictive\npleasure to finding something that may have been lost or perhaps evaded us for\nsome time. Dating back to the Victorians, the act of collecting items has been a\nconsistent habit driven by both necessity and desire. The entire Pokemon franchise\nis heavily built on this addictive action. It’s why we see their playing cards sold\nfor thousands of dollars. It’s why an entire video game can be built around simply\ndiscovering and photographing objects. And it’s partially why people are taking\ntime to feverishly compile libraries of Pokemon in their Pokedex sometimes entirely\nomitting from their play the many other aspects of the game. The idea of collection\nis built directly into their brand. You just “gotta catch them all!” It’s a\nchallenge we secretly love.\n\n### Augmented Reality\n\nWhile VR (virtual reality) is undoubtedly all the rage, there’s something to be\nsaid about AR (augmented reality). Let’s look at it in the context of Pokemon\nGO: It can be created without extra hardware, it’s portable in that it’s reliant\non a mobile device, it doesn’t cost much, and it fuses fictional subjects with\nthe reality of your environment – an actual, unprogrammed, environment. VR,\nwhile amazing in its own right for so many reasons, relies on those things AR\ndoesn’t. This isn’t to say Pokemon GO is popular because of its emphasis on AR,\nbut it proves that an AR driven experience can still be immensely successful.\nBefore we strap on our head gear, what opportunities can this success story shed\nlight on?\n\n### UX Exposure\n\nIt’s not a secret that the Pokemon GO application has kinks. On an average day,\nI have to close and restart the application several times do to it freezing or\ncompletely crashing. Do I care? No because I’m addicted. When I installed Pokemon\nGO it failed to install, and then failed to create my account two times. In fact\nI uninstalled it for a day I was so frustrated. But here I am a week later using\nit. As a visual designer in a UX word, this exposure to conflicts and failures\nhas actually caught my attention, mostly because I’ve forced myself to experience\nthem knowing the payoff will be worth it. It’s allowed me to take notice of how\nthe visuals handle failures on the server side. It’s allowed me to take notice\nof my behaviors when failures do happen. Do I wait to close the app? How long do\nI wait? When do I notice it’s not working correctly? How is this represented by\nthe field of view? Is the AR functionality instigating it? Because I’ve\nexperienced the pleasure of playing, and am willing to suffer to an extent, I’ve\nallowed myself to be content with its failures so much so that it’s begun to\nprovide me insight into aspects of the actual application I may not have given\nthe time to. Maybe it’ll result in a useless collection of observations. But\nmaybe it’ll result in my paying attention to these aspects more so in the next\nproject I’m involved in. Nevertheless, it’s a remarkable feat to be so successful\nyet still provide so many instances of frustration unrelated to the game itself.\n"},{"title":"Productive debugging","tags":["ember","javascript","testing"],"summary":"A peek into different debugging methods","legacy":false,"id":"2016/07/26/debugging-ember-tests","employee":"Romina Vargas","date":"2016-07-26T00:00:00","body":"\n\nIf you attended [Wicked Good Ember](https://wickedgoodember.com/) this past June,\nit quickly became apparent that it was a Test Driven Conference - three\ntesting-related talks happened to be grouped together at the start of the\nconference. It's clear that Ember developers care about testing. In fact, there\nis an open [RFC](https://github.com/rwjblue/rfcs/blob/42/text/0000-grand-testing-unification.md)\nto unify the way Ember does testing. I highly recommend reading it! Currently,\nthere are three different ways to test; one for each of the different types of\ntests: unit, integration, and acceptance. However, while the unification becomes\nreality, we must keep testing as usual, and I'd like to go over some quick tips\nfor debugging in the different test environments!\n\n## pauseTest();\n\nThis first function is acceptance test specific, but according to the RFC, it\nwill eventually become available to use in all types of tests. When writing\ntests, it's helpful to be able to inspect the state of the DOM. Inserting a\ncall to `pauseTest()` inside an acceptance test will pause the test suite at\nthe point that it sees the function call. This allows for developer interaction\nwith the current state of the application. Internally, `pauseTest()` returns a\npromise that will never resolve.\n\n```js\ntest('I can submit the contact form', function(/*assert*/) {\n  visit('/contact-form');\n  return pauseTest();\n\n  // failing interaction\n  click('button:contains(\"Submit\")');\n});\n```\n\nAfter running the above test on the browser, the test suite would pause once it\nreaches L3. The application would be viewable exactly as it appears before\nthe `click` takes place.\n\n_Example use case:_\n\nI want to click the \"Submit\" button but my test is not finding that element,\ntherefore, it's failing. With `return pauseTest()`, I'm able to see that I'm not\nactually in the expected `/contact-form` route, but that I'm being redirected to\nthe `/login` route. Now I can fix my test by logging in before visiting\n`/contact-form`.\n\n## assert.async();\n\nThis function is a favorite of mine, and I remember the excited when I first\nlearned about it a while ago (thanks [Marten][Marten]!). The use of\n`assert.async()` is available to use in both acceptance and integration tests,\nbut it's currently the only way to pause an integration test Calling\n`assert.async()` is similar to `pauseTest()`; you can inspect the state of the\nDOM and play around with it while the test is paused. It's a great tool for\nintegration testing because much of the time, you're testing that certain\ncontent/element appears on the page as a result of a user interaction. I find\nit particularly useful to quickly find `class` names, `data-auto-id`s, etc,\ninstead of going back to the templates where they are defined.\n\nThis [`async()`][async] method comes for free with Qunit, which is Ember's\nbuilt-in testing framework.\n\n```js\ntest('Clicking \"Add contact\" displays new contact form', function(assert) {\n  this.render(hbs`{{contacts users=users}}`);\n  click('button:contains(\"Add contact\")');\n\n  assert.async();\n\n  // failing assertion\n  let form = this.$('[data-auto-id=\"new-contact\"]');\n  assert.equal(form.length, 1, 'New contact form is displayed');\n});\n```\n\nLike with the `pauseTest()` example, once the test runner reaches L5 above,\nthe test suite will pause and the current state of the DOM can be viewed.\n\n_Example use case:_\n\nI want to make sure that my new contact form is displayed on the page. I know\nthat the functionality is working, but my test is still failing. I can add a\ncall to `assert.async()` to check out the DOM. Turns out I was using the wrong\n`data-auto-id`.\n\n## debugger;\n\nNo debugging function left behind. There's no need to explain what `debugger;`\ndoes, but when you need to debug some functionality without caring about what\nthe UI looks like, then you're good to place a `debugger;` call inside any test.\n\n[Marten]: https://twitter.com/martndemus\n[async]: https://api.qunitjs.com/async/\n"},{"title":"How to use git bisect by example","tags":["git","javascript","ember"],"summary":"Learn how to use Git's bisect command with Ember.js as the example","legacy":false,"id":"2016/07/26/how-to-bisect-ember","employee":"Marten Schilstra","date":"2016-07-26T00:00:00","body":"\n\nI'm writing this tutorial because I ran into a problem, while working on an addon, with Ember.js the other day. The problem was that the test suite did not pass anymore on Ember.js' canary build channel, while it used to pass before. After debugging the problem I wanted to find out which commit in Ember.js did break the tests. Thanks to [Robert Jackson](https://twitter.com/rwjblue), who pointed me to a [GitHub comment](https://github.com/emberjs/ember.js/issues/13846#issuecomment-234133694), I've been able to use `git bisect` to find the commit that introduced the issue and [report](https://github.com/emberjs/ember.js/issues/13888) it.\n\n### What bisect does\n\n`git bisect` uses the [bisection method](https://en.wikipedia.org/wiki/Bisection_method) to find the first commit that introduced the bug you are looking for. You will have to tell the bisect command one commit you are sure contains the bug and one commit that you are sure of that it does not contain the bug. Bisect will then start searching, asking you if a given commit it proposes is good or bad, until it has found the commit that introduces your bug.\n\n### Setting up before the bisect\n\nTo find out what commit has introduced a bug in the [Ember.js](https://github.com/emberjs/ember.js) repository, you need to clone a different repository, that is [`components/ember`](https://github.com/components/ember), which contains the Bower builds of Ember.js. You can link this repo to your app directly and then use `git bisect` to find the first build that contains the bug. You can then cross-reference the build with the real Ember.js repo to find the actual commit that introduced the bug.\n\nTo clone and link the `components/ember` repository:\n\n```\ngit clone git@github.com:components/ember.git components-ember -b canary\ncd components-ember\nbower link\n```\n\nNow you need to do a little bit of setup in the app that you are working with. You will need to modify your `bower.json` to use `components/ember#canary` for Ember.js and then link it to the local repository you just cloned. I recommend you do this in a seperate terminal window/tab, as you will have to go back and forth between this and the other a few times.\n\nExample `bower.json` after the change:\n\n```\n{\n  \"name\": \"my-app\",\n  \"dependencies\": {\n    \"ember\": \"components/ember#canary\"\n  },\n  \"resolutions\": {\n    \"ember\": \"canary\"\n  }\n}\n```\n\nAfter updating your `bower.json` remove the installed Ember Bower component and link it to the local one.\n\n```\nrm -rf bower_components/ember\nbower link ember\n```\n\nNow you're ready to start running `git bisect`.\n\n### Finding the bad commit with bisect\n\nFrom the `components-ember` folder start with running the `git bisect start` command, this will start your bisect session. Then run `git bisect bad` to tell the bisect session that the current commit is a bad commit. The next step is a little bit harder, you will need to find a commit that you are sure of to be good. One trick is to go back about six weeks (about one Ember version) in the history and pick a commit, this commit will have a high chance of being good. One warning though: going back too far might cause you to find a bug that is irrelevant to your case. When you have found such a commit, run `git bisect good <sha-of-good-commit>`. The response will look something like the following:\n\n```\nBisecting: 117 revisions left to test after this (roughly 7 steps)\n[4e1224de1687a86dc83936e880104b6b1a48bbe2] Ember Bower Auto build for https://github.com/emberjs/ember.js/commits/d2b56a290a45b23a792575dfa6e3af37cf58bc79.\n```\n\nThis means that there are 117 commits left that can contain the commit you are looking for, and that it will take about 7 more steps to find it.\n\nYou should now notice that bisect has moved the `components-ember` repository to a different commit somewhere between your initial good and bad commits. In this case it is `4e1224de1687a86dc83936e880104b6b1a48bbe2` This is the first commit bisect has selected to test. It will wait for you to report if this commit is good or bad.\n\nNow go back to your app's folder and run your tests (`ember test` for example). If all tests pass the suggested commit must be a good commit, run `git bisect good` in the `components-ember` folder to tell the bisect process that this commit is a good commit. If the tests fail, then run `git bisect bad` to tell the bisect process that this commit is a bad one.\n\nAfter having specified if the commit is either good or bad bisect will respond with a similar message:\n\n```\nBisecting: 58 revisions left to test after this (roughly 6 steps)\n[73f02564972bbd14a719f707af019d94c822939c] Ember Bower Auto build for https://github.com/emberjs/ember.js/commits/1be0354068d933065ac542f49d42d73409366a47.\n```\n\nWith this step it has eliminated 59 commits, and there are only 58 commits left that can contain the commit you are looking for. It has also moved the `components-ember` repository to the next commit that it needs you to test if it's good or bad.\n\nRun your app's tests again and either run `git bisect good` or `git bisect bad` based on the results of the tests.\n\nKeep repeating this process until it reports the bad commit:\n\n```\n9f6b98391523c4be437e1f6cd1a5956e69ecc0a9 is the first bad commit\ncommit 9f6b98391523c4be437e1f6cd1a5956e69ecc0a9\nAuthor: Tomster <tomster@emberjs.com>\nDate:   Sat Jun 11 00:03:22 2016 +0000\n\n    Ember Bower Auto build for https://github.com/emberjs/ember.js/commits/b44f9dad912a73668dda142c34a6858283003403.\n```\n\nCongratulations! You have found the bad commit that introduced the bug that you were looking for. In this case it's `9f6b98391523c4be437e1f6cd1a5956e69ecc0a9`, and luckily the commit message includes the commit the build is from, so you can go to the GitHub url from the commit message and see the original commit.\n\n### What if I wrongly report a commit as bad or good?\n\nUnfortunately, bisect has no undo command, so you will have to start from the top again. To do this first run `git bisect reset`, this will end your bisect session. Now you can start over by running `git bisect start` and then marking a good and bad commit, which then will start the iterative process of marking commits selected by bisect good or bad again.\n\n### Can I automate this a little bit more?\n\nYes you can! Bisect has the command `git bisect run`, which will run a command for you on each iteration. If the command succeeds it will mark the commit as good, if the command fails it will mark the commit as bad.\n\nLet's take a look at how to do this with our example.\n\nTo reliably run the tests each iteration I added the following bash script to the `components-ember` folder, I called it `ember-bisect-test.sh`:\n\n```\n#!/bin/sh\n\ncd <path/to/your/project/folder>\nrm -rf bower_components/ember\nbower link ember\nember test\n```\n\nMark the file as executable:\n\n```\nchmod +x ember-bisect-test.sh\n```\n\nAnd now we can let bisect run your script on each iteration:\n\n```\ngit bisect run ./ember-bisect-test.sh\n```\n\n### What have we learned?\n\nYou have now learned:\n\n  - The basics of how `git bisect` works.\n  - How to use `git bisect` with the Ember.js canary channel to track down commits that introduce regressions.\n  - How to restart the process when you mess it up.\n  - How to automate `git bisect` with a script.\n"},{"title":"Patterns from Ember Composable Helpers","tags":["ember","javascript","engineering"],"summary":"A walkthrough of one of the patterns used in Ember Composable Helpers","legacy":false,"id":"2016/07/27/patterns-from-composable-helpers","employee":"Marten Schilstra","date":"2016-07-27T00:00:00","body":"\n\nCo-creator of Ember Composable Helpers [Lauren Tan][lauren] recently wrote about the [what, why and how][blogpost-lauren] of Ember Composable Helpers.\nNow I'd like to talk about one of the patterns we have used to make Ember Composable Helpers work.\n\n## The fundament of the array helpers is the get helper\n\nMost of the array helpers are built upon the implementation of the [get helper][get-helper]. \nLet's take a closer look at a simplified version of the `get` helper:\n\n```js\nimport Ember from 'ember';\n\nconst { \n  Helper, \n  get,\n  set,\n  observer,\n  defineProperty,\n  computed: { oneWay }\n} = Ember;\n\nexport default Helper.extend({\n  compute([targetObject, propertyPath]) {\n    set(this, 'targetObject', targetObject);\n    set(this, 'propertyPath', propertyPath);\n\n    return get(this, 'content');\n  },\n\n  propertyPathDidChange: observer('propertyPath', function() {\n    let propertyPath = get(this, 'propertyPath');\n    defineProperty(this, 'content', oneWay(`targetObject.${propertyPath}`));\n  }),\n\n  contentDidChange: observer('content', function() {\n    this.recompute();\n  })\n});\n```\n\nLet's start with the `compute` function on lines 13-18. \nIt expects a `targetObject` and `propertyPath` param, which stands for the object you want to get the given property from.\nThese params are set as properties on the helper itself each time `compute` is called. Finally the `compute` function returns the `content` property. This will be the result of getting the `propertyPath` from the `targetObject`.\n\n## Why not just return the given property from the target object?\n\nWell, writing the helper as follows would have the downside that it will only recompute whenever the `targetObject` changes or when the `propertyPath` changes, but not when the desired property on the target object changes.\n\n```js\nimport Ember from 'ember';\n\nconst { Helper: { helper }, get } = Ember;\n\nexport function getHelper([targetObject, propertyPath]) {\n  return get(targetObject, propertyPath);\n}\n\nexport default helper(getHelper);\n```\n\n## Solution: Observers\n\nYes you heard it right, observers are a perfect candidate to solve the problem that our helper won't recompute when we want it to. So let's take a look at the `propertyPathDidChange` and `contentDidChange` observers.\n\n```js\npropertyPathDidChange: observer('propertyPath', function() {\n  let propertyPath = get(this, 'propertyPath');\n  defineProperty(this, 'content', oneWay(`targetObject.${propertyPath}`));\n})\n```\n\nLet me explain what happens with this observer. On the first line we define an observer that will be triggered every time `propertyPath` gets updated. In the function body we get the value of `propertyPath` and use it to define a new computed property _at runtime_. We do that using [`defineProperty`][defineproperty]. This means that every time the `propertyPath`'s value changes, the `content` computed property gets redefined to point towards the correct path on the target object.\n\n```js\ncontentDidChange: observer('content', function() {\n  this.recompute();\n})\n```\n\nThen there is the `contentDidChange` observer. This one watches for changes of the `content` property, which we define with the `propertyPathDidChange` observer. The `contentDidChange` observer calls `recompute`, which recomputes the end value of the helper.\n\n## Putting it all together to create the map-by helper\n\nNow that we know how to build a helper that can recompute when a property that we only know of at runtime changes, it is very simple to create other similar helpers upon this pattern. I'll leave you with the `map-by` helper, which doesn't look that different from the `get` helper I've shown you.\n\n```js\nimport Ember from 'ember';\n\nconst { \n  Helper, \n  get,\n  set,\n  isEmpty,\n  observer,\n  defineProperty,\n  computed: { mapBy }\n} = Ember;\n\nexport default Helper.extend({\n  compute([byPath, array]) {\n    set(this, 'array', array);\n    set(this, 'byPath', byPath);\n\n    return get(this, 'content');\n  },\n\n  byPathDidChange: observer('byPath', function() {\n    let byPath = get(this, 'byPath');\n\n    if (isEmpty(byPath)) {\n      defineProperty(this, 'content', []);\n      return;\n    }\n\n    defineProperty(this, 'content', mapBy('array', byPath));\n  }),\n\n  contentDidChange: observer('content', function() {\n    this.recompute();\n  })\n});\n```\n\n[lauren]: https://twitter.com/sugarpirate_\n[blogpost-lauren]: https://dockyard.com/blog/2016/04/18/ember-composable-helpers\n[get-helper]: https://github.com/jmurphyau/ember-get-helper/blob/master/addon/helpers/get-glimmer.js\n[defineproperty]: http://emberjs.com/api/classes/Ember.html#method_defineProperty\n"},{"title":"We're looking for a designer!","tags":["design","job"],"summary":"Join our DockYard team on some exciting incoming projects","legacy":false,"id":"2016/08/03/looking-for-a-designer","employee":"Maria Matveeva","date":"2016-08-03T00:00:00","body":"\n\nWe’ve got several exciting projects lined up, and we’re looking to grow the\ndesign team on a per-project basis.\n\nWe’re looking for a designer with strength in both UX and visual design. Design\nresearch experience would be a plus.\n\nFor this project, you would be paired up with a DockYard designer to help lead\na 4-6 week product discovery. You would get the opportunity to see a product\nthrough from conception to finished visual designs, user testing, and even\ncollaboration with Engineers. Our sprint-based, focused approach to working,\nin close collaboration with our team and the client, is ideal for achieving\ndeep, high quality work.\n\nThis contract engagement would be ideal for a mid- to senior designer looking to\nexpand their toolkit, and collaborate closely with a premier web application\nconsultancy. This opportunity could lead to a full time position in the future,\nbased on a 32-hour workweek.\n\nThis contract requires you to be in-person at our office in Boston for the duration.\n\n[Send us a note](https://dockyard.com/contact/join-us) - we’re looking forward\nto hearing from you!\n"},{"title":"We're looking for an HTML/CSS Specialist!","tags":["html","css","job"],"summary":"Join our DockYard team on some exciting incoming projects","legacy":false,"id":"2016/08/04/looking-for-a-uxd-senior","employee":"Cory Tanner","date":"2016-08-04T00:00:00","body":"\n\nIf you have a passion for HTML and CSS we want you at DockYard!\n\nWe’re a premiere design-first web consultancy based in Boston and we are looking for DockYarders to join our growing team.\n\nOur workflow involves three steps. Designers hand off mockups to the HTML/CSS specialists who then give styled templates to engineers. Traditionally writing HTML and CSS was the responsibility of designers or engineers but with the growth of HTML5 and CSS you need a role within the team solely focused on HTML and CSS.\n\nAs an HTML & CSS specialist at DockYard you will be in a unique position where you will work closely and engage in great communication with both the Design team and Engineering team to help facilitate the handoff between visual design and app implementation. Additionally to that, you'll be challenged with helping drive the creation of web applications and solving interesting problems regarding accessibility, browser compatibility, standards compliance, and responsive design.\n\n[Send us a note](https://dockyard.com/contact/join-us) - we are looking forward to hearing from you!\n"},{"title":"Measuring the unknown","tags":["design","process","business"],"summary":"Estimating the size of an unknown project can be tough. But you know more than you think you do.","legacy":false,"illustration_alt":"Painted planets on a background of stars","illustration":"https://i.imgur.com/KlXdtAE.jpg","id":"2016/08/05/measuring-the-unknown","employee":"Maria Matveeva","date":"2016-08-05T00:00:00","body":"\n\n![Painted planets on a background of stars](https://i.imgur.com/KlXdtAE.jpg)\n\nAs a designer, I often get the opportunity to participate in starting and planning projects. Some projects have many unknowns, and we follow a Discovery process before proposing a blueprint for what to build, and why. And sometimes, we need to understand the scale of a challenge without following this familiar discovery process. \n\n\n## Now, please measure the unknown\nAt first, it may seem impossible: how can I “size up” a solution to a problem without knowing all the variables, and the potential ranges for each one? How can I estimate when the thing I am measuring feels like a black box?\n\nIf you step back from the problem, however, you may find that you know more than you think. This situation reminds me of an example a Mathematics professor gave me to explain how they work with abstract concepts. \n\n\n## Start by measuring the infinity\nLet’s say you’re trying to measure an infinite thing. Imagine if  you were to remove two walls and the ceiling from the room you’re sitting in. Take in all the space, stretching out into the cosmos — in front, to your left and above you (but not the other four quadrants.) It is, indeed, an infinite amount of space that you couldn’t measure in familiar ways - but what you do know is that it’s smaller than the other three quarters you did not include. \n\nBy itself, a thing can feel immeasurable, but in the context of other like things, you can easily size it up.\n\n\n## Decide what kind of infinity it is\nYour problem might still feel like a black box. That’s fine. Shake the box a bit - does it rattle? How does it behave? What you’re trying to get at is the structure, rather than the size or weight.\n\nStructure corresponds to design intent, versus the weight and size deals with implementation. The intent of a bridge is fundamentally different from the intent of a house. They are meant to behave differently, even though the size, materials and construction techniques could be similar. If you can reliably say that you’re building a bridge, and it’s smaller than any of the previous three bridges you’ve seen - you can have a good amount of certainty that the project will fall between X and Y size.\n\nEven more importantly, by calling the project a bridge, you’ve now reduced the number of confusing variables you’re working with. You and your team can how have a conversation around how long, and how strong the bridge needs to be, but you’re not worrying about whether it needs to fly, or have a patio in the front.\n\n\n## No one has all the answers\nAs professionals, we often feel like we should have all the answers. But no one can have them all. True professionalism means being honest about what you don’t know while doing our homework to narrow down the infinity to something we can address intelligently.\n\nScientists do this all the time. We measure far away planets by looking at very scarce data and comparing it to what we know. As we learn more, whole theories get rewritten and replaced. But if we don’t start with the theory we have, and make a good attempt at solving a problem, we will never learn more. \n\nThe opposite of knowing isn’t not-knowing. It’s not trying. We must share openly what we don’t know and, in case of a design discovery, document assumptions and caveats. If we’re sizing up an unknown bridge, be vocal about your assumption that the bridge posts are not underwater (that’d triple their cost and complexity) or resting on a volcano (good luck). Your black box may contain an infinity, but by describing it and naming it you’ve gone a long way towards answering, “how large?” \n\n"},{"title":"Understanding the & (capture operator) in Elixir","tags":["elixir"],"summary":"how to use & (capture operator) in Elixir","legacy":false,"illustration_alt":"Alt text","illustration":"https://monosnap.com/file/RfDoLHTqzOzGGXetAoUfUvVwPpAf5j.png","id":"2016/08/05/understand-capture-operator-in-elixir","employee":"Daniel Xu","date":"2016-08-05T00:00:00","body":"\n\n# Understanding the & (capture operator) in Elixir\n\n`&` is the capture operator in Elixir, it is used to **capture** and **create** anonymous functions.\n\n## Anonymous functions and arity\n\nBefore going into details about the capture operator, let's get familiar with `anonymous functions` and `arity` first.\n\nGiven the following example:\n\n```elixir\nadd_one = fn x -> x + 1 end\n```\nwe defined a function, but it isn't bound to a global name, so it is an anonymous functions or a lambda.\n\nThis function takes one argument, so its arity is 1.\n\n## How to use `&`\n\n### capture function\n\nLet's first talk about capturing function.\nCapture means `&` can turn a function into an `anonymous functions ` which can be passed as arguments to other function or be bound to a variable.\n\n`&` can capture two types of functions:\n\n* function with given name and arity from a module\n\nThe notation is: `&(module_name.function_name/arity)`, e.g.\n\n```elixir\nspeak = &(IO.puts/1)\nspeak.(\"hello\")  # hello\n```\n\nWe capture `puts` function from `IO` module and bind it with a local name `speak`.\n\n* local function\n\nIn the following example, `put_in_columns` and `put_in_one_row` are defined in the same module, so we can capture `put_in_one_row` by\n`&put_in_one_row/1`, notice that we don't include the module name here.\n\n```elixir\ndefmodule Issues.TableFormatter do\n  def put_in_columns(data_by_columns, format) do\n\t Enum.each(data_by_columns, &put_in_one_row/1)\n  end\n\n  def put_in_one_row(fields) do\n  \t # Do some things...\n  end\nend\n```\n\n### create anonymous functions\n\nThe capture operator can also be used to create anonymous functions, for example:\n\n```elixir\nadd_one = &(&1 + 1)\nadd_one.(1) # 2\n```\n\nis the same with:\n\n```elixir\nadd_one = fn x -> x + 1 end\nadd_one.(1) # 2\n```\n\nYou might notice that `&1` is used in the above example. That's called a value placeholder, and it identifies the `nth` argument of the function\n\nIn addition, as `{}` and `[]` are also operators in Elixir, `&` can work with them too.\n\n```elixir\nreturn_list = &[&1, &2]\nreturn_list.(1, 2) # [1, 2]\n\nreturn_tuple = &{&1, &2}\nreturn_tuple.(1, 2) # {1, 2}\n```\n\nIt's hard to comprehend at first, we just need to think about it from another perpective:\n\n![Alt text](https://monosnap.com/file/RfDoLHTqzOzGGXetAoUfUvVwPpAf5j.png)\n"},{"title":"Phoenix Channels vs Rails Action Cable","tags":["phoenix","channels","elixir","ruby","rails","action cable"],"summary":"comparing phoenix and rails real-time performance","legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/jQOIhkX.gif","id":"2016/08/09/phoenix-channels-vs-rails-action-cable","employee":"Chris McCord","date":"2016-08-09T00:00:00","body":"\n\n\nAt DockYard, we transitioned our backend development from Ruby and Rails to Elixir and Phoenix once it became clear that Phoenix better served our clients needs to take on the modern web. As we've seen, [Phoenix is Not Rails](https://dockyard.com/blog/2015/11/18/phoenix-is-not-rails), but we borrow some of their great ideas. We were also delighted to give back in the other direction when Rails announced that Rails 5.0 would be shipping with Action Cable – a feature that takes inspiration from Phoenix Channels.\n\nNow that Rails 5.0 has been released, we have clients with existing Rails stacks asking if they should use Action Cable for their real-time features, or jump to Phoenix for more reliable and scalable applications. When planning architecture decisions, in any language or framework, you should always take measurements to prove out your assumptions and needs. To measure how Phoenix channels and Action Cable handle typical application work-flows, we created a chat application in both frameworks and stressed each through varying levels of workloads.\n\n## How the tests were designed\n\nFor our measurements, we used the [tsung](http://tsung.erlang-projects.org) benchmarking client to open WebSocket connections to each application. We added XML configuration to send specific Phoenix and Rails protocol messages to open channels on the established connection and publish messages. For hardware, we used two Digital Ocean 16GB, 8-core instances for the client and server.\n\nThe work-flows for each tsung client connection were as follows:\n\n- open a WebSocket connection to the server\n- create a single channel subscription on the connection, to a chat room chosen at random\n- Periodically send a message to the chat room, randomly once every 10s-60s to simulate messaging across members in the room\n\nOn the server, the channel code for Rails and Phoenix is quite simple:\n\n```elixir\ndefmodule Chat.RoomChannel do\n  use Chat.Web, :channel\n\n  def join(\"room:\" <> _id, _params, socket) do\n    {:ok, socket}\n  end\n\n  def handle_in(\"publish_msg\", %{\"body\" => body, \"user\" => user}, socket) do\n    broadcast!(socket, \"new_message\", %{body: body, user: user})\n    {:reply, :ok, socket}\n  end\nend\n```\n\n```ruby\nclass RoomsChannel < ApplicationCable::Channel\n  def subscribed\n    @topic = \"rooms:#{rand(1..8)}\"\n    stream_from @topic\n  end\n\n  def publish_msg(data)\n    ActionCable.server.broadcast(@topic,\n      body: data[\"body\"],\n      username: data[\"username\"],\n      started: data[\"started\"]\n    )\n  end\nend\n```\n\nAfter establishing N numbers of rooms, with varying numbers of users per room, we measured each application's responsiveness. We tested performance by joining a random room from the browser and timing the broadcasts from our local browser to all members in the room. As we increased the numbers of users per room, we measured the change in broadcast latency. We recorded short clips of each application's behavior under different loads.\n\nThis simulates a \"chat app\", but the work-flow applies equally to a variety of applications; real-time updates to visitors reading articles, streaming feeds, collaborative editors, and so on. As we evaluate the results, we'll explore how the numbers relate to different kinds of applications.\n\n## Rails Memory Leaks\n\nAfter creating the Rails chat application, setting up redis, and deploying the application to our instance, we immediately observed a memory leak in the application that was visible just by refreshing a browser tab and watching the memory grow; to never be freed. The following recording shows this in action (sped up 10x):\n\n![](http://i.imgur.com/jQOIhkX.gif)\n\nWe searched recently reported bugs around this area, and found an issue related to Action Cable [failing to call `socket.close` when cleaning up connections](https://github.com/rails/rails/pull/25615/files). This patch has been applied to the `5-0-stable` branch, so we updated the app to the unreleased branch and re-ran the tests. The memory leak persisted.\n\nWe haven't yet isolated the source of the leak, but given the simplicity of the channel code, it must be within the Action Cable stack. This leak is particularly concerning since Rails 5.0 has been released for some time now and the `5-0-stable` branch itself has unreleased memory leak patches going back greater than 30 days.\n\n## Scalability\n\nWe set the memory leak issue aside and proceeded with our tests for the following scenarios:\n\n- Max numbers of rooms supported by a single server, with 50 users per room\n- Max numbers of rooms supported by a single server, with 200 users per room\n\n\n*Note*: For Phoenix, for every scenario we maxed the *client server's* ability to open more WebSocket connections, giving us 55,000 users to simulate for our tests. Browser -> Server latency should also be considered when evaluating broadcast latency in these tests.\n\n\n### 50 users per room\n\n**Rails**: 50 rooms, 2500 users:\n\n![](http://i.imgur.com/l8mJ966.gif)\n\nResponsiveness was speedy at 50 rooms, so we upped the room count to 75, giving us 3750 users.\n\n**Rails:** 75 rooms, 3750 users:\n\n![](http://i.imgur.com/2Mb2gpT.gif)\n\nHere, we can see Action Cable falling behind on availability when broadcasting, with messages taking an average of 8s to be broadcast to all 50 users for the given room. For most applications, this level of latency is not acceptable, so the level of performance for maxinum rooms on this server would be somewhere between 50 and 75 rooms, given 50 users per room.\n\n\n**Phoenix:** 1100 rooms, 55,000 users (maxed 55,000 client connections)\n\n![](http://i.imgur.com/0Qu0pM5.gif)\n\nWe can see that Phoenix responds on average in 0.25s, and only is maxed at 1100 rooms because of the 55,000 client limit on the tsung box.\n\n### Making sense of the results, 50 users per room\n\nThese results show that if you are building an application for small to medium sized businesses, if 75 companies visit the app at the same time, their notifications will be delayed. Given the severe degradation in performance from 50 to 75 rooms, it may also be hard to pinpoint your server density when planning for load.\n\nFor load planning, horizontal scalability will be required with 50-75 companies per server, but the reliance on redis should be considered as a central bottleneck. Horizontal scalability was the obvious choice for Ruby when it came to stateless HTTP requests, but we can see why vertical scalability becomes increasingly important for stateful connections. If you require dozens or hundreds of servers, Action Cable will still rely on a central redis bottleneck for PubSub.\n\n\n### 200 users per room\n\n**Rails:** 8 rooms, 1600 users:\n\n![](http://i.imgur.com/rBbjAxr.gif)\n\nWe can see Action Cable starts off with acceptable latency, but begins to quickly fall behind as broadcast latency grows with each message. Broadcast latency grows longer than 10s. Next, we upped the room count by 1, to see where the limit was.\n\n**Rails:** 9 rooms, 1800 users before availability was compromised when broadcasting.\n\n![](http://i.imgur.com/S7tpHLm.gif)\n\nAt 200 users per room, Action Cable is unable to maintain the broadcast load and supported just 9 rooms before we experienced messages stop arriving or subscriptions failing to establish. At these levels, the only consistent performance we could get for 200 users per room, was limiting the server to 7 rooms, or 1400 users.\n\n\n**Phoenix:** 275 rooms, 55,000 users (maxed 55,000 client connections)\n\n![](http://i.imgur.com/noizwRP.gif)\n\nWe can see that Phoenix responds on average in 0.24s, and only is maxed at 275 rooms because of the 55,000 client limit on the tsung box. Additionally, it's important to note that Phoenix maintains the same responsiveness when broadcasting for both the 50 and 200 users per room tests.\n\n\n### Making sense of the results, 200 users per room\n\nYou may be thinking, \"but my application isn't a chat app, and only needs simple page updates\". These tests apply equally to many scenarios. Imagine you have an information system where you want to publish periodic updates to pages. This could be for a news site where visitors see new comments, or a booking site where visitors see \"20 other people are currently viewing this hotel\".\n\nThis tests shows that if your app receives a sudden spike in visitors and more than 7 articles have 200 or more readers, the server won't be able to keep up with the notification demand for both the popular articles, *as well as the low traffic ones*.\n\nFor a booking site, imagine 7 hotels across the country release a discount rate and customers jump online for the deal. Suddenly, you need to spin up extra servers to maintain booking notifications, and the severity of the delays becomes worse if critical functionality of your application relies on these notifications.\n\n\n## Conclusions\n\nIf memory leaks can be ruled out or addressed, the sweet-spot for Action Cable today is small workloads with few subscribers on any given topic. Going beyond this means engineering efforts and resources must be spent on managing multiple nodes and optimizing code out of channels. Higher workloads with broadcasts to more than a few dozen subscribers risks availability. With Phoenix, we've shown that channels performance remains consistent as notification demand increases, which is essential for handling traffic spikes and avoiding overload. \n\nWhen I started my own real-time Rails features with [Sync](https://github.com/chrismccord/render_sync) several years ago, memory leaks and consistent performance were my main fears that drove me to look elsewhere, find Elixir, and create Phoenix. The rails-core team has done a great job putting a real-time story in place, but wrangling Ruby's lack of concurrency features will continue to be a challenge.\n\nThe source code and instructions for running these tests on your own hardware can be found [here](https://github.com/chrismccord/channelsac).\n"},{"title":"ELI5: Upcoming Developments in Ember.js","tags":["ember"],"summary":"A brief tour of Ember's future through a few RFCs.","legacy":false,"id":"2016/08/10/upcoming-developments-ember","employee":"Rowan Krishnan","date":"2016-08-10T00:00:00","body":"\n\n# ELI5: Upcoming Developments in Ember.js\n\nAs a newcomer to [Ember](http://emberjs.com/) in the past few months, it's been fascinating to not only learn how to build applications with a great JS framework, but also to gain insight into how a massive and popular open source project grows and absorbs new ideas. Although I'm probably a little bit biased at this point, I believe Ember does a better job than most at managing and encouraging this process.\n\nThe primary channel for discussion of introducing new features into Ember is the [public RFC repository](https://github.com/emberjs/rfcs) on GitHub. RFCs, which stand for 'Request For Comment', are pull requests in which any developer can outline a feature specification and open the floor for comments and criticism. This is what true open source looks like, and the success of the RFC repo represents to me the best aspects of the Ember community. \n\nAll of that being said, it can certainly be a little intimidating for someone new to the framework to dive right in and catch up on the most significant RFCs being discussed. So I decided to do a little write up that made that easier.\n\nHere are the three RFCs that have provoked the most discussion, and perhaps demonstrate what the future of Ember looks like:\n\n## [Module Unification](https://github.com/emberjs/rfcs/pull/143)\n\n`Create a unified pattern for organizing and naming modules in Ember projects that is deterministic, extensible, and ergonomic.`\n\nThis seems like the best one to start with, since it's the one most likely to affect all users of Ember and dramatically impact daily use of the framework. In short, this RFC aims to provide an improved ergonomic directory structure for all new Ember projects.\n\nWhy? Well, there are unfortunately a few too many deficiencies with the current system of organizing Ember modules.\n\n- Developers have to decide between using the pod or classic app structure.\n- Addons are directly mixed into the codebase and therefore present opportunities for name collision.\n- Module resolution rules are esoteric and inefficient.\n\nThe proposed solution to these problems does a major refactor of default Ember app structure. Replacing `app` at the top level is a new directory called `src` which can contain several subdirectories (`data`, `init`, `ui`, `utils`, and `services`). Here's an example of what this could look like in a blogging application, as shown in the RFC:\n\n```\nsrc\n  data\n    models\n      author.js\n      comment\n        adapter.js\n        model.js\n        serializer.js\n      post\n        adapter.js\n        model.js\n        serializer.js\n    transforms\n      date.js\n  init\n    initializers\n      i18n.js\n    instance-initializers\n      auth.js\n  services\n    auth.js\n  ui\n    components\n      capitalize.js\n      date-picker\n        component.js\n        template.hbs\n      list-paginator\n        component.js\n        template.hbs\n        paginator-control\n          component.js\n          template.hbs\n    partials\n      footer.hbs\n    routes\n      application\n        template.hbs\n      index\n        template.hbs\n        route.js\n        controller.js\n      posts\n        -components\n          capitalize.js\n          titleize.js\n          -utils\n            strings.js\n        post\n          -components\n            post-viewer\n              component.js\n              template.hbs\n          edit\n            -components\n              post-editor\n                post-editor-button\n                  component.js\n                  template.hbs\n                calculate-post-title.js\n                component.js\n                template.hbs\n            route.js\n            template.hbs\n          route.js\n          template.hbs\n        route.js\n        template.hbs\n    styles\n      app.scss\n    index.html\n  utils\n    md5.js\n  main.js\n  router.js\n```\n\nThere are a couple of examples of this in action; namely the [Ghost Admin](https://github.com/rwjblue/--ghost-modules-sample/tree/grouped-collections/src) and [Travis Client](https://github.com/rwjblue/--travis-modules-sample/tree/modules/src). [Rob Jackson](https://twitter.com/rwjblue) has also done a fantastic job in releasing a [tool](https://github.com/rwjblue/ember-module-migrator) that allows us to migrate our apps over to this new structure.\n\nThe RFC goes into a great amount of detail regarding other changes that will need to take place, such as renaming and reorganizing modules, and a refactor of the Ember Resolver. You can read the whole thing [here](https://github.com/dgeb/rfcs/blob/module-unification/text/0000-module-unification.md).\n\n## [Testing Unification](https://github.com/emberjs/rfcs/pull/119)\n\n`The goal of this RFC is to unify the concepts amongst the various types of test (acceptance, integration, and unit) and provide a single common structure to tests.`\n\nLook, most of us don't really love writing tests. It's okay to admit it. But as [Rob Jackson](https://github.com/rwjblue) explains in his RFC, Ember's testing story is coming together quite nicely, and it's never been easier to write comprehensive tests across all the various pieces of your app (routes, components, templates, etc). One of the best aspects of Ember being a \"full featured\" framework is that it comes packaged with all the libraries and tools you'd need to write great tests, with as little friction as possible.\n\nThe only persisting problem is that these tests look and function quite different from one another. Specifically, they handle things like asynchronous requests differently and use unique sets of helpers. This RFC seeks to \"unify\" the three types of tests - acceptance, integration, and unit - by introducing new syntax to handle asynchronous test actions, and establishing a set of test helpers that would be shared across the three types of tests.\n\nLike the [Module Unification RFC](https://github.com/emberjs/rfcs/pull/143), this one goes into a great amount of detail that eclipses the scope of an ELI5. I highly recommend checking it out the [full spec](https://github.com/rwjblue/rfcs/blob/42/text/0000-grand-testing-unification.md) if you're interested in the future of testing.\n\n## [Routable Components](https://github.com/emberjs/rfcs/pull/38)\n\n`Eliminates Controllers.`\n\nAh, yes. The Holy Grail of RFCs. The future of Ember. The promised land.\n\nIn all seriousness, routable components are a pretty big deal, and received an appropriately large reaction when first presented at EmberConf 2015 by [Tom Dale](https://github.com/tomdale) & [Yehuda Katz](https://github.com/wycats). It's been a long time since then, and if you've been following along, you might need a little refresher on how they are intended to work.\n\nAs the description above concisely states, routable components essentially mean the death and deprecation of controllers. This is a good thing. For many months now, controllers have been a key point of confusion for new developers, and stick out as a remnant of pre-2.0 Ember. One of the biggest complaints about the framework in the early years was that the architectural pattern was far too complicated (\"MVC? MVVM? What's the difference between a view and a controller?\"). Ember continuing to simplify and mature these patterns is great news.\n\nRoutable components hope to replace controllers by absorbing the few functional responsibilities that they still have, such as query parameters and setting a route's model on the template or top-level component. Discussing the implementation for these changes, however, is a tricky subject due to the length of time passed since the concept of routable components was first introduced. Original proposals included removing older model hooks (such as `beforeModel` and `afterModel`) and introducing a new, automatically invoked hook called \"attributes\", that would allow a route to specify the positional and query parameters to be passed into a rendered component.\n\n\n\n\n\n\n"},{"title":"Using Ecto Changesets for HTML input validations","tags":["elixir","phoenix","html","engineering"],"summary":"Leverage the power of Phoenix to utilize your Ecto changeset validations as input validations in your HTML forms","legacy":false,"id":"2016/08/11/changeset-form-validation-bindings","employee":"Nico Mihalich","date":"2016-08-11T00:00:00","body":"\n\nAll web applications with user submitted input have some constraints on what input is acceptable.  We as developers have two methods to make sure what the user entered falls within those constraints.\n\n*Client Side Validation* where your application checks form data prior to a network call and prevents the call from happening if it finds the data invalid.\n\n*Server Side Validation* where your application sends data to the server and waits for it to tell you if the data is valid or not.\n\nBoth are means to the same end but have their advantages and disadvantages.\n\n## Server Side Validation (Necessary)\n\n### Pros\n- Source of truth / \"Last line of defense\"\n- Can be tied to DB logic\n- Knows context of the user, session, or other data\n- More powerful and secure\n\n### Cons\n- Slow to get feedback due to network latency\n- Sending the entire form just to get one error\n\n## Client Side Validations (Optional)\n\n### Pros\n- Immediate validation\n- Preventative\n- Semantically accurate\n- Nicer feeling feedback due to styling with CSS selectors\n\n### Cons\n- Have to keep it in sync with server side\n- Brittle\n- Not a substitute for server side validation\n\nGenerally client side validations are optional, faster, and provide better UX, while server side validations are necessary, stronger, and better tied to your data schema.\n\nIdeally you utilize both, but they're a pain to keep in sync.  In a perfect world your application's back end validations automatically apply to the client. We're going to explore how Phoenix and Ecto give us the power to help us do exactly that.\n\nWe can leverage [Phoenix](http://www.phoenixframework.org/) and [Ecto.Changeset](https://hexdocs.pm/ecto/Ecto.Changeset.html) on our front end with just a few lines of code. This doesn't work for everything (uniqueness constraints for example), but there are some nice things we can validate for: min/max, length, and required fields.\nEcto changesets within Phoenix support [validate_length](https://github.com/phoenixframework/phoenix_ecto/blob/master/lib/phoenix_ecto/html.ex#L143), [validate_number](https://github.com/phoenixframework/phoenix_ecto/blob/master/lib/phoenix_ecto/html.ex#L161), [validate_required](https://github.com/phoenixframework/phoenix_ecto/blob/master/lib/phoenix_ecto/html.ex#L114) which correspond to the [HTML input validations](https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Forms/Data_form_validation) `minlength`/`maxlength`, `min`/`max`, and `required`.\n\nOur goal is to have the validations defined in a schema's changeset function automatically apply the correct HTML input validation to our form.\n\nLet's write some code.\n\n---\n\n## The Code\n\nLet's work with a schema named `foo` with the following changeset function:\n\n```elixir\ndef changeset(struct, params \\\\ %{}) do\n  struct\n  |> cast(params, [:name])\n  |> validate_required([:name])\n  |> validate_length(:name, min: 2, max: 4)\nend\n```\n\nBy default our form should have something like this:\n\n```\n<%= text_input f, :name, class: \"form-control\" %>\n```\n\nWhich generates this markup:\n\n```html\n<input class=\"form-control\" id=\"foo_name\" name=\"foo[name]\" type=\"text\">\n```\n\nIt works, but we have to wait for a server round trip to get any validations. We can add client side validation by appending opts by hand like this:\n\n```\n<%= text_input f, :name, class: \"form-control\", required: true, minlength: 2, maxlength: 4 %>\n```\n\nWhich generates this markup:\n\n```html\n<input class=\"form-control\" id=\"foo_name\" maxlength=\"4\" minlength=\"2\" name=\"foo[name]\" required=\"required\" type=\"text\">\n```\n\nThis is better, but if we ever changed the max to something else we would have to remember to change it in two different places!\n\nWe can do better by using [input_validations](https://github.com/phoenixframework/phoenix_ecto/blob/master/lib/phoenix_ecto/html.ex#L113). This function generates the HTML validation attributes from our Ecto changeset for us.\n\nNow we can define our own functions which simply add on those generated input validations to our text and number inputs...\n\n```elixir\nalias Phoenix.HTML.Form\n\ndef text_input(form, field, opts \\\\ []) do\n  Form.text_input(form, field, opts ++ Form.input_validations(form, field))\nend\n\ndef number_input(form, field, opts \\\\ []) do\n  Form.number_input(form, field, opts ++ Form.input_validations(form, field))\nend\n```\n\nKeep the same markup we had initially...\n\n```\n<%= text_input f, :name, class: \"form-control\" %>\n```\n... and get the semantically correct markup with no changes to the template!\n\n```html\n<input class=\"form-control\" id=\"foo_name\" maxlength=\"4\" minlength=\"2\" name=\"foo[name]\" required=\"required\" type=\"text\">\n```\n\n## Other validations\n\nThis will also work for number validations.  Say our changeset function had a line like\n\n```\n|> validate_number(:count, greater_than: 2, less_than: 9)\n```\n\nThat would give us this markup\n\n```\n<input class=\"form-control\" id=\"foo_count\" max=\"8\" min=\"3\" name=\"foo[count]\" required=\"required\" step=\"1\" type=\"number\">\n```\n\n---\n\n## Using this in your application\n\nTo leverage this in your own Phoenix application, we'll use a module that we will automatically import in all our views.\n\nFirst define the module with our custom `text_input` and `number_input` functions in `web/views/valid_inputs.ex`\n\n```elixir\ndefmodule HelloPhoenix.ValidInputs do\n  alias Phoenix.HTML.Form\n\n  def text_input(form, field, opts \\\\ []) do\n    Form.text_input(form, field, opts ++ Form.input_validations(form, field))\n  end\n\n  def number_input(form, field, opts \\\\ []) do\n    Form.number_input(form, field, opts ++ Form.input_validations(form, field))\n  end\nend\n```\n\nThen in `web/web.ex` just have Phoenix make it available for all our views.\n\n```\ndef view do\n  quote do\n    use Phoenix.View, root: \"web/templates\"\n\n    # Import convenience functions from controllers\n    import Phoenix.Controller, only: [get_csrf_token: 0, get_flash: 2, view_module: 1]\n\n    # Use all HTML functionality (forms, tags, etc)\n    use Phoenix.HTML\n\n    # vvvv BEGIN OUR CODE vvvv\n    import Phoenix.HTML.Form, except: [number_input: 2, number_input: 3, text_input: 3]\n    import HelloPhoenix.ValidInputs\n    # ^^^^ END OUR CODE ^^^^\n\n    import HelloPhoenix.Router.Helpers\n    import HelloPhoenix.ErrorHelpers\n    import HelloPhoenix.Gettext\n  end\nend\n```\n\nAnd we're done! Now that your inputs have constraints, you can use CSS selectors like `:invalid` and `:required` to make things look a bit nicer for the user.\n\n## Custom Validations\n\nThere's also a lesser known `pattern` HTML attribute for regex validations.  The JavaScript and Elixir regex engines are not 100% compatible so it's not supported by default in `input_validations` but we can add it ourselves as an exercise in custom validations.\n\n```\n|> validate_format(:email, ~r/.+@.+/)\n```\n\n```\ndef text_input(form, field, opts \\\\ []) do\n  Form.text_input(form, field, extend_opts(form, field, opts))\nend\n\ndefp extend_opts(form, field, opts) do\n  defaults = opts ++ Form.input_validations(form, field)\n\n  case form.source.validations[field] do\n    {:format, regex} -> [{:pattern, Regex.source(regex)} | defaults]\n    _ -> defaults\n  end\nend\n```\n\n```\n<input class=\"form-control\" id=\"foo_email\" name=\"foo[email]\" pattern=\".+@.+\" type=\"text\">\n```\n\nBecause we're just composing and calling functions, we can extend our initial implementation easily without having to inherit or monkey patch from an existing View module. Going further, you can tweak your `text_input` and `number_input` to, for example, take an optional `validate` parameter to include opt in/opt out functionality.\n\n## The takeaway\n\nUsing simple functions available in Phoenix, your application can automatically apply some of your in-place server side validations to your front end markup to improve your UX in only a few lines of code!\n"},{"title":"Pieces of Ember: Part 1","tags":["ember","javascript"],"summary":"How to leverage the Ember ecosystem without the Ember ecosystem","legacy":false,"illustration_alt":null,"illustration":"https://i.imgur.com/PfqFoEW.png","id":"2016/08/12/pieces-of-ember-part1","employee":"Heather Brysiewicz","date":"2016-08-12T00:00:00","body":"\n\nI've been working with [Ember][ember] for years now, even though it feels like just yesterday. Not everyone has had this opportunity and I am often met with questions from inquisitive developers and engineers about the state of Ember.\n\nThey know that Ember is an ambitious framework. They've heard it can help boost their productivity. Yet, they hesitate. The project put in their hands is \"basically just a landing page\" or they believe most frameworks to be excessive - and this concern can be valid. Ember is a mature framework with opinions, build tools, and blueprints that enable me, an Ember developer, to focus on engineering an application rather than boilerplate and redundancy.\n\nWhat these developers probably don't know is that many of the core pieces that make the Ember ecosystem the beautiful powerhouse that it is are also available as micro-libraries.\n\n<br><br>\n<div style=\"text-align:center;\">\n  <img src=\"https://i.imgur.com/PfqFoEW.png\">\n</div>\n<br><br>\n\nSome of the most well known micro-libraries behind the Ember framework are:\n\n* [tildeio/rsvp.js][rsvp]\n* [broccolijs/broccoli][broccoli]\n* [tildeio/route-recognizer][route-recognizer]\n* [tildeio/router.js][router]\n* [wycats/handlebars.js][handlebars]\n* [tildeio/htmlbars][htmlbars]\n\nThese pieces of Ember would be able to provide any JavaScript project with:\n\n* Promises\n* Build tools\n* Routing capabilities\n* View templating\n* Templating with Virtual DOM\n\nAll without the need to buy into the entire Ember ecosystem.\n\nThis post is part 1 of a 3 part series on the pieces of Ember. It is also a continuation or elaboration of a lightning talk I gave at the July [SanDiego.js Community][sandiegojs] event which can be found [here][sdjs-talk].\n\n* [Part 1: RSVP and Broccoli][part1]\n* Part 2: Route-recognizer and Router\n* Part 3: Handlebars and HTMLBars\n\n### [tildeio/rsvp.js][rsvp]\n\nThis library is a tiny implementation of the [Promises/A+ spec][promises]. This can be used without a transpiler just like any other promise library.\n\nThe library itself is rather similar to [Bluebird][bluebird] and [When][when]. Under the hood there are some performance boosts gained by avoiding unnecessary internal promise allocations. This provides noticeable improvements in many common scenarios.\n\nThe other unique thing to note about this library is that RSVP aims to be fast across more than just the V8 runtime, while libraries like Bluebird are more or less V8-focused.\n\n```js\nlet RSVP = require('rsvp');\n\nlet promise = new RSVP.Promise((resolve, reject) => {\n  //succeed\n  resolve(value);\n  // or reject\n  reject(error)\n});\n\npromise.then((value) => {\n  //success\n}).catch((error) => {\n  // failure\n});\n\n```\n\n### [broccolijs/broccoli][broccoli]\n\nBroccoli is the fast build pipeline used by [ember-cli][ember-cli] and that is available outside of the Ember ecosystem. Broccoli is intended to be relatively easy to learn, performant, and composable. The plugin system for broccoli is what makes it so composable and even with plugins depending on other plugins, creating a large tree of plugin dependencies, broccoli manages to still provide performant sub-second speeds.\n\nBroccoli provides a powerful build tool chain that can be used very easily to get a project up and running outside of Ember.\n\nGiven a simple project with the following structure:\n\n```\n.\n+-- app\n|   +-- css\n|   +-- js\n|   +-- img\n|   +-- index.html\n+-- node_modules/\n+-- .gitignore\n+-- Brocfile.js\n+-- README.md\n+-- package.json\n```\n\nIt is easy to serve up the assets and create a pipeline with just a few key broccoli plugins and a rather short `Brocfile.js`.\n\n```bash\n$ npm i --save-dev broccoli-concat\n$ npm i --save-dev broccoli-merge-trees\n$ npm i --save-dev broccoli-static-compiler\n$ npm i --save-dev broccoli-uglify-js\n```\n\n```js\n'use strict';\n\nconst concatenate = require('broccoli-concat');\nconst mergeTrees = require('broccoli-merge-trees');\nconst pickFiles = require('broccoli-static-compiler');\nconst uglifyJS = require('broccoli-uglify-js');\n\nconst app = 'app';\n\nlet appCSS;\nlet appHTML;\nlet appJS;\nlet appImages;\n\n/*\n * move index from `app/` to root of tree\n */\nappHTML = pickFiles(app, {\n    srcDir: '/',\n    files: ['index.html'],\n    destDir: '/'\n});\n\n/*\n * concat and compress all js files from `app/js/` and move to root\n */\nappJS = concatenate(app, {\n  inputFiles: ['js/**/*.js'],\n  outputFile: '/app.js'\n});\n\nappJS = uglifyJS(appJS, {\n  compress: true\n});\n\n/*\n * concat all css files from `app/css/` and move to root\n */\nappCSS = concatenate(app, {\n  inputFiles: ['css/**/*.css'],\n  outputFile: '/app.css'\n});\n\n/*\n * move images from `app/img` to image folder\n */\nappImages = pickFiles(app, {\n  srcDir: '/img',\n  files: ['**/*'],\n  destDir: '/img'\n});\n\n// merge the trees and export\nmodule.exports = mergeTrees([appHTML, appJS, appCSS, appImages]);\n\n```\n\nNow running `broccoli serve` will build and serve the project and provide build times in a well formated and easy to read table.\n\n```\nServing on http://localhost:4200\n\n\nSlowest Trees                                 | Total\n----------------------------------------------+---------------------\nSourceMapConcat                               | 30ms\nUglifyJSFilter                                | 13ms\nBroccoliMergeTrees                            | 7ms\nStaticCompiler                                | 3ms\nSlowest Trees (cumulative)                    | Total (avg)\n----------------------------------------------+---------------------\nSourceMapConcat (1)                           | 30ms\nUglifyJSFilter (1)                            | 13ms\nBroccoliMergeTrees (1)                        | 7ms\nStaticCompiler (2)                            | 6ms (3 ms)\n\nBuilt - 63 ms @ Tue Jul 26 2016 16:43:40 GMT-0700 (PDT)\n```\n\nWhen ready to build for deployment the command `broccoli build 'dist'` would compile all of the assets into the `dist` directory.\n\n### Get more from the Ember ecosystem\n\nCheck back for part 2 and part 3 of this series where I review the routing capabilities and templating systems and how to use them outside of Ember.\n\n[ember]: //emberjs.com\n[ember-cli]: https://ember-cli.com\n[stefanpenner]: https://github.com/stefanpenner\n[rsvp]: //github.com/tildeio/rsvp.js\n[bluebird]: http://bluebirdjs.com/\n[when]: https://github.com/cujojs/when\n[broccoli]: //github.com/broccolijs/broccoli\n[broccoli-release]: https://www.solitr.com/blog/2014/02/broccoli-first-release/\n[brocolli-deps]: https://libraries.io/npm/broccoli/dependents?page=1\n[router]: //github.com/tildeio/router.js\n[route-recognizer]: //github.com/tildeio/route-recognizer\n[handlebars]: //github.com/wycats/handlebars.js\n[htmlbars]: //github.com/tildeio/htmlbars\n[promises]: https://promisesaplus.com/\n[sandiegojs]: //sandiegojs.org\n[sdjs-talk]: https://youtu.be/wb-24NqCOT0?t=33m34s\n[part1]: //dockyard.com/blog/2016/08/12/pieces-of-ember-part1\n"},{"title":"The minimum knowledge you need to start Metaprogramming in Elixir","tags":["elixir"],"summary":"Metaprogramming Elixir","legacy":false,"illustration_alt":"","illustration":"https://i.imgur.com/Pl3zRn8.png","id":"2016/08/16/The-minumum-knowledge-you-need-to-start-metaprogramming-in-Elixir","employee":"Daniel Xu","date":"2016-08-16T00:00:00","body":"\n\nMetaprogramming is `writing code that writes code`. In Elixir, we use macros to transform our internal program structure (AST) in compile time to something else. For example, the `if` macro is transformed to `case` during compilation, we call this `macro expansion`.\n\n```elixir\nif true do\n  IO.puts \"yea\"\nend\n\n# becomes\n\ncase(true) do\n  x when x in [false, nil] ->\n    nil\n  _ ->\n    IO.puts(\"yea\")\nend\n```\n\n## The Abstract Syntax Tree (AST) and AST literal\n\nThe internal representation of Elixir code is an [abstract syntax tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree) which is the protagonist in program transformation. Elixir also refers to an AST as a `quoted expression`.\n\nThe quoted expression is composed of three-element tuples:\n\n```elixir\n# simple one: AST for 1 + 2\n{:+, [context: Elixir, import: Kernel], [1, 2]}\n\n# nested one:\n# AST for\n# def hello do\n#\tIO.puts \"hello\"\n# end\n\n{:def, [context: Elixir, import: Kernel],\n [{:hello, [context: Elixir],\n   [[do: {{:., [], [{:__aliases__, [alias: false], [:IO]}, :puts]}, [],\n      [\"hello\"]}]]}]}\n\n```\nEssentially, All tuples in the AST follow the same pattern:\n\n`{function_call, meta_data_for_context, argument_list}`\n\nDuring compilation, all of our source code will be **transformed into AST** before producing final bytecode. However, there are **five** Elixir literals that will remain the same format as their high-level source.\n\n![](https://i.imgur.com/Pl3zRn8.png)\n\nThe following example shows the differences between Elixir literal and other normal data types:\n\n```elixir\n# AST for {1, 2, 3}\n{:{}, [], [1, 2, 3]}\n\n# AST for %{a: :hello}\n{:%{}, [], [a: :hello]}\n\n# AST for {1, 2} (AST literal)\n{1, 2}\n```\n\n## Macro\n\n**Macros receive AST as arguments and provide AST as return values**. The returned AST is injected back into the global program’s compile tree, in this way, macros enable syntactic extensions and code generation.\n\n* Syntactic extensions: e.g. we can implement `while` which is not available in Elixir or create DSL\n* Code generation: e.g. generate function from external data\n\n### Return AST\n\nThere are three ways to create quoted expressions in Elixir:\n\n1. Manually construct it\n2. `Macro.escape`\n3. `quote`/`unquote` to compose AST\n\n```elixir\ndefmodule MyMacro do\n  @opts: %{time: :am}\n\n  # case 1\n  defmacro one_plus_two do\n    {:+, [], [1, 2]}\n  end\n\n  # case 2\n  defmacro say_hi do\n    quote do\n      IO.puts \"hello world\"\n    end\n  end\n\n  # case 3\n  defmacro ops do\n    Macro.escape(@opts)\n  end\nend\n\ndefmodule MyModule do\n  import Mymacro\n\n  def case1 do\n    IO.puts one_plus_two()\n  end\n\n  def case2 do\n    say_hi()\n  end\n\n  def case3 do\n    IO.inspect ops()\n  end\nend\n\n#=> c \"example.exs\"\n#=> MyModule.case1()\n#=> \"3\"\n#=> MyModule.case2()\n#=> \"hello world\"\n#=> MyModule.case3()\n#=> %{time: :am}\n```\n\nIn this example, we define three macros using `defmacro`, all of them return quoted expressions, then we import `MyMacro` module into `MyModule`. During compilation, these macros will be expanded and the returned AST will be injected into `MyModule's` compile tree.\n\nIt's difficult to construct an AST by hand. We should almost always should use `quote` and `Macro.escape` to build up an AST using Elixir's own syntax. The main differences between these two are:\n\n* `quote` returns AST of passed in code block.\n\n* `Macro.escape` returns AST of passed in value.\n\nHere are some examples:\n\n```elixir\ndata = {1, 2, 3}\n\nquote do: {1, 2, 3}\n#=> {:{}, [], [1, 2, 3]} (AST of {1, 2, 3})\n\nquote do: data\n#=> {:data, [], Elixir} (data is not inject into returned AST)\n\nquote do: IO.inspect(1)\n#=> {{:., [], [{:__aliases__, [alias: false], [:IO]}, :inspect]}, [], [1]}\nquote do: IO.inspect(data)\n#=>{{:., [], [{:__aliases__, [alias: false], [:IO]}, :inspect]}, [],\n [{:data, [], Elixir}]}\n\nMacro.escape(data)\n#=> {:{}, [], [1, 2, 3]}\n\nIO.inspect(1)\n|> Macro.escape()\n#=> :error\n```\nNotice that `data` variable is not injected into the AST returned by `quote` block, in order to do that, we need to use `unquote`, which we will discuss later.\n\n\n### Receive AST\n\nLet's take an example to see how macros receive AST:\n\n```elixir\ndefmodule M do\n  defmacro macro_args(a, b) do\n    IO.inspect a\n    IO.inspect b\n  end\nend\n\n#=> c \"example.exs\"\n{:+, [line: 22], [1, 1]}\n2\n```\nAfter compiling the module, we can see the results: `{{:+, [line: 22], [1, 1]}}` and `2`, they are both quoted expressions. Remember that number is an AST literal so its quoted expressions remains the same as itself.\n\nCombining this fact with the pattern of AST, we can easily do pattern matching to get what we want from the argument for further AST composition.\n\nKeep in mind that code passed into a macro is not evaluated or executed. As we saw earlier, **Macros receive AST as arguments and provide AST as return values**.\n\n### unquote\n\n`unquote` injects quoted expressions into the AST returned by `quote`. **You can only use `unquote` inside `quote blocks`**.\n\nTo make it easier to understand, you can think **quote/unquote** as **string interpolation**. When you do `quote`, it's like creating string using `\"\"`. When you do `unquote`, it's like injecting value into string by `\"#{}\"`. However, instead of manipulating string, we are composing AST.\n\nThere are two types of unquote:\n\n* Normal unquote\n\n```elixir\ndata = {1, 2, 3}\nquote do\n  IO.inspect(unquote(data))\nend\n```\n\nIt looks correct, but when we evaluate the AST, we will get an error:\n\n![](https://i.imgur.com/M7fHcmu.png)\n\nHow come? It's because we forget an important concept:\n> unquote injects AST into AST returned by quote.\n\n`{1, 2, 3}` is not an AST literal, so we need to get the quoted expressions. first by using `Macro.escape`.\n\n```elixir\ndata = {1, 2, 3}\nquote do\n  IO.inspect(unquote(Macro.escape(data)))\nend\n```\n\n* Unquote fragment\n\nUnquote fragment is added to support **dynamic generation of functions** and **nested macros**.\n\n```\ndefmodule MyModule do\n  Enum.each [foo: 1, bar: 2, baz: 3], fn { k, v } ->\n    def unquote(k)(arg) do\n      unquote(v) + arg\n    end\n  end\nend\n\n#=> MyModule.foo(1) #2\n#=> MyModule.bar(1) #3\n#=> MyModule.baz(2) #4\n```\nIn this example, we use `unquote(k)` as function name to generate functions from keys of a Keyworld list.\n\nYou might wonder why we can use `unquote` without `quote`. It's because `def` is macro, its arguments will be quoted automatically as we discussed above.\n\nBesides, we need `quote(v)` inside function body because of scope rule in Elixir:\n\n> for named function, any variable coming from the surrounding scope has to be unquoted inside a function clause body.\n\n### Bind_quoted\n\n`bind_quoted` does two things:\n\n**1** prevent accidental reevaluation of bindings.\n\nIf we have two same `unquote` inside `quote` block, the `unquote` will be evaluated twice, this can cause problem.\nWe can use `bind_quoted` to fix it:\n\n```elixir\n# bad\ndefmacro my_macro(x) do\n  quote do\n  \t IO.inspect unquote(x) * unquote(x)\n  end\nend\n\n# good\ndefmacro my_macro(x) do\n  quote bind_quoted: [x: x] do\n  \t IO.inspect x * x\n  end\nend\n```\n\n**2** Defer the execution of `unquote` via `unquote: false`\n\n`unquote: false` is the default behavior of `bind_quoted`.\n\nThe **order of execution** is:\n\nwhen a macro module is compiled, code in the macro context will run first (`IO.puts 1`). Normal code in `quote` block will not be executed until the returned AST is injected into caller module. However, `unquote` code will \"break the wall\" and run in macro's context.\n\nMacro module\n\n```elixir\ndefmodule M do\n  defmacro my_macro(name) do\n    # macro context\n    IO.puts 1\n\n    quote do\n      # caller context\n      IO.puts 4\n      unquote(IO.puts 2)\n    end\n  end\nend\n\n```\nCaller Module\n\n```elixir\ndefmodule Create do\n  import M\n  IO.puts 3\n  my_macro(\"hello\")\nend\n```\nAccording to the explanation above, we can know the result of the example is: `1 2 3 4`.\n\nIf we use `bind_quoted` in the example, the order will change. The `unquote` code will be treated as normal code and run in caller's context. Therefore, the result for the following example is: `1 3 4 2`.\n\n```elixir\ndefmodule M do\n  defmacro my_macro(name) do\n    IO.puts 1\n\n    quote bind_quoted: [name: name] do\n      IO.puts 4\n\n      def unquote(name)() do\n        unquote(IO.puts 2)\n        IO.puts \"hello #{unquote(name)}\"\n      end\n    end\n  end\nend\n```\n```elixir\ndefmodule Create do\n  import M\n  IO.puts 3\n  my_macro(:hello)\nend\n```\n\nThis is helpful because when we change `my_macro(:hello)` in caller module  to\n\n```elixir\n  [:foo, :bar]\n  |> Enum.each(&my_macro(&1))\n```\n\nOur code will still work because the `each` function is executed before the injected AST.\n\n## How to do experiments\n\nThe best way to learn is trial and error. Elixir provides a few functions that can help us: `IO.inspect`, `Code.eval_quoted`, `Macro.to_string`, and `Macro.expand/Macro.expand_once`. Let's find out more about each one:\n\n* IO.inspect\n\nWe can use `IO.inspect` to output the details of macro arguments or whatever we want.\n\n* Code.eval_quoted\n\n`eval_quoted` helps to evalute AST we created:\n\n```elixir\ndata = {1, 2, 3}\nast = quote do\n  IO.inspect(unquote(Macro.escape(data)))\nend\nCode.eval_quoted(ast)\n\n#=> {1, 2, 3}\n```\n\n* Macro.to_string\n\nIt converts the given quoted expressions to a string.\n\n```\nMacro.to_string(ast)\n#=> \"IO.inspect({1, 2, 3})\"\n```\n\n* Macro.expand/Macro.expand_once\n\n`Macro.expand` will receive an AST node and recursively expand it.\nWe can also expand AST once a time using `Macro.expand_once`.\n\n```elixir\nast = quote do: if true, do: IO.puts 1\nMacro.expand_once(ast, __ENV__)\n\n{:case, [optimize_boolean: true],\n     [true,\n      [do: [{:->, [],\n         [[{:when, [],\n            [{:x, [counter: 0], Kernel},\n             {:in, [context: Kernel, import: Kernel],\n              [{:x, [counter: 0], Kernel}, [false, nil]]}]}], nil]},\n        {:->, [],\n         [[{:_, [], Kernel}],\n          {{:., [], [{:__aliases__, [alias: false, counter: 0], [:IO]}, :puts]}, [],\n           [1]}]}]]]}\n```\n\n## Resources\n\nNow we know the basic about metaprogramming in Elixir, it's time to write simple macro, do some experiments and read source code of Elixir or Phoenix.\n\nAlso, there are two great resouces:\n\n* [Metaprogramming Elixir](https://pragprog.com/book/cmelixir/metaprogramming-elixir) by [ChrisMcCord](https://twitter.com/chris_mccord)\n\nGreat book to read. A lot of practical examples in the book that teach you how to write macros.\n\n* [understanding macro blog series](http://theerlangelist.com/article/macros_1) by [Saša Jurić\n](https://twitter.com/sasajuric)\n"},{"title":"What design discovery feels like","tags":["design","process","ux design"],"summary":"Sometimes your job is to do the figuring-out so others can start building and designing the actual thing.","legacy":false,"illustration_alt":"designer at work","illustration":"https://i.imgur.com/xQ3DXsy.jpg","id":"2016/08/23/what-design-discovery-feels-like","employee":"Maria Matveeva","date":"2016-08-23T00:00:00","body":"\n\nI often struggle to describe what it is that I do for a living. You may\nfeel the same, especially when talking to friends outside of your\nindustry, or at any given family gathering. In the past few months, a\nlarge and I believe most important part of my job at DockYard was\nhelping get projects started right.\n\n![designer at work](https://i.imgur.com/xQ3DXsy.jpg)\n> _A stereotypical UX designer at work. Sticky notes in bright colors are essential._\n\nWe call this initial phase of a project design discovery, and believe\nthat a design-first approach saves a lot of money and frustration by\nfiguring everything out with the simplest paper-and-pen prototypes\nfirst. But I’m not talking about the business logic, or methods that\ninform discovery right now. I want to talk about how it feels to be part\nof it - from the beginning, staring at a bunch of unknowns, and right\nthrough the end when the answer becomes clear.\n\nAmong all the things I do, the activity of kicking off projects is the\nhardest one to describe. It’s the thing that needs to happen before\nanyone can start making the *actual* thing. Before you’ve done a\ndiscovery, you mostly have questions, or rather, you have questions\nabout what the questions should be. (After all, asking the correct\nquestion is 80% of solving a problem.) Then, as you work through user\nflows and specific screens the answers start to become more obvious, and\nyou can make decisions together with the client about what the thing\nyou’re building should do, and which features you’ll build first to make\nthat possible.\n\n![paper and pen prototypes](https://i.imgur.com/4A8ahwJ.jpg)\n> _Feeling “done” with discovering something doesn’t always look complex._\n\nIf all goes well, the end result should look suspiciously simple.\nObvious, even. You’ll have gotten rid of many creative but complex\nfeatures. Those would be nice to have in the future,  but it doesn’t\nmake sense to invest in the bells and whistles until you’ve built the\nbasics. The outcome of a Discovery can feel like the outcome of a good\nsummer vacation. You’ve done some (but not all) of all the possible\nthings you’d imagined you’d do. You’ve had to narrow down your long list\nof fuzzy imagined dream-like things you could possibly do to a realistic\nand actionable schedule.\n\n![river grass underwater](https://i.imgur.com/oDu1uJ3.gif)\n> _The feeling of summer and possibility is similar to the beginning of\n> discovery. It won’t last forever, but enjoy it while it does!\n> [Image Credit](http://www.designartpractice.com/blog/38)_\n\nDiscovery is a process that turns a strong desire to have a vacation,\nplus a list of ideas and dreams into something you can reliably act\nupon. If the end of summer has ever hit you by surprise, as you realized\nyou’d never made time for the one important trip you’d definitely\nthought you’d do this year - planning could help.\n\nAnd if you’re an entrepreneur, or a UX designer, or even an engineer\nabout to embark on a discovery process, this is how it should feel.\n\n**And in the beginning**, it’s open and exciting but often so open it’s\nscary. Your collaborators keep asking seemingly obvious questions.  (We\nuncover a new and important motivation every single time. It’s worth the\ntime and effort.) It can be frustrating because the things you thought\nwere clear still need definition. Things can even get heated, as you\ndiscuss the details of a collaborative project and realize your\nassumptions might be different from your collaborators’, and also\ndifferent from the assumptions your users hold. The early stages of a\ndiscovery are like the beginning, dreamy stages of planning a vacation.\nYou know a good thing is ahead, and you can spend some time with all the\npossible amazing options open to you, but know that the longer you delay\nthe decisions, the longer you wait to do the actual thing.\n\n**In the middle**, it’s hard. You’re making tough decisions to\nprioritize among ideas and features, while you care and see the need for\nall of them. (Eventually).\n\n**At the end**, things look obvious - so obvious that you can’t wait to\nget started actually making them. You know exactly what to do first.\n\nEnjoy the rest of the summer! (Remember, officially, we have till\nSeptember 21st :-)\n"},{"title":"Deep Work - Lessons I will apply to UX Design","tags":["design","process","ux design"],"summary":"When should you schedule deep vs. shallow work for a UX design team?","legacy":false,"illustration_alt":"Deep Work book cover","illustration":"http://calnewport.com/wp-content/uploads/2015/11/deep-work-cal-newport.jpg","id":"2016/08/24/deep-work","employee":"Maria Matveeva","date":"2016-08-24T00:00:00","body":"\n\nLast week, I finished Kal Newport’s [Deep\nWork](http://calnewport.com/books/deep-work/). I started out reading the\nbook, but about halfway through realized I’m getting a lot of value from\nit and purchased the audiobook of it as well. This not only increased my\nretention of the material, but allowed me to listen to it while doing\nother things. I got through the book at least twice within three weeks,\na relatively fast pace for me.\n\n![Deep Work book cover](http://calnewport.com/wp-content/uploads/2015/11/deep-work-cal-newport.jpg)\n\n_Deep Work_ had many takeaways for my career as a whole, but it seemed\nespecially useful for running design processes. A key concept in the\nbook is the title, Deep Work: it is both the state and the ability to\nconcentrate on knowledge work, and is the opposite of a distracted\nstate. Kal argues that deep work is becoming more important _and_ more\nscarce in the current economy.\n\n## There is deep work in UX design\n\nThe first thing I considered was, which parts of my and my team’s jobs\ndeep work applies to. Does my entire day need to be deep? When is the\nbest time to schedule “shallow” vs. deep tasks?\n\n1. One key activity where I see the most need for deep work is **the\nDiscovery phase of a project**. Specifically, the second half - once\nwe’ve opened up the playing field and outlined all the possible ideas\nand directions in which we could potentially focus our effort, we must\nnarrow down to get to a realistic product definition. Kal describes this\nprocess as operating with many variables and considerations in our\nactive memory. To keep this focus, we must perform deep work.\nDistraction at this point is very costly, because it requires a long\ntime to get re-started even after a quick break.\n\n2. Another key activity where I know deep work is needed is **the\nwrap-up of a project**. The last week of design work (let’s say we’re\ntalking about a 5-6 weeks total) involves making detailed changes and\nrefinements to designs, as well as looking at the big picture to ensure\nall needs are covered. The combination of detail focus and the “big\npicture” in the active memory is quite taxing as it is. Even a quick\nswitch of focus to answer a question on another project will impact the\nquality or speed of the wrap-up.\n\n\n## There’s a time & place for less-deep work\n\nIn planning my and my team’s time I also need to consider activities\nwhich can be performed in a more “shallow work” mindset. While we could\nideally have full focus all of the time, we do need to prioritize. Here\nare some things that would suffer less from a shallow focus mindset, and\npotentially even benefit from a  relaxed, improvisational atmosphere,\nwhere group chatter and distraction can actually lead to new ideas.\n\n1. Every project has some component of “**poking around**” or initial\nresearch into visual style, the industry, or typical interactions of\na given type. (Do not confuse this with the deeper research and strategy\nefforts, which are focused on getting very specific, hard-to-find\nanswers.)\n\n2. In the **middle of the visual design effort**, with tasks and\npriorities lined up and activities somewhat predictable, shallow work\nmay be acceptable. It’s still beneficial to keep sustained focus, but\nthe cost of focus switching is relatively lower.\n3. **Collaboration and critique** (also called design reviews) can be a\ngreat “shallow” activity. For example, when I check in with the team\nto see how their day went, I might actually benefit from having a\nshallower focus on their specific project. From this outsider\nperspective, I can catch “obvious” things they may not have noticed due\nto a deeper focus on the details, but avoid micro-managing and let folks\nbe professionals and own their own work.\n\n\n## You may already be scheduling deep work\n\nAs I looked back on the way DockYard Design operates after reading _Deep\nWork_, I noticed that we’re well on our way to creating a system that\nsupports deep work where needed. For example, when running design\nsprints, we go “offline” - meaning we’re less available on Slack or by\nemail - for large chunks of the day. We also schedule time to catch up\non shallow tasks around those focused times: a typical in-person\ncollaboration would be scheduled 10–noon and 1–4, leaving an hour of our\nworkday in the morning and afternoon to catch up, document and regroup\nwith the team.\n\nI also noticed (with no surprise) that a schedule heavily focused on\nmanagement cannot be fully tailored to maximize deep work. There will be\ntimes when meetings, or urgent questions will take priority and the\namount of deep work I can schedule around them will be decreased.\n\n## The main takeaways\n\nIf I were to summarize the key takeaways from the book, here’s what\nyou’d see:\n\n1. Schedule deep and important work in large, unbroken chunks of time\nfirst. Then, schedule shallower tasks together in batches around that.\n\n2. Most people don’t consider their availability purposefully. With\nmodern communication tools, we’ve become available by default, and\nit is costing us the ability to focus. If nothing else - question this\nassumption, and consider the consequences of allowing yourself to be\ndistracted.\n\n3. One interesting strategy to manage shallow work is to schedule a\nspecific, limited portion of your work day to tackle shallow tasks.\nThis way, the less-important tasks may not get done, but they will also\nnot prevent you from achieving the truly important goals, which require\ndeep work.\n\n4. Kal proposes to measure the depth of any given task by imagining how\nlong it would take a bright and energetic recent college graduate to\ntrain up to do the task for you. If the time is relatively short (e.g.\ntaking a couple of weeks to learn how to manage a social media presence)\nthen the task is shallow. If the time is long (e.g. taking several years\nto learn how to create original academic research or acquire insight to\nwrite a book) then the task is deep.\n\nIn conclusion - _Deep Work_ questions many assumptions about the way we\nrun our work lives, and proposes specific alternatives. The book is\nstructured as such a clear logical argument (perhaps, owing to Kal’s\nbackground in the theory of computation and his academic writing) that\nit’s hard to ignore the advice. It felt a bit repetitive as I was\nlistening to the introductory chapter (in a Dale Carnegie kind of way)\nbut I’m now reaping the benefit of that repetition by being able to\nrecite the argument back to anyone who’d care to listen. This is great\nbook for any knowledge worker, and I’ve confirmed that it’s useful for\nanyone in a design role. I highly recommend it!\n"},{"title":"KISS by Example: Authorization in Phoenix","tags":["engineering","elixir","phoenix"],"summary":"A short example of authorization in Phoenix to show how modules, functions, and pattern matching can easily fill a common web application need.","legacy":false,"id":"2016/09/08/kiss-phoenix-auth","employee":"Nico Mihalich","date":"2016-09-08T00:00:00","body":"\n\n## Modules, Functions, and Pattern Matching. Oh My!\n\nAs a relatively new Elixir developer, I continue to be impressed by the things the language allows me to accomplish relatively easily.  Features that seemed daunting or time consuming before end up being as simple as: \"Modules. Functions. Pattern Matching.\" Instead of relying on pre-built solutions, a lot of the time your code ends up simpler and easier to reason about if you take advantage of what is in front of you.\n\n## Example: Web App Authorization\n\nLet's pretend we're building a web application where users submit talk ideas for a conference and then the best ones are selected to be included.  Users can submit and edit their own proposals, and admins can mark a talk as `chosen`.  We want to enforce that a rogue user can't select random talks or edit other users' talks to be about nonsense.\n\nNot worrying about how the logic works within the application, let's just lay out some rules for what users can do to talks.\n\n\n```elixir\ndefmodule FakeConf.TalkAuthorizer do\n  alias FakeConf.{Talk, User}\n\n  # Anyone can go and create a talk\n  def authorize(:create_talk, %User{} = _user), do: :ok\n\n  # Only the user that created a talk can edit it\n  def authorize(:edit_talk, %User{} = user, %Talk{} = talk) do\n    if owned_by?(user, talk) do\n      :ok\n    else\n      {:error, :unauthorized}\n    end\n  end\n\n  # Only admins can 'choose' talks\n  def authorize(:choose_talk, %User{is_admin: true} = user, %Talk{}), do: :ok\n  def authorize(:choose_talk, %User{}, %Talk{}), do: {:error, :unauthorized}\n\n  defp owned_by?(%User{} = user, %Talk = talk) do\n    talk.user_id == user.id\n  end\nend\n```\n\nThis keeps our authorization code nice and contained!  When we implement more features, it will be easy to add them to this module.\n\nNow that we have these rules, we can use them in our application.  We'll use the new [with](http://elixir-lang.org/docs/stable/elixir/Kernel.SpecialForms.html#with/1) macro here to chain authorization into our existing app logic.\n\n```elixir\ndefmodule FakeConf.Talks do\n  alias FakeConf.{Talk, Repo, TalkAuthorizer}\n\n  def create_talk(%User{} = user, talk_params) do\n    talk = %Talk{user_id: user.id}\n    with :ok <- TalkAuthorizer.authorize(:create_talk, user),\n         {:ok, talk} <- Repo.insert(changeset(talk, talk_params)) do\n      :ok\n    else\n      {:error, :unauthorized} -> {:error, :unauthorized}\n    end\n  end\n\n  def edit_talk(%User{} = user, talk_id, talk_params) do\n    with %Talk{} = talk <- Repo.get(Talk, talk_id),\n         :ok <- TalkAuthorizer.authorize(:edit_talk, user, talk),\n         {:ok, talk} <- Repo.update(changeset(talk, talk_params)) do\n      :ok\n    else\n      {:error, :unauthorized} -> {:error, :unauthorized}\n      {:error, :not_found} -> {:error, :not_found}\n    end\n  end\n\n  def choose_talk(%User{} = user, talk_id) do\n    with %Talk{} = talk <- Repo.get(Talk, talk_id),\n         :ok <- TalkAuthorizer.authorize(:choose_talk, user, talk),\n         {:ok, talk} <- Repo.insert(changeset(talk, %{chosen: true})) do\n      :ok\n    else\n      {:error, :unauthorized} -> {:error, :unauthorized}\n      {:error, :not_found} -> {:error, :not_found}\n    end\n  end\nend\n```\n\nSuper simple, clean, and easy to read because we're combining functions that are organized in modules.  Nothing crazy happening.\n\nThis isn't just an example of how to do authorization. When you're looking to add a feature to your application, consider it might be simpler than you think when you take advantage of the tools you have available.  When in doubt... 'Keep It Simple, Silly'!\n"},{"title":"Understanding Ember's resolver","tags":["ember","javascript","engineering"],"summary":"An introduction to how Ember's resolver works","legacy":false,"id":"2016/09/14/understanding-ember-s-resolver","employee":"Marten Schilstra","date":"2016-09-14T00:00:00","body":"\n\nEmber's [dependency injection](https://guides.emberjs.com/v2.8.0/applications/dependency-injection/) system is driven by a resolver.\nIt is used to lookup JavaScript modules agnostic from what kind of module system is used, which can be AMD, CommonJS or just plain globals.\nA resolver works based on a set of rules, which reflects how Ember apps are structured.\n\n## How the resolver is used\n\nThe resolver is used widely throughout an Ember application.\nIt is used to lookup routes, models, components and much more.\n\nWhen your Ember app transitions into a route, the resolver is used to find the corresponding route module. \nFor example: if you navigate to `/blog`, then the blog route needs to be looked up. \nThis is done by asking the resolver to resolve `route:blog`, this will resolve a module named `blog` of type `route`.\nAfter the route is done loading the model, we need a controller, so we ask the resolver for `controller:blog`. \nLastly a template needs to be rendered, so once again we go to the resolver and ask for `template:blog`.\n\nThe same thing happens when rendering a component. First the resolver is asked for `component:my-component`,\nthen `template:component/my-component`.\n\n## The rules of the resolver\n\nToday the resolver is used the most to resolve modules using Ember CLI's AMD module system.\nSo I'm going to use that in the next few examples.\n\n### The prefix\n\nFirst of all, a resolver requires a `modulePrefix` variable.\nThis variable is found in the `config/environment` file of an Ember CLI app and is being passed to the resolver by your Ember application.\nYou should also know that the `app/routes/blog.js` file in your Ember CLI app gets a different path in the compiled output.\nThe `app` part of the path is replaced by the `modulePrefix` variable. So our example would become `my-app/routes/blog` if our `modulePrefix` variable is `my-app`.\n\n### Dissecting a resolver statement\n\nThe resolver disects the statement `route:blog` into two parts, a type (`route`) and a name (`blog`). Those parts are then translated into a path which can be used to load a module.\nIn the case of Ember CLI's AMD modules it would give you `my-app/routes/blog`, which is constructed of `modulePrefix` / `type` (pluralized) / `name`.\n\nThe resolver can also easily resolve things nested inside subfolders.\nFor example, `template:component/my-component`, it'll be resolved to `my-app/templates/components/my-component`.\n\nYou can also make up your own type, it doesn't have to be one of Ember's types.\nFor example, [Ember Validations](https://github.com/DockYard/ember-validations) uses the resolver to look up modules of the `validator` type.\n\n### Resolving addon modules \n\nThe resolver has one more trick up its sleeve, it can resolve things outside of your app using a custom `modulePrefix`.\nIf you prefix the statement asked to the resolver with your custom `modulePrefix` and an `@`, then it'll replace the configured `modulePrefix` with yours.\nThe statement `an-addon@component:x-utility` would be resolved to `an-addon/components/x-utility`.\n\n### Some exceptions\n\nThe resolver has some exceptions built in, to resolve a few special things. \nAnything with `main` as the name part will resolve without the name in the resulting module name.\nSo `router:main` will resolve to `my-app/router`, leaving out the name part. The same rule applies to `store:main`.\n\n### Conclusion\n\nThe resolver is a fairly straightforward abstraction that helps you resolve modules, agnostic from all the various module loading systems.\nIf you get to know how it works it can be a great new tool in your arsenal.\n"},{"title":"How to Contribute to Ember","tags":["engineering","open source","ember"],"summary":"A brief guide on how to contribute to open source software","legacy":false,"illustration_alt":"","illustration":"https://i.imgur.com/Y2Zr7NA.jpg","id":"2016/09/30/how-to-contribute-to-ember","employee":"Doug Yun","date":"2016-09-30T00:00:00","body":"\n\n## tl;dr\n\nThere are numerous ways to contribute to open source software. You can do one of\nthe following:\n\n1. Engage, Help and Teach\n1. Write articles and improve learning resources\n1. Create and comment on issues\n1. Contribute code\n1. Build the community\n\nToday, we'll use Ember as an example. To find out ways to aid the Ember community,\nread more below!\n\n## Open Source is Used by Everyone\n\nA majority of the tools we use at DockYard are open source software (OSS) and we\nlove [giving back to the community][dockyard-oss]. If you're reading this post,\nthe chances that you are using OSS are pretty darn high. Just take a look at the\nWikipedia page for [the list of free and open source software packages][wikipedia].\nIt's safe to say that OSS is used by a bizallion companies each day!\n\n## Examples of OSS at DockYard\n\nSome highlights of DockYard's current stack includes [Elixir][elixir-website],\n[Phoenix][phoenix-website], and [Ember][ember-website]. Not only do we utilize these\ntools to build [amazing applications][amazing-work], we also contribute back to these\nfantastic organizations.\n\nIf you're interested in Elixir, I recommend checking out Brian's post entitled\n[How to contribute to Elixir][contribute-elixir]. In that post, he goes over his\nexperience contributing code to the language.\n\n## Cheesy Call to Action: What Can You Do?\n\nToday, we'll touch upon a few basic ways to contribute back to the Ember community.\n\nIf you're a beginner to open source, have no fear! I have had the great fortune\nof working with some amazing OSS contributors, who all started out inexperienced,\nyet, have grown to become open source powerhouses.\n\n## Let's Start Contributing (to Ember)\n\nEmber has been around for while (some say as early as 2011), and as expected,\nhas greatly matured. From recommended tools to best practices, Ember's\never improving wave has been a wild, yet relatively safe ride. I've been working\nwith Ember before it was cool, and can share my personal experience\nwith helping out the community.\n\n![](https://i.imgur.com/Y2Zr7NA.jpg)\n\n_Thanks, [Hassan][hassan-twitter] for the hilarious infuriated Tomster_\n\n### Engage, Help and Teach\n\nThe [Ember community page][ember-community-page] lists various places where users\ncan chat, discuss, or ask questions. However, it should be noted that from my experience,\nIRC and discussion forum do not receive as much traffic as the [Slack community][ember-slack].\n\nI recommend using the Slack community as the number one communication resource.\nThere are numerous channels that range from local user groups to\ntesting practices. I suggest examining the channels you'd like to belong to, and engage with\nfellow users.\n\nThe `#-help` channel is a great place to ask Ember-related questions.\nFurthermore, there are plenty of opportunities to help and teach your fellow developers\nabout Ember.\n\n![](https://i.imgur.com/Hxw1qtd.png)\n_A real life enactment of someone helping another person in the Ember Slack community_\n\n### Write articles and improve learning resources\n\nI have read my fair share of articles based upon web development (I have stopped\nreading any articles about JavaScript fatigue though). I imagine many of us have\nlearned a great deal from articles detailing one cool trick by a seasoned developer,\nor an article describing the pros and cons of a given programming language.\nMy point is that so many of us learn from consuming blog posts, articles, etc.\n\nSo, add to the sea of knowledge, and write something you know about. Heck,\nI'm doing that right now! And, if someone has [already written about a topic\nyou care about][mixonic-article], perhaps you can offer another perspective\nor additional advice.\n\nThe [Ember guides][ember-guides-site] are [open sourced on GitHub][ember-guides-gh],\nand there are plenty of [issues marked as \"help-wanted\"][ember-guide-issues].\n\n### Create and Comment On Issues\n\nJust like any other open source project, Ember and its associated libraries, receive\na [high number issues][ember-issues]. Luckily, we can help out!\n\nLet's say you happen to run into a \"bug\", what should you do next? First, search through\nthe existing issue tracker for the given project, and [attempt to find your issue][obligatory-xkcd].\nIf you find your issue, add a comment!\n\nThorough comments on a particular issue can help tremendously. If you see a comment, and\nare experiencing the same issue, please don't bombard the maintainers with a \"+1\" comment.\nInstead, offer something more insightful. You can attach an [Ember Twiddle][ember-twiddle]\nin an effort to recreate the issue, and state your expectation vs. actual behavior.\n\nIf you can't find an existing issue that replicates yours, create a new one.\nEmber actually has a [good recommendation on issue reporting][ember-issue-reporting].\nFollowing these steps helps to ensure that your issue can be recreated and corrected\nas soon as possible. Moreover, it opens up the opportunity for others from the community\nto solve your issue.\n\n### Contribute Code\n\nSubmitting [pull requests to Ember libraries is straightforward][ember-pr-guide].\nThere is a channel within the Slack community called `dev-ember` that is reserved\nfor the discussion of \"development on Emberjs itself.\"\n\nSo long as you follow the aforementioned guidelines, submitting a PR is an easy\nprocess.\n\nJust like any other code base, Ember libraries can be intimidating at first, however\nwith enough persistence, you'll be cooking in no time! In addition, \"contributing\ncode\" can take the form of [contributing documentation][ember-issues-docs].\n\nLastly, if you stick around, the maintainers occasionally ask for community help,\nand you'll be rewarded with a great opportunity to help out.\n\n![](https://i.imgur.com/KRQr2p6.png)\n\n_Please Ember community... you're my only hope_\n\n### Build the community\n\nWhen I say building the community, I mean you don't necessarily need to go\nout and create a whole new meetup, or start a brand new conference (though\nthose are all good things). There are other less exhausting methods of\nbuilding and improving the Ember community.\n\nThere are various meetups to join, and plenty of ways to contribute.\nSubmitting a talk - whether it is a conference proposal or a lightning talk -\nwill allow you to broadcast your experiences with Ember, and help generate new discussions.\nSecondly, I enjoy attending local meetups and conferences as it gives me the chance to\nplace faces with GitHub, Twitter, and Slack handles.\n\n## Fin\n\nHope you found this article helpful! And before you go, our entire blog is open sourced,\nso if you find a typo or want to make a suggestion, [please feel free][reefpoints]!\n\n[dockyard-oss]: https://github.com/dockyard\n[wikipedia]: https://en.wikipedia.org/wiki/List_of_free_and_open-source_software_packages\n[elixir-website]: http://elixir-lang.org/\n[phoenix-website]: http://phoenixframework.org\n[ember-website]: http://emberjs.com\n[amazing-work]: https://dockyard.com/work\n[contribute-elixir]: https://dockyard.com/blog/2016/02/02/how-to-contribute-to-elixir\n[hassan-twitter]: https://twitter.com/habdelra\n[ember-community-page]: http://emberjs.com/community/\n[ember-slack]: https://ember-community-slackin.herokuapp.com/\n[mixonic-article]: http://madhatted.com/2014/11/5/contribute-to-ember-js-2-0-no-coding-required\n[ember-guides-site]: https://guides.emberjs.com/\n[ember-guides-gh]: https://github.com/emberjs/guides\n[ember-guide-issues]: https://github.com/emberjs/guides/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22\n[ember-issues]: https://github.com/emberjs/ember.js/issues\n[ember-twiddle]: https://ember-twiddle.com/\n[obligatory-xkcd]: https://xkcd.com/979/\n[ember-issue-reporting]: https://github.com/emberjs/ember.js/blob/master/CONTRIBUTING.md#issues\n[ember-pr-guide]: https://github.com/emberjs/ember.js/blob/master/CONTRIBUTING.md#pull-requests\n[ember-issues]: https://github.com/emberjs/ember.js/issues\n[ember-issues-docs]: https://github.com/emberjs/ember.js/labels/Documentation\n[ember-help-us]: https://github.com/emberjs/ember.js/issues/13127\n[reefpoints]: https://github.com/dockyard/reefpoints"},{"title":"Retiring Ember Suave","tags":["engineering","ember","javascript"],"summary":"Following the merge of JSCS with ESLint, `ember-suave` now has a new successor.","legacy":false,"id":"2016/09/30/retiring-ember-suave","employee":"Estelle DeBlois","date":"2016-09-30T00:00:00","body":"\n\n_\"The role of style in programming is the same as in literature: It makes for better reading. A great writer doesn't express herself by putting the spaces before her commas instead of after, or by putting extra spaces inside her parentheses. A great writer will slavishly conform to some rules of style, and that in no way constrains her power to express herself creatively.\"_\n\nWhile the writer analogy taken from Douglas Crockford's much rigid [JSLint](https://github.com/douglascrockford/JSLint) may hold true for the English language, even something as simple as a space can follow different rules in different parts of the world. For instance, in French, the exclamation point is always preceded by a space.\n\nIn the world of code, it matters less whether you are a fan of semi-colons first, or whether you favor [tabs over spaces](https://www.youtube.com/watch?v=SsoOG6ZeyUI) (except that we all know one is right and the other is wrong); what matters is that code style is consistent within a team, and that there is a way to enforce it.\n\n## The rise of `ember-suave`\n\nWhen my fellow DockYarders and I originally decided to make code style checking a part of our regular Ember CLI development workflow, [JSCS](http://jscs.info/) was the de facto code style checker. We thus set out to build [`ember-suave`](https://github.com/DockYard/ember-suave).\n\nThe addon used [`broccoli-jscs`](https://github.com/kellyselden/broccoli-jscs) internally, but it also shipped with an already configured set of JSCS rules as well as custom rules we had written. We wanted it to be opinionated, something that we could simply drop into any of our Ember CLI projects and start coding against. We wanted to put the S in Suave.\n\nWe also made the preset configurable with the hope that it would be usable by anyone outside of DockYard who might be looking for a quick jump start on JSCS, since they would only need to overwrite those rules that do not align with their team's style guide. It turns out that `ember-suave` did end up being used across a sizeable number of [projects](https://github.com/search?l=&p=3&q=ember-suave+extension%3Ajson&ref=advsearch&type=Code&utf8=%E2%9C%93).\n\nFor all those folks, I would like to announce at last that we are retiring `ember-suave`. This means that we will no longer build custom rules for it or enhance it in any way, and that it may just as well find its way into [Davy Jones' Locker](https://github.com/DavyJonesLocker), which is where all abandoned DockYard open-source projects go to die.\n\n## JSHint, JSCS, and ESLint\n\nJSCS reached [end-of-life](http://eslint.org/blog/2016/07/jscs-end-of-life) back in July, three months after joining up with [ESLint](http://eslint.org/).\n\nFor a bit of history, when [JSHint](http://jshint.com/about/) started focusing strictly on functional rules, JSCS emerged as the static analysis tool for all stylistic concerns in JavaScript. This was sometime back in 2013. For the longest time, JSHint and JSCS complemented each other rather well.\n\nMeanwhile, Nicholas Zakas [created](https://www.nczonline.net/blog/2013/07/16/introducing-eslint/) ESLint as a fully pluggable alternative to JSHint. As ESLint and JSCS matured and grew in popularity, the two projects started overlapping in functionality and goals, so instead of continuing to lead separate ways, they joined up. You can read more about the merge [here](http://eslint.org/blog/2016/04/welcoming-jscs-to-eslint).\n\n## `ember-suave` returns as an ESLint plugin\n\nMost of the rules from `ember-suave`, including the custom ones, have been converted to ESLint in a new repo called [`eslint-plugin-ember-suave`](https://github.com/DockYard/eslint-plugin-ember-suave).\n\nThe biggest difference is that you are no longer looking at an Ember CLI addon. `eslint-plugin-ember-suave`, as its name implies, is simply an ESLint plugin (the equivalent of a JSCS preset). It's just a collection of custom rules and their configuration, as well as configuration of additional rules already built into ESLint.\n\nIn order to run ESLint with the supplied configuration, you will need to install the [`ember-cli-eslint`](https://github.com/ember-cli/ember-cli-eslint) addon into your Ember project. It is worth noting that doing so will also uninstall any existing installation of [`ember-cli-jshint`](https://github.com/ember-cli/ember-cli-jshint), since it doesn't make sense to use both linters simultaneously.\n\n## The joy of having contributors\n\nMigrating `ember-suave` over to an ESLint plugin had been a lingering goal for quite some time. I just happened to have limited time to devote to it. To that end, I have contributors to thank, particularly [Alex LaFroscia](https://github.com/alexlafroscia), for spearheading the effort. He rewrote all the JSCS custom rules we had in `ember-suave` to their ESLint equivalents. [Robert Wagner](https://github.com/rwwagner90) also landed a hand in accelerating the development of the plugin, at a time when I was mostly taking a hands-off stance due to maternity leave. I do appreciate that they motivated me to code every now and then, as much as it was challenging to pair program with a two-month old.\n"},{"title":"The Role of Discovery Phases and Design Sprints","tags":["design","design process","user experience","business"],"summary":"Understanding what they are and when to use them","legacy":false,"id":"2016/10/06/the-role-of-discovery-phases-and-design-sprints","employee":"Patrick Branigan","date":"2016-10-06T00:00:00","body":"\n\nIn terms of design processes, there are two that have proven to be integral parts to building a project: the Discovery \nPhase and the Design Sprint. Both provide vital information and guidance in the pursuit of bringing an idea to fruition. \nHowever there are occasions when it can be difficult to decide which to employ. Do you need one or the other? Do you need \nboth? \n\nFirst, we need to remind ourselves of the definition and purpose of each process and better educate clients on the two.\n\n## What are they?\n\nIn essence a Discovery Phase is an interval of time in which a team focuses on exploring the ins and outs of an existing \nproduct and identifying its impact on a client’s bottom line. We use Discovery Phases to discover untapped value. This is \ndone by executing an array of exercises ranging from stakeholder interviews to user interviews, from personas to journey \nmaps. At its end, a client is provided opportunistic suggestions on how to improve on an existing product in ways that add \nvalue to their company and/or their customers.\n\nIn regards to a Discovery Phase, it’s important to recognize that while this process’ deliverable might take many forms, its \npurpose is primarily to audit and recommend, not necessarily to build and implement. Instead, part of the deliverable might \nbe specific options for designing, building and implementing the recommendations.\n\nWhile a Discovery Phase is focused on review of existing products, a Design Sprint is intended to be utilized when there is \na need for something new – new products, features, services, etc. It is a methodology of agile product design that revolves \nmost heavily around end users. We design, prototype and test ideas with users to validate or invalidate new products, \nfeatures and services whose value is solving business questions. At its end, a client is witness to a new idea come to life \nand put in front of their users in the hopes of rapid validation or invalidation. This product, feature or service is \nintended to show value quickly or otherwise fail quickly, saving time and resources that otherwise might have been spent on \na more robust build. \n\nIn regards to a Design Sprint, it’s important to recognize that its purpose is to allow for rapid validation or failure of a \nproduct (or feature, service, etc.) which requires user involvement and feedback.\n\nWhile there are some similarities in how the two processes are carried out, their intent is quite different. This difference \nbecomes especially clear  when we look at the staples of a design project lifecycle: the time it takes, what’s being \nproduced and the people involved.\n\nWith a better understanding of the two, we can better dictate with our clients whether to conduct a Discovery Phase or a \nDesign Sprint (and when not to).\n\n## Differentiating the Two\n\n#### Length (time)\nDiscovery Phases and Design Sprints are often drastically different in terms of the amount of time needed to complete each. \nWhile a Design Sprint is modeled within one week’s time, a Discovery Phase can take as little as 1 week or up to 8 weeks to \ncomplete depending on the project size, complexity, familiarity and goals. Sprints can be repeated, but they follow the same routine and still focus on validating or invalidating a narrowed idea or question.\n\n#### Structure (time)\nA Discovery Phase might call for very mild quantitative research or it might require a plethora of user research methods to \nbe carried out. Because of the variability from project to project, the organization and scheduling of a Discovery Phase \noften requires a much more custom approach than the Design Sprint. A Design Sprint, due to the nature of its deliverable, \ngenerally follows a similar structure each and every time. A Discovery Phase has us discover, research, assess, report and \nrecommend ideas via an array of design research methods. A Design Sprint has us map, sketch, storyboard, prototype and user \ntest in the same or similar structured approach each time.\n\n#### Completion (deliverable)\nA Discovery Phase can generally be considered complete when the variables surrounding the existing challenge, and the way \nforward for the product, are defined. What are the goals? Have we identified not just what’s wanted but what’s needed? \nWhat’s the scope of the challenges uncovered and the solutions proposed? How are the outcomes of these solutions going to be \nmeasured? \n\nA Design Sprint can generally be considered complete when users have validated or invalidated the product, feature or \nservice to be built via testing prototypes. Was this product, feature, service, etc. desired by users? Did users achieve \ntheir goals? What patterns surfaced from interviews and tests? What can we do better? What have we learned?\n\n#### Expertise (team)\nIn both a Discovery Phase and a Design Sprint it’s important to bring the right team together. In a Discovery Phase we want \nstakeholders such as owners, designers, developers, business analysts, service reps, etc. who can identify problems to be \nsolved. Yes, in a Design Sprint we might involve these entities as well, but we need to involve users who can validate \nsolutions to the challenges we’re trying to solve. \n\nUnderstanding the general differences between a Discovery Phase and a Design Sprint will help in deciphering which one is \nneeded and when, as well as when and to whom to sell these processes. What are some things to look for when determining if \nyou should pursue a Discovery Phase or a Design Sprint? \n\n## Deciding Between the Two\n\nGenerally, the broader the scope of the challenge the less likely a team is in a position to do a Design Sprint. Instead, \none might consider engaging in a Discovery Phase to narrow a problem area first. Then, consider Design Sprints to prototype \nand test primary solutions to a target facet of that narrowed problem. For example, asking to “reinvent the way in which we \ncommunicate” might be a tall order for a week long Design Sprint, and more so a discussion suited for Discovery. \n\nThe value of a Discovery Phase to a business owner its ability to provide a crystal-clear understanding of what their \ncompany, product or service needs in order to advance and increase value moving forward. It’s a hands-on experience that \nwill give everyone involved the tools and insight they need to make informed decisions about the future of their product or \nservice.\n\nIn order to focus in on a Design Sprint there generally needs to be a significant amount of input to draw from. This would \nmean design research data should already exist, particularly in regards to users. Interviews, personas, journeymaps, \nethnography, etc. should be considered prior to a Design Sprint, often within Discovery. However if these already exist, \none might consider using a Sprint.\n\nThe value of a Design Sprint to a business owner is it’s ability to bring an idea to life and then validate or invalidate \nit quickly. This is because its structure allows for failure to happen without wasting resources, therefore quickly \ninvalidating ideas. Yet it provides a rapid and solid foundation for beginning development on validated ideas. The time and \neffort spent on validation or invalidation is significantly less, therefore potentially saving business owners large \namounts of money when chasing prospective innovation.\n"},{"title":"When you could turn a bug into a feature","tags":["design","design process","user experience","culture"],"summary":"Understand why quirky behaviors are happening","legacy":false,"id":"2016/10/19/bug-or-feature","employee":"Maria Matveeva","date":"2016-10-19T00:00:00","body":"\n\nMy background often plays into what I pay attention to when assessing design projects. I grew up outside of the US - in Soviet Russia, where the proverbial [fill-in-the-blank] eats you. I’ve now spent about half my life in the US. This experience gives me a good amount of insight into both worlds, and just enough distance to question things.\n\n## “Bug” in behavior\n\nOne of my favorite things to explore is the meaning behind behavior oddities - small quirks we might often make fun of, or find “incorrect” when we observe them in others. I see many of these in tech and web products, but first let’s explore an example from physical life, very analog indeed. \n\nWhen commuting on the metro in Moscow, I would often see folks reading a book wrapped protectively in newspaper. This trend would continue even after books have become relatively easy to find and purchase. The folks who continued the seemingly antiquated habit of wrapping books in newspaper tended to be older, and you’d be forgiven for chuckling at their behavior. _“They’re not with the times! Why would they inconvenience themselves by dealing with that unwieldy newspaper?”_\n## Bug or feature?\n\nLook deeper. The newspaper wrapper doesn’t just protect a book’s surface. It gives the user a sense of safety and individuality. \n\nBooks were a controversial item in Soviet Russia. A large portion of what is now considered classic Russian literature was censored. Censorship extended to encouraging citizens to snitch on others if they observe suspicious behavior. Reading a book in public was an invitation for others to check out what it is, and express an opinion. A camouflage behavior emerged: when reading anything more controversial than a gardening manual, or a state-issued newspaper, people would wrap the cover for privacy. \n\nHow would you feel, knowing that your phone screen is clearly visible to everyone else on the train? Probably not that comfortable. To someone who’s grown up 30 or so years ago in Russia, an exposed book cover would feel the same. It’s a protective wrapper that gives us a bit of room to disagree with the system - and to avoid judgement.\n\nIn my practice, I’ve seen plenty of examples of “bugs” that reveal desired behaviors. For example, when redesigning a complex dashboard interface for specialist users, we noticed that the screen seemed overwhelmed with tabular data, almost to the point of being unreadable. It seemed like a quick visual design fix to reduce the clutter and show less information to help people focus. But that “bug” revealed a level of comfort the users had with seeing all of the information at once. They actually preferred the high density of information in some parts of the experience, because it matched an existing workflow in Excel, and reduced the cognitive load of switching back and forth.\n\n\n## Tl;dr.\n\nQuaint behaviors that don’t make sense are a signal. When we observe them, we should know there’s more to discover. Something that looks like a bug to a design practitioner, can lead to a valuable feature in the eyes of a specialized user. \n\nWe should train ourselves to see these little “bugs” in others’ habits as opportunities to discover a deeper motivation, then build uniquely useful products as a result. And learn a fun fact for a blog post!\n"},{"title":"Live Search with Ember & JSON API","tags":["engineering","ember","javascript","phoenix","rails"],"summary":"Build a JSON API-compliant live search using Ember and Phoenix/Rails","legacy":false,"id":"2016/10/20/live-search-with-jsonapi","employee":"Romina Vargas","date":"2016-10-20T00:00:00","body":"\n\nLive search is a feature commonly found in applications. There are various\nsolutions to implementing search functionality on a website, but \"live search\"\npromotes a better user experience over the traditional way of searching\n(i.e. type in keyword and click to view results); it's satisfying to a user\nsince immediate feedback is received based on what they have typed, without\nhaving to click some form of a \"submit\" or \"search\" button. It's refreshing to\nsee results narrow as you type more words, or broaden as you backspace to delete\nalready-typed characters from the search box. The less work your user\nhas to do, the better.\n\nLive search is not new concept whatsoever, but if you're new to the\n[JSON API specification][jsonapi-spec] and would like to follow its conventions,\nthis may be helpful.\n\nThe specification states the following on the subject of filtering:\n\n* The `filter` query parameter is reserved for filtering data.\n* Servers and clients **SHOULD** use this key for filtering operations.\n\nGiven that info, we'll go over how to set up the client-side (Ember), and the\nserver-side (in both Phoenix and Rails) to get live search working. In the\nfollowing examples, we'll work with a `Food` model having a `category` attribute.\n\n## On the Ember side\n\nTo get started, make sure your application is using the `DS.JSONAPIADAPTER`;\nit's the default adapter in a new Ember application. This informs your\napplication of the type of data that it should be expecting from the server. In\nour case, the payload will be expected to have a specific format and will be\nexpected to contain certain keys. Check out the [spec][jsonapi-spec] if you'd\nlike more details on this.\n\nHaving that, we only need to add a couple of things:\n[query parameters][query-params] and the call to the server itself.\n\n```js\n// controllers/foods.js\nimport Ember from 'ember';\nconst { Controller } = Ember;\n\nexport default Controller.extend({\n  queryParams: 'category',\n  category: ''\n});\n```\n\n```js\n// routes/foods.js\nimport Ember from 'ember';\nconst { Route } = Ember;\n\nexport default Route.extend({\n  queryParams: {\n    category: { refreshModel: true }\n  },\n\n  model(params) {\n    return this.store.query('food', { filter: { category: params.category } });\n  }\n});\n```\n\nIt's that simple. Notice that we're using the store's `query` method and\nproviding it with a `filter`. This `filter` **must** be included in the call.\nThis will result in a `GET` request containing a URL encoded string with the\n`filter` query parameter:\n\n`/foods?filter%5Bcategory%5D=pastry`\n\nNow let's see how to set this up on the backend for a seamless integration.\n\n## On the Phoenix side\n\n* Hex package needed: [ja_resource][ja-resource]\n* Recommended to use with: [ja_serializer][ja-serializer]\n\nAfter following the lib's quick installation instructions, and aside from\nneeding to add our route and schema, that's all we need to do in Phoenix\nbefore heading over to our controller for some filtering logic.\n\n```elixir\ndefmodule MyApp.FoodController do\n  import Ecto.Query\n\n  use JaResource\n  use MyApp.Web, :controller\n\n  plug JaResource\n\n  def filter(_conn, query, \"category\", category) do\n    from f in query,\n      where: ilike(f.category, ^(\"%#{category}%\"))\n  end\nend\n```\n\nOn L7, `plug JaResource` is reponsible for providing all the controller actions\nby default. There is no need for you to implement these actions unless you'd\nlike to add custom logic. That's a pretty nice time saver!  Plus we can\ncustomize our controller's behavior via the many callbacks that the library\nprovides. JaSerializer conveniently provides the callback `filter/4` where we\ncan handle our custom filtering given our filter parameters. In the example, we\nonly want to filter by category, so we add \"category\" as the third argument\nso that we get a match. You'll have to define one of these filter callbacks for\nas many filter parameters as you want to pass. \"Anything not explicitly matched\nby your callbacks will get ignored.\"\n\n## On the Rails side\n\n* Gem needed: [jsonapi-resources][jsonapi-resources]\n\nAfter having installed the gem, like in the Phoenix section above, you'll need to\ndeclare your routes and models. To gain the simplest form of the `filter`\nfunctionality, you just need to add the following (L5) to the corresponding\nresource file (this will find an exact match):\n\n```ruby\nclass FoodResource < JSONAPI::Resource\n  attributes :category\n\n  filter :category\nend\n```\n\nThe filter will be based on the term passed in from the `GET` request coming\nfrom the Ember side; it will make sure that we are only returned `Food` records\nwhose `category` value matches _exactly_ that of the request parameter\n(i.e. \"pastry\").\n\nBelow, I show another example that leverages the `:apply` option whose\narguments are records (an `ActiveRecord::Relation`), the value to filter by,\nand an options hash.  However, you have much flexibility on how you decide to\nimplement your filter. The [README filter section][jsonapi-resources-readme]\nhas a more comprehensive list of the possibilities.\n\n```ruby\nclass FoodResource < JSONAPI::Resource\n  attributes :category\n\n  filter :category, apply: -> (records, value, _options) {\n   records.where('category LIKE ?', \"%#{value[0]}%\")\n  }\nend\n```\n\n## Conclusion\nThat wraps it up! The Ember frontend and the Phoenix/Rails backends now work\ntogether to provide a live search functionality to a web application. Since\nwe're following the JSON API spec, there is little to no friction on either\nside in order to get this working as expected. Happy filtering!\n\n[jsonapi-spec]: http://jsonapi.org/format\n[query-params]: https://guides.emberjs.com/v2.8.0/routing/query-params/#toc_specifying-query-parameters\n[ja-resource]: https://github.com/AgilionApps/ja_resource\n[ja-serializer]: https://github.com/AgilionApps/ja_serializer\n[jsonapi-resources]: https://github.com/cerebris/jsonapi-resources\n[jsonapi-resources-readme]: https://github.com/cerebris/jsonapi-resources#filters\n"},{"title":"Making a DDAU checkbox list in Ember.js","tags":["engineering","ember","javascript"],"summary":"Use Data Down, Actions Up to create a simple Checkbox List UI element in Ember","legacy":false,"id":"2016/11/18/checkbox-list-ember","employee":"Nico Mihalich","date":"2016-11-18T00:00:00","body":"\n\n## Data Down, Actions Up (A refresher)\n\nAn important part of creating stable, maintainable Ember applications is following the Data Down, Actions Up (DDAU) paradigm.  This means that your data comes in at the route level and is displayed further down in your UI (by templates and components), while when you want to manipulate that data, you trigger an action which gets sent back up to the route that manipulate the data at its source.  This makes your application simple and easy to reason about because there is a single source of truth for your data and the route that manipulates the data.\n\n## Okay... so?\n\nSo, it's hockey season! Let's finally build that favorite player voting app you've always wanted. We'll display a list of players via a list of checkboxes and have the user select which ones they like.  Our input will be a list of strings, and we want the output to be another list of strings. Following DDAU, ideally we want our checkboxes to not actually manipulate a `selected` value directly, but send an action back up which manipulates our model and marks the player as `selected`. (We'll leverage [One Way Controls](https://github.com/DockYard/ember-one-way-controls) for that).\n\n## Setup\n\nModel:\nOur model hook is dead simple:\n\n```javascript\nmodel() {\n  return [];\n}\n```\n\nAlso we'll need some options to select from.  Let's put that in the controller:\n\n```javascript\nimport Ember from 'ember';\n\nconst { Controller, set } = Ember;\n\nexport default Controller.extend({\n  init() {\n    this._super(...arguments);\n    set(this, 'playerOptions', [\n      'Phil Kessel',\n      'Sidney Crosby',\n      'Tyler Seguin',\n      'Steven Stamkos',\n      'Connor McDavid',\n      'Patrick Kane'\n    ]);\n  }\n});\n```\n\nAnd a simple template:\n\n```handlebars\n<div>\n  <h2>Pick your favorites</h2>\n  <ul>\n    {{#each playerOptions as |player|}}\n      <li>\n        {{!TODO Checkbox}}\n        {{player}}\n      </li>\n    {{/each}}\n  </ul>\n</div>\n\n<div>\n  <h2>You picked</h2>\n  <ul>\n    {{#each model as |player|}}\n      <li>{{player}}</li>\n    {{/each}}\n  </ul>\n</div>\n```\n\n## Checkboxes\n\nNow we have some options, and a place to select them into.  Let's write the checkbox logic!  The API for a checkbox looks something like:\n\n```handlebars\n{{one-way-checkbox selected update=(action \"someAction\")}}\n```\n\nWhere selected is a boolean.\n\nFor our use case, the checkbox should be selected when the player is in the model. Note our input and output are both lists of strings, no `selected` attribute. So how do we mark it as selected if we don't store it?\n\n## Quick detour into helpers!\n\nWe want to have `selected` in our template be true when an item is in an array.  We can write a [helper](https://guides.emberjs.com/v2.9.0/templates/writing-helpers/) that does this for us which we can use in the template to return our `selected` boolean value:\n\n```javascript\nimport Ember from 'ember';\n\nconst { Helper: { helper } } = Ember;\n\nexport function includes([haystack, needle]) {\n  return haystack.includes(needle);\n}\n\nexport default helper(includes);\n```\n\nThis enables us to write\n\n```handlebars\n{{one-way-checkbox (includes model player) ...}}\n```\n\nIt's also useful in that if your model returns some options, the template is reactive to that and automatically marks them as selected because the helper is computing it from the higher up data flowing into it.\n\nCool!\n\n## Actions\n\nSo far so good, but if we click on the checkbox... it doesn't do anything.  We'll need an update action, which we want in our route (using [ember-route-action-helper](https://github.com/DockYard/ember-route-action-helper)).\n\n```javascript\n  actions: {\n    togglePlayer(player, checked) {\n      let model = get(this, 'currentModel');\n      if (checked) {\n        model.pushObject(player);\n      } else {\n        model.removeObject(player);\n      }\n    }\n  }\n```\n\n## Finally\n\nNow we can insert a checkbox using our `includes` helper and action.\n\n```handlebars\n  {{one-way-checkbox (includes model player)\n    update=(route-action \"togglePlayer\" player)}}\n```\n\nAnd we're done! [Here's a demo](https://ember-twiddle.com/da6865aefe607e9deb460b5f29e20b0b).\n\nI hope this demonstrates a practical example of DDAU in Ember to build a pretty common UI element.\n"},{"title":"How GenServer deals with errors in a concurrent environment","tags":["elixir"],"summary":"GenServer can help deal with race conditions, deadlocks, and many edge cases","legacy":false,"illustration_alt":"msg","illustration":"http://d.pr/i/BS8a+","id":"2016/11/18/how-genserver-helps-to-handle-errors","employee":"Daniel Xu","date":"2016-11-18T00:00:00","body":"\n\n## Pattern for stateful server process\n\nAfter newcomers wrap their minds around immutability, they quickly question how to hold and change state in a language that\ndoes not allow mutation. Elixir uses Erlang's OTP libraries to formalize state access and mutation,\nbut to understand how this can happen in an immutable world we can implement our own stateful server using only a process with tail recursion:\n\n* In the following sample code, we define a start function which can be used to start the server process with an initial state.\n* Because of `receive`, the process will be blocked to wait for messages. Whenever clients send a message to the server process using `call`,\n  it will pattern match on `{:message, caller, msg}` and invoke the corresponding function to get the new state.\n* After getting the new state, it replies to the client and runs the loop function from the beginning with the new state.\n\n```elixir\ndef start(inital_state) do\n  spawn(fn ->\n    initial_state = ...\n    loop(initial_state)\n  end)\nend\n\ndefp loop(state) do\n  receive do\n    {:message, caller, msg} ->\n      new_state = handle(msg, state)\n      send(caller, {:reply, new_msg})\n      loop(new_state)\n    :stop -> terminate()\n  end\nend\n\ndef call(name_or_pid, message)\n  send(name_or_pid, {:message, self(), message})\n  receive do\n    {:reply, reply} -> reply\n  end\nend\n```\n\nIt's simple but error-prone because we don't handle any error condition. This becomes more complicated when dealing with a concurrent environment.\nThe good news is that [GenServer](http://elixir-lang.org/docs/stable/elixir/GenServer.html) can help deal with race conditions, deadlocks,\nand many edge cases.\n\n## GenServer helps with error handling\n\n### Ensure source of message using `reference`\n\nIn the stateful server process above, the client sends a message to the server with a format of `{:message, pid_or_name, message}`\nand waits for a message with a format of `{:reply, reply}`.\n\nAs shown in the picture, the client might receive a similarly formatted reply from different servers,\nhow can we make sure that the reply is from the correct server?\n\n![msg](http://d.pr/i/BS8a+)\n\nThe solution is to use **a unique reference** to tag the message. when the client sends a request to the server,\nit creates a unique reference first and sends it with its pid together: `{:message, {ref, pid}, message}`,\nand the server can reply with `{:reply, ref, reply}`. This way, the client can pattern match based on the unique reference.\n\nNow, the `call` function becomes:\n\n```elixir\ndef call(name_or_pid, message)\n  ref = make_ref()\n  send(name_or_pid, {:message, {ref, self()}, message})\n  receive do\n    {:reply, ^ref, reply} -> reply\n  end\nend\n```\n\nErlang/OTP solves this problem with a unique reference as shown [here](https://github.com/erlang/otp/blob/maint/lib/stdlib/src/gen.erl#L167).\n\n### What if the server crashes\n\n1. Server crashes before message is sent by client via server Pid\n\n  If the server crashes before the message is sent from the client, the message will be lost and the client will be **blocked** in the `receive` block.\n\n  The solution is to monitor the server process using `Process.monitor(server_pid)`. The reason why we choose `monitor` instead of\n  `links` is that monitor is unidirectional, so termination of the client will not affect the server.\n\n  In case of a server crash, the client will receive a `Down` message, so we can take action in the `receive` block.\n  Noting that `monitor` returns a reference, we can now drop the `make_ref()`.\n\n2. Server crashes before message is sent by client via registered name\n\n  In this case, the client process will terminate. To avoid crashing and return better error stack, we need to rescue the runtime error by\n  using `try...rescue`.\n\n3. Server crashes right after replying to client\n\n  If the server crashes right after it sends its reply to the client, a `Down` message will be sent to the client's\n  mailbox. The client, however, will never have a chance to pattern match this message because it `demonitors` the server.\n\n  This might cause memory leak and slow down the server. Ultimately, a single slow process may cause an entire system to crash by consuming all the available memory.\n\n  `Process.demonitor(ref, [:flush])` is the solution for this issue. Every time we demonitor a server,\n  passing in a `flush` option can make sure that any Down message that belongs to that monitor will be cleared.\n\nAfter handling the server crash, the `call` function looks like:\n\n```elixir\ndef call(name_or_pid, message, timeout \\\\ 5000)\n  ref = Process.monitor(name_or_pid)\n  try do\n    send(name_or_pid, {:message, {ref, self()}, message})\n  rescue\n    _ -> :error\n  end\n  receive do\n    {:reply, ref, reply} ->\n      Process.demonitor(ref, [:flush])\n      reply\n    {:DOWN, ref, ...} ->\n      {:error, reason}\n      exit(reason)\n    {:DOWN, ref, ..., :noconnection} ->\n      node = get_node(name_or_pid)\n      exit({:node_down, node})\n  after timeout -> exit(:timeout)\n  end\nend\n```\n\n### Deadlock\n\nIf two processes synchronously call each other using the code above, both of them enter the `receive` block which will cause\na [Deadlock](https://en.wikipedia.org/wiki/Deadlock). This can be resolved with a timeout in the receive block. When the time is\nout, the system can terminate the process and release the resources held by the process.\n\nAn example is shown [here](https://github.com/erlang/otp/blob/maint/lib/stdlib/src/gen.erl#L178-L181).\n\n## Conclusion\n\nThere are a lot more concurrent errors that we haven't discussed yet. Fortunately, GenServer handles all the concurrent conditions and\nedge cases, we should almost always use it instead of reinventing the wheel.\n"},{"title":"Improving Ember app page load times using the App Shell model","tags":["javascript","ember","pwa"],"summary":"Experimenting with the App Shell model to make the DockYard.com website load faster","legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/GNrFsfe.png","id":"2017/02/17/page-load-improvements-with-app-shell","employee":"Marten Schilstra","date":"2017-02-17T00:00:00","body":"\n*In the past week I have been experimenting with the [App Shell Model](https://developers.google.com/web/fundamentals/architecture/app-shell) to make the [DockYard.com](https://dockyard.com) website load faster. In this blog post I'll walk through which changes I made and how I've made them. Complete with some benchmarks!*\n\n### Why improve page load speed?\n\nAccording to Google, if [loading a page takes too long](https://www.thinkwithgoogle.com/articles/mobile-page-speed-load-time.html), they'll just abandon it. This hurts your conversion rates. Key metrics that contribute to better conversion rates are when the browser is able to make its first paint and when the page is fully loaded.\n\n### Tools of the trade\n\n*In this section I'll introduce the tools I've used to measure the loading performance. Please take a minute to follow the links to the mentioned tools and read how they work and what they are for.*\n\nTo be able to measure the performance of DockYard.com I have used [Lighthouse](https://developers.google.com/web/tools/lighthouse/) and the [Application](https://developers.google.com/web/fundamentals/getting-started/codelabs/debugging-service-workers/), [Network](https://developers.google.com/web/tools/chrome-devtools/network-performance/) and [Timeline](https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/timeline-tool) DevTools from the Google Chrome team to see changes made a positive impact on loading speed.\n\nLighthouse is the successor of Google's [PageSpeed](https://developers.google.com/speed/pagespeed/) tool. Lighthouse uses your Chrome DevTool to do a host of automated audits. I.E. it checks if a [Service Worker](https://developers.google.com/web/fundamentals/getting-started/primers/service-workers) is registered and that a [Web App Manifest](https://developers.google.com/web/updates/2014/11/Support-for-installable-web-apps-with-webapp-manifest-in-chrome-38-for-Android) can be found. The audits I'm most interested in are the page load performance audits. These measure the [first meaningful paint](https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint), the [speed index](https://developers.google.com/web/tools/lighthouse/audits/speed-index) and [time to interactive](https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive) performance.\n\n### What I'm measuring\n\nI'm measuring the page load in two situations. The first situation is as if it's the very first time I'm visiting the website, this means no assets have been cached yet. The second situation is when I'm loading the website on a repeat visit, which means the browser had a chance to cache the assets. I'll also measure the same two scenarios using network and CPU throttling to simulate being out and about on a mobile device. Mobile simulation is done on the 'Regular 3G' network throttling setting and the 'Low end device' cpu throttling setting.\n\nThere are three key performance metrics I'm looking for in each test, first I'll look for when the first meaningful paint happens and second I'll look for the moment when the Ember.JS app has booted client side and when the Ember.JS app has done its initial render on the client side. The first meaningful paint and the initial render metric are the two metrics that according to [Google](https://www.thinkwithgoogle.com/articles/mobile-page-speed-load-time.html) contribute the most to abandonment rate.\n\n### Getting the baseline\n\n*Benchmarks have been made on a standard mid 2015 15\" MacBook Pro, all tests have been done with a wired 500 megabit up/down internet connection. I have about 90ms latency towards the webserver and about 7ms to the assets server.*\n\nTo start out, here are the baseline performance metrics of the current DockYard.com website. It is a Ember.js application that is served with [FastBoot](https://ember-fastboot.com).\n\n#### Baseline Lighthouse score\n\n![](http://i.imgur.com/GNrFsfe.png)\n\n*Note: Lighthouse measures without CPU slowdown and a custom network throttling setting*\n\nThis initial lighthouse score shows that the first meaningful paint comes just before the time to interactive. This does mean that when the page shows up, it's almost immediately interactive, but you'll see nothing before that.\n\n#### Baseline Desktop: Page load with empty cache\n\n![](http://i.imgur.com/pRF7ak0.png)\n\n- First paint: 600ms\n- App boot: 1,175ms (the dip in the CPU graph)\n- Initial render: 1,400ms\n \n#### Baseline Desktop: Page load with warmed cache\n\n![](http://i.imgur.com/LQVYcYN.png)\n\n- First paint: 325ms\n- App boot: 750ms\n- Initial render: 950ms\n \n#### Baseline Mobile: Page load with empty cache\n\n![](http://i.imgur.com/LNL0fSB.png)\n\n- First paint: 1,200ms\n- App boot: 8,900ms\n- Initial render: 10,200ms\n \n#### Baseline Mobile: Page load with warmed cache.\n\n![](http://i.imgur.com/Z3Y9JZO.png)\n\n- First paint: 850ms\n- App boot: 2,850ms\n- Initial render: 4,200ms\n \n### The changes I've made\n\nFirst off I've added (offline) caching by a Service Worker, using [Ember Service Worker](http://ember-service-worker.com) with various plugins. This did not, as expected, improve the cold boot scenarios, but did improve the scenarios with warmed cache slightly. Especially the first paint was much earlier. Results of the warmed cache scenarios are:\n\n#### Service Worker only Desktop: Page load with warmed cache\n\n![](http://i.imgur.com/oasoMXS.png)\n\n- First paint: 125ms\n- App boot: 725ms\n- Initial render: 900ms\n \n#### Service Worker only Mobile: Page load with warmed cache\n\n![](http://i.imgur.com/Hq8beZk.png)\n\n- First paint: 300ms\n- App boot: 2,700ms\n- Initial render: 4,000ms\n \nNext I wrote a small [Ember CLI addon](https://github.com/DockYard/ember-cli-one-script) that concats both scripts (`vendor.js` and `dockyard.js`) that Ember CLI produces together. Then I proceeded to load that single JavaScript file using a `` element in the head that was marked `async`. This had no significant improvement on the desktop side, but loading on mobile did improve. There is a small downside to this technique though, the two files aren't cached seperately by the browser anymore, which can increase the amount of data needed to be transferred when deploying new builds often.\n\n#### Async'ed script Mobile: Page load with empty cache\n\n![](http://i.imgur.com/s6Uq246.png)\n\n- First paint: 750ms\n- App boot: 7,950ms\n- Initial render: 9,000ms\n \n#### Async'ed script Mobile: Page load with warmed cache\n\n![](http://i.imgur.com/me4jkYA.png)\n\n- First paint: 200ms\n- App boot: 2,350ms\n- Initial render: 3,550ms\n \nLastly I extracted all the critical CSS for an initial render and inlined it into the `` section. Then proceeded to asynchronously load the remaining CSS using [loaddCSS](https://github.com/filamentgroup/loadCSS). This made the first paint come slightly earlier in all scenarios, but hurts the initial render by about 150ms on mobile.\n\n#### Async'ed CSS Desktop: Page load with empty cache\n\n![](http://i.imgur.com/IykzFzl.png)\n\n- First paint: 550ms\n- App boot: 1.100ms\n- Initial render: 1.325ms\n \n#### Async'ed CSS Desktop: Page load with warmed cache\n\n![](http://i.imgur.com/jSl4eiJ.png)\n\n- First paint: 125ms\n- App boot: 675ms\n- Initial render: 900ms\n \n#### Async'ed CSS Mobile: Page load with empty cache\n\n![](http://i.imgur.com/Y9vAfls.png)\n\n- First paint: 500ms\n- App boot: 8,100ms\n- Initial render: 9,150ms\n \n#### Async'ed CSS Mobile: Page load with warmed cache\n\n![](http://i.imgur.com/j9JCLsg.png)\n\n- First paint: 125ms\n- App boot: 2,500ms\n- Initial render: 3,700ms\n \n#### All the stats summed up in a table\n\n![](http://i.imgur.com/7NTHg9u.png)\n\n#### Final Lighthouse score\n\n![](http://i.imgur.com/B2dq8p5.png)\n\n*Note: To get the perfect 100/100 score we also added a Web App Manifest.*\n\nThat's an impressive 10x speed up in first paint and almost a second and a half in time to interactive. This gives your user much more confidence in that your page is loading.\n\n### Browsers without Service Worker\n\nYou might ask: \"How does this affect page loading in browsers that not yet support Service Workers?\". I've tested the before and after with Safari's timeline tool. The results show no significant speed up in full page load, but actually a slight slowdown. The results do show a significant speed up in first paint time with either empty or warm cache.\n\nAfter the benchmarks I've noticed that loading the service worker registration script plays a big part in the slowdown. I'd need to fiddle some more with loading that script to see if I can get rid of the slowdown.\n\nBelow are the timeline graphs for loading in Safari. Notice the big shift of the blue `DOMContentLoaded` line. That counts as the first paint. The red `Load` line is the app boot. The last green bar is the initial render.\n\n#### Baseline: Page load with empty cache\n\n![](http://i.imgur.com/Skyo7Dk.png)\n\n- First paint: 510ms\n- App boot: 600ms\n- Initial render: 740ms\n \n#### After improvements: Page load with empty cache\n\n![](http://i.imgur.com/AZuSkqW.png)\n\n- First paint: 250ms\n- App boot: 650ms\n- Initial render: 820ms\n \n#### Baseline: Page load with warm cache\n\n![](http://i.imgur.com/dE536q5.png)\n\n- First paint: 510ms\n- App boot: 575ms\n- Initial render: 730ms\n \n#### After improvements: Page load with warm cache\n\n![](http://i.imgur.com/QcDuWBI.png)\n\n- First paint: 250ms\n- App boot: 620ms\n- Initial render: 780ms\n \n#### Safari tests summarized\n\n![](http://i.imgur.com/kZT1iWE.png)\n\n### Conclusion\n\nA Service Worker and a bit of techniques from the App Shell model can boost your page load times. Your app will show up on the screen earlier and be interactive quicker, which in turn can improve the conversion rates of your website.\n\nPlease try out these techniques and see for yourself if it improves page load times of your app. In any case let me know how it works out for you.\n\nClosing: don't forget to compress your images, svg's and fonts! Those too can impact page load performance by seconds on mobile.\n"},{"title":"What type of business problem are we solving?","tags":["design","design process","best practices","business","design thinking"],"summary":"The decision about where a problem & solution belong within a business is as important as execution and quality.","legacy":false,"id":"2017/04/17/what-business-problem-are-we-solving","employee":"Maria Matveeva","date":"2017-04-17T00:00:00","body":"\n\nTl;dr: skills or expertise alone don’t guarantee a great business outcome. You also need to know where to apply them.\n\nI was listening to [an episode](http://www.marketingforowners.com/podcast/595/) of _Marketing for Owners_ podcast recently, and one idea stopped me in my tracks. \n\nKate Cook, a nutrition specialist, leads a consulting company focused on the benefits of nutrition. As part of her practice, she audits work environments from the nutritional health perspective, setting up educational programs and/or planning meals. Improving something like the food employees eat may seem like a nice-to-have and might often be treated casually. However, there is a different approach.\n\n> Kate is often asked to go to a company and has done so under health and safety rather than employee wellness. That’s because you’re far more likely to have a manual handling accident if your blood sugar levels are not balanced. And that happens as a result of coming to work without breakfast and drinking energy drinks.\n\n- [source](http://www.marketingforowners.com/podcast/595/)\n\nThe idea that struck me was this: **the fact that Kate’s work is classified under Health & Safety can allow her to make a much bigger impact**. This is because the business can clearly see value in preventing accidents and improving safety. Accidents cause suffering, can stop work, increase insurance premiums, etc. etc..\n\nIf the same specialist’s work is classified under “human resources” instead, the impact can be limited by the scope and budget of that department. Human Resources deals with important issues, of course – but nutritional advice filed under HR could be interpreted as optional. The problem to be solved here is comfort, pleasure, and perhaps health. But without a clear connection to known important business goals (like health and safety) there will not be enough room in the budget to create an impactful nutritional program.\n\n## It’s not just what you do—it’s where you do it. \n\nMy takeaway from listening to the podcast is this: the impact of my work is never defined by my skill or expertise alone. The impact of my work will be limited or multiplied by how it’s classified - what _type_ of business problem I am solving, in the client’s eyes? \n\nJust like categorizing a nutrition program as “Optional” vs. “Safety”, you could think of design as something optional, or as something essential. You’ll get different results depending on your approach. \n\nYou can expect better results if you have the opportunity to define not just the solution, but also the problem and where that problem belongs in the bigger picture of a business. A thoughtful, structured approach of a discovery frames both the problem and a proposed solution against a set of assumptions and constraints.\n\nWhen we bring in design after the problem has been fully defined, or even once it’s been partially solved, we reduce the potential impact. With a limited impact (for example, if we treat design as aesthetic-only) we can only justify a respectively smaller effort. \n\n## What this means for designers\n\nAs a practitioner, I know this understanding comes with experience. It took several years to see  how much the impact of design work depends on the “category” it’s been assigned by a client. You can be the best designer, but if there’s a limited field to work in, you can only do so much. This can feel frustrating at times, but a good understanding of where you stand can help propose a right-size project instead of wasting time on an unnecessarily ambitious proposal, or under-estimating the impact your work can truly have.\n\n## What this means for business owners\n\nFor folks who are considering hiring design to solve a problem, it’s important to consider two things. One – the earlier you bring in design thinking - the larger potential impact it can have. Bring designers in at the planning stages to help define big wins for a project. And two – when you do collaborate with designers, at any stage, be honest about what “category” the project falls into within your business. You’ll support the design team’s ability to think at the right level, right away, and get better answers to your questions around scope, time, and scale.\n\n\n"},{"title":"DockYard Launches Redesigned Website","tags":["press-release"],"summary":"Today, DockYard released a new version of their flagship website DockYard.com.","legacy":false,"id":"2017/04/18/dockyard-launches-redesigned-website","employee":"Jess Krywosa","date":"2017-04-18T00:00:00","body":"\n\nToday, DockYard released a new version of their flagship website [DockYard.com](https://dockyard.com). This latest iteration provides more indepth information on DockYard’s software design and engineering services, body of work, and pursuit of best practice web app development.\n\n“Our new website design represents a collaborative effort between our design and engineering teams to deliver a clean, fast, and beautiful vision for how we want the world to view DockYard,” says Brian Cardarella, DockYard CEO. “As with all of our internal design and engineering efforts we pushed ourselves to not compromise on the implementation.”\n\nIn the coming weeks users will see even more advances on DockYard.com, including better representations on the company's culture, hiring, and team. Their blog—“[Reefpoints](https://dockyard.com/blog)”—will also receive a refresh with a design that better organizes content and provides a more immersive reading experience. New case studies and exclusive content on Progressive Web Applications (PWAs) will also be updated regularly, providing a more thorough understanding of the solutions that DockYard creates.\n\n “We have many lessons learned that we hope to share with the community as a whole,” continues Cardarella. “One of our primary missions at DockYard is to help improve the eco-system that we work in. Improvements to many of our Ember.js and Elixir libraries came out of this effort, and we’re excited to share these in the coming weeks.”\n\nFor more information on DockYard and it’s services please visit [DockYard.com/services](https://dockyard.com/services).\n\nDockYard is a software consultancy driven by creating exceptional user experiences.\nBy approaching software with the user experience at the forefront, DockYard delivers web applications that beat out native applications in any web browser using HTML5, CSS, and JavaScript.\n"},{"title":"DockYard Senior Engineer To Present at GOTO Chicago","tags":["press-release"],"summary":"DockYard Senior Engineer Marten Schilstra will present at GOTO Chicago 2017.","legacy":false,"id":"2017/04/28/dockyard-to-present-at-goto-conf","employee":"Jess Krywosa","date":"2017-04-28T00:00:00","body":"\n\n[DockYard.com](https://dockyard.com) Senior Engineer Marten Schilstra will present at [GOTO Chicago](https://gotochgo.com) on May 2, 2017. He joins a number of other industry experts and leaders presenting at the two day international software conference.\n\nTuesday, May 2, Schilstra will present in the Frontend track ‘Making the web frameworks titans feel tiny.’ This talk will focus on Service Worker technology and solutions that web frameworks are implementing to alleviate their deficiencies.\n\nGOTO is the enterprise software development conference designed for team leads, architects, and project management organized by developers, for developers. \n\nDockYard is a software consultancy driven by creating exceptional user experiences. By approaching software with the user experience at the forefront, DockYard delivers web applications that beat out native applications in any web browser using HTML5, CSS, and JavaScript.\n"},{"title":"Five Business Problems Progressive Web Apps Solve","tags":["business","pwa"],"summary":"Progressive Web Apps are not only a forward thinking technology but also an answer to issues that businesses face on a daily basis.","legacy":false,"id":"2017/05/03/five-business-problems-pwas-solve","employee":"Jess Krywosa","date":"2017-05-03T00:00:00","body":"\n\nToday’s businesses are extremely reliant on the web. Finding and acquiring new customers while engaging and retaining current ones is a costly balancing act requiring more and more bandwidth and budget. \n\nHow can businesses communicate with all customers, across all devices, and in the most cost effective way? Progressive Web Apps (PWAs) are not only forward thinking technology but also an answer to issues like this that businesses face on a daily basis. \n\n**The need to develop and maintain for multiple platforms.** A Progressive Web App works in the browser so there is no need for specialized development. Specifically, Chrome, Opera, and Firefox support PWAs with Safari—while not (yet?) supporting them—[still sees an increase in engagement.](https://developers.google.com/web/showcase/2016/aliexpress) When implementing a PWA, many companies like Alibaba see a 76% [increase in conversion across all browsers](https://developers.google.com/web/showcase/2016/alibaba), not only those in which they are completely supported. \n\n**Mobile applications are not discoverable.** A big barrier to mobile application adoption is that they do not show up in search results. This means that new customers looking for solutions you provide are unable to find you, unless they are already aware of you. By implementing a Progressive Web App the opportunities for new user acquisition are amplified by their ability to find you on their own terms when they need you. Not to mention the fact that [Google rewards mobile-friendly content in it’s search algorithm](https://webmasters.googleblog.com/2016/03/continuing-to-make-web-more-mobile.html). \n\n**Re-engagement and timely communication is costly (and ‘people don’t read email’).** PWAs allow websites to be added to home screens on mobile devices and receive push notifications. After users opt in they can be provided timely information on sales, abandoned carts, or other information valuable to them at that specific time or location. Push notifications offer users the right information at the right time without the need to check, open, and interact with email. \n\n**Still, one experience doesn’t fit both desktop and mobile visitor goals.** Should you want to provide a varied experience for your mobile audience this is also supported by Progressive Web Apps. Where your desktop users may be completing tasks focused on research and narrowing solutions, your mobile users may be looking to make decisions and purchases. Providing upfront information on sales, new products, or upcoming events can be spotlighted making it easier for them to move from discovery to purchase. \n\n**Mobile sites can be slow and not user friendly.** It is true that mobile apps provide a user and device driven experience which many websites are not optimized for. Progressive web apps solve for this by providing an app like feeling to the user without the need to develop for multiple devices. PWAs create a faster, lighter, and interactive way for consumers to interact with a business in a way that makes sense for them. Given that [53% of users will abandon a site if it takes longer than 3 seconds to load](https://developers.google.com/web/progressive-web-apps/), speed is a very important consideration. \n\nWhether combatting a poor mobile experience or trying to reduce long term costs, all businesses can benefit from upgrading to a Progressive Web App. The reduction in overhead and simplification of communication with your key customers are just a couple of ways companies can see the immediate impact of PWA implementation. \n"},{"title":"Optimizing Your Elixir and Phoenix projects with ETS","tags":["engineering","elixir","phoenix","ets"],"summary":"Learn how to optimize your elixir applications with a fast in-memory store","legacy":false,"id":"2017/05/19/optimizing-elixir-and-phoenix-with-ets","employee":"Chris McCord","date":"2017-05-19T00:00:00","body":"\n\nMany Elixir programmers have probably heard references to \"ets\" or\n\"ETS\" in talks, or may have seen calls to the Erlang `:ets` module in\ncode, but I would wager the majority haven't used this feature of\nErlang in practice. Let's change that.\n\nETS, or Erlang Term Storage, is one of those innovative Erlang\nfeatures that feels like it has been hiding in plain sight once you\nuse it. Projects across the community like `Phoenix.PubSub`,\n`Phoenix.Presence`, and Elixir's own `Registry` take advantage of ETS, along with many internal Erlang and Elixir modules.\nSimply put, ETS is an in-memory store for Elixir and Erlang terms with\nfast access. Critically, it allows access to state outside of a\nprocess and message passing. Before we talk when to ETS (*and when not to*), let's begin with a basic primer by firing up iex:\n\nFirst, we'll create an ETS table with `:ets.new/2`:\n\n\n```elixir\niex> tab = :ets.new(:my_table, [:set])\n8211\n```\n\nThat was easy enough. We created a table of type `:set`, which will allows us to map unique keys to values as a standard key-value storage. Let's insert a couple items:\n\n```elixir\niex> :ets.insert(tab, {:key1, \"value1\"})\ntrue\niex> :ets.insert(tab, {:key2, \"value1\"})\ntrue\n```\n\nNow with a couple items in place, let's do a lookup:\n```elixir\niex> :ets.lookup(tab, :key1)\n[key1: \"value1\"]\n```\n\nNotices how we aren't re-binding `tab` to a new value after inserting items. ETS tables are managed by the VM and their existence lives and dies by the process that created them. We can see this in action by killing the current iex shell process:\n\n```elixir\niex> Process.exit(self(), :kill)\n** (EXIT from #PID<0.88.0>) killed\n\nInteractive Elixir (1.4.4) - press Ctrl+C to exit (type h() ENTER for help)\niex> :ets.insert(8211, {:key1, \"value1\"})\n** (ArgumentError) argument error\n    (stdlib) :ets.insert(12307, {:key1, \"value1\"})\n```\n\nOnce iex crashes, we lose our previous bindings, but we can pass the ets table ID returned from our call to `:ets.new/2`. We can see that when we tried to access the table after its owner crashed, an `ArgumentError` was thrown. This automatic cleanup of tables and data when the owning process crashes is one of ETS's great features. We don't have to be concerned about memory leaks when processes terminate after creating tables and inserting data. Here, we also got our first glimpse of the esoteric `:ets` API and its often unhelpful errors, such as `ArgumentError` with no other guidelines on what the problem may be. As you use the `:ets` module more and more, you'll undoubtably become famliar with frustrating argument errors and the [`:ets` documentation](http://erlang.org/doc/man/ets.html) is likely to end up in your bookmarks.\n\nThis just barely scratched the surface of what features ETS provides. We'll only be using a fraction of its capabilities, but just remember where it really shines is fast reads and writes to key-value storage, with the ability to efficiently match on most erlang terms stored within the table (excluding maps). In our examples, we'll only be storing simple key-values with basic lookups, but you should consult the docs to explore the breadth of provided features.\n\n\n## Optimizing `GenServer` access with an ETS table\n\nOptimizing code is a rewarding experince, but doubly so when you don't have to change your public interface. Let's see a common way ETS is used to optimize data access for state wrapped in a `GenServer`.\n\nImagine we're writing a rate limiter `GenServer` which is a process in our app that counts user requests and allows us to deny access once a user exceeds their allotted requests per minute. We know right away that we'll need to store the request count state for our users somewhere, as well as a process that periodically sweeps the state once per minute. A naive first-pass with a plain-old `GenServer` might look something like this:\n\n```elixir\ndefmodule RateLimiter do\n  use GenServer\n  require Logger\n\n  @max_per_minute 5\n  @sweep_after :timer.seconds(60)\n\n  ## Client\n\n  def start_link do\n    GenServer.start_link(__MODULE__, [], name: __MODULE__)\n  end\n\n  def log(uid) do\n    GenServer.call(__MODULE__, {:log, uid})\n  end\n\n  ## Server\n  def init(_) do\n    schedule_sweep()\n    {:ok, %{requests: %{}}}\n  end\n\n  def handle_info(:sweep, state) do\n    Logger.debug(\"Sweeping requests\")\n    schedule_sweep()\n    {:noreply, %{state | requests: %{}}}\n  end\n\n  def handle_call({:log, uid}, _from, state) do\n    case state.requests[uid] do\n      count when is_nil(count) or count < @max_per_minute ->\n        {:reply, :ok, put_in(state, [:requests, uid], (count || 0) + 1)}\n      count when count >= @max_per_minute ->\n        {:reply, {:error, :rate_limited}, state}\n    end\n  end\n\n  defp schedule_sweep do\n    Process.send_after(self(), :sweep, @sweep_after)\n  end\nend\n```\n\nFirst, we defined `start_link/0` which starts a `GenServer`, using our `RateLimiter` module as the callback module. We also named the server as our module so we can reference it later in our call to `log/1`. Next, we defined a `log/1` function which makes a synchronous call to the rate limiter server, asking it to log our user's request. We expect to receive either `:ok` back, to indicate our request can proceed, or `{:error, :rate_limited}`, to indicate the user has exceeded their allotted requests, and the request should not proceed.\n\nNext, in `init/1`, we called a `schedule_sweep/0` function which simply has the server send itself a message one per minute to clear out all request data. Then we defined a `handle_info/2` clause to pickup the `:sweep` event and clear out the request state. To complete our implementation, we defined a `handle_call/3` clause to track request state for the user and return an `:ok`, or `{:error, :rate_limited}` response for our caller in `log/2`.\n\nLet's try it out in iex:\n\n```elixir\niex> RateLimiter.start_link()\n{:ok, #PID<0.126.0>}\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n{:error, :rate_limited}\n\n13:55:44.803 [debug] Sweeping requests\niex(9)> RateLimiter.log(\"user1\")\n:ok\n```\n\nIt works! Once our \"user1\" exceeded 5 requests/minute, the server returned the expected error response. Then after we waited we observed the debug output of the state sweep, and we confirmed we were no longer rate limited. Looks great right? Unfortunately, there's some serious performance issues in our implementation. Let's see why.\n\nSince this feature is for rate limiting, *all user requests* must pass through this server. Since messages are processed in serial, this effectively limits our application to single-threaded performance, and creates a bottleneck on this single process.\n\n## ETS to the rescue\n\nFortunately for us, Erlangers solved these kinds of problems for us. We can refactor our rate limiter server to use a publicly accessible ETS table so clients can log their requests directly in ets, and our owning process can be responsible only for sweeping and cleaning up the table. This allows concurrent reads and writes against ETS without having to serialize calls through the single server. Let's make it happen:\n\n```elixir\ndefmodule RateLimiter do\n  use GenServer\n  require Logger\n\n  @max_per_minute 5\n  @sweep_after :timer.seconds(60)\n  @tab :rate_limiter_requests\n\n  ## Client\n\n  def start_link do\n    GenServer.start_link(__MODULE__, [], name: __MODULE__)\n  end\n\n  def log(uid) do\n    case :ets.update_counter(@tab, uid, {2, 1}, {uid, 0}) do\n      count when count > @max_per_minute -> {:error, :rate_limited}\n      _count -> :ok\n    end\n  end\n\n  ## Server\n  def init(_) do\n    :ets.new(@tab, [:set, :named_table, :public, read_concurrency: true,\n                                                 write_concurrency: true])\n    schedule_sweep()\n    {:ok, %{}}\n  end\n\n  def handle_info(:sweep, state) do\n    Logger.debug(\"Sweeping requests\")\n    :ets.delete_all_objects(@tab)\n    schedule_sweep()\n    {:noreply, state}\n  end\n\n  defp schedule_sweep do\n    Process.send_after(self(), :sweep, @sweep_after)\n  end\nend\n```\n\nFirst, we modified our `init/1` function to create an ETS table with the `:named_table` and `:public` options so that callers outside of our process can access it. We also used the `read_concurrency` and `write_concurrency` options to optimize access. Next, we changed our `log/1` function to write the request count to `:ets` directly, rather than going through the `GenServer`. This allows requests to concurrently track their own rate-limit usage. Here we used the `update_counter/4` feature of ETS, which allows us to efficiently, and atomically, update a counter. After checking rate limit usage, we return the same value to the caller as before. Lastly, in our `:sweep` callback, we simply use `:ets.delete_all_objects/1` to wipe the table for the next rate limit interval.\n\nLet's try it out:\n\n```elixir\niex> RateLimiter.start_link\n{:ok, #PID<0.124.0>}\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n:ok\niex> RateLimiter.log(\"user1\")\n{:error, :rate_limited}\niex> :ets.tab2list(:rate_limiter_requests)\n[{\"user1\", 7}]\niex> RateLimiter.log(\"user2\")\n:ok\niex> :ets.tab2list(:rate_limiter_requests)\n[{\"user2\", 1}, {\"user1\", 7}]\n\n14:27:19.082 [debug] Sweeping requests\n\niex> :ets.tab2list(:rate_limiter_requests)\n[]\niex> RateLimiter.log(\"user1\")\n:ok\n```\n\nIt works just as before. We also used `:ets.tab2list/1` to spy on the data in the table. We can see our users requests are tracked properly, and the table is swept as expected.\n\nThat's all there to it. Our public interface remained unchanged and we vastly improve the performance of our mission-critical feature. Not bad!\n\n\n## Here Be Dragons\n\nThis just scratched the surface on what's possible with ETS. But before you get too carried away and extract out all your serialized state access from `GenServer`'s and `Agent`'s to ETS, you need to think carefully about which actions in your application are atomic, and which require serialized access. You can easily introduce race conditions by allowing concurrent reads and writes in the pursuit of performance. One of the beautiful things about Elixir's process model is the serial processing of messages. It lets us avoid race conditions exactly because we can serialize access to state that requires atomic operations. In the case of our rate limiter, each user wrote to ets with the atomic `update_counter` operation so concurrent writes are not a problem. Use the following rules to determine if you can move from serial access to ETS:\n\n1. The operations must be atomic. If clients are reading data from ets in one operation, then writing to ETS based on the result, you have a race condition and the fix is serial access in a server\n\n2. If the operations are not atomic, ensure different processes write to distinct keys. For example, Elixir's registry uses the Pid as key and allows only the current process to change its own entry. This guarantees there are no races as each process work on a different row of the ETS table\n\n3. If none of the above apply, consider keeping the operation serial. Concurrent reads with serial writes is a common ETS pattern\n\n\nIf you're curious about using ETS for a dependency-free in-memory cache, check out Saša Jurić's excellent [ConCache](https://github.com/sasa1977/con_cache) library.\n"},{"title":"Experience Economy, user interviews, and design discovery","tags":["design","design process","best practices","business","design thinking"],"summary":"The principle of customer sacrifice illustrates how a discovery process can reveal new opportunities.","legacy":false,"id":"2017/05/26/experience-economy-user-interviews-and-design-discovery","employee":"Maria Matveeva","date":"2017-05-26T00:00:00","body":"\n\nIn my reading and podcast-listening lately, I’ve found myself more and more interested in business rules and principles. Part of the reason I’m doing all this reading is, I’m just curious about how things work. But I also noticed that the better I understand how a business operates, the more I can use design strategically to solve the right problems *at the right time*.\n\n## The principle of customer sacrifice\n\nIn *The Experience Economy*, B. Joseph Pine II and James H. Gilmore  talk about the principle of [Customer Sacrifice](https://books.google.com/books?hl=en&lr=&id=edtOyzyKgXUC&oi=fnd&pg=PR7&dq=the+experience+economy&ots=2lsBAIOqsQ&sig=2d_tgqGxXrZ9TjgH3pF6Kc5hx-w#v=onepage&q=customer%20sacrifice&f=false). This sacrifice happens when a customer settles for something they know is available, rather than what they’d truly want, if only they could have it. The book explains that even a business attentive to its customers will often miss the customer sacrifice. We often measure how well a business is doing for its customers by conducting customer surveys. These questionnaires are great at measuring satisfaction levels: the difference between what a customer expected, and what they think they’ve received. \n\n### Are you limiting the upside of customer UX?\n\nBut customer satisfaction is only a good retroactive measurement: how did we do, compared to how well our customers thought we might do? Satisfaction pre-supposes that the best a business could possibly do is within the bounds of what the customer already expected. This approach is limiting because it caps potential improvements at what the customers already knew they wanted. And, perhaps more importantly, satisfaction does not measure what the customer might have preferred but assumed they couldn’t have. \n\n*The Experience Economy* uses [soft drink preference](https://books.google.com/books?hl=en&lr=&id=edtOyzyKgXUC&oi=fnd&pg=PR7&dq=the+experience+economy&ots=2lsBAIOqsQ&sig=2d_tgqGxXrZ9TjgH3pF6Kc5hx-w#v=onepage&q=pepsi&f=false) to illustrate this second type of missed opportunity. On most airlines, if asked for a Pepsi, the attendant will offer a Coke instead. After a few flights, the customer would realize Pepsi is not an option and start asking for a Coke instead. If the airline were to measure customer satisfaction at this point, it would look like the customer received exactly what they wanted, and there’s no room for improvement. The airline would miss an existing opportunity to improve customer experience by providing a preferred drink.\n\n\n## Understand customer sacrifice through user interviews during design discovery\n\nCustomer sacrifice is one of the reasons unbiased, open-ended user interviews are so important. We normally conduct several of these as part of a [design discovery](https://dockyard.com/services/design). When you apply design thinking, and [ask good questions](https://dockyard.com/blog/2015/03/11/ask-good-questions) you’ll get a broad set of insights from users. The interview style I always recommend, and practice myself, includes open-ended questions and touches on the experience around the product, not just the product itself. Doing this work takes time, but the quality and depth of insight is well worth the investment.\n\nMy favorite, most rewarding moments when leading a design project are when discovery wraps up, and I can confidently propose a way forward based on what we’ve learned. It usually goes something like this: here’s the problem you hired us to solve. But actually, your customers are experiencing a slightly different problem. And here’s how you can be even more successful in the future by solving *that*.\n\nAs a designer, it’s a humbling experience to be able to jump into a business problem, rapidly learn its key aspects from the folks who are infinitely more experienced in their field than I am, then talk to their users and other stakeholders… and come back with something new or surprising. How can we do this? Part of what helps us find these new things is a [beginner’s mentality](https://dockyard.com/blog/2015/03/23/beginner-mentality). (I call it: *we’re not afraid to ask the “stupid” questions!*) Another part is - applying the right process to a business problem at the right time will yield results. Design can still have a limited interpretation as “decorative stuff”, but more and more businesses are [realizing design’s strategic role in tech](https://designintechreport.wordpress.com).\n\nReading more business books, in a funny way, makes me more optimistic for the future of design. I’m making connections and realizing that the business world has terms for the stuff I’ve sometimes been doing intuitively, because it feels right and gives results. \n\nIf your company could benefit from a strategic design engagement, [contact us](https://dockyard.com/contact/hire-us). \n"},{"title":"Building a Shared Language","tags":["design"],"summary":"A process to help understand clients and the industry you’re designing for","legacy":false,"id":"2017/05/30/building-a-shared-language","employee":"Tim Walsh","date":"2017-05-30T00:00:00","body":"\n\nWhen we start a project at [DockYard](http://dockyard.com), we rely on a process that we refer to as ‘Discovery.’ This exploratory period occurs at the start of an engagement and helps to uncover the parameters of a project. We treat discovery as an opportunity to identify stakeholders, business goals, project requirements, user types, communication expectations, etc.\n\nDuring a discovery we select techniques to help distill out problems. These problems then inform decisions for building a product. Over time this process has gotten more efficient but I wouldn't say it's gotten easier. Strictly because every project drums up a different set of problems, each unique to the design and the industry we're designing for.\n\nRecently, our design team read [_Practical Design Discovery_](https://abookapart.com/products/practical-design-discovery), a great resource, chock-full of strategies and techniques for running a valuable discovery. One section that I found interesting talked about \"building a shared language.\"\n\nA crucial component of discovery is understanding - understanding the people, the users, & the problems. For this, we rely on language. However, as with any new project comes a glossary of new terms often referenced while explaining a project's goals. If it's an unfamiliar industry, this can be confounding, almost like being in a country that is foreign to you.\n\nThe most recent discovery I was a part of was for a project in an industry very foreign to me.\n\nBefore discovery had started, we prepared by reading a few materials including project goals, user descriptions, and desired functionality. It was quickly apparent to me that there was quite a few terms that I was unfamiliar with. I immediately thought of \"building a shared language.\"\n\nTo help us get acquainted with the industry, I scoured the documents pulling out each unfamiliar term. I then dropped those terms into a document with space to the right of each item. During discovery we printed out the document handing it over to the stakeholders of the project. We asked them to independently define each term and its association to the project at hand, an activity that took maybe 20-30 minutes.\n\nThe results were insightful. These definitions helped outline expectations for delivery. It shed light on alignment between stakeholders. It showed us that these terms could mean something different for each person, or that a discussion needs to happen to help bring people onto the same page. Not only was this revealing, it will also serve as reference material when we move deeper into the project. We can feel confident about decisions around functionality, because together we have agreed on the meaning.\n\nDiscovery is really about understanding and it always helps to be able to speak the same language.  \n\nThink your company can benefit from a design discovery or other UX support? [Contact us.](https://dockyard.com/contact/hire-us)\n"},{"title":"Do you need your design quiet, or loud?","tags":["design","business"],"summary":"When evaluating design teams, some work stands out immediately. That’s not always the type of work you need done.","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/hus04WV.jpg","id":"2017/06/06/loud-vs-quiet-design","employee":"Maria Matveeva","date":"2017-06-06T00:00:00","body":"\n\nDesigners are pretty specific about what kind of notebook to use - and I’m no exception. There are a few I consistently like, and find practical. There are (many) others, that I find unusable. If a bookshop only has wrapped notebooks to pick from, I don’t buy one, or go with a known trusted brand, because I don’t want to be left  with a pretty but useless thing. \n\n![Imgur](https://i.imgur.com/hus04WV.jpg)\n\nThe single most important quality I look for in a notebook is contrast. For example, this notebook is a beautiful object - wrapped in cloth, and well-constructed. But because I couldn’t open it to check the pages, I didn’t even consider buying it as a notebook. A beautiful souvenir - yes, maybe. But never as a tool to get things done. I’m afraid it’s too high-contrast inside to offset the red edged pages. \n\n![Imgur](https://i.imgur.com/Fj30xzS.jpg)\n\n## The quiet design of my favorite notebooks\n\nFor me, a high-contrast notebook is useless. My personal favorites are the Moleskine notebooks with slightly toned paper (not-too-bright white) and Muji sketchbooks with a light warm grey tint on the pages, because the paper has not been bleached. The biggest thing both brands get right every time, is that the “plumbing” in them – gridlines, dates in a planner, or page margins - are never too dark. They never compete with the things I write in the notebook, even if I use a pencil.\n\nThe way these notebooks work for me is – **they get out of the way** and let me do the important thing: to write and to sketch. They’re not attracting attention to themselves. The Muji brand itself is built around “modesty and plainness” on purpose, because this way it can unobtrusively belong to many people’s lives. (That’s probably why designers love it!)\n\n![Imgur](https://i.imgur.com/d41XMzf.jpg)\n\nBecause of a “quiet” approach to design, the notebook is a great tool. It allows me as a user to focus on the task at hand. It’s flexible: I can complete several types of tasks (drawing, sketching, paper-airplane-making) using the same notebook. \n\n## Quiet design is best for products\n\nJust like a notebook is a tool – most web interfaces these days are a tool for people who need to get something done. And like the practical notebooks, online tools shouldn’t attract attention to themselves. They should let us get things done, and get on with our lives. \n\n### So, should everything be light-grey?\n\nOf course, not all interfaces need to be low-key: we can take the opportunity to delight our users with an immersive, high-contrast interface or accent graphic when appropriate. And we certainly can, and should, use high contrast to attract attention to safety hazards. (“Delete all my files” should never be allowed to exist as a tastefully subtle button.) But the vast majority of web interface use cases don’t involve high levels of danger, or need to fully immerse the user. They simply need to get the job done and get out of the way.\n\nQuiet (calm) interfaces in visual, sound, or touch form are the subject of an insightful book by [Amber Case](http://caseorganic.com): *[Calm Technology](https://books.google.com/books/about/Calm_Technology.html?id=Mp88CwAAQBAJ&printsec=frontcover&source=kp_read_button#v=onepage&q&f=false)*. I read it last year, and will recommend it to anyone making large-scale decisions about UX design systems. Amber emphasizes that most technology use cases should be accomplished with the [minimum amount of attention](https://www.calmtech.com/) necessary to do the job, and even work on the periphery of our attention, rather than trying to be at the center of it. \n\n![Imgur](https://i.imgur.com/Rboh4pD.jpg)\n\n## Problem is, quiet design can be too quiet for its own good.\n\nThere is one problem with quiet design that I’ve encountered as I show off the work our team at [DockYard](http://dockyard.com) does. It can be a bit too quiet for its own good, especially when compared to other kinds of “louder” design.\n\nHow do you evaluate, or even show off something that’s meant to be functional and practical? If you’re comparing portfolios of work to select a design partner – the pieces that immediately attract attention are naturally the louder ones. Designers who focus on storytelling through campaigns, or attractive splash screens, or even user experiences that are meant to be short and attention-grabbing will naturally produce work that attracts attention _first_ as a portfolio piece. In this situation, it can be difficult to find and evaluate a great design partner for product work. \n\n## To evaluate quiet product design, dig deeper.\n\nThere are ways to evaluate quiet design: they are just below the surface. Here are a few. \n\n**1: Look for telling details** \nDesign is in the details, and they can make or break the user experience. Get some inspiration on [Little Big Details](http://littlebigdetails.com/) blog, and then looks for these inspiring bits in a design case study. While the most interesting and shareable details will be “Easter eggs” and not mission-critical features, their presence indicates a high level of care.\n\n**2: Dig into use cases**\nA visually quiet design system conceals a lot of depth “under the hood”. For a system to work well, it needs to accommodate different use cases, often with sub-optimal data. You’re likely to see the best default images on a case study or portfolio, but ask (or test a live example) to find out what happens when data is missing, or user behavior is non-standard. A well-built resilient system will continue looking and working well, even under such tests.\n\n**3: How does the UI look with data?**\nRelated to the use cases example above – if real data added to the system by humans (not design placeholder examples) breaks something, the problem is not with the data. It’s likely that the system is either not resilient enough, or the workflow rules were not set up for it to succeed in the long-term. \n\n**4: Do the content pages look and work OK?**\nWe often judge a website or app by its landing page, but in reality, most of the useful stuff happens elsewhere. A compelling landing page will help you acquire users, but only a solid experience throughout the app will let you keep them long-term. The design of a sign-up form, or a content submission dialog can be more important in the long-term. Look for these examples when hiring for strategic product design.\n\n**5: How well does the system age?**\nWhile content, upkeep, and business decisions after a project completes aren’t in the designer’s control, a good strategic product designer will do their best to set you up for success. If a system breaks down with even small changes once it’s been handed off, it’s not a great investment. \n\nIt’s not easy to judge what will happen in the future without experiencing it, but there are a few indicators of a solid product design result. Forward-thinking designers will not only solve your immediate UI problems, but help you with future ones by offering a **style guide**. The files they hand over will document all necessary states, as well as constraints and some history of **decision-making** that led to a solution. Often, a big part of the value a product designer delivers is advising ***not* to implement a feature**. \n\nKnowing when you need the quiet kind of design, and when you need it loud, is about knowing your business. Often, you need both at the same time to solve for user acquisition, but also to keep them coming back. Make sure you pick the right kind of designer for the job each time [👋](http://dockyard.com/contact/hire-us).\n"},{"title":"Can you see your invisible problems?","tags":["design","design process","best practices","business","design thinking","user experience","ux design"],"summary":"A UX audit can reveal big problems and simple fixes much faster than an insider ever could. Here it is, explained with paper towels.","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/6g1bRM8.jpg","id":"2017/06/13/can-you-see-you-invisible-problems","employee":"Maria Matveeva","date":"2017-06-13T00:00:00","body":"\n\n Earlier this spring, I was at a hotel in New York City and (as I often do) noticed a funny UX detail in the washroom. \n \n![Imgur](https://i.imgur.com/6g1bRM8.jpg)\n \nThe sign by itself looks correct. Sure, it could use an update for typography and clarity, but it makes sense for a hotel sign. It reminds people to wash their hands, and place the paper towels in a wastebasket. \n \nExcept there aren’t any paper towels.\n \nIt looked like the hotel had recently switched to a greener approach throughout their maintenance systems, and added hand dryers, reduced-flow faucets, and improved insulation in the building. The paper towels were removed, but another part of the system – a sign that referred to them – stayed. \n \nAn outside visitor would likely notice this detail, but I suspect that the hotel staff had become accustomed to seeing the same sign, to the point that it’s now invisible to them. They’d notice if it were missing or askew, but not that it’s no longer accurate.\n \n## Some things are invisible from the inside\n \nAs a UX designer I was intrigued by this sign, because it represents an opportunity to improve a system, and this type of opportunity is only visible from the outside. \n \nSome people call it “sanity check”, others “getting feedback”. When the process of reviewing a user-facing system is formalized, we call it a UX audit.\n \nHere are a few things that make it a useful exercise.\n \n### There are different levels of stakeholders\n\nSometimes a UX glitch occurs because a detail has fallen in-between the responsibility areas of different stakeholders. Perhaps, here, one person was responsible for hanging signs, while someone else removed paper products and installed a hand dryer. A manager might be responsible for the look of the hotel overall, but they realistically wouldn’t have the time to check the details (every sentence on that sign). \n \n### Things become invisible\n\nThe fact that things become invisible when you’re used to them is normal. It does not speak to a low level of attention, or poor quality. It’s just human nature. \n \nThe best way to work with this invisibility is to get fresh eyes on all the parts of the systems you rely on regularly. \n \n### Adding features is fun. Removing them is not\n\nOur natural response to any problem is to add something to solve it. Get a better tool. Add a process (go shopping, eat ice cream…). But in some situations, it’s like trying to fix an overcrowded storage closet by adding another clever storage container system. At some point, you need to reduce instead of add.\n \nBut reducing isn’t always easy or enjoyable short-term. Users might complain when a familiar feature is no longer available. Back in 2014, [37 Signals](https://37signals.com/), a successful software company with several well-loved SAAS products, made a decision to kill all but one of them and become Basecamp. They definitely disappointed _some_ users short-term, when they announced several products will no longer be supported. But by putting all of their energy behind one, they ensured that Basecamp will be a success for years to come.\n \nAn outsider is more likely to notice when features or processes are redundant, and the system overall would benefit from removing them. Or, when a detail no longer works with a bigger change in the system, like that paper towel sign.\n \n### The fix may be a lot of work… or it might be simple!\n\nSometimes, we know a problem exists, but assume the fix would be too expensive and complex to do now. While an audit of any sort often reveals a large or expensive underlying problem - it can do the opposite as well. Experienced UX designers are good at spotting the small things that, when fixed, would result in a greater benefit compared to the effort.\n \n## The UX audit gets at the big picture, _and_ the details. \n \n ![Imgur](https://i.imgur.com/ghkA4rW.jpg)\n \nThis is what’s going on inside a UX designer’s head when they see anything, even a paper towel sign. We can’t help it – we think in systems, and map out the impact of even the smallest details. \n \nThe hotel did everything right, internally. But they could have prevented the outdated sign by bringing in an outsider to have a fresh look at their experience from time to time. Little details like this contribute to the overall perception of a business. Even small details that seem unimportant from the inside can impact a user’s experience to the point that trust is compromised. Sometimes a UX designer’s job is to make a case for why the little details make all the difference. The small details _can_ be the big problem a business didn’t know they had.\n \nThis is what we do at DockYard. We’d love to talk about how a UX audit or another strategic design engagement would serve your business needs. [Let’s talk.](https://dockyard.com/contact/hire-us)\n"},{"title":"Ember Best Practices: What are controllers good for?","tags":["engineering","ember","best practices"],"summary":"What are the responsibilities of Controllers? Should I still use Controllers? Let's find out!","legacy":false,"id":"2017/06/16/ember-best-practices-what-are-controllers-good-for","employee":"Marten Schilstra","date":"2017-06-16T00:00:00","body":"\n\nThere possibly is a lot of confusion around what Ember's Controllers are good for. I've seen some situations where Controllers have been avoided at all cost, where everything has been delegated to either the corresponding Route or to Components. I've also seen the flip side, where a Controller was used like a Component.\n\nWhat should you do and what shouldn't you do with them?\n\n## Don't not use controllers\nLet's get the controversy out of the door. Do use your Controllers, it's still there, not deprecated, and you can use it for great good. You just need to know what they can and can't do.\n\nFirst off, you need to know that a Route's Controller is a singleton and thus it will keep state between activations, like when a user leaves the Route and then re-enters it. Therefore, you can't keep any UI state on a Controller, for example a `isExpanded` variable for keeping track of expanded/collapsed state.\n\n### What can you do with a Controller?\nWell, the first thing you can do is add an `alias` Computed Property (CP) to give the `model` property a more descriptive name. If you return multiple Models using `RSVP.hash` from a Route's model hook I prefer using aliases instead of setting it up in the Route's `setupController` hook.\n\nNext to alias CP's, you can also have any other CP's, but only if those CP's derive its state from the Model. The same principle goes for actions: put all the actions that update the Model on the Controller, no need to use ember-route-action-helper for that. In fact, most of those actions end up becoming [ember-concurrency](http://ember-concurrency.com) tasks, because they tend to be of an async nature.  \n\nYou can let actions trigger transitions too, but only do that if you can't use a `link-to` component, for example transitioning after having submitted a form.\n\n Let's look at a simple (contrived) example:\n\n```javascript\nimport Controller from '@ember/controller';\nimport { computed, get } from '@ember/object';\nimport { alias } from '@ember/object/computed';\n\nexport default Controller.extend({\n  user: alias('model'),\n\n  fullName: computed('user.{firstName,lastName}', function() {\n    return `${get(this, 'user.firstName')} ${get(this, 'user.lastName')}`;\n  }),\n\n  actions: {\n    updateUserModel(userAttributes) {\n      let user = get(this, 'user');\n      setProperties(user, userAttributes);\n      return user.save()\n        .catch(() => user.rollbackAttributes())\n        .then(() => this.transitionToRoute('index'));\n    }\n  }\n});\n```\n\nHere you can see that I aliased the Model to give it a more useful name and then created a CP that derives from the user Model. Lastly, there is an action that updates the user Model, saves it, and then transitions to the `index` Route.\n\n### What about Query Parameters?\nGood question! You should treat Query Parameters like the state from your Model. So you can derive Computed Properties from it and update the Query Parameters using actions.\n\n### But I absolutely need UI state on my Controller\nI advise against it, but if you really need to have some state on the Controller that does not derive from the Model or a Query Parameter, and it's not intended to stick around between transitions, then you should use the Route's `setupController` or `resetController` hook to reset the state between transitions.\n\n## In conclusion\nUse Controllers as an extension of the model loaded from the Route. Derive state from the Model or Query Parameters using Computed Properties. Update the Model or Query Parameters using actions. Avoid putting any state on the Controller that doesn't derive from either the Model or Query Parameters. \n\nHave a more complex Ember issue? [Contact us](https://dockyard.com/contact/hire-us). \n"},{"title":"Job: UX & Visual Designer","tags":["job"],"summary":"DockYard is looking for a great designer to join our team.","legacy":false,"id":"2017/06/20/job-ux-and-visual-designer","employee":"Maria Matveeva","date":"2017-06-20T00:00:00","body":"\n\n# Job: UX & Visual Designer\n \nDockYard is looking for a great designer to join our team. \n \nThe ideal candidate is someone who:\n- Can demonstrate a strong user-centric approach to their work\n- Has been part of the user research process in the past\n- Has previous client services experience\n- Shows strength in typography, color, and information layout\n- Has experience and is comfortable working remotely\n \nWe’re looking for **mid-level designers and above**. \n\nWe value diversity and strongly encourage candidates from all backgrounds to apply. \n \n## More about the job\n \nWe’re a design-driven software consultancy. We make web applications, focusing on Progressive Web Apps. Our projects can last between 2-3 weeks and several months. Many of our client projects are “greenfield”, so you’ll have the opportunity to define the core concepts that will have impact throughout the application and be built upon as the product grows.\n \nOur designers work with the most innovative clients in the industry, and provide design leadership in collaboration with DockYard’s Engineering team. Designers don’t code their own HTML/CSS, but a familiarity with how the web is built is a big plus.\n \nThis is a position in Boston, MA – but we will consider remote for the right candidate. Some flexibility to travel is expected.\n \nBecause designers start projects and communicate directly with clients and the rest of the team each day, we value writing and communication skills. We help you develop these skills, and grow professionally in other ways: a conference/education budget, DockYard Friday projects, and internal training are all part of the deal.\n \n## Responsibilities\n- Work directly with clients\n- Gather project requirements from various stakeholders\n- Create visual assets to support product discovery: from rough sketches, to user flows, to wireframes\n- Create polished visual design layouts\n- Collaborate with HTML/CSS engineers to ensure quality and implementability\n \n## Apply!\n \nIf this working style interests you, we’d love to hear from you!  Individual applications only, please: we do not work with recruiters and aren’t looking to outsource work.\n \nTo apply, **email careers (at) dockyard.com** with the subject “UX & Visual Designer” and include:\n- your portfolio\n- your experience level or resume\n- why you’re interested in DockYard specifically\n- what you hope to do with your career in the next 3 years\n \nTalk soon!\n"},{"title":"Who’s responsible for what happens after design?","tags":["design","design process","best practices","business","design thinking"],"summary":"As a designer, I am responsible for the ethics of the products I  help build. But ethics aren’t always convenient to discuss.","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/kOOUY8H.jpg","id":"2017/06/20/whos-responsible-for-what-happens-after-design","employee":"Maria Matveeva","date":"2017-06-20T00:00:00","body":"\n\n![Imgur](https://i.imgur.com/kOOUY8H.jpg)\n_Original photo by [Julia Caesar](https://unsplash.com/photos/asct7UP3YDE)_\n \nDesigners are naturally positioned to think about the long-term impact of a product or tool. We focus on users and think of ethics and impact on the world outside of the immediate business problem.\n \nHowever, this long-term thinking isn’t typically part of the “package” of services we’re hired for. When companies neglect to consider long-term impact it can be for a number of reasons. Perhaps there's a separate ethics department, or the product thinking is on a different scale (quarter to quarter, year to year… rather than 10 years) than the long-term impact we want to look into for ethics reasons. Companies don’t usually ignore ethics intentionally. It’s just that implications are not always visible from the inside view.\n \n## How can a designer influence ethical decisions?\n \nWhat should designers do in the face of this discrepancy: we’re not hired specifically to advise on ethics - but as design gets more strategic, we really _should_. \n \nMy instinct in these situations has been to ask questions. In any client interaction, but usually during a discovery to define what the product should be, I ask (rather than tell) for the stakeholders’ opinion of the different long-term questions. This can lead to a broader discussion, and help me tie ethical questions to business strategy. \n \n**Example 1:** if I feel the audience for a product is not diverse, and it should be — I can ask how the client feels about target audience, and addressable market. Then, look for opportunity to overlap bigger addressable market through inclusion - rather than preaching inclusion before it’s become an institutional value. \n \n**Example 2:** if I feel long-term impact of a mechanism of user interaction or user selection can be to discriminate, or to harm users, I would ask about the company’s philosophy on how to treat users long-term, as well as risk/liability management. If the potential for abusive practices within the tool we’re building does not quite get solved within the “treat users nicely just because” category, I could steer the conversation toward the risk/liability direction and explain the long-term risks. \n \nIt is a designer’s job to think about what happens after the design job is done, and the product or tool we made is running efficiently. Is it harming anyone? Is it serving the folks who need it most? \n \nAnd it’s not enough to be only thinking and caring. Our responsibility is to bring this information to everyone involved in the project, _in the way that they’d care to listen_. If ethical questions feel too philosophical or removed from a business perspective, we must do our best to connect them to business impact, reputation, long-term success, and other things stakeholders already care about. And just like with user interviews - asking the right questions will make all the difference.\n \nCould your business benefit from working with designers who ask the hard, future-focused questions? [Work with us!](https://dockyard.com/contact/hire-us)\n"},{"title":"Accelerated Mobile Pages (AMP): What are you willing to sacrifice for speed?","tags":["pwa","progressive web apps","business"],"summary":"A simple, Google backed, solution to slow loading mobile content is very enticing. But what will you have to give up to make this happen?","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/vP6xYKB.png","id":"2017/06/22/accelerated-mobile-pages-what-are-you-willing-to-sacrifice","employee":"Jess Krywosa","date":"2017-06-22T00:00:00","body":"\n\nThe speed of content delivery via mobile matters more every day. Competition extends beyond search engine results, to landing pages, and even deeper page engagement and conversions. Some would have you think speed is something that only an external force can fix. Facebook’s Instant Articles. Apple’s News format. Google’s AMP project. But what would you be willing to sacrifice to gain speed by implementing them?\n \n![Imgur](https://i.imgur.com/vP6xYKB.png)\n \n## The allure of AMP.\n \n[Accelerated Mobile Pages (AMP)](https://www.ampproject.org/) is an open-source project by Google, whose stated purpose was to enable fast loading mobile pages. This is important to site owners—especially those who rely heavily on revenue generated from onsite advertising (publishers, news outlets) which can significantly slow mobile experiences. Many have speculated, however, that the unstated purpose of this project could be Google’s attempt to prevent ad revenue being driven away due to [the rise of adblockers](https://blog.kissmetrics.com/is-adblock-killing-conversions/). \n \nSome have also questioned the effect AMP may have on search engine results pages (SERPs). Will preferential treatment be given to pages that use Google’s format for these speedy mobile pages? [Google assures us](http://adage.com/article/digital/official-launch-date-google-amp-confirmed/302746/) that, while speed is a factor in SERPs, AMP will be treated like any other content. But, should two similar results compete in all other factors and the AMP is faster, it will, in fact, outrank the other. \n \n## What you’ll potentially have to part with.\n \nA simple, Google backed, solution to slow loading mobile content is very enticing. But what will you have to give up to make this happen through AMP implementation?\n \n* **Your autonomy.**\nBy adopting this trend, content owners will become dependent on Google’s solution for a problem they already can solve themselves. Support, requirements, and cost for the AMP project may change and you’ll have no choice but to comply. AMP’s longevity resides entirely in its adoption, and while current reports sound optimistic, we all know how quickly the web can change. Especially with the growth in support of self sustained, all-in-one solutions like [Progressive Web Applications](https://dockyard.com/blog/2017/05/03/five-business-problems-pwas-solve).\n \n* **Your code.**\nYou’ll need to use AMP HTML, AMP JS, and AMP Cache.\n \n* **Your design.**\nYou’ll need to keep your [CSS size under 50K](https://www.ampproject.org/docs/guides/responsive_amp), in some cases resort to [using iFrames](https://www.ampproject.org/docs/guides/iframes), and [cut out dynamic content](https://www.ampproject.org/learn/about-how/) not supported by the proprietary code. \n \n* **Your analytics.**\nYou’ll need to add AMP analytics in addition to any other analytic code you may be using on your non-AMP pages. Earlier this year, [issues were reported](http://marketingland.com/amp-bug-bad-google-analytics-208217) in tracking unique visits, sessions, bounce rate, and other metrics. [Until recently](http://marketingland.com/amp-bug-bad-google-analytics-208217), the complete user journey from AMP to non-AMP pages was also a mystery, causing incomplete information for site owners. \n \n## Step back: what is causing the underlying problem?\nAt first glance, AMP seems like the way forward in an environment full of competitors, content, and weighted down sites. But what if instead of creating a new language that assumes certain mobile first standards, we build our sites to perform better on mobile to begin with? \n \nProgressive Web Apps (PWAs) not only solve the issue of poor mobile performance, but they also use language we’re already familiar with, allow for the creation of beautiful user experiences, and maintain the separate, yet interconnectedness the web was built on. PWAs condense our growing site sizes, use less data, provide speeds rivaling—if not equal to—AMP, and are [supported across browsers](https://jakearchibald.github.io/isserviceworkerready/). All this plus push notifications, add to homescreen, and offline mode. \n \nSo, the answer to increased performance on mobile may not be a new, separate, and owned format for it, but perhaps one update that solves the problem across **_all_** platforms. If you’d like to learn more, [we’d love to chat](https://dockyard.com/contact/hire-us).\n"},{"title":"Safari, iOS, and Progressive Web Apps: What You Should Know","tags":["pwa","business"],"summary":"Interested in a Progressive Web App but unsure about implementing one without Safari/iOS support? Here’s what you should know before making a decision.","legacy":false,"id":"2017/07/13/safari-ios-and-progressive-web-apps","employee":"Jess Krywosa","date":"2017-07-13T00:00:00","body":"\n\nProgressive Web Apps (PWAs) are gaining in popularity due to their ability to send push notifications, add to homescreen prompts, and provide offline content, with one build for all devices. Since PWAs focus on the browser and are device agnostic, they allow for seamless adoption by all users, while cutting costs and maintenance for businesses. Outcomes for implementors like MakeMyTrip.com include [triple the conversion rates, 38% improvement in page load times, and 160% increase in sessions](https://developers.google.com/web/showcase/2017/make-my-trip). \n\nA lot of the functionality that PWAs provide is due to the addition of [service workers](https://developers.google.com/web/fundamentals/getting-started/primers/service-workers). Currently, Chrome, Opera, Firefox, Samsung internet, and Edge [all support or plan to support, service workers](https://jakearchibald.github.io/isserviceworkerready/). But many still feel unsure about adopting PWAs due to the lack of full-throated support for service workers—and PWAs–from Apple. \n\nInterested in transitioning to a Progressive Web App but unsure about implementing one without Safari/iOS support? Here’s what you should know before making a decision. \n\n## What about PWAs doesn’t Safari/iOS readily support?\n\nAs of today, Safari/iOS does not support service workers or web app manifests. Without these, many forward thinking components of PWAs will not work as intended including push notifications, homescreen installation, and offline mode. \n\n## Are there any browsers that support PWAs on Apple mobile devices? \n\nSadly, no. Browsers like Chrome that do readily support all aspects of PWAs are really only [re-skinned versions of Safari](https://www.digitalcommerce360.com/2017/05/02/apples-dirty-little-secret-about-chrome/) on iOS devices.\n\n## So, if my primary mobile audience is Apple users, why would I implement a PWA?\n\nEven without this support, PWAs still work, just not as they were originally envisioned and require workarounds. You can still manually add homescreen installation, for instance, using ember-web-app. And, while you can implement OS X push notifications from your web site using [Apple’s developer guides](https://developer.apple.com/library/content/documentation/NetworkingInternet/Conceptual/NotificationProgrammingGuideForWebsites/Introduction/Introduction.html), this does not solve the issue for iOS. One inelegant solution is to wrap the PWA in a native app to gain initial approval for notifications. Offline content is a harder issue to solve, though the other enhancements can be combatted while we anxiously await iOS support. \n\n[Documented early adopter outcomes](https://developers.google.com/web/showcase/2017/) actually show that not only do PWAs work across all browsers, but they actually convert higher than non-PWA sites. Since Progressive Web Apps were built to be lighter they automatically perform better via mobile even without the added enhancements. Lancome recently opted to upgrade to a PWA instead of developing a native app to be able to both serve current customers and reach new users. Even without iOS support [they still saw iOS sessions increase by 53% and overall conversions increase by 17%](https://developers.google.com/web/showcase/2017/lancome). \n\n## Will Apple adopt?\n\nIndications look positive. Webkit shows that both [service workers](https://webkit.org/status/#specification-service-workers) and [web app manifests](https://webkit.org/status/#specification-web-app-manifest) are ‘under consideration’, with the former given specific mention in the [five year plan](https://webkit.org/status/#specification-web-app-manifest). Speculation is that Apple could be slow to adopt due to their current reliance on apps and the App Store. Why promote technology that may eat into that owned pipeline? With Samsung, Google, and Microsoft currently running with this functionality, Apple may be hedging their bets. And with PWAs meaning an easier, single point of contact with consumers, will apps soon be a thing of the past? \n\nCurious about what it would take for your company to upgrade to a Progressive Web App? [Let’s talk](https://dockyard.com/contact/hire-us).\n"},{"title":"Ember Best Practices: Reducing CRUD complexity with components","tags":["ember","best practices","engineering"],"summary":"Reduce your Ember CRUD code with form components","legacy":false,"id":"2017/07/18/ember-best-practices-form-components","employee":"Nico Mihalich","date":"2017-07-18T00:00:00","body":"\n\nA fair amount of web applications can be boiled down to simple CRUD (Create, Read, Update, Delete).  Thankfully Ember/Ember Data/JSON API make doing this pretty trivial.  Let's fake out a little example of the create template for our fancy new *MyWidgets™* application.\n\n```handlebars\n<form>\n  <label for=\"widget-name\">Name</label>\n  {{one-way-input model.name id=\"widget-name\" update=(action (mut model.name))}}\n\n  {{one-way-checkbox model.isFancy id=\"widget-is-fancy\" update=(action (mut model.isFancy)}}\n  <label for=\"widget-is-fancy\">Fancy?</label>\n\n  <button type=\"submit\" {{action \"save\"}}>\n    Create Widget\n  </button>\n</form>\n```\n\nGreat! We have inputs for name, if it's fancy or not, and a save button.\n\n\nNow let's build a template for editing an existing widget.\n\n```handlebars\n<form>\n  <label for=\"widget-name\">Name</label>\n  {{one-way-input model.name id=\"widget-name\" update=(action (mut model.name))}}\n\n  {{one-way-checkbox model.isFancy id=\"widget-is-fancy\" update=(action (mut model.isFancy)}}\n  <label for=\"widget-is-fancy\">Fancy?</label>\n\n  <button type=\"submit\" {{action \"save\"}}>\n    Update Widget\n  </button>\n</form>\n```\n\n### Changing requirements\n\nAs we're doing this we might realize we forgot to add the description field for our widget. No problem. We just have to add it back to both forms.\n\n... wait a minute both are basically the same and we're making the same edits! Maybe we realized this and copy/pasted; but even that should have set off a red flag.\n\n## Let's make it better\n\nLet's move that template into a component, with one small change.\n\n```handlebars\n<form>\n  <label for=\"widget-name\">Name</label>\n  {{one-way-input model.name id=\"widget-name\" update=(action (mut model.name))}}\n\n  {{one-way-checkbox model.isFancy id=\"widget-is-fancy\" update=(action (mut model.isFancy)}}\n  <label for=\"widget-is-fancy\">Fancy?</label>\n\n  {{yield}}\n</form>\n```\n\nSince our save buttons are different, we can yield the area where the buttons are and add our different buttons in the create and edit templates. Now our create form looks like this:\n\n```handlebars\n{{#widget-form model=model}}\n  <button type=\"submit\" {{action \"save\"}}>\n    Create Widget\n  </button>\n{{/widget-form}}\n```\n\nAnd edit like this:\n\n```handlebars\n{{#widget-form model=model}}\n  <button type=\"submit\" {{action \"save\"}}>\n    Update Widget\n  </button>\n{{/widget-form}}\n```\n\nThis is good, but we can do better with some Ember Data properties.\n\n## Let's make it even better\n\nSince the model hook from our new route is returning a new widget, and the edit is returning an existing one, we can leverage some built-in Ember Data functionality to clean our forms up more: [isNew](https://www.emberjs.com/api/data/classes/DS.Model.html#property_isNew)\n\n```handlebars\n<form>\n  <label for=\"widget-name\">Name</label>\n  {{one-way-input model.name id=\"widget-name\" update=(action (mut model.name))}}\n\n  {{one-way-checkbox model.isFancy id=\"widget-is-fancy\" update=(action (mut model.isFancy)}}\n  <label for=\"widget-is-fancy\">Fancy?</label>\n\n  <button type=\"submit\" {{action \"save\"}}>\n    {{#if model.isNew}}\n      Create Widget\n    {{else}}\n      Update Widget\n    {{/if}}\n  </button>\n</form>\n```\n\n```handlebars\n{{widget-form model=model save=(action \"save\")}}\n```\n\nAnd edit like this:\n\n```handlebars\n{{widget-form model=model save=(action \"save\")}}\n```\n\n(They're still identical but much more DRY, and you can imagine some different CSS/HTML wrapping them in your create/edit pages. Also now you can drop a form wherever you need it!)\n\n## Takeaways\n\nThis is a fairly simple example, but thinking about where and how your application manipulates your models, and using components to encapsulate functionality, can save you from making double edits, or forgetting to make changes in one place and not another and introducing a bug. Your forms might have more complicated actions for save, or different inputs and layouts, but you will save time by [taking the time to do things right](https://xkcd.com/1691/).\n\nNeed more complex Ember support? [Here's how to get in touch](https://dockyard.com/contact/hire-us). \n"},{"title":"How to build a Progressive Web App with Ember","tags":["ember","pwa"],"summary":"This tutorial will go through the basics of making your Ember app home screen installable and available offline.","legacy":false,"id":"2017/07/20/how-to-build-a-pwa-with-ember","employee":"Marten Schilstra","date":"2017-07-20T00:00:00","body":"\n\nTo make any app a Progressive Web App (PWA) you need it to do two things: you need to make it installable to the home screen and make the app available offline in some degree using a Service Worker.\n\nIt's not too hard nowadays to transform an Ember app into a basic PWA.  In true Ember fashion there are addons for both things needed to make it a PWA. For basic PWA functionality you only need to install a few addons and configure them.\n\n## Making the app installable\nStart with installing the [ember-web-app](https://github.com/san650/ember-web-app) addon: `ember install ember-web-app`. Then update the generated `config/manifest.js` file with your app's details.\n\nThe ember-web-app addon will use your configuration `manifest.js` to generate a web app manifest and add it to your build. If you now build and deploy your app, then visit it in a browser that supports web app manifest, you can install it to the home screen of that device. It also supports generating meta tags for Safari home screen installs out of the box.\n\n## Making the app available offline\nTo add a Service Worker for offline capability start with [ember-service-worker](http://github.com/dockyard/ember-service-worker). This addon will take care of building and installing a Service Worker script along with your Ember app. \n\nNext you will need a few of ember-service-worker's plugin addons to add actual functionality. The first one is [ember-service-worker-index](http://github.com/dockyard/ember-service-worker-index), which will take care of making your `index.html` available offline. For most apps this plugin should work out of the box. If it doesn't, you can configure the plugin in your `ember-cli-build.js` file, using the options documented in the plugin's readme.\n\nThe second plugin you will need is [ember-service-worker-asset-cache](http://github.com/dockyard/ember-service-worker-asset-cache), to make the files in the `assets` folder of your build available offline. Again, by default, you do not need to configure anything: this addon will take care of making your assets available offline. However, if you have a lot of assets you might want to exclude some of the non-essential assets, as this plugin will aggressively try to cache a copy of the asset files when the Service Worker is installed. Use the readme of the plugin to see how you can exclude some files.\n\nIf you did exclude some assets there is a third plugin you might want to install: [ember-service-worker-cache-first](http://github.com/dockyard/ember-service-worker-cache-first). This plugin will lazily make the configured assets available offline when they are requested. This plugin does not work out of the box, so you will have to configure it to your app's specifics in `ember-cli-build.js`.\n\nTo put it all together, here's an example `ember-cli-build.js` file to give you an idea how you can configure your app:\n\n```javascript\nconst EmberApp = require('ember-cli/lib/broccoli/ember-app');\n\nmodule.exports = function(defaults) {\n  let app = new EmberApp(defaults, {\n    'asset-cache': {\n      exclude: [\n        'assets/images/**/*',\n        'assets/fonts/**/*'\n      ]\n    },\n    'esw-cache-first': {\n      patterns: [\n        '/assets/images/(.+)',\n        '/assets/fonts/(.+)'\n      ]\n    },\n  });\n};\n```\n\n## Conclusion\nThere you have it. If you followed along with this guide your app should now be installable on the home screen and running a Service Worker that will take care of making your app's assets available offline. Ideas for next steps are making your app's data available offline using LocalStorage and/or IndexedDB, or sending push notifications to your users using the Service Worker's push notification API.\n\nIf you need more help, [we'd be happy to do the heavy lifting](https://dockyard.com/contact/hire-us). \n"},{"title":"Job: Project Manager","tags":["job","business","project management"],"summary":"DockYard is seeking a Project Manager to join our growing national team!","legacy":false,"id":"2017/07/26/job-project-manager","employee":"Jon Lacks","date":"2017-07-26T00:00:00","body":"\n\n[DockYard](https://dockyard.com/) is seeking a Project Manager to join our growing national team!  \n\nWant to work with some of the most highly respected engineers/designers in the industry?\nTired of the regular PM grind where organizational complexity stifles team productivity and morale? \nWant to work on projects where people come before tools?\nDo you know what it means to be a Servant Leader?\nWant to work with some of the most respected global brands?  \n\nLooking for full health, vision & dental benefits plus a 401K plan? \nWould you like to attend one industry conference each year and regular company team-building activities? \nInterested in a very generous amount of PTO?\n\nThen read on!\n\n**RESPONSIBILITIES**\n\n- Facilitate definition of project scope, including the creation of living prioritized backlog of work, using visual planning techniques (e.g. storyboards)\n- Help team/client prepare for and successfully participate in Release Planning and Iteration (sprint) planning events\n- Help the Agile team prepare for and successfully conduct demos and retrospectives at the end of each iteration\n- Rigorously remove impediments for the team and aid in improving transparency \n- Perform risk management to mitigate project risks \n- Ensure resource availability and allocation\n- Manage/monitor the project budget, project estimates, and manage to the approved spend\n- Reveal/identify potential Biz Dev opportunities to management team\n- Report and escalate to management as needed\n\n**BASIC QUALIFICATIONS**\n\n- Minimum of 5 years of experience in Software Development environment as a PM and/or Engineer \n- Strong/proven team orientation \n- Proven experience/understanding of what it means to be a Servant Leader\n- Experience working in Scrum and/or other types of Agile environments\n- Solid technical background with understanding and/or hands-on experience with software development and web technologies\n- Ability to apply project management knowledge to real world scenarios (Pragmatic)\n- Strong written and oral communication skills\n- Ability to develop and maintain strong client relationships\n- Willingness to learn, grow and be flexible in small company environment\n- Experience managing projects involving remote teams\n\n**NICE TO HAVES**\n\n- Experience managing projects in Client Services (Consulting) context\n- Familiarity with GitHub\n\n[If this sounds like you, we’d love to connect](https://dockyard.com/contact/join-us). \n\n"},{"title":"How do you responsibly design a transformational experience?","tags":["design","design process","best practices","business"],"summary":"Design goes beyond a valuable business service. We have a hand in transforming people’s future. How can we deal with this responsibility?","legacy":false,"id":"2017/07/28/how-do-you-responsibly-design-transformational-business","employee":"Maria Matveeva","date":"2017-07-28T00:00:00","body":"\n \nDesign is firmly established as a valuable thing for business. As a designer, that’s something I know and teach. The [yearly Design in Tech report by John Maeda](https://designintechreport.wordpress.com/) is a welcome reminder. I share it with colleagues, and use Maeda’s concise way to word things just right, as well as his research, to support my arguments. \n \nLike in previous years, Maeda emphasized computational design as the type of design skill entrepreneurs need to hire for, in order to succeed. To me, computational design includes not just an awareness of how to code for the web, but also systems thinking, the ability to quickly understand states and use cases. It means taking responsibility not just for the beauty of an individual screen — but the ability to evaluate one interaction’s importance within a larger workflow for one or more users. (Though screens designed in isolation can often look glorious in a visual design portfolio, and gather likes on Dribbble.) In short, user experience design is what a business needs to succeed these days.\n \n## Effective UX design will have a transforming effect on users\n \nWhen you design something, and it works well, that’s powerful. Good designers take responsibility, and **[ask questions](https://dockyard.com/blog/2017/06/20/whos-responsible-for-what-happens-after-design)**, about how the products we make affect users long-term. But after reading \"The Experience Economy\", I realized that as designed experiences and businesses based on those experiences become more sophisticated, our responsibility for the outcome grows accordingly.\n \n> “The experiences we have affect who we are, what we can accomplish, and where we are going, and we will increasingly ask companies to stage experiences that change us.” [source](https://books.google.com/books?id=5hs-tyRrSXMC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false)\n \n## How we’re working with transforming experiences\n \nIn our current work with [CollegeVine](https://www.collegevine.com/), we’re privileged to be a part of creating just such a transformational experience for aspiring college students. All their services are aimed at helping students put their best selves forward, to become better while staying true to their unique identity. Whether it’s editing a college admissions essay, preparing a list of schools to apply to, or staying on top of many separate tasks that need to happen before sending in the applications—CollegeVine takes responsibility for making their clients a better version of themselves. \n \nBecause college admissions can determine the trajectory of a high schooler's life in probably the most significant way compared to other activities, this responsibility is something the company (or we as a design collaborator) can not take lightly. Designers can no longer only consider whether a business objective has been met. We must consider how an interface, within a larger workflow, within a product offering, and together with a company’s philosophy, ultimately affects a human’s life going many years into the future. \n \nThis stuff can be scary at times, but it also gives me confidence and makes me enthusiastic for the future. This transformational experience design collaboration has been an easy choice for me. Of course, this needs to exist. Doing market research before and during this project, I am finding more and more confirmation that CollegeVine’s near-peer mentoring approach truly works, and is better (and more responsible) than anything comparable on the market. I am confident that it does, and will continue to change many people’s lives for the better.\n \n## What to expect in the future\n \nAs transformational experiences increasingly become what customers want, and what businesses offer, consultants like DockYard will increasingly need to decide whether they agree with the goal and methods of a transformational experience before they take up the professional responsibility of a project. \n \nAny experience can turn transformational for our users, and many already are. The responsibility of creating these experiences can feel like a heavy weight to carry. But it doesn’t have to be. In the future, “do you agree that this should exist?” will become a standard question when interviewing all collaborators and vendors, not just prospective employees. And everyone, not just clients or employers, will ask some form of this question.\n \nAnd, when we work on something we believe in, people will be transformed by things we offer them, whether we consider this fact, or not. So if we take responsibility for the transformation we’re helping create, and think through long-term implications, we’ll have a hand in improving and de-risking future outcomes. When we’ve asked all the right questions and done due diligence for a designed system to serve its audience, we can rest assured that we’ve done it right. \n \nCurious about thoughtful, experienced design that supports your business in a transformation? [Let’s chat](https://dockyard.com/contact/hire-us). \n"},{"title":"Authorization Considerations For Phoenix Contexts","tags":["elixir","phoenix","authorization"],"summary":"Should authorization be handled in the Web layer or within the context? Let's find out which approach is better and when.","legacy":false,"id":"2017/08/01/authorization-for-phoenix-contexts","employee":"Chris McCord","date":"2017-08-01T00:00:00","body":"\n\nWith the recent [Phoenix 1.3 release](http://phoenixframework.org/blog/phoenix-1-3-0-released), Phoenix introduced *Contexts*, which are dedicated modules that expose and group related functionality. One frequent question that has come up is where to handle authorization for domain operations. Should authorization be handled in the Web layer at the controller, or within the context? Both are valid approaches, so let's find out which approach is better and when.\n\nThere are a few things to consider when determining where to handle authorization. Decoupling authorization from the contexts can allow you to apply different business rules on a case-by-case basis for underlying domain operations, but in some cases, enforcing a business rule in a single place, uniformly, is more desirable.\n\nLet's walk through a couple scenarios with code. Imagine the `CMS` system from the [phoenix context guide](https://hexdocs.pm/phoenix/contexts.html). In this system, we have `Accounts.User`'s and `CMS.Author`'s, and we chose to authorize CMS page updates in the controller before allowing `CMS.update_page/2` to be called:\n\n```elixir\n  plug :authorize_page when action in [:edit, :update, :delete]\n  ...\n  defp authorize_page(conn, _) do\n    page = CMS.get_page!(conn.params[\"id\"])\n\n    if conn.assigns.current_author.id == page.author_id do\n      assign(conn, :page, page)\n    else\n      conn\n      |> put_flash(:error, \"You can't modify that page\")\n      |> redirect(to: cms_page_path(conn, :index))\n      |> halt()\n    end\n  end\n```\n\nOur authorization here enforces the rule that only page owners are allowed to update their pages. Now, imagine we continue building our CMS, and we introduce a `Staff.PageController` where `%Staff.User{}`'s of our company can moderate published content. If we had enforced our authorization rules in `CMS.update_page/2`, we would not be able to expose another endpoint for staff members to moderate posts without either adding new functions to the CMS, or making the caller aware of the internal authorization details and have them pass the owner in themselves. We may also need to make the CMS staff-user aware, which adds more coupling. In cases where you have domain operations that you want carried out, but under different policy scenarios, decoupling authorization makes the most sense.\n\nHaving said that, now let's imagine a `Warehouse` context where we allow businesses to update their warehouse inventory. Imagine we have an HTML interface, a REST API, and long-running processes which consume CSV data from warehouses (common in the industry). Under this scenario, we have multiple different paths of user input, all being applied to the same domain action, like `Warehouse.increment_quantity`. This function must be an atomic, performant operation. For usecases such as processesing batched CSV data, we don't want to fetch the entire product only to authorize the organization against it for atomatically updating a single field. Instead, we would need only the `product_id` from user input, which we can authorize within the query itself as we pass through each CSV row. From a performance and code re-use perspective, pushing authorization logic into the Warehouse where only businesses that own a particular product record can update it makes sense. The code using Ecto would look something like this: \n\n```elixir\ndefmodule MyApp.Warehouse do\n\n  def increment_quantity(product_id, %Organization{} = org, amount) do\n    from(p in Product,\n      where: p.id == ^product_id and p.org_id == ^org.id),\n      [inc: [quantity: amount]], returning: [:quantity])\n    |> Repo.update_all()\n    |> case do\n      {1, [%Product{quantity: new_quantity}]} ->\n        {:ok, new_quantity)}\n      {0, []} -> {:error, :unauthorized}\n    end\n  end\nend\n```\n\nWe have the option of enforcing the rules at each HTML controller, API controller, and CSV task, but we would need to duplicate the logic and make sure it stays up-to-date with our business rules in each location. However, in some cases performance dictates that we must move the authorization into the query itself, making the context the only suitable place for authorizing the operation.\n\nFor code-reuse and maintainability when doing authorization outside of the context, we at DockYard like to expose plain old modules:\n\n```elixir\ndefmodule MyApp.Authorizer do\n\n  def authorize(:update, %CMS.Page{}, %Accounts.User{}) do\n    if page.user_id == user.id or page.organization_id == user.organization_id do\n      :ok \n    else\n      {:error, :unauthorized}\n    end\n  end\n\n  def authorize(:update, %CMS.Page{}, %Staff.User{}) do\n    :ok\n  end\nend\n```\n\nWhich we can then call in the controller:\n\n```elixir\ndefmodule CMS.PageController do\n  \n  def update(conn, %{\"id\" => id, \"page\" => page_params}, current_user) do\n    with page = CMS.get_page!(id),\n         :ok <- Authorizer.authorize(:update, page, current_user),\n         {:ok, page} <- CMS.update_page(page, page_params) do\n    \n      conn\n      |> put_flash(:info, \"Page Updated\")\n      |> redirect(to: cms_page_path(conn, :show, page)\n    end\n  end\nend\n\n```\n\n\nThis allows us to wrap up the business rules inside a module to be called from multiple code paths. It also keeps our contexts decoupled from business rules they don't need to care about, such as super user or staff users. You can read more about this approach in a [post by our own Nico Mihalich](https://dockyard.com/blog/2016/09/08/kiss-phoenix-auth)\n\nAs we can see, both options are completely valid, and in some cases one may make more sense over the other given your use case. Authorizing at the integration layer with your context gives you the most flexibility, but you need to take care to ensure business rules are applied at each integration point. Authorizing in the context allows you to apply business rules uniformely under all usecases, and at times is the only option when high throughput operations are required.\n"},{"title":"Part 1: Should you use Ember FastBoot or not?","tags":["ember"],"summary":"Ember FastBoot comes with trade-offs. Let's explore if your app is the right candidate for FastBoot.","legacy":false,"id":"2017/08/01/should-you-use-ember-fastboot-or-not-part-1","employee":"Brian Cardarella","date":"2017-08-01T00:00:00","body":"\n \n<a href=\"https://www.youtube.com/watch?v=OInJBwS8VDQ&t=41m10s\">DockYard.com was one of the world's first production FastBoot enabled applications</a>. We have had signifcant experience building FastBoot enabled websites for us and our clients. Over the course of that time I have developed \"opinions\" on when apps should use FastBoot and if the costs are too high to implement it.\n\nLet's start with agreeing on what FastBoot gets you: Server Side Rendering (SSR). The value of SSR to your company depends upon what your revenue model is. More likely than not this value is going to be tied to your SEO score. Ensuring that your app can be crawled by the most popular search engines is very important to many businesses. FastBoot will also help improve the <a href=\"https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint\">First Meaningful Paint</a> on your app. This has a direct impact upon Page Rank, Conversion Rate, Bounce Rate. In other words, the faster your content is available to your visitors improved the quality of their visit.\n\nHowever, it is not all gravy. There are significant costs to building and maintaining a FastBoot enabled Ember app and that's what I will discuss over this series of blog posts. Too often I am seeing developers struggle with building, maintaining, and deploying a properly built FastBoot Ember app. Do you even need FastBoot for your given context? Is the ROI the same as without SSR for your customers or can you get similar or better ROI by going the route of a Progressive Web App?\n\nThere are future benefits that FastBoot will eventually yield. For example, we can imagine a future where FastBoot can deliver specially built asset packages that are customized for the route your visitors access. If you visit just one section of a much larger content site why should you incur the cost of downloading bytes you don't need? However, this is not a reality as of today and is likely very far off in the future so we will not be taking features like this or other future features into consideration when weighing the cost/benefits. You are building an application today so we need to view the technology as of today and what comes with it.\n\nI feel compelled to add a notice here: this isn't intended to be an indictment of FastBoot. I respect the time, effort, the team, and engineering complexity that has gone into building this technology.\n\nTomorrow we will delve into the costs of FastBoot and weighing them against real-world uses cases."},{"title":"SVG Assets in PWAs","tags":["pwa","engineering"],"summary":"With a new exciting way to build web applications, we need to rethink our development process.","legacy":false,"id":"2017/08/01/SVG-assets-in-pwas","employee":"Cory Tanner","date":"2017-08-01T00:00:00","body":"\nProgressive Web Apps are a hot topic currently and chances are there will be a talk on them at most web conferences. With a new exciting way to build web applications, we need to rethink our development process. Let’s dive into managing SVG assets within PWAs!\n\n## Changing our old method\nFor a while now our go-to method for including SVGs in our apps has been the external\n\n```html\n<use xlink:href=\"foo.svg#bar\">\n```\n\nwhich you can read up on over at [css-tricks: SVG `use` with External Reference, Take 2](https://css-tricks.com/svg-use-with-external-reference-take-2/).\n\nThis worked great before HTTP2 when assets were pulled from the server one at a time. One optimized SVG file was pulled down from the server and individual SVGs would be linkable with IDs inside that one SVG file. This was before PWA’s cached your assets per page. With this method in a PWA you would be downloading one large SVG file for every page. Not very performant.\n\nNow, one pull request from the server can include multiple files with HTTP2. Having individual SVG assets now makes sense; you don’t need to pull down all your SVG assets at once. After your SVG assets are in the browser, they will be cached.\n\n## On to using SVGJar\nThe bird's eye view description of this method is that we include every SVG on our app inline. This is done with the plugin [Ember SVGJar](https://www.npmjs.com/package/ember-svg-jar).  This, in a sense, gives you an icon font set, but purely done with SVG.\n\nThere are some upfront advantages of having individual inline SVG files with SVGJar that should be outlined:\n\n* SVG assets used with CSS background property\n* SVG assets are included inline so you have full creative control over the SVG with CSS styling\n* Most performant way of including optimized SVGs on a page\n\nYou can read up on how the plugin works in detail, but we still organize our SVG assets in an asset folder that is linked to SVGJar. The plugin will then take those SVG assets and inject them into the page where you include the handlebar helper.\n\n```handlebars\n{{svg-jar \"asset-name\"}}\n```\n\nThe result is that the Ember app sees what SVGs are needed and, thanks to SVGJar, pulls the asset from the asset folder, injecting the SVG code directly into the HTML before it gets sent to the server and then browser.\n\nSimple and customizable inline SVGs make for a great environment for SVG creativity and gets out of the way of the PWA. What more could you ask for?\n\nWant to talk more about PWAs? [Drop us a line](https://dockyard.com/contact/hire-us).\n"},{"title":"Part 2: Should you use Ember FastBoot or not?","tags":["ember"],"summary":"In this part we'll look at the performance considerations for FastBoot and the ROI for your use-case.","legacy":false,"illustration_alt":"","illustration":"http://i.imgur.com/qcBJGBK.png","id":"2017/08/02/should-you-use-ember-fastboot-or-not-part-2","employee":"Brian Cardarella","date":"2017-08-02T00:00:00","body":"\n\n### TTFB\n\n<a href=\"https://en.wikipedia.org/wiki/Time_To_First_Byte\">Time To First Byte</a>. If you are unfamiliar with this term, it is simply how long does it take the server to start respondnig back with the first byte of the request. With certain advances in technology like HTTP/2 TTFB has become less of an issue because you can load all of your assets in parallel.  With HTTP/1.1 you had to wait for each asset to finish being received before requesting the next. As you can imagine, the longer it takes to even start receiving your asset, let alone the time it takes to get the entire asset, can really accumulate.\n\nTTFB becomes an issue for any FastBoot enabled web app because the `index.html` that it serves has all of the rules on what to download next. The browser cannot download in parallel assets it hasn't yet been instructed to fetch. So while the actual transfer time of the given `index.html` files from FastBoot may be trivial, especially when gzipped, the latency to start receiving the file can really add to the overall impression of your application's performance. Let's look into why this is, how much latency FastBoot adds, and some strategies around this.\n\n### Why is there any TTFB delay?\n\nKeep in mind what FastBoot is doing. When your browser requests the URL it will hit the FastBoot server. FastBoot then starts a new Ember app (more on this later), routes based upon the requested URL, may make one or more external requests via Ember Data to an API, renders the page, and returns it. This is a typical render cycle for any server-side application (with the exception of instantiating a new app) and shouldn't be looked at in any other way. We *must* incur this cost if we want to render the uniquely rendered page for the given URL.\n\nWhat is less understood at this point is what we probably shouldn't be incurring the cost of. And that falls back to the Ember app being instantiated on each request. In my opinion, the community is still very early in the process of learning how best to use and optimize Ember server-side. The big challenge was to get Ember working with SSR in a stable way. <a href=\"https://emberjs.com/blog/2017/07/19/ember-fastboot-1-0-release.html\">With FastBoot 1.0 recently being released</a> that has been accomplished. I'd like to see a focus on server-side rendering performance.\n\n### How much latency does FastBoot add?\n\nThe answer to this question is, as it is with most things in life, \"it depends\". There are different scenarios. For example, is this the first request to the URL? Is it the 10th request? Are you making external requests, if so how many? So to help inform this let's look at the most basic use case: a first time request (cold) to the app with a newly generated Ember app: **100ms** on my machine. The 2nd request reduces to roughly **60ms**. The 10th request bring it down to around the **10ms** mark.\n\nThese numbers are very far apart. Without getting into the source we can assume that Node or Express is making some run-time optimizations based upon code it is seeing more frequently. We don't have any caching set up and FastBoot is not written to boost performance on additional renders. FastBoot does do a one-time `initialize` of your app, so it is now in a state of pre-instantiation but has gotten some of the work out of the way. This is why pushing work out of `instance-initializers` to `initilaizers` is important if you don't need app state and want to avoid repeat cost.\n\nThis is all before you have actually written any business logic in your app. On this site on a warm FastBoot instance (10+ requests for the given URL) fetching `index.html` averages out to above **500ms**:\n\n![](http://i.imgur.com/qcBJGBK.png)\n\nSo, not great. Especially considering that we are not doing that much. We make very few network requests and don't have too many complex components to render.\n\nThe TTFB can directly impact the time it takes to render your app, and crawlers like Google take this time into consideration as part of their PageRank score. It's important to try and reduce this as much as possible.\n\n### Some strategies to improve FastBoot performance\n\nThe nice part about getting Ember rendering on the server is that anything you do to improve the performance of the app in the browser will improve the performance of the app on the server. Two birds, one stone. I would start there. Use the <a href=\"https://github.com/emberjs/ember-inspector\">Ember Inspector</a> to help measure your app's performance and identify rendering issues.\n\nNext, you should take a look at your network requests. How performant are they? The SSR app will block on their responses. If your API is not fast it is just having a cascade affect on everything else. We use <a href=\"http://phoenixframework.org/\">Elixir / Phoenix</a> so our average API resonse times are **&#60; 1ms** (I'm not joking).\n\nOnce you've tuned your API to be as fast as possible, there are some decisions to make. A change that fellow DockYarder <a href=\"http://twitter.com/MiguelCamba\">Miguel Camba</a> landed in FastBoot was an extraction from a recent client project. The idea is detailed in <a href=\"https://github.com/emberjs/rfcs/pull/185\">an RFC I opened a while back</a>. The basic idea is if you have a proxy server in front of your FastBoot server and that proxy has access to the data it can mutate the `GET` request into a `POST` request and embed the data in the `body` of the request. There are complexities here for sure, your proxy has to be smart enough to know what resources are necessary to embed based only upon the URL requested. Does it make sense to duplicate this business logic in both the app and the proxy server? Again, it depends. The benefit is getting rid of the outbound request your Ember app would make. This would have been an HTTP request and that carries its own overhead with it. <a href=\"https://dockyard.com/contact/hire-us\">If you are interested in the Post to FastBoot functionality please talk to us, we're happy to help</a>.\n\nThe last recommendation is one that can either be simple to do or <a href=\"https://martinfowler.com/bliki/TwoHardThings.html\">one of the hardest problems in Computer Science to solve</a>. With a Content Delivery Network (CDN) such as Cloudfront or Fastly you can serve your requests from the CDN and have the CDN request for the newer resource from your server. This can significantly cut down on the TTFB time by an order of magnitude. Those 500ms requests would be closer to single digit ms if we were doing this. It is our intention to do so, but we haven't fully done so yet. Why? Because we need to properly model how and when the cache would expire.\n\nDockYard is a content driven site. We don't make a lot of content updates (other than blog) but when we do we want them immediately available. So we would need a way to inform the CDN when a given resouce is stale and it should re-fetch on the next request. This would require us to do so on any deploy of the Ember app. But then build a notifier for our backend Phoenix app for any blog updates or other contet related changes. Our use case is not terribly complex, but just one we haven't yet had the dev cycles to do properly.\n\nIn any event, CDN caching would be my recommendation on how to improve the TTFB performance for FastBoot. But again, what is your context? Maybe you are a big time content generator who only has very short-term cache cyles. So even with the intermittant performance boost of the CDN the amount of traffic you receive could still be trashing the FastBoot server. This brings us back to the original question of if you need FastBoot or not. Tomorrow we'll discuss app design use cases that are likely mis-using FastBoot. Maybe you fall within this category?"},{"title":"How will the rise of AI affect my job as a UI/UX designer?","tags":["design"],"summary":"Could AI in fact consume all jobs? Could it take mine? This post explores what it may look like if AI was to replace a UI/UX designer.","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/aJ3lbmV.jpg","id":"2017/08/08/will-ai-replace-UX-designers","employee":"Tim Walsh","date":"2017-08-08T00:00:00","body":"\n\n![Imgur](https://i.imgur.com/aJ3lbmV.jpg)\n\nThere has been a ton of news recently about artificial intelligence (AI). And a lot of the conversations, at least the ones that garner attention, often focus on the idea that this movement will negatively impact human beings - about how the robots will take over all of our jobs; that humans will become irrelevant, sentenced to a life of serving the machines; that we are ultimately creating the next evolutionary superior being.\n\nI'm a designer. I focus on user experience and interface design. Recently I've been very curious about AI. Could it in fact consume all jobs? Could it take mine? This post explores what it may look like if AI was to replace a UI/UX designer.\n\n**DISCLAIMER** - This is in no way a statement of how much I know about artificial intelligence, how it's built or what the future holds, rather an evaluation of what its potential MAY look like. For the sake of this post, I'm going to refer to my mega-brilliant AI counterpart as HAL (ahem ahem).\n\nAs a consultancy, we work with people who approach us and have a problem. Mostly, I think it can be distilled down into two different types of projects. One is where a company already has a product and they want improvements and additions on existing design. The other would be a company who has an idea and wants us to help create it. In either case, business development will do their thing and create contracts, agreements, etc. Design gets on board during the initial kickoff meeting, after the deal is made and agreements are reached. So, for the sake of this post, that's where I'll start.  \n\n![Imgur](https://i.imgur.com/mc6UWWa.jpg)\n\n## Kickoff Meeting\n\n**What I do**: Before a kickoff meeting, I prepare by reading through any and all existing documents that we've received. I compile questions, create to-do lists, make schedules, prepare exercises; all to assist in moving the discussion along. This will help establish where the problem lies and support coming up with a game plan for the solution, all the while, keeping features in mind.\n\n**What HAL does**: As long as all documentation is available in a digital platform, HAL is able to digest this information instantly. HAL can listen to the conversation, interjecting where necessary. HAL keeps things on schedule and on topic, making sure that the correct conversations (goals, stakeholders, user groups, platform, etc.) happen. HAL can ask questions, pivoting the conversation and moving it in ways that help yield a better product. HAL doesn't need bathroom breaks, but understands that some people might, and allows time for that.\n\n![Imgur](https://i.imgur.com/MNMTTMw.jpg)\n\n## Researching\n\n**What I do**: I'll take all of the information that was gathered during the discovery period and begin researching. I search for similar companies or competitors, look at and experience their products, and research branding to help make decisions on things like color, logo, and typography.\n\n**What HAL does**: HAL scours the digital world, accumulating all related matter that is of most value to the project. This happens instantly.\n\nOne thing I often have to do, is sign up for a service to access the product. Would AI be able to do this - taking action on a confirmation email, etc.? In that case would AI have their own email? (EXISTENTIAL CRISIS CLOSING IN).\n\n![Imgur](https://i.imgur.com/KBYscMT.jpg)\n\n## Identifying Users & Creating Flows\n\n**What I do**: This is a vital part of the experience. I’ll outline user types and user choices as a step by step process. This is often done using flow-maps, or site maps, essentially anything that allows representation of a product experience at a high level.\n\n**What HAL does**: HAL understands the goal of the app and knows the parameters with which to abide in order to achieve that goal. From research & client feedback, HAL creates a list of user types - outlining all conceivable routes for those users while focusing on business goals and desired features.\n\n![Imgur](https://i.imgur.com/64Ys6yb.jpg)\n\n## Sketching & Wireframing\n\n**What I do**: I begin sketching wireframes and layouts based on the features that were defined in the flows. This will generally be informed by previous work that we've completed or trends in popular web or app design. The more complicated or unique experiences require these initial sketches to be pretty low fidelity and will likely be a dialogue between design and client. This is done to: move rapidly, avoid making any concrete decisions too early on, and keeps options flexible.\n\n**What HAL does**: Knowing the overall purpose of the product, HAL can generate wireframes and layouts keeping the product goal in mind at all times. HAL can utilize client responses, making decisions off of their positive and negative feedback. Just imagine: instant turnaround. \n\n(Side note - Does time between phases make something feel more substantial - does a longer wait imply better work?) \n\n![Imgur](https://i.imgur.com/x7Jk7MK.jpg)\n\n## Styling\n\n**What I do**: Once wireframes have been approved, the structure of the app is pretty much in place. Decisions around styling come from a culmination of previous discussions around branding preferences, research, competitors, and trends.\n\n**What HAL does**: HAL references every digital product ever created, identifying trends that are popular in particular industries. HAL then presents options, highlighting decisions made (I chose this color because it corresponds to this percent of the industry, other similar products identify user groups who respond to this layout, etc.).\n\n![Imgur](https://i.imgur.com/cAzBRj4.jpg)\n\n## Testing\n\n**What I do**: User testing can begin once the product has been styled. This is a vital part of the experience because it gives me the opportunity to test whether my decisions work for users and that the product functions efficiently and as expected.\n\n**What HAL does**: HAL identifies issues that users are running into and self corrects accordingly. For more complicated experiences, HAL presents several designs, monitoring users across the board, ultimately selecting the one that performs the best, propagating it to all users. HAL operates, at this point, without the feedback of the client. HAL understands what success and failure means, and makes decisions accordingly.\n\n## Final Thoughts\n\nAfter writing this, the biggest areas where I imagine that AI could improve human capability is time it takes to create something, the sheer access and understanding of information, and the ability to parse through mass amounts of data, finding trends to make decisions.\n\nNow, obviously what I've outlined above is far from where we stand with our current computing technology - and even then, it is likely not realistic nor will it shape out exactly as I've described. I simply wanted to envision for myself what it might look like if a computer was to replace my current role. I guess the takeaway would be that it's not that difficult to imagine. \n\nIn addition, I'd like to leave you with my version of 'the darkest timeline.' AI identifies problem, creates solution. Humans remain blissfully unaware.\n"},{"title":"Why higher education needs to adopt Progressive Web Apps","tags":["pwa","business"],"summary":"Even more than ecommerce and publishing, higher education marketing could benefit tremendously from adopting Progressive Web Application (PWA) implementation.","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/yeiuw3h.jpg","id":"2017/08/10/why-higher-ed-needs-progressive-web-apps","employee":"Jess Krywosa","date":"2017-08-10T00:00:00","body":"\n\n![Imgur](https://i.imgur.com/yeiuw3h.jpg)\n\nThere may be nothing scarier than working in a vertical with a shrinking market, high price tag, scrutinized value, and massive competition. Higher education in the US is a sector that has seen all of these challenges over the past five years, the hardest of which could be yet to come with the [shortage of traditionally aged students and the recent changes to immigration policies](https://www.nytimes.com/2017/06/07/education/higher-education-seeks-answers-to-leaner-years.html). \n\nWhen up against such odds, any business needs to ensure that they are fiercely competitive while taking advantage of every opportunity to connect with potential buyers. As an industry that caters primarily to the most tech savvy—and likely impatient—consumers, mobile optimization and adoption in the marketing of higher education is crucial. \n\nIf you’re like many in the higher ed sector (as I previously was), you’d be happy if your site was mobile friendly, let alone responsive. But being responsive is yesterday’s ‘nice to have.’ As we continue to see more and more of consumers’ buying cycle happen via their phones, technologies like [Progressive Web Apps](https://dockyard.com/blog/2017/05/03/five-business-problems-pwas-solve) (PWA) that provide device specific functionality through one destination are now the new responsive. \n\n## Getting found\nYou can’t nurture a prospective student if they cannot find you. PWAs help in that they are lighter and faster, something that helps in boosting your search ranking, and that most higher ed sites lack. Because they are mobile focused, PWAs are also mobile search friendly. Unlike a native application, they are discoverable, linkable, and shareable. \n\n## Removing barriers\nOnce found, prospective students and their families can be prompted to add your site to their homescreen, perhaps after a certain number of visits or other predetermined triggers. They can also take advantage of other native functionality such as click to call, autocomplete, and offline mode. The latter is extremely helpful in completing forms or reading more about your offerings in areas with less than reliable cell service. (Offline mode can also be particularly handy if presenting in low or no connectivity areas like college fairs or admission events.)\n\n## Staying in touch\nProgressive Web Apps take advantage of app-like functionality including push notifications. Implementing push notifications means minimal email campaigns and no need to collect cell numbers or pay for an SMS vendor. You’ll be able to centralize (and measure) communications and the school application and buying cycle much more easily.\n\n## Providing the right content\nMaybe the most powerful for higher education would be geo-focused content based on the device location. Invite prospective students to admission events and target key recruitment locations with special information. And, because it's not a native app, content will always be fresh: no need to hope users have kept their app updated. \n\n## Cutting costs\nOne PWA takes the place of your desktop site, mobile site, iOS app, and Android app. This means promoting one site and no longer needing app re-engagement campaigns. You’ll also no longer need to maintain separate apps, vendors, or a large in-house technical staff. Money you can probably find a much better use for. \n\nIf at a crossroads on where to take your web and mobile presence, adopting a Progressive Web Application could allow any future focused organization a way to leapfrog over lacking a responsive design and/or a mobile app while also cutting costs in the long run. Wondering how this may be possible for your organization? [Let’s talk](https://dockyard.com/contact/hire-us). \n"},{"title":"5 Elixir tricks you should know","tags":["elixir","engineering"],"summary":"Elixir tricks","legacy":false,"id":"2017/08/15/elixir-tips","employee":"Daniel Xu","date":"2017-08-15T00:00:00","body":"\n\n## alias `__MODULE__`\nThis one looks mysterious at first, but once we break it down, it's very straightforward.\n\n`alias` allows you to define aliases for the module name, for example:\n\n`alias Foo.Bar` will set up an alias for module `Foo.Bar`, and you can reference that module with just `Bar`.\n\n`__MODULE__` is a compilation environment macros which is the current module name as an atom.\n\nNow you know `alias __MODULE__` just defines an alias for our Elixir module. This is very useful when used with `defstruct` which we will talk about next.\n\nIn the following example, we pass `API.User` struct around to run some checks on our data. Instead of writing the full module name, we set up an alias `User` for it and pass that around. It's pretty concise and easy to read.\n\n```elixir\ndefmodule API.User do\n  alias __MODULE__\n\n  defstruct name: nil, age: 0\n\n  def old?(%User{name: name, age: age} = user) do\n    ...\n  end\nend\n```\n\nIn case of module name changing, you can also do this:\n\n```\nalias __MODULE__, as: SomeOtherName\n```\n\n## defstruct with @enforce_keys\n\nWhenever you want to model your data with `maps`, you should also consider `struct` because `struct` is a `tagged map` which offers compile time checks on the key and allows us to do run-time checks on the struct's type, for example:\n\nyou can't create a struct with field that is not defined. In the following example you can also see how we apply the first trick we just learned.\n\n```elixir\ndefmodule Fun.Game do\n  alias __MODULE__\n  defstruct(\n    time: nil,\n    status: :init\n  )\n\n  def new() do\n    %Game{step: 1}\n  end\nend\n\niex> IO.inspect Fun.Game.new()\niex> ** (KeyError) key :step not found in: %{__struct__: Fun.Game, status: :init, time: nil}\n```\n\nHowever, sometimes you want to ensure that some fields are present whenever you create a new struct. Fortunately, Elixir provides  `@enforce_keys` module attribute for that:\n\n```elixir\ndefmodule Fun.Game do\n  @enforce_keys [:status]\n\n  alias __MODULE__\n  defstruct(\n    time: nil,\n    status: :init\n  )\n\n  def new() do\n    %Game{}\n  end\nend\n\niex> Fun.Game.new()\niex> ** (ArgumentError) the following keys must also be given when building struct Fun.Game: [:status]\n```\n\nBased on the result, you can see that in this case we can't rely on the default value of `status`, we need to specify its value when we create a new Game:\n\n```elixir\ndef new(status) do\n  %Game{status: status}\nend\n\niex> Fun.Game.new(:won)\niex> %Fun.Game{status: :won, time: nil}\n```\n\n## `v()` function in `iex`\n\nWhenever I write a `GenServer` module, I usually want to start the server and check the result in `iex`.\nOne thing that really bothers me is that I almost always forget to pattern match the process pid, like this:\n\n```elixir\niex(1)> Metex.Worker.start_link()\n{:ok, #PID<0.472.0>}\n```\n\nthen, I need to type that command again with pattern matching:\n\n```\n{:ok, pid} = Metex.Worker.start_link()\n```\n\nBeing tired of doing this over and over again, I found that you can use `v()` to return the result from last command:\n\n```elixir\niex(1)> Metex.Worker.start_link()\n{:ok, #PID<0.472.0>}\niex(2)> {:ok, pid} = v()\n{:ok, #PID<0.472.0>}\niex(3)>  pid\n#PID<0.472.0>\n```\n\nThis trick saves me couple of seconds every time I use it, I hope that you will find it helpful too.\n\n## cancel bad command in `iex`\n\nHave you ever had this kind of moment when you use `iex`:\n\n```elixir\niex(1)> a = 1 + 1'\n...(2)>\n...(2)>\n...(2)>\nBREAK: (a)bort (c)ontinue (p)roc info (i)nfo (l)oaded\n       (v)ersion (k)ill (D)b-tables (d)istribution\n```\n\nNormally, I will `ctrl + c` twice to exit `iex` and create a new one. However, sometimes you've already typed in a bunch of commands, and you definitely want to keep the session. Here is what you can do: `#iex:break`\n\n```\niex(2)> a = 1 + 1\niex(2)> b = 1 + 1'\n...(2)>\n...(2)> #iex:break\n** (TokenMissingError) iex:1: incomplete expression\n\niex(2)> a\n2\n```\n\nFrom the code block above, you can see that we still have the session after canceling a bad command.\n\n## bind value to an optional variable\n\nI'm sure most of people know that you can bind a value to an optional variable like this:\n\n```elixir\n_dont_care = 1\n```\n\nThe reason why I bring this up is because we can actually apply this trick to our functions to make them more readable:\n\n```elixir\ndefp accept_move(game, _guess, _already_used = true) do\n  Map.put(game, :state, :already_used)\nend\ndefp accept_move(game, guess, _not_used) do\n  Map.put(game, :used, MapSet.put(game.used, guess))\n  |> score_guess(Enum.member?(game.letters, guess))\nend\n```\n\nThanks for reading this post and always share your Elixir tricks with the community.\n"},{"title":"Progressive Web Applications got love for the desktop, too","tags":["pwa","business","ux"],"summary":"Could a Progressive Web App strategy reinvent how we use desktop software?","legacy":false,"illustration_alt":"Imgur","illustration":"https://i.imgur.com/VSaFGGU.png","id":"2017/08/17/progressive-web-apps-for-the-desktop","employee":"Matt Ludwig","date":"2017-08-17T00:00:00","body":"\n\n![Imgur](https://i.imgur.com/VSaFGGU.png)\n\nEverything we do and create on our computers seem to benefit from the web. Actually, check that, everything except the majority of desktop applications. Go ahead, peruse your Applications/Programs directory on your computer and think about which ones have a web browser built-in, I’ll wait. And, aside from messaging or email applications, which ones actually authenticate you/themselves in any secure way? Or ever? \n\nThis is not to suggest that all desktop apps on a computer should be forced to run in the browser, far from it. But the manner in which desktop apps are deployed and installed, the redundancy of version after version needing updates across countless machines requiring more and more hard drive space, and their lack of leveraging any sort of machine learning or web capabilities for an improved UX, leaves us asking the question: why not change the paradigm in which desktop apps are built? \n\n## Desktops are ignorant; long live the desktop.\nDesktop apps as we know them today for the common/average user are insecure, unintelligent, and lack future-focused UX. The majority of current desktop apps lack the ability to communicate with you directly (ex: push notifications), don’t really learn from your usage and adapt the UI to better suit your needs, or in any way leverage the power of machine learning on its cloud storage. Why not? \n\nThe bar for how all software (desktop or web) behaves has to account for these new expectations equally. Desktop apps should have an inherent data security model, app-level notifications, and leverage the power of the Web in some way. Web app companies, Web Browsers, and _certainly_ Users have all come to expect these traits. So why haven’t desktop apps seen some love here, too? \n\n## Progressive Web Apps - now in desktop flavors! \nWhile primarily gaining attention as the future of mobile app solutions, a Progressive Web Application (PWA) should be considered just as much for the desktop experience. I love the idea of simply “saving” a URL to my laptop, clicking on it, and having it launch like any other desktop app I installed via CD once upon a time. Moreover, with Chromebooks rising with the secular tailwinds for common retail and business uses as the laptop d’jour, this reality is getting closer with every passing quarter. \n\n## Customers should expect a desktop app to notify them directly, not their inbox.\nWhy can’t my desktop apps be more communicative? For example, why can’t these applications themselves provide me with a notification when something needs my attention? Our mobile apps do it; our messaging services do it; our teammates, partners, heck- even our spouses walk up to us and do it! So why can’t our desktop apps? When someone I’m collaborating with has completed their portion of the work; when the app itself wants to inform or show me about a feature it can do that may help me (because it has learned on its own about the contents of the work) - why can’t my desktop app do that? Why does our inbox need to be the go-between in that communication? Google Docs on my Android device can tell me itself, so can my father’s iPhone when new pictures/videos of his grandchild have synced…. There is no inbox interaction required in either scenario, [and both have exceptionally high levels of re-engagement and User satisfaction](https://www.thinkwithgoogle.com/marketing-resources/experience-design/progressive-web-apps-benefit-brands/). \n\n## When was the last time you considered your data’s security when opening Excel?\nIt seems that collectively, we care more about making sure that little green lock icon is in the URL bar when we buy shoes than we do about any of the access or data integrity of the financial and planning data in our business-critical spreadsheet software that we use daily. If we’re truly being honest with ourselves, we should acknowledge that there should be more to a desktop app’s intrinsic security than your office WiFi password. \n\nWhat about the local storage security of your company-issued laptop?- not sure. Do you have any revision history on that file being passed around for the presentation to the bank for the Small Business Loan?- no clue. And what’s the plan if your GM leaves her laptop on an airplane, and she’s the only one with the file of your entire donor list that includes personal/banking/postal/web information on it?- don’t know. \n\nThese scenarios are far from uncommon, and with a clearly stated strategy to avoid them, building them as a PWA could have massive benefits. With a PWA, all data created/opened with it could be secured (encryption, secure certificate, etc.), revision history could be accessible as a standard feature, and it could remotely freeze access to the account using the app until validated.\n\n## How does a PWA change the way users get my app?\nSaving a PWA from the browser to your desktop is quick, lightweight, and responsive to any device. It can be pushed to the customer in the form of a native/browser message, or simply as a hyperlink within the web page itself. In doing this, a nominal amount of files, instructions, and assets would, in turn, be downloaded to the computer. However, no multi-gigabyte download would be necessary and no install wizard/package handler would be required or even appropriate. Hard disk spaces on lower cost machines wouldn’t need to be huge, and in the end, the entire experience from discovery to launch should be seconds, not minutes or hours. Yes, the application would be powered by the browser at its core, but none of this would be felt (or even noticed), as the application would be projected full screen with whatever ‘chrome’ the application supplied. It would be much like when Photoshop runs in its core C++; Users don’t know that’s going on or even care- they just use it. \n\nSo, having some core requirements of your next version of desktop software UX to include push notifications, the power of server side learning, and a data security model seems pretty reasonable. Seeing a PWA strategy as a clear option for how your organization handles its much needed desktop app responsive design and/or a legacy update could also be the key to bringing back the desktop experience love your customers expect, too. Wondering how this may be possible for your organization? [Let’s talk](https://dockyard.com/contact/hire-us).\n"},{"title":"Building An Image Upload API With Phoenix","tags":["engineering","elixir","phoenix"],"summary":"Learn how to create an image upload API with Elixir and Phoenix.","legacy":false,"illustration_alt":"File Upload with Phoenix Logo in the background","illustration":"https://i.imgur.com/xKrSHaM.png","id":"2017/08/22/building-an-image-upload-api-with-phoenix","employee":"Alex Garibay","date":"2017-08-22T00:00:00","body":"\n\n![File Upload with Phoenix Logo in the background](https://i.imgur.com/xKrSHaM.png)\n\nFor many API applications, there comes a time when the application needs to save images uploaded to the server either locally or on a CDN. Luckily for us, Elixir and Phoenix provide the tools we need to build a simple image upload API.\n\n## The Simple API\n\nLet's define exactly how this API is supposed to work:\n\n* accept a request containing a base64 encoded image as a field\n* preserve the image extension by reading the image binary\n* upload the image to Amazon's S3\n* provide the URL to the image on S3 in the response\n\n## Update Your Dependencies\n\nTo assist us with uploading images to S3, we will use [ExAws](https://github.com/CargoSense/ex_aws) to interact with the AWS API, [sweet_xml](https://github.com/kbrw/sweet_xml) for XML parsing, and [UUID]() to help generate random IDs. Update your `mix.exs` file to include both libraries as dependencies.\n\n```elixir\ndef deps do\n  [\n    ...,\n    {:ex_aws, \"~> 1.1\"},\n    {:sweet_xml, \"~> 0.6.5\"},\n    {:uuid, \"~> 1.1\"}\n  ]\nend\n```\n\nAlso, make sure to update your application list if you're using Elixir 1.3 or lower.\n\n```elixir\ndef application do\n  [\n    applications: [\n      ...,\n      :ex_aws,\n      :hackney,\n      :poison,\n      :sweet_xml,\n      :UUID\n    ]\n  ]\nend\n```\n\nLastly, include your AWS credentials in your `config.exs`.\n\n```elixir\nconfig :ex_aws,\n  access_key_id: [\"ACCESS_KEY_ID\", :instance_role],\n  secret_access_key: [\"SECRET_ACCESS_KEY\", :instance_role]\n```\n\n## The AssetStore \"Context\"\n\nBefore we create the controller, let's define the application logic in a separate module that is specific for handling uploaded assets. For our application, we are only going to support JPEG and PNG files. With a name like `AssetStore`, we can add additional file types in the future but use the same context.\n\n```elixir\ndefmodule MyApp.AssetStore do\n  @moduledoc \"\"\"\n  Responsible for accepting files and uploading them to an asset store.\n  \"\"\"\n  \n  import SweetXml\n  alias ExAws.S3\n  \n  @doc \"\"\"\n  Accepts a base64 encoded image and uploads it to S3.\n\n  ## Examples\n  \n      iex> upload_image(...)\n      \"https://image_bucket.s3.amazonaws.com/dbaaee81609747ba82bea2453cc33b83.png\"\n      \n  \"\"\"\n  @spec upload_image(String.t) :: s3_url :: String.t\n  def upload_image(image_base64) do\n    # Decode the image\n    {:ok, image_binary} = Base.decode64(image_base64)\n\n    # Generate a unique filename\n    filename =\n      image_binary\n      |> image_extension()\n      |> unique_filename()\n\t\t  \n    # Upload to S3\n    {:ok, response} = \n      S3.put_object(\"image_bucket\", filename, image_binary)\n      |> ExAws.request()\n    \n    # Return the URL to the file on S3\n    response.body\n    |> SweetXml.xpath(~x\"//Location/text()\")\n    |> to_string()\n  end\n  \n  # Generates a unique filename with a given extension\n  defp unique_filename(extension) do\n    UUID.uuid4(:hex) <> extension\n  end\n  \n  # Helper functions to read the binary to determine the image extension\n  defp image_extension(<<0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A, _::binary>>), do: \".png\"\n  defp image_extension(<<0xff, 0xD8, _::binary>>), do: \".jpg\"\nend\n```\n\n## Designing the Controller\n\nCreate a new controller responsible for images. We simply need to call our module that we previously made.\n\n```elixir\ndefmodule MyApp.ImageController do\n  use MyApp.Web, :controller\n  \n  def create(conn, %{\"image\" => image_base64}) do\n    s3_url = MyApp.AssetStore.upload(image_base64)\n    \n    conn\n    |> put_status(201)\n    |> json(%{\"url\" => s3_url})\n  end\nend\n```\n\nNow let's go update our router to include the new route in our API.\n\n```elixir\nscope \"/api\", MyApp do\n  ...\n  \n  # Our new images route\n  resources \"/images\", ImageController, only: [:create]\nend\n```\n\nOur application is now ready to accept images!\n\n## Try It Out\n\nWe can easily try out our new API by hitting up our terminal for a quick run-through with cURL. We can try uploading a 1x1 transparent PNG file.\n\n```\ncurl -X \"POST\" \"http://localhost:4000/api/images\" \\\n     -H \"Content-Type: application/json\" \\\n     -d $'{\n  \"image\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\"\n}'\n\n{\"url\": \"https://image_bucket.s3.amazonaws.com/dbaaee81609747ba82bea2453cc33b83.png\"}\n```\n\n\n## Wrap Up\n\nAs we can see, Elixir and Phoenix provide the tools to add an API to accept base64 encoded image uploads with very little code. Be sure to read the docs of the dependencies we leveraged.\n"}]}